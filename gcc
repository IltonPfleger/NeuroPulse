Layer.c:7:34: missed: statement clobbers memory: _3 = aligned_alloc (64, _2);
Layer.c:8:35: missed: statement clobbers memory: _6 = aligned_alloc (64, _5);
Layer.c:9:34: missed: statement clobbers memory: _7 = aligned_alloc (64, _5);
Layer.c:14:19: missed: statement clobbers memory: _8 = PULSE_GetActivationFunctionPtr (activation_function_18(D));
Layer.c:19:9: note: ***** Analysis succeeded with vector mode V8SI
Layer.c:19:9: note: SLPing BB part
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x35d77c8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 0 MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 1 MEM <unsigned int> [(struct PULSE_Layer *)&<retval> + 4B] = optimization_type_17(D);
Layer.c:19:9: note: 	children 0x35d7848
Layer.c:19:9: note: node (external) 0x35d7848 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ type_16(D), optimization_type_17(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x35d78c8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 0 <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 1 <retval>.n_outputs = n_outputs_12(D);
Layer.c:19:9: note: 	children 0x35d7948
Layer.c:19:9: note: node (external) 0x35d7948 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x35d7a48 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 0 <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 1 <retval>.outputs = _6;
Layer.c:19:9: note: 	children 0x35d7ac8
Layer.c:19:9: note: node (external) 0x35d7ac8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	stmt 0 _3 = aligned_alloc (64, _2);
Layer.c:19:9: note: 	stmt 1 _6 = aligned_alloc (64, _5);
Layer.c:19:9: note: 	children 0x35d7b48 0x35d7bc8
Layer.c:19:9: note: node (constant) 0x35d7b48 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 64, 64 }
Layer.c:19:9: note: node 0x35d7bc8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: patt_40 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 0 patt_40 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 1 patt_41 = n_outputs_12(D) w* 4;
Layer.c:19:9: note: 	children 0x35d7c48 0x35d7cc8
Layer.c:19:9: note: node (external) 0x35d7c48 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: node (constant) 0x35d7cc8 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ 4, 4 }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x35d7dc8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: op template: <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 0 <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 1 <retval>.back = back_21(D);
Layer.c:19:9: note: 	stmt 2 <retval>.fix = fix_22(D);
Layer.c:19:9: note: 	stmt 3 <retval>.destroy = destroy_23(D);
Layer.c:19:9: note: 	children 0x35d7e48
Layer.c:19:9: note: node (external) 0x35d7e48 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: 	{ feed_20(D), back_21(D), fix_22(D), destroy_23(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 64
  Scalar cost: 64
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x35d7f48 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 0 <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 1 <retval>.child = 0B;
Layer.c:19:9: note: 	children 0x35d7fc8
Layer.c:19:9: note: node (constant) 0x35d7fc8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ 0B, 0B }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Basic block will be vectorized using SLP
Layer.c:19:9: optimized: basic block part vectorized using 8 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x35d77c8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 0 MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 1 MEM <unsigned int> [(struct PULSE_Layer *)&<retval> + 4B] = optimization_type_17(D);
Layer.c:19:9: note: 	children 0x35d7848
Layer.c:19:9: note: node (external) 0x35d7848 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ type_16(D), optimization_type_17(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: vect_is_simple_use: operand optimization_type_17(D), type of def: external
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>]
Layer.c:19:9: note: created &MEM <unsigned int> [(struct PULSE_Layer *)&<retval>]
Layer.c:19:9: note: add new stmt: MEM <vector(2) unsigned int> [(struct PULSE_Layer *)&<retval>] = _42;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 8 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x35d78c8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 0 <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 1 <retval>.n_outputs = n_outputs_12(D);
Layer.c:19:9: note: 	children 0x35d7948
Layer.c:19:9: note: node (external) 0x35d7948 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: vect_is_simple_use: operand n_outputs_12(D), type of def: external
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: <retval>.n_inputs
Layer.c:19:9: note: created &<retval>.n_inputs
Layer.c:19:9: note: add new stmt: MEM <vector(2) unsigned int> [(unsigned int *)&<retval> + 96B] = _44;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 16 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x35d7a48 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 0 <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 1 <retval>.outputs = _6;
Layer.c:19:9: note: 	children 0x35d7ac8
Layer.c:19:9: note: node (external) 0x35d7ac8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	stmt 0 _3 = aligned_alloc (64, _2);
Layer.c:19:9: note: 	stmt 1 _6 = aligned_alloc (64, _5);
Layer.c:19:9: note: 	children 0x35d7b48 0x35d7bc8
Layer.c:19:9: note: node (constant) 0x35d7b48 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 64, 64 }
Layer.c:19:9: note: node 0x35d7bc8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: patt_40 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 0 patt_40 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 1 patt_41 = n_outputs_12(D) w* 4;
Layer.c:19:9: note: 	children 0x35d7c48 0x35d7cc8
Layer.c:19:9: note: node (external) 0x35d7c48 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: node (constant) 0x35d7cc8 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ 4, 4 }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.inputs = _3;
Layer.c:19:9: note: vect_is_simple_use: operand aligned_alloc (64, _5), type of def: internal
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.inputs
Layer.c:19:9: note: created &<retval>.inputs
Layer.c:19:9: note: add new stmt: MEM <vector(2) long unsigned int> [(float * *)&<retval> + 8B] = _48;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 32 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x35d7dc8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: op template: <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 0 <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 1 <retval>.back = back_21(D);
Layer.c:19:9: note: 	stmt 2 <retval>.fix = fix_22(D);
Layer.c:19:9: note: 	stmt 3 <retval>.destroy = destroy_23(D);
Layer.c:19:9: note: 	children 0x35d7e48
Layer.c:19:9: note: node (external) 0x35d7e48 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: 	{ feed_20(D), back_21(D), fix_22(D), destroy_23(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.feed = feed_20(D);
Layer.c:19:9: note: vect_is_simple_use: operand back_21(D), type of def: external
Layer.c:19:9: note: vect_is_simple_use: operand fix_22(D), type of def: external
Layer.c:19:9: note: vect_is_simple_use: operand destroy_23(D), type of def: external
Layer.c:19:9: note: conflicting alias set types.
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(4) long unsigned int  vectorizing a pointer ref: <retval>.feed
Layer.c:19:9: note: created &<retval>.feed
Layer.c:19:9: note: add new stmt: MEM <vector(4) long unsigned int> [(void *)&<retval> + 32B] = _54;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 16 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x35d7f48 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 0 <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 1 <retval>.child = 0B;
Layer.c:19:9: note: 	children 0x35d7fc8
Layer.c:19:9: note: node (constant) 0x35d7fc8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ 0B, 0B }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.parent = 0B;
Layer.c:19:9: note: vect_is_simple_use: operand 0B, type of def: constant
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.parent
Layer.c:19:9: note: created &<retval>.parent
Layer.c:19:9: note: add new stmt: MEM <vector(2) long unsigned int> [(struct PULSE_Layer * *)&<retval> + 72B] = { 0, 0 };
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: note: ***** The result for vector mode V32QI would be the same
Layer.c:24:2: missed: statement clobbers memory: free (_1);
Layer.c:25:2: missed: statement clobbers memory: free (_2);
Layer.c:26:2: missed: statement clobbers memory: free (_3);
Layer.c:27:1: note: ***** Analysis failed with vector mode V4DI
Layer.c:27:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:9:27: missed: couldn't vectorize loop
Dense.c:9:27: missed: not vectorized: unsupported outerloop form.
Dense.c:12:20: missed: couldn't vectorize loop
Dense.c:13:21: missed: not vectorized: complicated access pattern.
Dense.c:6:13: note: vectorized 0 loops in function.
Dense.c:16:2: missed: statement clobbers memory: _30 (pretmp_91, _50, 0);
Dense.c:9:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:9:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:24:27: missed: couldn't vectorize loop
Dense.c:24:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:28:20: optimized: loop vectorized using 32 byte vectors
Dense.c:28:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:28:20: optimized: loop vectorized using 16 byte vectors
Dense.c:28:20: missed: couldn't vectorize loop
Dense.c:30:20: missed: not vectorized: no vectype for stmt: _21 = *_20;
 scalar_type: float
Dense.c:20:13: note: vectorized 1 loops in function.
Dense.c:23:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:24:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:24:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:41:28: missed: couldn't vectorize loop
Dense.c:41:28: missed: not vectorized: unsupported outerloop form.
Dense.c:45:21: optimized: loop vectorized using 32 byte vectors
Dense.c:45:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:45:21: optimized: loop vectorized using 16 byte vectors
Dense.c:37:13: note: vectorized 1 loops in function.
Dense.c:37:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:37:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:41:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:145:19: missed: couldn't vectorize loop
Dense.c:145:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:136:19: missed: couldn't vectorize loop
Dense.c:136:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:129:13: note: vectorized 0 loops in function.
Dense.c:153:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:153:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:98:28: missed: couldn't vectorize loop
Dense.c:98:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:101:21: missed: couldn't vectorize loop
Dense.c:101:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:115:28: missed: couldn't vectorize loop
Dense.c:115:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:118:21: missed: couldn't vectorize loop
Dense.c:118:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:84:19: missed: couldn't vectorize loop
Dense.c:84:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:78:13: note: vectorized 0 loops in function.
Dense.c:81:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:103:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:103:17: note: SLPing BB part
Dense.c:120:17: note: Costing subgraph: 
Dense.c:120:17: note: node 0x8010d88 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:120:17: note: op template: _49 = (sizetype) j_137;
Dense.c:120:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:120:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:120:17: note: 	children 0x8010e88
Dense.c:120:17: note: node (external) 0x8010e88 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:120:17: note: 	{ j_137, wi_136 }
Dense.c:120:17: note: Cost model analysis: 
Dense.c:120:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:120:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:120:17: missed: not vectorized: vectorization is not profitable.
Dense.c:103:17: note: Costing subgraph: 
Dense.c:103:17: note: node 0x8010f88 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:103:17: note: op template: _24 = (sizetype) j_134;
Dense.c:103:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:103:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:103:17: note: 	children 0x8011088
Dense.c:103:17: note: node (external) 0x8011088 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:103:17: note: 	{ j_134, wi_133 }
Dense.c:103:17: note: Cost model analysis: 
Dense.c:103:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:103:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:103:17: missed: not vectorized: vectorization is not profitable.
Dense.c:103:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:103:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:103:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:103:17: note: SLPing BB part
Dense.c:120:17: note: Costing subgraph: 
Dense.c:120:17: note: node 0x8010f88 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:120:17: note: op template: _49 = (sizetype) j_137;
Dense.c:120:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:120:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:120:17: note: 	children 0x8010d88
Dense.c:120:17: note: node (external) 0x8010d88 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:120:17: note: 	{ j_137, wi_136 }
Dense.c:120:17: note: Cost model analysis: 
Dense.c:120:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:120:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:120:17: missed: not vectorized: vectorization is not profitable.
Dense.c:103:17: note: Costing subgraph: 
Dense.c:103:17: note: node 0x8011108 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:103:17: note: op template: _24 = (sizetype) j_134;
Dense.c:103:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:103:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:103:17: note: 	children 0x8011008
Dense.c:103:17: note: node (external) 0x8011008 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:103:17: note: 	{ j_134, wi_133 }
Dense.c:103:17: note: Cost model analysis: 
Dense.c:103:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:103:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:103:17: missed: not vectorized: vectorization is not profitable.
Dense.c:103:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:98:55: note: ***** Analysis failed with vector mode V8QI
Dense.c:98:55: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:98:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:58:27: missed: couldn't vectorize loop
Dense.c:58:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:61:20: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:905:10: missed: not vectorized: no vectype for stmt: _41 = MEM[(__m256_u * {ref-all})_6];
 scalar_type: __m256_u
Dense.c:61:20: note: ***** Analysis failed with vector mode VOID
Dense.c:54:13: note: vectorized 0 loops in function.
Dense.c:54:13: missed: splitting region at dont-vectorize loop 3 entry at bb18
Dense.c:63:14: note: ***** Analysis failed with vector mode V4DI
Dense.c:63:14: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:63:14: missed: splitting region at dominance boundary bb8
Dense.c:63:14: note: ***** Analysis failed with vector mode VOID
Dense.c:63:14: missed: splitting region at loop 1 exit at bb16
Dense.c:58:27: note: ***** Analysis failed with vector mode V8SF
Dense.c:58:27: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Dense.c:58:27: missed: splitting region at dominance boundary bb10
Dense.c:58:27: note: ***** Analysis failed with vector mode VOID
Dense.c:74:2: missed: statement clobbers memory: _27 (pretmp_153, _61, 0);
Dense.c:75:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:75:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:160:2: missed: statement clobbers memory: free (_1);
Dense.c:161:2: missed: statement clobbers memory: free (_2);
Dense.c:162:2: missed: statement clobbers memory: free (_3);
Dense.c:163:2: missed: statement clobbers memory: free (_4);
Dense.c:164:2: missed: statement clobbers memory: free (dense_7);
Dense.c:165:2: missed: statement clobbers memory: PULSE_DestroyLayer (this_6(D));
Dense.c:166:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:166:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:180:19: missed: couldn't vectorize loop
Dense.c:180:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:170:13: note: vectorized 0 loops in function.
Dense.c:172:47: missed: statement clobbers memory: dense_35 = malloc (40);
Dense.c:174:36: missed: statement clobbers memory: _5 = aligned_alloc (64, _4);
Dense.c:175:38: missed: statement clobbers memory: _6 = aligned_alloc (64, _4);
Dense.c:176:36: missed: statement clobbers memory: _8 = aligned_alloc (64, _7);
Dense.c:177:35: missed: statement clobbers memory: _9 = aligned_alloc (64, _7);
Dense.c:178:36: missed: statement clobbers memory: _10 = aligned_alloc (64, _7);
Dense.c:181:39: missed: statement clobbers memory: _11 = rand ();
Dense.c:181:73: missed: statement clobbers memory: _63 = sqrt (_18);
Dense.c:198:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:199:4: missed: statement clobbers memory: exit (1);
Dense.c:191:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.3_29, n_outputs.2_28, 1, activation_function_51(D), _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:187:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.1_27, n_outputs.0_26, 1, activation_function_51(D), _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:205:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Dense.c:205:9: note: ***** Analysis failed with vector mode V4DI
Dense.c:205:9: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Activations.c:17:19: optimized: loop vectorized using 32 byte vectors
Activations.c:17:19: optimized: loop vectorized using 16 byte vectors
Activations.c:17:19: optimized: loop vectorized using 32 byte vectors
Activations.c:17:19: optimized: loop vectorized using 16 byte vectors
Activations.c:14:13: note: vectorized 2 loops in function.
Activations.c:14:13: note: ***** Analysis failed with vector mode V8SF
Activations.c:14:13: note: ***** The result for vector mode V32QI would be the same
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V16QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V16QI
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V8QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V8QI
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V4QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V4QI
Activations.c:28:19: missed: couldn't vectorize loop
Activations.c:28:19: missed: not vectorized: unsupported control flow in loop.
Activations.c:28:19: optimized: loop vectorized using 32 byte vectors
Activations.c:28:19: optimized: loop vectorized using 16 byte vectors
Activations.c:25:13: note: vectorized 1 loops in function.
Activations.c:25:13: note: ***** Analysis failed with vector mode V8SF
Activations.c:25:13: note: ***** The result for vector mode V32QI would be the same
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V16QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V16QI
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V8QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V8QI
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V4QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V4QI
Activations.c:38:1: note: ***** Analysis failed with vector mode VOID
Activations.c:5:19: missed: couldn't vectorize loop
Activations.c:9:21: missed: statement clobbers memory: _36 = expf (_18);
Activations.c:5:19: missed: couldn't vectorize loop
Activations.c:9:21: missed: statement clobbers memory: _12 = expf (_11);
Activations.c:3:13: note: vectorized 0 loops in function.
Activations.c:9:21: missed: statement clobbers memory: _12 = expf (_11);
Activations.c:9:21: missed: statement clobbers memory: _36 = expf (_18);
Activations.c:11:1: note: ***** Analysis failed with vector mode V8SF
Activations.c:11:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Activations.c:44:2: note: ***** Analysis failed with vector mode VOID
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:4:18: note: vectorized 0 loops in function.
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_4, inputs_15, _3);
PULSE.c:8:2: missed: statement clobbers memory: _5 (layer_17);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_12, pretmp_26, _9);
PULSE.c:13:28: note: ***** Analysis failed with vector mode V8SI
PULSE.c:13:28: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:22:2: missed: statement clobbers memory: _1 (layer_10(D));
PULSE.c:22:2: missed: statement clobbers memory: _14 (_2);
PULSE.c:22:2: missed: statement clobbers memory: _21 (_15);
PULSE.c:22:2: missed: statement clobbers memory: _28 (_22);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_29);
PULSE.c:26:3: missed: statement clobbers memory: memset (_34, 0, _32);
PULSE.c:26:3: missed: statement clobbers memory: memset (_27, 0, _25);
PULSE.c:26:3: missed: statement clobbers memory: memset (_20, 0, _18);
PULSE.c:26:3: missed: statement clobbers memory: memset (_7, 0, _5);
PULSE.c:28:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:28:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:32:6: note: vectorized 1 loops in function.
PULSE.c:34:8: missed: statement clobbers memory: _1 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_2);
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _9 = rand ();
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8SI
PULSE.c:32:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:61:16: missed: couldn't vectorize loop
PULSE.c:61:16: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:64:17: missed: couldn't vectorize loop
PULSE.c:64:17: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:73:19: missed: couldn't vectorize loop
PULSE.c:73:19: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _64 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:53:22: missed: couldn't vectorize loop
PULSE.c:53:22: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:47:6: note: vectorized 1 loops in function.
PULSE.c:48:1: missed: statement clobbers memory: saved_stack.7_35 = __builtin_stack_save ();
PULSE.c:49:46: missed: statement clobbers memory: _1 = PULSE_GetLossFunctionPtr (loss_function_36(D));
PULSE.c:60:10: missed: statement clobbers memory: random.4_42 = __builtin_alloca_with_align (_4, 32);
PULSE.c:34:8: missed: statement clobbers memory: _56 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_57);
PULSE.c:39:29: missed: statement clobbers memory: _64 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _67 = rand ();
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_93, inputs_88, _92);
PULSE.c:8:2: missed: statement clobbers memory: _94 (layer_89);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_100, _99, _98);
PULSE.c:67:11: missed: statement clobbers memory: loss_51 = PULSE_GetLoss_38 (_17, _16, _12, _11);
PULSE.c:22:2: missed: statement clobbers memory: _81 (output_30);
PULSE.c:22:2: missed: statement clobbers memory: _103 (_82);
PULSE.c:22:2: missed: statement clobbers memory: _110 (_104);
PULSE.c:22:2: missed: statement clobbers memory: _117 (_111);
PULSE.c:22:2: missed: statement clobbers memory: _124 (_118);
PULSE.c:22:2: missed: statement clobbers memory: _131 (_125);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_132);
PULSE.c:26:3: missed: statement clobbers memory: memset (_137, 0, _135);
PULSE.c:26:3: missed: statement clobbers memory: memset (_130, 0, _128);
PULSE.c:26:3: missed: statement clobbers memory: memset (_123, 0, _121);
PULSE.c:26:3: missed: statement clobbers memory: memset (_116, 0, _114);
PULSE.c:26:3: missed: statement clobbers memory: memset (_109, 0, _107);
PULSE.c:26:3: missed: statement clobbers memory: memset (_87, 0, _85);
PULSE.c:75:6: missed: statement clobbers memory: _21 (current_183, args);
PULSE.c:80:4: missed: statement clobbers memory: printf ("Epoch: %d Item: %d Loss: %.10f\r", i_181, j_182, _22);
PULSE.c:47:6: missed: statement clobbers memory: __builtin_stack_restore (saved_stack.7_35);
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4DI
PULSE.c:47:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:89:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:89:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:94:8: missed: couldn't vectorize loop
PULSE.c:94:8: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:91:6: note: vectorized 0 loops in function.
PULSE.c:96:3: missed: statement clobbers memory: _1 (current_10);
PULSE.c:99:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:99:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Loss.c:15:19: optimized: loop vectorized using 32 byte vectors
Loss.c:15:19: optimized:  loop versioned for vectorization because of possible aliasing
Loss.c:15:19: optimized: loop vectorized using 16 byte vectors
Loss.c:12:23: note: vectorized 1 loops in function.
Loss.c:12:23: note: ***** Analysis failed with vector mode V8SF
Loss.c:12:23: note: ***** The result for vector mode V32QI would be the same
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V16QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V16QI
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V8QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V8QI
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V4QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V4QI
Loss.c:7:19: missed: couldn't vectorize loop
Loss.c:8:38: missed: not vectorized: unsupported use in stmt.
Loss.c:4:23: note: vectorized 0 loops in function.
Loss.c:9:13: note: ***** Analysis failed with vector mode V8SF
Loss.c:9:13: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Loss.c:23:2: note: ***** Analysis failed with vector mode VOID
Loss.c:15:19: optimized: loop vectorized using 32 byte vectors
Loss.c:15:19: optimized:  loop versioned for vectorization because of possible aliasing
Loss.c:15:19: optimized: loop vectorized using 16 byte vectors
Loss.c:12:23: note: vectorized 1 loops in function.
Loss.c:12:23: note: ***** Analysis failed with vector mode V8SF
Loss.c:12:23: note: ***** The result for vector mode V32QI would be the same
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V16QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V16QI
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V8QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V8QI
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V4QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V4QI
Loss.c:7:19: missed: couldn't vectorize loop
Loss.c:8:38: missed: not vectorized: unsupported use in stmt.
Loss.c:4:23: note: vectorized 0 loops in function.
Loss.c:9:13: note: ***** Analysis failed with vector mode V8SF
Loss.c:9:13: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Loss.c:23:2: note: ***** Analysis failed with vector mode VOID
Dense.c:9:27: missed: couldn't vectorize loop
Dense.c:9:27: missed: not vectorized: unsupported outerloop form.
Dense.c:12:20: missed: couldn't vectorize loop
Dense.c:13:21: missed: not vectorized: complicated access pattern.
Dense.c:6:13: note: vectorized 0 loops in function.
Dense.c:16:2: missed: statement clobbers memory: _30 (pretmp_91, _50, 0);
Dense.c:9:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:9:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:24:27: missed: couldn't vectorize loop
Dense.c:24:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:28:20: optimized: loop vectorized using 32 byte vectors
Dense.c:28:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:28:20: optimized: loop vectorized using 16 byte vectors
Dense.c:28:20: missed: couldn't vectorize loop
Dense.c:30:20: missed: not vectorized: no vectype for stmt: _21 = *_20;
 scalar_type: float
Dense.c:20:13: note: vectorized 1 loops in function.
Dense.c:23:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:24:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:24:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:41:28: missed: couldn't vectorize loop
Dense.c:41:28: missed: not vectorized: unsupported outerloop form.
Dense.c:45:21: optimized: loop vectorized using 32 byte vectors
Dense.c:45:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:45:21: optimized: loop vectorized using 16 byte vectors
Dense.c:37:13: note: vectorized 1 loops in function.
Dense.c:37:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:37:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:41:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:145:19: missed: couldn't vectorize loop
Dense.c:145:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:136:19: missed: couldn't vectorize loop
Dense.c:136:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:129:13: note: vectorized 0 loops in function.
Dense.c:153:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:153:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:98:28: missed: couldn't vectorize loop
Dense.c:98:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:101:21: missed: couldn't vectorize loop
Dense.c:101:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:115:28: missed: couldn't vectorize loop
Dense.c:115:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:118:21: missed: couldn't vectorize loop
Dense.c:118:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:84:19: missed: couldn't vectorize loop
Dense.c:84:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:78:13: note: vectorized 0 loops in function.
Dense.c:81:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:103:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:103:17: note: SLPing BB part
Dense.c:120:17: note: Costing subgraph: 
Dense.c:120:17: note: node 0x6e94798 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:120:17: note: op template: _49 = (sizetype) j_137;
Dense.c:120:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:120:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:120:17: note: 	children 0x6e94898
Dense.c:120:17: note: node (external) 0x6e94898 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:120:17: note: 	{ j_137, wi_136 }
Dense.c:120:17: note: Cost model analysis: 
Dense.c:120:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:120:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:120:17: missed: not vectorized: vectorization is not profitable.
Dense.c:103:17: note: Costing subgraph: 
Dense.c:103:17: note: node 0x6e94998 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:103:17: note: op template: _24 = (sizetype) j_134;
Dense.c:103:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:103:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:103:17: note: 	children 0x6e94a98
Dense.c:103:17: note: node (external) 0x6e94a98 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:103:17: note: 	{ j_134, wi_133 }
Dense.c:103:17: note: Cost model analysis: 
Dense.c:103:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:103:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:103:17: missed: not vectorized: vectorization is not profitable.
Dense.c:103:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:103:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:103:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:103:17: note: SLPing BB part
Dense.c:120:17: note: Costing subgraph: 
Dense.c:120:17: note: node 0x6e94998 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:120:17: note: op template: _49 = (sizetype) j_137;
Dense.c:120:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:120:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:120:17: note: 	children 0x6e94798
Dense.c:120:17: note: node (external) 0x6e94798 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:120:17: note: 	{ j_137, wi_136 }
Dense.c:120:17: note: Cost model analysis: 
Dense.c:120:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:120:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:120:17: missed: not vectorized: vectorization is not profitable.
Dense.c:103:17: note: Costing subgraph: 
Dense.c:103:17: note: node 0x6e94b18 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:103:17: note: op template: _24 = (sizetype) j_134;
Dense.c:103:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:103:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:103:17: note: 	children 0x6e94a18
Dense.c:103:17: note: node (external) 0x6e94a18 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:103:17: note: 	{ j_134, wi_133 }
Dense.c:103:17: note: Cost model analysis: 
Dense.c:103:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:103:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:103:17: missed: not vectorized: vectorization is not profitable.
Dense.c:103:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:98:55: note: ***** Analysis failed with vector mode V8QI
Dense.c:98:55: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:98:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:58:27: missed: couldn't vectorize loop
Dense.c:58:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:61:20: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:905:10: missed: not vectorized: no vectype for stmt: _41 = MEM[(__m256_u * {ref-all})_6];
 scalar_type: __m256_u
Dense.c:61:20: note: ***** Analysis failed with vector mode VOID
Dense.c:54:13: note: vectorized 0 loops in function.
Dense.c:54:13: missed: splitting region at dont-vectorize loop 3 entry at bb18
Dense.c:63:14: note: ***** Analysis failed with vector mode V4DI
Dense.c:63:14: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:63:14: missed: splitting region at dominance boundary bb8
Dense.c:63:14: note: ***** Analysis failed with vector mode VOID
Dense.c:63:14: missed: splitting region at loop 1 exit at bb16
Dense.c:58:27: note: ***** Analysis failed with vector mode V8SF
Dense.c:58:27: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Dense.c:58:27: missed: splitting region at dominance boundary bb10
Dense.c:58:27: note: ***** Analysis failed with vector mode VOID
Dense.c:74:2: missed: statement clobbers memory: _27 (pretmp_153, _61, 0);
Dense.c:75:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:75:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:160:2: missed: statement clobbers memory: free (_1);
Dense.c:161:2: missed: statement clobbers memory: free (_2);
Dense.c:162:2: missed: statement clobbers memory: free (_3);
Dense.c:163:2: missed: statement clobbers memory: free (_4);
Dense.c:164:2: missed: statement clobbers memory: free (dense_7);
Dense.c:165:2: missed: statement clobbers memory: PULSE_DestroyLayer (this_6(D));
Dense.c:166:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:166:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:180:19: missed: couldn't vectorize loop
Dense.c:180:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:170:13: note: vectorized 0 loops in function.
Dense.c:172:47: missed: statement clobbers memory: dense_35 = malloc (40);
Dense.c:174:36: missed: statement clobbers memory: _5 = aligned_alloc (64, _4);
Dense.c:175:38: missed: statement clobbers memory: _6 = aligned_alloc (64, _4);
Dense.c:176:36: missed: statement clobbers memory: _8 = aligned_alloc (64, _7);
Dense.c:177:35: missed: statement clobbers memory: _9 = aligned_alloc (64, _7);
Dense.c:178:36: missed: statement clobbers memory: _10 = aligned_alloc (64, _7);
Dense.c:181:39: missed: statement clobbers memory: _11 = rand ();
Dense.c:181:73: missed: statement clobbers memory: _63 = sqrt (_18);
Dense.c:193:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:194:4: missed: statement clobbers memory: exit (1);
Dense.c:190:4: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.3_29, n_outputs.2_28, 1, activation_function_51(D), _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:187:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.1_27, n_outputs.0_26, 1, activation_function_51(D), _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:200:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Dense.c:200:9: note: ***** Analysis failed with vector mode V4DI
Dense.c:200:9: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:9:27: missed: couldn't vectorize loop
Dense.c:9:27: missed: not vectorized: unsupported outerloop form.
Dense.c:12:20: missed: couldn't vectorize loop
Dense.c:13:21: missed: not vectorized: complicated access pattern.
Dense.c:6:13: note: vectorized 0 loops in function.
Dense.c:16:2: missed: statement clobbers memory: _30 (pretmp_91, _50, 0);
Dense.c:9:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:9:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:24:27: missed: couldn't vectorize loop
Dense.c:24:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:28:20: optimized: loop vectorized using 32 byte vectors
Dense.c:28:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:28:20: optimized: loop vectorized using 16 byte vectors
Dense.c:28:20: missed: couldn't vectorize loop
Dense.c:30:20: missed: not vectorized: no vectype for stmt: _21 = *_20;
 scalar_type: float
Dense.c:20:13: note: vectorized 1 loops in function.
Dense.c:23:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:24:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:24:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:41:28: missed: couldn't vectorize loop
Dense.c:41:28: missed: not vectorized: unsupported outerloop form.
Dense.c:45:21: optimized: loop vectorized using 32 byte vectors
Dense.c:45:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:45:21: optimized: loop vectorized using 16 byte vectors
Dense.c:37:13: note: vectorized 1 loops in function.
Dense.c:37:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:37:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:41:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:145:19: missed: couldn't vectorize loop
Dense.c:145:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:136:19: missed: couldn't vectorize loop
Dense.c:136:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:129:13: note: vectorized 0 loops in function.
Dense.c:153:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:153:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:98:28: missed: couldn't vectorize loop
Dense.c:98:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:101:21: missed: couldn't vectorize loop
Dense.c:101:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:115:28: missed: couldn't vectorize loop
Dense.c:115:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:118:21: missed: couldn't vectorize loop
Dense.c:118:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:84:19: missed: couldn't vectorize loop
Dense.c:84:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:78:13: note: vectorized 0 loops in function.
Dense.c:81:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:103:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:103:17: note: SLPing BB part
Dense.c:120:17: note: Costing subgraph: 
Dense.c:120:17: note: node 0x857a0a8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:120:17: note: op template: _49 = (sizetype) j_137;
Dense.c:120:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:120:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:120:17: note: 	children 0x857a1a8
Dense.c:120:17: note: node (external) 0x857a1a8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:120:17: note: 	{ j_137, wi_136 }
Dense.c:120:17: note: Cost model analysis: 
Dense.c:120:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:120:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:120:17: missed: not vectorized: vectorization is not profitable.
Dense.c:103:17: note: Costing subgraph: 
Dense.c:103:17: note: node 0x857a2a8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:103:17: note: op template: _24 = (sizetype) j_134;
Dense.c:103:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:103:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:103:17: note: 	children 0x857a3a8
Dense.c:103:17: note: node (external) 0x857a3a8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:103:17: note: 	{ j_134, wi_133 }
Dense.c:103:17: note: Cost model analysis: 
Dense.c:103:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:103:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:103:17: missed: not vectorized: vectorization is not profitable.
Dense.c:103:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:103:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:103:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:103:17: note: SLPing BB part
Dense.c:120:17: note: Costing subgraph: 
Dense.c:120:17: note: node 0x857a2a8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:120:17: note: op template: _49 = (sizetype) j_137;
Dense.c:120:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:120:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:120:17: note: 	children 0x857a0a8
Dense.c:120:17: note: node (external) 0x857a0a8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:120:17: note: 	{ j_137, wi_136 }
Dense.c:120:17: note: Cost model analysis: 
Dense.c:120:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:120:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:120:17: missed: not vectorized: vectorization is not profitable.
Dense.c:103:17: note: Costing subgraph: 
Dense.c:103:17: note: node 0x857a428 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:103:17: note: op template: _24 = (sizetype) j_134;
Dense.c:103:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:103:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:103:17: note: 	children 0x857a328
Dense.c:103:17: note: node (external) 0x857a328 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:103:17: note: 	{ j_134, wi_133 }
Dense.c:103:17: note: Cost model analysis: 
Dense.c:103:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:103:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:103:17: missed: not vectorized: vectorization is not profitable.
Dense.c:103:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:98:55: note: ***** Analysis failed with vector mode V8QI
Dense.c:98:55: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:98:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:58:27: optimized: loop vectorized using 32 byte vectors
Dense.c:58:27: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:58:27: optimized: loop vectorized using 16 byte vectors
Dense.c:54:13: note: vectorized 1 loops in function.
Dense.c:74:2: missed: statement clobbers memory: _11 (pretmp_42, _31, 0);
Dense.c:54:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:54:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:160:2: missed: statement clobbers memory: free (_1);
Dense.c:161:2: missed: statement clobbers memory: free (_2);
Dense.c:162:2: missed: statement clobbers memory: free (_3);
Dense.c:163:2: missed: statement clobbers memory: free (_4);
Dense.c:164:2: missed: statement clobbers memory: free (dense_7);
Dense.c:165:2: missed: statement clobbers memory: PULSE_DestroyLayer (this_6(D));
Dense.c:166:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:166:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:180:19: missed: couldn't vectorize loop
Dense.c:180:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:170:13: note: vectorized 0 loops in function.
Dense.c:172:47: missed: statement clobbers memory: dense_35 = malloc (40);
Dense.c:174:36: missed: statement clobbers memory: _5 = aligned_alloc (64, _4);
Dense.c:175:38: missed: statement clobbers memory: _6 = aligned_alloc (64, _4);
Dense.c:176:36: missed: statement clobbers memory: _8 = aligned_alloc (64, _7);
Dense.c:177:35: missed: statement clobbers memory: _9 = aligned_alloc (64, _7);
Dense.c:178:36: missed: statement clobbers memory: _10 = aligned_alloc (64, _7);
Dense.c:181:39: missed: statement clobbers memory: _11 = rand ();
Dense.c:181:73: missed: statement clobbers memory: _63 = sqrt (_18);
Dense.c:193:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:194:4: missed: statement clobbers memory: exit (1);
Dense.c:190:4: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.3_29, n_outputs.2_28, 1, activation_function_51(D), _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:187:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.1_27, n_outputs.0_26, 1, activation_function_51(D), _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:200:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Dense.c:200:9: note: ***** Analysis failed with vector mode V4DI
Dense.c:200:9: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Layer.c:7:34: missed: statement clobbers memory: _3 = aligned_alloc (64, _2);
Layer.c:8:35: missed: statement clobbers memory: _6 = aligned_alloc (64, _5);
Layer.c:9:34: missed: statement clobbers memory: _7 = aligned_alloc (64, _5);
Layer.c:14:19: missed: statement clobbers memory: _8 = PULSE_GetActivationFunctionPtr (activation_function_18(D));
Layer.c:19:9: note: ***** Analysis succeeded with vector mode V8SI
Layer.c:19:9: note: SLPing BB part
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x4a547c8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 0 MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 1 MEM <unsigned int> [(struct PULSE_Layer *)&<retval> + 4B] = optimization_type_17(D);
Layer.c:19:9: note: 	children 0x4a54848
Layer.c:19:9: note: node (external) 0x4a54848 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ type_16(D), optimization_type_17(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x4a548c8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 0 <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 1 <retval>.n_outputs = n_outputs_12(D);
Layer.c:19:9: note: 	children 0x4a54948
Layer.c:19:9: note: node (external) 0x4a54948 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x4a54a48 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 0 <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 1 <retval>.outputs = _6;
Layer.c:19:9: note: 	children 0x4a54ac8
Layer.c:19:9: note: node (external) 0x4a54ac8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	stmt 0 _3 = aligned_alloc (64, _2);
Layer.c:19:9: note: 	stmt 1 _6 = aligned_alloc (64, _5);
Layer.c:19:9: note: 	children 0x4a54b48 0x4a54bc8
Layer.c:19:9: note: node (constant) 0x4a54b48 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 64, 64 }
Layer.c:19:9: note: node 0x4a54bc8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: patt_40 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 0 patt_40 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 1 patt_41 = n_outputs_12(D) w* 4;
Layer.c:19:9: note: 	children 0x4a54c48 0x4a54cc8
Layer.c:19:9: note: node (external) 0x4a54c48 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: node (constant) 0x4a54cc8 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ 4, 4 }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x4a54dc8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: op template: <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 0 <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 1 <retval>.back = back_21(D);
Layer.c:19:9: note: 	stmt 2 <retval>.fix = fix_22(D);
Layer.c:19:9: note: 	stmt 3 <retval>.destroy = destroy_23(D);
Layer.c:19:9: note: 	children 0x4a54e48
Layer.c:19:9: note: node (external) 0x4a54e48 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: 	{ feed_20(D), back_21(D), fix_22(D), destroy_23(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 64
  Scalar cost: 64
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x4a54f48 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 0 <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 1 <retval>.child = 0B;
Layer.c:19:9: note: 	children 0x4a54fc8
Layer.c:19:9: note: node (constant) 0x4a54fc8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ 0B, 0B }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Basic block will be vectorized using SLP
Layer.c:19:9: optimized: basic block part vectorized using 8 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x4a547c8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 0 MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 1 MEM <unsigned int> [(struct PULSE_Layer *)&<retval> + 4B] = optimization_type_17(D);
Layer.c:19:9: note: 	children 0x4a54848
Layer.c:19:9: note: node (external) 0x4a54848 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ type_16(D), optimization_type_17(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: vect_is_simple_use: operand optimization_type_17(D), type of def: external
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>]
Layer.c:19:9: note: created &MEM <unsigned int> [(struct PULSE_Layer *)&<retval>]
Layer.c:19:9: note: add new stmt: MEM <vector(2) unsigned int> [(struct PULSE_Layer *)&<retval>] = _42;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 8 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x4a548c8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 0 <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 1 <retval>.n_outputs = n_outputs_12(D);
Layer.c:19:9: note: 	children 0x4a54948
Layer.c:19:9: note: node (external) 0x4a54948 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: vect_is_simple_use: operand n_outputs_12(D), type of def: external
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: <retval>.n_inputs
Layer.c:19:9: note: created &<retval>.n_inputs
Layer.c:19:9: note: add new stmt: MEM <vector(2) unsigned int> [(unsigned int *)&<retval> + 96B] = _44;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 16 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x4a54a48 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 0 <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 1 <retval>.outputs = _6;
Layer.c:19:9: note: 	children 0x4a54ac8
Layer.c:19:9: note: node (external) 0x4a54ac8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	stmt 0 _3 = aligned_alloc (64, _2);
Layer.c:19:9: note: 	stmt 1 _6 = aligned_alloc (64, _5);
Layer.c:19:9: note: 	children 0x4a54b48 0x4a54bc8
Layer.c:19:9: note: node (constant) 0x4a54b48 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 64, 64 }
Layer.c:19:9: note: node 0x4a54bc8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: patt_40 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 0 patt_40 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 1 patt_41 = n_outputs_12(D) w* 4;
Layer.c:19:9: note: 	children 0x4a54c48 0x4a54cc8
Layer.c:19:9: note: node (external) 0x4a54c48 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: node (constant) 0x4a54cc8 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ 4, 4 }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.inputs = _3;
Layer.c:19:9: note: vect_is_simple_use: operand aligned_alloc (64, _5), type of def: internal
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.inputs
Layer.c:19:9: note: created &<retval>.inputs
Layer.c:19:9: note: add new stmt: MEM <vector(2) long unsigned int> [(float * *)&<retval> + 8B] = _48;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 32 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x4a54dc8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: op template: <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 0 <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 1 <retval>.back = back_21(D);
Layer.c:19:9: note: 	stmt 2 <retval>.fix = fix_22(D);
Layer.c:19:9: note: 	stmt 3 <retval>.destroy = destroy_23(D);
Layer.c:19:9: note: 	children 0x4a54e48
Layer.c:19:9: note: node (external) 0x4a54e48 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: 	{ feed_20(D), back_21(D), fix_22(D), destroy_23(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.feed = feed_20(D);
Layer.c:19:9: note: vect_is_simple_use: operand back_21(D), type of def: external
Layer.c:19:9: note: vect_is_simple_use: operand fix_22(D), type of def: external
Layer.c:19:9: note: vect_is_simple_use: operand destroy_23(D), type of def: external
Layer.c:19:9: note: conflicting alias set types.
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(4) long unsigned int  vectorizing a pointer ref: <retval>.feed
Layer.c:19:9: note: created &<retval>.feed
Layer.c:19:9: note: add new stmt: MEM <vector(4) long unsigned int> [(void *)&<retval> + 32B] = _54;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 16 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x4a54f48 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 0 <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 1 <retval>.child = 0B;
Layer.c:19:9: note: 	children 0x4a54fc8
Layer.c:19:9: note: node (constant) 0x4a54fc8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ 0B, 0B }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.parent = 0B;
Layer.c:19:9: note: vect_is_simple_use: operand 0B, type of def: constant
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.parent
Layer.c:19:9: note: created &<retval>.parent
Layer.c:19:9: note: add new stmt: MEM <vector(2) long unsigned int> [(struct PULSE_Layer * *)&<retval> + 72B] = { 0, 0 };
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: note: ***** The result for vector mode V32QI would be the same
Layer.c:24:2: missed: statement clobbers memory: free (_1);
Layer.c:25:2: missed: statement clobbers memory: free (_2);
Layer.c:26:2: missed: statement clobbers memory: free (_3);
Layer.c:27:1: note: ***** Analysis failed with vector mode V4DI
Layer.c:27:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:9:27: missed: couldn't vectorize loop
Dense.c:9:27: missed: not vectorized: unsupported outerloop form.
Dense.c:12:20: missed: couldn't vectorize loop
Dense.c:13:21: missed: not vectorized: complicated access pattern.
Dense.c:6:13: note: vectorized 0 loops in function.
Dense.c:16:2: missed: statement clobbers memory: _30 (pretmp_91, _50, 0);
Dense.c:9:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:9:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:24:27: missed: couldn't vectorize loop
Dense.c:24:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:28:20: optimized: loop vectorized using 32 byte vectors
Dense.c:28:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:28:20: optimized: loop vectorized using 16 byte vectors
Dense.c:28:20: missed: couldn't vectorize loop
Dense.c:30:20: missed: not vectorized: no vectype for stmt: _21 = *_20;
 scalar_type: float
Dense.c:20:13: note: vectorized 1 loops in function.
Dense.c:23:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:24:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:24:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:41:28: missed: couldn't vectorize loop
Dense.c:41:28: missed: not vectorized: unsupported outerloop form.
Dense.c:45:21: optimized: loop vectorized using 32 byte vectors
Dense.c:45:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:45:21: optimized: loop vectorized using 16 byte vectors
Dense.c:37:13: note: vectorized 1 loops in function.
Dense.c:37:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:37:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:41:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:54:13: note: vectorized 0 loops in function.
Dense.c:74:2: missed: statement clobbers memory: _3 (_4, _11, 0);
Dense.c:75:1: note: ***** Analysis failed with vector mode V8SI
Dense.c:75:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
Dense.c:145:19: missed: couldn't vectorize loop
Dense.c:145:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:136:19: missed: couldn't vectorize loop
Dense.c:136:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:129:13: note: vectorized 0 loops in function.
Dense.c:153:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:153:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:98:28: missed: couldn't vectorize loop
Dense.c:98:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:101:21: missed: couldn't vectorize loop
Dense.c:101:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:115:28: missed: couldn't vectorize loop
Dense.c:115:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:118:21: missed: couldn't vectorize loop
Dense.c:118:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:84:19: missed: couldn't vectorize loop
Dense.c:84:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:78:13: note: vectorized 0 loops in function.
Dense.c:81:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:103:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:103:17: note: SLPing BB part
Dense.c:120:17: note: Costing subgraph: 
Dense.c:120:17: note: node 0x873b5e8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:120:17: note: op template: _49 = (sizetype) j_137;
Dense.c:120:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:120:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:120:17: note: 	children 0x873b6e8
Dense.c:120:17: note: node (external) 0x873b6e8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:120:17: note: 	{ j_137, wi_136 }
Dense.c:120:17: note: Cost model analysis: 
Dense.c:120:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:120:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:120:17: missed: not vectorized: vectorization is not profitable.
Dense.c:103:17: note: Costing subgraph: 
Dense.c:103:17: note: node 0x873b7e8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:103:17: note: op template: _24 = (sizetype) j_134;
Dense.c:103:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:103:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:103:17: note: 	children 0x873b8e8
Dense.c:103:17: note: node (external) 0x873b8e8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:103:17: note: 	{ j_134, wi_133 }
Dense.c:103:17: note: Cost model analysis: 
Dense.c:103:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:103:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:103:17: missed: not vectorized: vectorization is not profitable.
Dense.c:103:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:103:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:103:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:103:17: note: SLPing BB part
Dense.c:120:17: note: Costing subgraph: 
Dense.c:120:17: note: node 0x873b7e8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:120:17: note: op template: _49 = (sizetype) j_137;
Dense.c:120:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:120:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:120:17: note: 	children 0x873b5e8
Dense.c:120:17: note: node (external) 0x873b5e8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:120:17: note: 	{ j_137, wi_136 }
Dense.c:120:17: note: Cost model analysis: 
Dense.c:120:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:120:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:120:17: missed: not vectorized: vectorization is not profitable.
Dense.c:103:17: note: Costing subgraph: 
Dense.c:103:17: note: node 0x873b968 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:103:17: note: op template: _24 = (sizetype) j_134;
Dense.c:103:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:103:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:103:17: note: 	children 0x873b868
Dense.c:103:17: note: node (external) 0x873b868 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:103:17: note: 	{ j_134, wi_133 }
Dense.c:103:17: note: Cost model analysis: 
Dense.c:103:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:103:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:103:17: missed: not vectorized: vectorization is not profitable.
Dense.c:103:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:98:55: note: ***** Analysis failed with vector mode V8QI
Dense.c:98:55: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:98:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:160:2: missed: statement clobbers memory: free (_1);
Dense.c:161:2: missed: statement clobbers memory: free (_2);
Dense.c:162:2: missed: statement clobbers memory: free (_3);
Dense.c:163:2: missed: statement clobbers memory: free (_4);
Dense.c:164:2: missed: statement clobbers memory: free (dense_7);
Dense.c:165:2: missed: statement clobbers memory: PULSE_DestroyLayer (this_6(D));
Dense.c:166:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:166:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:180:19: missed: couldn't vectorize loop
Dense.c:180:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:170:13: note: vectorized 0 loops in function.
Dense.c:172:47: missed: statement clobbers memory: dense_35 = malloc (40);
Dense.c:174:36: missed: statement clobbers memory: _5 = aligned_alloc (64, _4);
Dense.c:175:38: missed: statement clobbers memory: _6 = aligned_alloc (64, _4);
Dense.c:176:36: missed: statement clobbers memory: _8 = aligned_alloc (64, _7);
Dense.c:177:35: missed: statement clobbers memory: _9 = aligned_alloc (64, _7);
Dense.c:178:36: missed: statement clobbers memory: _10 = aligned_alloc (64, _7);
Dense.c:181:39: missed: statement clobbers memory: _11 = rand ();
Dense.c:181:73: missed: statement clobbers memory: _63 = sqrt (_18);
Dense.c:193:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:194:4: missed: statement clobbers memory: exit (1);
Dense.c:190:4: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.3_29, n_outputs.2_28, 1, activation_function_51(D), _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:187:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.1_27, n_outputs.0_26, 1, activation_function_51(D), _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:200:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Dense.c:200:9: note: ***** Analysis failed with vector mode V4DI
Dense.c:200:9: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Activations.c:17:19: optimized: loop vectorized using 32 byte vectors
Activations.c:17:19: optimized: loop vectorized using 16 byte vectors
Activations.c:17:19: optimized: loop vectorized using 32 byte vectors
Activations.c:17:19: optimized: loop vectorized using 16 byte vectors
Activations.c:14:13: note: vectorized 2 loops in function.
Activations.c:14:13: note: ***** Analysis failed with vector mode V8SF
Activations.c:14:13: note: ***** The result for vector mode V32QI would be the same
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V16QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V16QI
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V8QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V8QI
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V4QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V4QI
Activations.c:28:19: missed: couldn't vectorize loop
Activations.c:28:19: missed: not vectorized: unsupported control flow in loop.
Activations.c:28:19: optimized: loop vectorized using 32 byte vectors
Activations.c:28:19: optimized: loop vectorized using 16 byte vectors
Activations.c:25:13: note: vectorized 1 loops in function.
Activations.c:25:13: note: ***** Analysis failed with vector mode V8SF
Activations.c:25:13: note: ***** The result for vector mode V32QI would be the same
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V16QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V16QI
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V8QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V8QI
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V4QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V4QI
Activations.c:38:1: note: ***** Analysis failed with vector mode VOID
Activations.c:5:19: missed: couldn't vectorize loop
Activations.c:9:21: missed: statement clobbers memory: _36 = expf (_18);
Activations.c:5:19: missed: couldn't vectorize loop
Activations.c:9:21: missed: statement clobbers memory: _12 = expf (_11);
Activations.c:3:13: note: vectorized 0 loops in function.
Activations.c:9:21: missed: statement clobbers memory: _12 = expf (_11);
Activations.c:9:21: missed: statement clobbers memory: _36 = expf (_18);
Activations.c:11:1: note: ***** Analysis failed with vector mode V8SF
Activations.c:11:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Activations.c:44:2: note: ***** Analysis failed with vector mode VOID
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:4:18: note: vectorized 0 loops in function.
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_4, inputs_15, _3);
PULSE.c:8:2: missed: statement clobbers memory: _5 (layer_17);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_12, pretmp_26, _9);
PULSE.c:13:28: note: ***** Analysis failed with vector mode V8SI
PULSE.c:13:28: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:22:2: missed: statement clobbers memory: _1 (layer_10(D));
PULSE.c:22:2: missed: statement clobbers memory: _14 (_2);
PULSE.c:22:2: missed: statement clobbers memory: _21 (_15);
PULSE.c:22:2: missed: statement clobbers memory: _28 (_22);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_29);
PULSE.c:26:3: missed: statement clobbers memory: memset (_34, 0, _32);
PULSE.c:26:3: missed: statement clobbers memory: memset (_27, 0, _25);
PULSE.c:26:3: missed: statement clobbers memory: memset (_20, 0, _18);
PULSE.c:26:3: missed: statement clobbers memory: memset (_7, 0, _5);
PULSE.c:28:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:28:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:32:6: note: vectorized 1 loops in function.
PULSE.c:34:8: missed: statement clobbers memory: _1 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_2);
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _9 = rand ();
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8SI
PULSE.c:32:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:61:16: missed: couldn't vectorize loop
PULSE.c:61:16: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:64:17: missed: couldn't vectorize loop
PULSE.c:64:17: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:73:19: missed: couldn't vectorize loop
PULSE.c:73:19: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _64 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:53:22: missed: couldn't vectorize loop
PULSE.c:53:22: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:47:6: note: vectorized 1 loops in function.
PULSE.c:48:1: missed: statement clobbers memory: saved_stack.7_35 = __builtin_stack_save ();
PULSE.c:49:46: missed: statement clobbers memory: _1 = PULSE_GetLossFunctionPtr (loss_function_36(D));
PULSE.c:60:10: missed: statement clobbers memory: random.4_42 = __builtin_alloca_with_align (_4, 32);
PULSE.c:34:8: missed: statement clobbers memory: _56 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_57);
PULSE.c:39:29: missed: statement clobbers memory: _64 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _67 = rand ();
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_93, inputs_88, _92);
PULSE.c:8:2: missed: statement clobbers memory: _94 (layer_89);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_100, _99, _98);
PULSE.c:67:11: missed: statement clobbers memory: loss_51 = PULSE_GetLoss_38 (_17, _16, _12, _11);
PULSE.c:22:2: missed: statement clobbers memory: _81 (output_30);
PULSE.c:22:2: missed: statement clobbers memory: _103 (_82);
PULSE.c:22:2: missed: statement clobbers memory: _110 (_104);
PULSE.c:22:2: missed: statement clobbers memory: _117 (_111);
PULSE.c:22:2: missed: statement clobbers memory: _124 (_118);
PULSE.c:22:2: missed: statement clobbers memory: _131 (_125);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_132);
PULSE.c:26:3: missed: statement clobbers memory: memset (_137, 0, _135);
PULSE.c:26:3: missed: statement clobbers memory: memset (_130, 0, _128);
PULSE.c:26:3: missed: statement clobbers memory: memset (_123, 0, _121);
PULSE.c:26:3: missed: statement clobbers memory: memset (_116, 0, _114);
PULSE.c:26:3: missed: statement clobbers memory: memset (_109, 0, _107);
PULSE.c:26:3: missed: statement clobbers memory: memset (_87, 0, _85);
PULSE.c:75:6: missed: statement clobbers memory: _21 (current_183, args);
PULSE.c:80:4: missed: statement clobbers memory: printf ("Epoch: %d Item: %d Loss: %.10f\r", i_181, j_182, _22);
PULSE.c:47:6: missed: statement clobbers memory: __builtin_stack_restore (saved_stack.7_35);
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4DI
PULSE.c:47:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:89:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:89:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:94:8: missed: couldn't vectorize loop
PULSE.c:94:8: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:91:6: note: vectorized 0 loops in function.
PULSE.c:96:3: missed: statement clobbers memory: _1 (current_10);
PULSE.c:99:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:99:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Loss.c:15:19: optimized: loop vectorized using 32 byte vectors
Loss.c:15:19: optimized:  loop versioned for vectorization because of possible aliasing
Loss.c:15:19: optimized: loop vectorized using 16 byte vectors
Loss.c:12:23: note: vectorized 1 loops in function.
Loss.c:12:23: note: ***** Analysis failed with vector mode V8SF
Loss.c:12:23: note: ***** The result for vector mode V32QI would be the same
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V16QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V16QI
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V8QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V8QI
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V4QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V4QI
Loss.c:7:19: missed: couldn't vectorize loop
Loss.c:8:38: missed: not vectorized: unsupported use in stmt.
Loss.c:4:23: note: vectorized 0 loops in function.
Loss.c:9:13: note: ***** Analysis failed with vector mode V8SF
Loss.c:9:13: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Loss.c:23:2: note: ***** Analysis failed with vector mode VOID
Dense.c:9:27: missed: couldn't vectorize loop
Dense.c:9:27: missed: not vectorized: unsupported outerloop form.
Dense.c:12:20: missed: couldn't vectorize loop
Dense.c:13:21: missed: not vectorized: complicated access pattern.
Dense.c:6:13: note: vectorized 0 loops in function.
Dense.c:16:2: missed: statement clobbers memory: _30 (pretmp_91, _50, 0);
Dense.c:9:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:9:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:24:27: missed: couldn't vectorize loop
Dense.c:24:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:28:20: optimized: loop vectorized using 32 byte vectors
Dense.c:28:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:28:20: optimized: loop vectorized using 16 byte vectors
Dense.c:28:20: missed: couldn't vectorize loop
Dense.c:30:20: missed: not vectorized: no vectype for stmt: _21 = *_20;
 scalar_type: float
Dense.c:20:13: note: vectorized 1 loops in function.
Dense.c:23:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:24:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:24:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:41:28: missed: couldn't vectorize loop
Dense.c:41:28: missed: not vectorized: unsupported outerloop form.
Dense.c:45:21: optimized: loop vectorized using 32 byte vectors
Dense.c:45:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:45:21: optimized: loop vectorized using 16 byte vectors
Dense.c:37:13: note: vectorized 1 loops in function.
Dense.c:37:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:37:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:41:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:145:19: missed: couldn't vectorize loop
Dense.c:145:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:136:19: missed: couldn't vectorize loop
Dense.c:136:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:129:13: note: vectorized 0 loops in function.
Dense.c:153:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:153:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:98:28: missed: couldn't vectorize loop
Dense.c:98:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:101:21: missed: couldn't vectorize loop
Dense.c:101:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:115:28: missed: couldn't vectorize loop
Dense.c:115:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:118:21: missed: couldn't vectorize loop
Dense.c:118:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:84:19: missed: couldn't vectorize loop
Dense.c:84:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:78:13: note: vectorized 0 loops in function.
Dense.c:81:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:103:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:103:17: note: SLPing BB part
Dense.c:120:17: note: Costing subgraph: 
Dense.c:120:17: note: node 0x7df9388 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:120:17: note: op template: _49 = (sizetype) j_137;
Dense.c:120:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:120:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:120:17: note: 	children 0x7df9488
Dense.c:120:17: note: node (external) 0x7df9488 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:120:17: note: 	{ j_137, wi_136 }
Dense.c:120:17: note: Cost model analysis: 
Dense.c:120:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:120:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:120:17: missed: not vectorized: vectorization is not profitable.
Dense.c:103:17: note: Costing subgraph: 
Dense.c:103:17: note: node 0x7df9588 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:103:17: note: op template: _24 = (sizetype) j_134;
Dense.c:103:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:103:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:103:17: note: 	children 0x7df9688
Dense.c:103:17: note: node (external) 0x7df9688 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:103:17: note: 	{ j_134, wi_133 }
Dense.c:103:17: note: Cost model analysis: 
Dense.c:103:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:103:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:103:17: missed: not vectorized: vectorization is not profitable.
Dense.c:103:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:103:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:103:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:103:17: note: SLPing BB part
Dense.c:120:17: note: Costing subgraph: 
Dense.c:120:17: note: node 0x7df9588 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:120:17: note: op template: _49 = (sizetype) j_137;
Dense.c:120:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:120:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:120:17: note: 	children 0x7df9388
Dense.c:120:17: note: node (external) 0x7df9388 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:120:17: note: 	{ j_137, wi_136 }
Dense.c:120:17: note: Cost model analysis: 
Dense.c:120:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:120:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:120:17: missed: not vectorized: vectorization is not profitable.
Dense.c:103:17: note: Costing subgraph: 
Dense.c:103:17: note: node 0x7df9708 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:103:17: note: op template: _24 = (sizetype) j_134;
Dense.c:103:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:103:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:103:17: note: 	children 0x7df9608
Dense.c:103:17: note: node (external) 0x7df9608 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:103:17: note: 	{ j_134, wi_133 }
Dense.c:103:17: note: Cost model analysis: 
Dense.c:103:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:103:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:103:17: missed: not vectorized: vectorization is not profitable.
Dense.c:103:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:98:55: note: ***** Analysis failed with vector mode V8QI
Dense.c:98:55: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:98:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:58:27: missed: couldn't vectorize loop
Dense.c:58:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:61:20: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:905:10: missed: not vectorized: no vectype for stmt: _41 = MEM[(__m256_u * {ref-all})_6];
 scalar_type: __m256_u
Dense.c:61:20: note: ***** Analysis failed with vector mode VOID
Dense.c:54:13: note: vectorized 0 loops in function.
Dense.c:54:13: missed: splitting region at dont-vectorize loop 3 entry at bb18
Dense.c:63:14: note: ***** Analysis failed with vector mode V4DI
Dense.c:63:14: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:63:14: missed: splitting region at dominance boundary bb8
Dense.c:63:14: note: ***** Analysis failed with vector mode VOID
Dense.c:63:14: missed: splitting region at loop 1 exit at bb16
Dense.c:58:27: note: ***** Analysis failed with vector mode V8SF
Dense.c:58:27: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Dense.c:58:27: missed: splitting region at dominance boundary bb10
Dense.c:58:27: note: ***** Analysis failed with vector mode VOID
Dense.c:74:2: missed: statement clobbers memory: _27 (pretmp_153, _61, 0);
Dense.c:75:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:75:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:160:2: missed: statement clobbers memory: free (_1);
Dense.c:161:2: missed: statement clobbers memory: free (_2);
Dense.c:162:2: missed: statement clobbers memory: free (_3);
Dense.c:163:2: missed: statement clobbers memory: free (_4);
Dense.c:164:2: missed: statement clobbers memory: free (dense_7);
Dense.c:165:2: missed: statement clobbers memory: PULSE_DestroyLayer (this_6(D));
Dense.c:166:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:166:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:180:19: missed: couldn't vectorize loop
Dense.c:180:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:170:13: note: vectorized 0 loops in function.
Dense.c:172:47: missed: statement clobbers memory: dense_35 = malloc (40);
Dense.c:174:36: missed: statement clobbers memory: _5 = aligned_alloc (64, _4);
Dense.c:175:38: missed: statement clobbers memory: _6 = aligned_alloc (64, _4);
Dense.c:176:36: missed: statement clobbers memory: _8 = aligned_alloc (64, _7);
Dense.c:177:35: missed: statement clobbers memory: _9 = aligned_alloc (64, _7);
Dense.c:178:36: missed: statement clobbers memory: _10 = aligned_alloc (64, _7);
Dense.c:181:39: missed: statement clobbers memory: _11 = rand ();
Dense.c:181:73: missed: statement clobbers memory: _63 = sqrt (_18);
Dense.c:193:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:194:4: missed: statement clobbers memory: exit (1);
Dense.c:190:4: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.3_29, n_outputs.2_28, 1, activation_function_51(D), _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:187:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.1_27, n_outputs.0_26, 1, activation_function_51(D), _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:200:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Dense.c:200:9: note: ***** Analysis failed with vector mode V4DI
Dense.c:200:9: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:9:27: missed: couldn't vectorize loop
Dense.c:9:27: missed: not vectorized: unsupported outerloop form.
Dense.c:12:20: missed: couldn't vectorize loop
Dense.c:13:21: missed: not vectorized: complicated access pattern.
Dense.c:6:13: note: vectorized 0 loops in function.
Dense.c:16:2: missed: statement clobbers memory: _30 (pretmp_91, _50, 0);
Dense.c:9:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:9:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:24:27: missed: couldn't vectorize loop
Dense.c:24:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:28:20: optimized: loop vectorized using 32 byte vectors
Dense.c:28:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:28:20: optimized: loop vectorized using 16 byte vectors
Dense.c:28:20: missed: couldn't vectorize loop
Dense.c:30:20: missed: not vectorized: no vectype for stmt: _21 = *_20;
 scalar_type: float
Dense.c:20:13: note: vectorized 1 loops in function.
Dense.c:23:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:24:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:24:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:41:28: missed: couldn't vectorize loop
Dense.c:41:28: missed: not vectorized: unsupported outerloop form.
Dense.c:45:21: optimized: loop vectorized using 32 byte vectors
Dense.c:45:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:45:21: optimized: loop vectorized using 16 byte vectors
Dense.c:37:13: note: vectorized 1 loops in function.
Dense.c:37:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:37:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:41:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:147:19: missed: couldn't vectorize loop
Dense.c:147:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:138:19: missed: couldn't vectorize loop
Dense.c:138:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:131:13: note: vectorized 0 loops in function.
Dense.c:155:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:155:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:100:28: missed: couldn't vectorize loop
Dense.c:100:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:103:21: missed: couldn't vectorize loop
Dense.c:103:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:117:28: missed: couldn't vectorize loop
Dense.c:117:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:120:21: missed: couldn't vectorize loop
Dense.c:120:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:86:19: missed: couldn't vectorize loop
Dense.c:86:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:80:13: note: vectorized 0 loops in function.
Dense.c:83:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:105:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:105:17: note: SLPing BB part
Dense.c:122:17: note: Costing subgraph: 
Dense.c:122:17: note: node 0x767bc18 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:122:17: note: op template: _49 = (sizetype) j_137;
Dense.c:122:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:122:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:122:17: note: 	children 0x767bd18
Dense.c:122:17: note: node (external) 0x767bd18 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:122:17: note: 	{ j_137, wi_136 }
Dense.c:122:17: note: Cost model analysis: 
Dense.c:122:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:122:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:122:17: missed: not vectorized: vectorization is not profitable.
Dense.c:105:17: note: Costing subgraph: 
Dense.c:105:17: note: node 0x767be18 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:105:17: note: op template: _24 = (sizetype) j_134;
Dense.c:105:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:105:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:105:17: note: 	children 0x767bf18
Dense.c:105:17: note: node (external) 0x767bf18 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:105:17: note: 	{ j_134, wi_133 }
Dense.c:105:17: note: Cost model analysis: 
Dense.c:105:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:105:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:105:17: missed: not vectorized: vectorization is not profitable.
Dense.c:105:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:105:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:105:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:105:17: note: SLPing BB part
Dense.c:122:17: note: Costing subgraph: 
Dense.c:122:17: note: node 0x767be18 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:122:17: note: op template: _49 = (sizetype) j_137;
Dense.c:122:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:122:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:122:17: note: 	children 0x767bc18
Dense.c:122:17: note: node (external) 0x767bc18 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:122:17: note: 	{ j_137, wi_136 }
Dense.c:122:17: note: Cost model analysis: 
Dense.c:122:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:122:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:122:17: missed: not vectorized: vectorization is not profitable.
Dense.c:105:17: note: Costing subgraph: 
Dense.c:105:17: note: node 0x767bf98 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:105:17: note: op template: _24 = (sizetype) j_134;
Dense.c:105:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:105:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:105:17: note: 	children 0x767be98
Dense.c:105:17: note: node (external) 0x767be98 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:105:17: note: 	{ j_134, wi_133 }
Dense.c:105:17: note: Cost model analysis: 
Dense.c:105:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:105:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:105:17: missed: not vectorized: vectorization is not profitable.
Dense.c:105:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:100:55: note: ***** Analysis failed with vector mode V8QI
Dense.c:100:55: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:100:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:59:27: missed: couldn't vectorize loop
Dense.c:72:19: missed: not vectorized: no vectype for stmt: _200 = dense_41->weights;
 scalar_type: float *
Dense.c:62:7: missed: couldn't vectorize loop
Dense.c:62:7: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:54:13: note: vectorized 0 loops in function.
Dense.c:76:2: missed: statement clobbers memory: _31 (prephitmp_215, _166, 0);
Dense.c:77:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:77:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:162:2: missed: statement clobbers memory: free (_1);
Dense.c:163:2: missed: statement clobbers memory: free (_2);
Dense.c:164:2: missed: statement clobbers memory: free (_3);
Dense.c:165:2: missed: statement clobbers memory: free (_4);
Dense.c:166:2: missed: statement clobbers memory: free (dense_7);
Dense.c:167:2: missed: statement clobbers memory: PULSE_DestroyLayer (this_6(D));
Dense.c:168:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:168:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:182:19: missed: couldn't vectorize loop
Dense.c:182:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:172:13: note: vectorized 0 loops in function.
Dense.c:174:47: missed: statement clobbers memory: dense_35 = malloc (40);
Dense.c:176:36: missed: statement clobbers memory: _5 = aligned_alloc (64, _4);
Dense.c:177:38: missed: statement clobbers memory: _6 = aligned_alloc (64, _4);
Dense.c:178:36: missed: statement clobbers memory: _8 = aligned_alloc (64, _7);
Dense.c:179:35: missed: statement clobbers memory: _9 = aligned_alloc (64, _7);
Dense.c:180:36: missed: statement clobbers memory: _10 = aligned_alloc (64, _7);
Dense.c:183:39: missed: statement clobbers memory: _11 = rand ();
Dense.c:183:73: missed: statement clobbers memory: _63 = sqrt (_18);
Dense.c:195:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:196:4: missed: statement clobbers memory: exit (1);
Dense.c:192:4: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.3_29, n_outputs.2_28, 1, activation_function_51(D), _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:189:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.1_27, n_outputs.0_26, 1, activation_function_51(D), _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:202:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Dense.c:202:9: note: ***** Analysis failed with vector mode V4DI
Dense.c:202:9: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:9:27: missed: couldn't vectorize loop
Dense.c:9:27: missed: not vectorized: unsupported outerloop form.
Dense.c:12:20: missed: couldn't vectorize loop
Dense.c:13:21: missed: not vectorized: complicated access pattern.
Dense.c:6:13: note: vectorized 0 loops in function.
Dense.c:16:2: missed: statement clobbers memory: _30 (pretmp_91, _50, 0);
Dense.c:9:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:9:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:24:27: missed: couldn't vectorize loop
Dense.c:24:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:28:20: optimized: loop vectorized using 32 byte vectors
Dense.c:28:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:28:20: optimized: loop vectorized using 16 byte vectors
Dense.c:28:20: missed: couldn't vectorize loop
Dense.c:30:20: missed: not vectorized: no vectype for stmt: _21 = *_20;
 scalar_type: float
Dense.c:20:13: note: vectorized 1 loops in function.
Dense.c:23:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:24:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:24:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:41:28: missed: couldn't vectorize loop
Dense.c:41:28: missed: not vectorized: unsupported outerloop form.
Dense.c:45:21: optimized: loop vectorized using 32 byte vectors
Dense.c:45:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:45:21: optimized: loop vectorized using 16 byte vectors
Dense.c:37:13: note: vectorized 1 loops in function.
Dense.c:37:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:37:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:41:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:148:19: missed: couldn't vectorize loop
Dense.c:148:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:139:19: missed: couldn't vectorize loop
Dense.c:139:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:132:13: note: vectorized 0 loops in function.
Dense.c:156:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:156:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:101:28: missed: couldn't vectorize loop
Dense.c:101:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:104:21: missed: couldn't vectorize loop
Dense.c:104:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:118:28: missed: couldn't vectorize loop
Dense.c:118:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:121:21: missed: couldn't vectorize loop
Dense.c:121:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:87:19: missed: couldn't vectorize loop
Dense.c:87:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:81:13: note: vectorized 0 loops in function.
Dense.c:84:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:106:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:106:17: note: SLPing BB part
Dense.c:123:17: note: Costing subgraph: 
Dense.c:123:17: note: node 0x7515148 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:123:17: note: op template: _49 = (sizetype) j_137;
Dense.c:123:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:123:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:123:17: note: 	children 0x7515248
Dense.c:123:17: note: node (external) 0x7515248 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:123:17: note: 	{ j_137, wi_136 }
Dense.c:123:17: note: Cost model analysis: 
Dense.c:123:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:123:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:123:17: missed: not vectorized: vectorization is not profitable.
Dense.c:106:17: note: Costing subgraph: 
Dense.c:106:17: note: node 0x7515348 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:106:17: note: op template: _24 = (sizetype) j_134;
Dense.c:106:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:106:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:106:17: note: 	children 0x7515448
Dense.c:106:17: note: node (external) 0x7515448 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:106:17: note: 	{ j_134, wi_133 }
Dense.c:106:17: note: Cost model analysis: 
Dense.c:106:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:106:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:106:17: missed: not vectorized: vectorization is not profitable.
Dense.c:106:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:106:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:106:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:106:17: note: SLPing BB part
Dense.c:123:17: note: Costing subgraph: 
Dense.c:123:17: note: node 0x7515348 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:123:17: note: op template: _49 = (sizetype) j_137;
Dense.c:123:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:123:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:123:17: note: 	children 0x7515148
Dense.c:123:17: note: node (external) 0x7515148 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:123:17: note: 	{ j_137, wi_136 }
Dense.c:123:17: note: Cost model analysis: 
Dense.c:123:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:123:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:123:17: missed: not vectorized: vectorization is not profitable.
Dense.c:106:17: note: Costing subgraph: 
Dense.c:106:17: note: node 0x75154c8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:106:17: note: op template: _24 = (sizetype) j_134;
Dense.c:106:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:106:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:106:17: note: 	children 0x75153c8
Dense.c:106:17: note: node (external) 0x75153c8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:106:17: note: 	{ j_134, wi_133 }
Dense.c:106:17: note: Cost model analysis: 
Dense.c:106:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:106:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:106:17: missed: not vectorized: vectorization is not profitable.
Dense.c:106:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:101:55: note: ***** Analysis failed with vector mode V8QI
Dense.c:101:55: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:101:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:59:27: missed: couldn't vectorize loop
Dense.c:59:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:71:11: optimized: loop vectorized using 32 byte vectors
Dense.c:71:11: optimized: loop vectorized using 16 byte vectors
Dense.c:63:11: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:905:10: missed: not vectorized: no vectype for stmt: _61 = MEM[(__m256_u * {ref-all})_6];
 scalar_type: __m256_u
Dense.c:54:13: note: vectorized 1 loops in function.
Dense.c:77:2: missed: statement clobbers memory: _38 (pretmp_240, _70, 0);
Dense.c:54:13: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:54:13: note: SLPing BB part
Dense.c:54:13: note: Costing subgraph: 
Dense.c:54:13: note: node 0x74128b8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:54:13: note: op template: _3 = (sizetype) j_89;
Dense.c:54:13: note: 	stmt 0 _3 = (sizetype) j_89;
Dense.c:54:13: note: 	stmt 1 _239 = (sizetype) wi_88;
Dense.c:54:13: note: 	children 0x74129b8
Dense.c:54:13: note: node (external) 0x74129b8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:54:13: note: 	{ j_89, wi_88 }
Dense.c:54:13: note: node 0x7412ab8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:54:13: note: op template: _150 = (sizetype) j_68;
Dense.c:54:13: note: 	stmt 0 _150 = (sizetype) j_68;
Dense.c:54:13: note: 	stmt 1 _239 = (sizetype) wi_88;
Dense.c:54:13: note: 	children 0x7412bb8
Dense.c:54:13: note: node (external) 0x7412bb8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:54:13: note: 	{ j_68, wi_88 }
Dense.c:54:13: note: Cost model analysis: 
Dense.c:54:13: note: Cost model analysis for part in loop 1:
  Vector cost: 40
  Scalar cost: 8
Dense.c:54:13: missed: not vectorized: vectorization is not profitable.
Dense.c:54:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:54:13: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:54:13: note: SLPing BB part
Dense.c:54:13: note: Costing subgraph: 
Dense.c:54:13: note: node 0x7412ab8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:54:13: note: op template: _3 = (sizetype) j_89;
Dense.c:54:13: note: 	stmt 0 _3 = (sizetype) j_89;
Dense.c:54:13: note: 	stmt 1 _239 = (sizetype) wi_88;
Dense.c:54:13: note: 	children 0x74128b8
Dense.c:54:13: note: node (external) 0x74128b8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:54:13: note: 	{ j_89, wi_88 }
Dense.c:54:13: note: node 0x7412cb8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:54:13: note: op template: _150 = (sizetype) j_68;
Dense.c:54:13: note: 	stmt 0 _150 = (sizetype) j_68;
Dense.c:54:13: note: 	stmt 1 _239 = (sizetype) wi_88;
Dense.c:54:13: note: 	children 0x7412f38
Dense.c:54:13: note: node (external) 0x7412f38 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:54:13: note: 	{ j_68, wi_88 }
Dense.c:54:13: note: Cost model analysis: 
Dense.c:54:13: note: Cost model analysis for part in loop 1:
  Vector cost: 40
  Scalar cost: 8
Dense.c:54:13: missed: not vectorized: vectorization is not profitable.
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:59:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:59:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:59:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:163:2: missed: statement clobbers memory: free (_1);
Dense.c:164:2: missed: statement clobbers memory: free (_2);
Dense.c:165:2: missed: statement clobbers memory: free (_3);
Dense.c:166:2: missed: statement clobbers memory: free (_4);
Dense.c:167:2: missed: statement clobbers memory: free (dense_7);
Dense.c:168:2: missed: statement clobbers memory: PULSE_DestroyLayer (this_6(D));
Dense.c:169:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:169:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:183:19: missed: couldn't vectorize loop
Dense.c:183:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:173:13: note: vectorized 0 loops in function.
Dense.c:175:47: missed: statement clobbers memory: dense_35 = malloc (40);
Dense.c:177:36: missed: statement clobbers memory: _5 = aligned_alloc (64, _4);
Dense.c:178:38: missed: statement clobbers memory: _6 = aligned_alloc (64, _4);
Dense.c:179:36: missed: statement clobbers memory: _8 = aligned_alloc (64, _7);
Dense.c:180:35: missed: statement clobbers memory: _9 = aligned_alloc (64, _7);
Dense.c:181:36: missed: statement clobbers memory: _10 = aligned_alloc (64, _7);
Dense.c:184:39: missed: statement clobbers memory: _11 = rand ();
Dense.c:184:73: missed: statement clobbers memory: _63 = sqrt (_18);
Dense.c:196:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:197:4: missed: statement clobbers memory: exit (1);
Dense.c:193:4: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.3_29, n_outputs.2_28, 1, activation_function_51(D), _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:190:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.1_27, n_outputs.0_26, 1, activation_function_51(D), _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:203:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Dense.c:203:9: note: ***** Analysis failed with vector mode V4DI
Dense.c:203:9: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:9:27: missed: couldn't vectorize loop
Dense.c:9:27: missed: not vectorized: unsupported outerloop form.
Dense.c:12:20: missed: couldn't vectorize loop
Dense.c:13:21: missed: not vectorized: complicated access pattern.
Dense.c:6:13: note: vectorized 0 loops in function.
Dense.c:16:2: missed: statement clobbers memory: _30 (pretmp_91, _50, 0);
Dense.c:9:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:9:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:24:27: missed: couldn't vectorize loop
Dense.c:24:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:28:20: optimized: loop vectorized using 32 byte vectors
Dense.c:28:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:28:20: optimized: loop vectorized using 16 byte vectors
Dense.c:28:20: missed: couldn't vectorize loop
Dense.c:30:20: missed: not vectorized: no vectype for stmt: _21 = *_20;
 scalar_type: float
Dense.c:20:13: note: vectorized 1 loops in function.
Dense.c:23:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:24:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:24:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:41:28: missed: couldn't vectorize loop
Dense.c:41:28: missed: not vectorized: unsupported outerloop form.
Dense.c:45:21: optimized: loop vectorized using 32 byte vectors
Dense.c:45:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:45:21: optimized: loop vectorized using 16 byte vectors
Dense.c:37:13: note: vectorized 1 loops in function.
Dense.c:37:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:37:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:41:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:148:19: missed: couldn't vectorize loop
Dense.c:148:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:139:19: missed: couldn't vectorize loop
Dense.c:139:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:132:13: note: vectorized 0 loops in function.
Dense.c:156:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:156:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:101:28: missed: couldn't vectorize loop
Dense.c:101:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:104:21: missed: couldn't vectorize loop
Dense.c:104:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:118:28: missed: couldn't vectorize loop
Dense.c:118:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:121:21: missed: couldn't vectorize loop
Dense.c:121:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:87:19: missed: couldn't vectorize loop
Dense.c:87:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:81:13: note: vectorized 0 loops in function.
Dense.c:84:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:106:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:106:17: note: SLPing BB part
Dense.c:123:17: note: Costing subgraph: 
Dense.c:123:17: note: node 0x6e5f008 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:123:17: note: op template: _49 = (sizetype) j_137;
Dense.c:123:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:123:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:123:17: note: 	children 0x6e5f108
Dense.c:123:17: note: node (external) 0x6e5f108 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:123:17: note: 	{ j_137, wi_136 }
Dense.c:123:17: note: Cost model analysis: 
Dense.c:123:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:123:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:123:17: missed: not vectorized: vectorization is not profitable.
Dense.c:106:17: note: Costing subgraph: 
Dense.c:106:17: note: node 0x6e5f208 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:106:17: note: op template: _24 = (sizetype) j_134;
Dense.c:106:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:106:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:106:17: note: 	children 0x6e5f308
Dense.c:106:17: note: node (external) 0x6e5f308 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:106:17: note: 	{ j_134, wi_133 }
Dense.c:106:17: note: Cost model analysis: 
Dense.c:106:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:106:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:106:17: missed: not vectorized: vectorization is not profitable.
Dense.c:106:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:106:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:106:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:106:17: note: SLPing BB part
Dense.c:123:17: note: Costing subgraph: 
Dense.c:123:17: note: node 0x6e5f208 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:123:17: note: op template: _49 = (sizetype) j_137;
Dense.c:123:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:123:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:123:17: note: 	children 0x6e5f008
Dense.c:123:17: note: node (external) 0x6e5f008 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:123:17: note: 	{ j_137, wi_136 }
Dense.c:123:17: note: Cost model analysis: 
Dense.c:123:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:123:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:123:17: missed: not vectorized: vectorization is not profitable.
Dense.c:106:17: note: Costing subgraph: 
Dense.c:106:17: note: node 0x6e5f388 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:106:17: note: op template: _24 = (sizetype) j_134;
Dense.c:106:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:106:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:106:17: note: 	children 0x6e5f288
Dense.c:106:17: note: node (external) 0x6e5f288 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:106:17: note: 	{ j_134, wi_133 }
Dense.c:106:17: note: Cost model analysis: 
Dense.c:106:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:106:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:106:17: missed: not vectorized: vectorization is not profitable.
Dense.c:106:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:101:55: note: ***** Analysis failed with vector mode V8QI
Dense.c:101:55: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:101:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:59:27: missed: couldn't vectorize loop
Dense.c:59:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:71:11: optimized: loop vectorized using 32 byte vectors
Dense.c:71:11: optimized: loop vectorized using 16 byte vectors
Dense.c:63:38: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:905:10: missed: not vectorized: no vectype for stmt: _61 = MEM[(__m256_u * {ref-all})_6];
 scalar_type: __m256_u
Dense.c:54:13: note: vectorized 1 loops in function.
Dense.c:77:2: missed: statement clobbers memory: _38 (pretmp_198, _69, 0);
Dense.c:54:13: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:54:13: note: SLPing BB part
Dense.c:65:14: note: Costing subgraph: 
Dense.c:65:14: note: node 0x6e8f038 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:65:14: note: op template: _3 = (sizetype) j_89;
Dense.c:65:14: note: 	stmt 0 _3 = (sizetype) j_89;
Dense.c:65:14: note: 	stmt 1 _162 = (sizetype) wi_88;
Dense.c:65:14: note: 	children 0x6e8f138
Dense.c:65:14: note: node (external) 0x6e8f138 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:65:14: note: 	{ j_89, wi_88 }
Dense.c:65:14: note: Cost model analysis: 
Dense.c:65:14: note: Scalar 1 and vector 2 loop part do not match up, skipping scalar part
Dense.c:65:14: note: Cost model analysis for part in loop 2:
  Vector cost: 36
  Scalar cost: 8
Dense.c:65:14: missed: not vectorized: vectorization is not profitable.
Dense.c:54:13: note: Costing subgraph: 
Dense.c:54:13: note: node 0x6e8f238 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:54:13: note: op template: _131 = (sizetype) j_90;
Dense.c:54:13: note: 	stmt 0 _131 = (sizetype) j_90;
Dense.c:54:13: note: 	stmt 1 _132 = (sizetype) wi_88;
Dense.c:54:13: note: 	children 0x6e8f338
Dense.c:54:13: note: node (external) 0x6e8f338 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:54:13: note: 	{ j_90, wi_88 }
Dense.c:54:13: note: Cost model analysis: 
Dense.c:54:13: note: Cost model analysis for part in loop 1:
  Vector cost: 36
  Scalar cost: 12
Dense.c:54:13: missed: not vectorized: vectorization is not profitable.
Dense.c:54:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:54:13: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:54:13: note: SLPing BB part
Dense.c:65:14: note: Costing subgraph: 
Dense.c:65:14: note: node 0x6e8f238 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:65:14: note: op template: _3 = (sizetype) j_89;
Dense.c:65:14: note: 	stmt 0 _3 = (sizetype) j_89;
Dense.c:65:14: note: 	stmt 1 _162 = (sizetype) wi_88;
Dense.c:65:14: note: 	children 0x6e8f038
Dense.c:65:14: note: node (external) 0x6e8f038 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:65:14: note: 	{ j_89, wi_88 }
Dense.c:65:14: note: Cost model analysis: 
Dense.c:65:14: note: Scalar 1 and vector 2 loop part do not match up, skipping scalar part
Dense.c:65:14: note: Cost model analysis for part in loop 2:
  Vector cost: 36
  Scalar cost: 8
Dense.c:65:14: missed: not vectorized: vectorization is not profitable.
Dense.c:54:13: note: Costing subgraph: 
Dense.c:54:13: note: node 0x6e8f3b8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:54:13: note: op template: _131 = (sizetype) j_90;
Dense.c:54:13: note: 	stmt 0 _131 = (sizetype) j_90;
Dense.c:54:13: note: 	stmt 1 _132 = (sizetype) wi_88;
Dense.c:54:13: note: 	children 0x6e8f638
Dense.c:54:13: note: node (external) 0x6e8f638 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:54:13: note: 	{ j_90, wi_88 }
Dense.c:54:13: note: Cost model analysis: 
Dense.c:54:13: note: Cost model analysis for part in loop 1:
  Vector cost: 36
  Scalar cost: 12
Dense.c:54:13: missed: not vectorized: vectorization is not profitable.
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:59:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:59:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:59:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:163:2: missed: statement clobbers memory: free (_1);
Dense.c:164:2: missed: statement clobbers memory: free (_2);
Dense.c:165:2: missed: statement clobbers memory: free (_3);
Dense.c:166:2: missed: statement clobbers memory: free (_4);
Dense.c:167:2: missed: statement clobbers memory: free (dense_7);
Dense.c:168:2: missed: statement clobbers memory: PULSE_DestroyLayer (this_6(D));
Dense.c:169:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:169:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:183:19: missed: couldn't vectorize loop
Dense.c:183:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:173:13: note: vectorized 0 loops in function.
Dense.c:175:47: missed: statement clobbers memory: dense_35 = malloc (40);
Dense.c:177:36: missed: statement clobbers memory: _5 = aligned_alloc (64, _4);
Dense.c:178:38: missed: statement clobbers memory: _6 = aligned_alloc (64, _4);
Dense.c:179:36: missed: statement clobbers memory: _8 = aligned_alloc (64, _7);
Dense.c:180:35: missed: statement clobbers memory: _9 = aligned_alloc (64, _7);
Dense.c:181:36: missed: statement clobbers memory: _10 = aligned_alloc (64, _7);
Dense.c:184:39: missed: statement clobbers memory: _11 = rand ();
Dense.c:184:73: missed: statement clobbers memory: _63 = sqrt (_18);
Dense.c:196:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:197:4: missed: statement clobbers memory: exit (1);
Dense.c:193:4: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.3_29, n_outputs.2_28, 1, activation_function_51(D), _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:190:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.1_27, n_outputs.0_26, 1, activation_function_51(D), _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:203:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Dense.c:203:9: note: ***** Analysis failed with vector mode V4DI
Dense.c:203:9: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:9:27: missed: couldn't vectorize loop
Dense.c:9:27: missed: not vectorized: unsupported outerloop form.
Dense.c:12:20: missed: couldn't vectorize loop
Dense.c:13:21: missed: not vectorized: complicated access pattern.
Dense.c:6:13: note: vectorized 0 loops in function.
Dense.c:16:2: missed: statement clobbers memory: _30 (pretmp_91, _50, 0);
Dense.c:9:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:9:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:24:27: missed: couldn't vectorize loop
Dense.c:24:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:28:20: optimized: loop vectorized using 32 byte vectors
Dense.c:28:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:28:20: optimized: loop vectorized using 16 byte vectors
Dense.c:28:20: missed: couldn't vectorize loop
Dense.c:30:20: missed: not vectorized: no vectype for stmt: _21 = *_20;
 scalar_type: float
Dense.c:20:13: note: vectorized 1 loops in function.
Dense.c:23:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:24:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:24:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:41:28: missed: couldn't vectorize loop
Dense.c:41:28: missed: not vectorized: unsupported outerloop form.
Dense.c:45:21: optimized: loop vectorized using 32 byte vectors
Dense.c:45:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:45:21: optimized: loop vectorized using 16 byte vectors
Dense.c:37:13: note: vectorized 1 loops in function.
Dense.c:37:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:37:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:41:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:148:19: missed: couldn't vectorize loop
Dense.c:148:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:139:19: missed: couldn't vectorize loop
Dense.c:139:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:132:13: note: vectorized 0 loops in function.
Dense.c:156:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:156:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:101:28: missed: couldn't vectorize loop
Dense.c:101:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:104:21: missed: couldn't vectorize loop
Dense.c:104:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:118:28: missed: couldn't vectorize loop
Dense.c:118:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:121:21: missed: couldn't vectorize loop
Dense.c:121:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:87:19: missed: couldn't vectorize loop
Dense.c:87:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:81:13: note: vectorized 0 loops in function.
Dense.c:84:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:106:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:106:17: note: SLPing BB part
Dense.c:123:17: note: Costing subgraph: 
Dense.c:123:17: note: node 0x885dd78 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:123:17: note: op template: _49 = (sizetype) j_137;
Dense.c:123:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:123:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:123:17: note: 	children 0x885de78
Dense.c:123:17: note: node (external) 0x885de78 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:123:17: note: 	{ j_137, wi_136 }
Dense.c:123:17: note: Cost model analysis: 
Dense.c:123:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:123:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:123:17: missed: not vectorized: vectorization is not profitable.
Dense.c:106:17: note: Costing subgraph: 
Dense.c:106:17: note: node 0x885df78 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:106:17: note: op template: _24 = (sizetype) j_134;
Dense.c:106:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:106:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:106:17: note: 	children 0x885e078
Dense.c:106:17: note: node (external) 0x885e078 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:106:17: note: 	{ j_134, wi_133 }
Dense.c:106:17: note: Cost model analysis: 
Dense.c:106:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:106:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:106:17: missed: not vectorized: vectorization is not profitable.
Dense.c:106:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:106:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:106:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:106:17: note: SLPing BB part
Dense.c:123:17: note: Costing subgraph: 
Dense.c:123:17: note: node 0x885df78 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:123:17: note: op template: _49 = (sizetype) j_137;
Dense.c:123:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:123:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:123:17: note: 	children 0x885dd78
Dense.c:123:17: note: node (external) 0x885dd78 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:123:17: note: 	{ j_137, wi_136 }
Dense.c:123:17: note: Cost model analysis: 
Dense.c:123:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:123:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:123:17: missed: not vectorized: vectorization is not profitable.
Dense.c:106:17: note: Costing subgraph: 
Dense.c:106:17: note: node 0x885e0f8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:106:17: note: op template: _24 = (sizetype) j_134;
Dense.c:106:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:106:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:106:17: note: 	children 0x885dff8
Dense.c:106:17: note: node (external) 0x885dff8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:106:17: note: 	{ j_134, wi_133 }
Dense.c:106:17: note: Cost model analysis: 
Dense.c:106:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:106:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:106:17: missed: not vectorized: vectorization is not profitable.
Dense.c:106:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:101:55: note: ***** Analysis failed with vector mode V8QI
Dense.c:101:55: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:101:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:60:22: missed: couldn't vectorize loop
Dense.c:60:22: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:71:11: optimized: loop vectorized using 32 byte vectors
Dense.c:71:11: optimized: loop vectorized using 16 byte vectors
Dense.c:63:38: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:905:10: missed: not vectorized: no vectype for stmt: _55 = MEM[(__m256_u * {ref-all})_3];
 scalar_type: __m256_u
Dense.c:54:13: note: vectorized 1 loops in function.
Dense.c:77:2: missed: statement clobbers memory: _30 (pretmp_182, _63, 0);
Dense.c:54:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:54:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:163:2: missed: statement clobbers memory: free (_1);
Dense.c:164:2: missed: statement clobbers memory: free (_2);
Dense.c:165:2: missed: statement clobbers memory: free (_3);
Dense.c:166:2: missed: statement clobbers memory: free (_4);
Dense.c:167:2: missed: statement clobbers memory: free (dense_7);
Dense.c:168:2: missed: statement clobbers memory: PULSE_DestroyLayer (this_6(D));
Dense.c:169:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:169:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:183:19: missed: couldn't vectorize loop
Dense.c:183:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:173:13: note: vectorized 0 loops in function.
Dense.c:175:47: missed: statement clobbers memory: dense_35 = malloc (40);
Dense.c:177:36: missed: statement clobbers memory: _5 = aligned_alloc (64, _4);
Dense.c:178:38: missed: statement clobbers memory: _6 = aligned_alloc (64, _4);
Dense.c:179:36: missed: statement clobbers memory: _8 = aligned_alloc (64, _7);
Dense.c:180:35: missed: statement clobbers memory: _9 = aligned_alloc (64, _7);
Dense.c:181:36: missed: statement clobbers memory: _10 = aligned_alloc (64, _7);
Dense.c:184:39: missed: statement clobbers memory: _11 = rand ();
Dense.c:184:73: missed: statement clobbers memory: _63 = sqrt (_18);
Dense.c:196:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:197:4: missed: statement clobbers memory: exit (1);
Dense.c:193:4: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.3_29, n_outputs.2_28, 1, activation_function_51(D), _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:190:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.1_27, n_outputs.0_26, 1, activation_function_51(D), _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:203:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Dense.c:203:9: note: ***** Analysis failed with vector mode V4DI
Dense.c:203:9: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:9:27: missed: couldn't vectorize loop
Dense.c:9:27: missed: not vectorized: unsupported outerloop form.
Dense.c:12:20: missed: couldn't vectorize loop
Dense.c:13:21: missed: not vectorized: complicated access pattern.
Dense.c:6:13: note: vectorized 0 loops in function.
Dense.c:16:2: missed: statement clobbers memory: _30 (pretmp_91, _50, 0);
Dense.c:9:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:9:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:24:27: missed: couldn't vectorize loop
Dense.c:24:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:28:20: optimized: loop vectorized using 32 byte vectors
Dense.c:28:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:28:20: optimized: loop vectorized using 16 byte vectors
Dense.c:28:20: missed: couldn't vectorize loop
Dense.c:30:20: missed: not vectorized: no vectype for stmt: _21 = *_20;
 scalar_type: float
Dense.c:20:13: note: vectorized 1 loops in function.
Dense.c:23:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:24:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:24:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:41:28: missed: couldn't vectorize loop
Dense.c:41:28: missed: not vectorized: unsupported outerloop form.
Dense.c:45:21: optimized: loop vectorized using 32 byte vectors
Dense.c:45:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:45:21: optimized: loop vectorized using 16 byte vectors
Dense.c:37:13: note: vectorized 1 loops in function.
Dense.c:37:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:37:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:41:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:149:19: missed: couldn't vectorize loop
Dense.c:149:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:140:19: missed: couldn't vectorize loop
Dense.c:140:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:133:13: note: vectorized 0 loops in function.
Dense.c:157:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:157:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:102:28: missed: couldn't vectorize loop
Dense.c:102:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:105:21: missed: couldn't vectorize loop
Dense.c:105:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:119:28: missed: couldn't vectorize loop
Dense.c:119:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:122:21: missed: couldn't vectorize loop
Dense.c:122:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:88:19: missed: couldn't vectorize loop
Dense.c:88:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:82:13: note: vectorized 0 loops in function.
Dense.c:85:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:107:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:107:17: note: SLPing BB part
Dense.c:124:17: note: Costing subgraph: 
Dense.c:124:17: note: node 0x8135ae8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:124:17: note: op template: _49 = (sizetype) j_137;
Dense.c:124:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:124:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:124:17: note: 	children 0x8135be8
Dense.c:124:17: note: node (external) 0x8135be8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:124:17: note: 	{ j_137, wi_136 }
Dense.c:124:17: note: Cost model analysis: 
Dense.c:124:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:124:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:124:17: missed: not vectorized: vectorization is not profitable.
Dense.c:107:17: note: Costing subgraph: 
Dense.c:107:17: note: node 0x8135ce8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:107:17: note: op template: _24 = (sizetype) j_134;
Dense.c:107:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:107:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:107:17: note: 	children 0x8135de8
Dense.c:107:17: note: node (external) 0x8135de8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:107:17: note: 	{ j_134, wi_133 }
Dense.c:107:17: note: Cost model analysis: 
Dense.c:107:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:107:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:107:17: missed: not vectorized: vectorization is not profitable.
Dense.c:107:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:107:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:107:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:107:17: note: SLPing BB part
Dense.c:124:17: note: Costing subgraph: 
Dense.c:124:17: note: node 0x8135ce8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:124:17: note: op template: _49 = (sizetype) j_137;
Dense.c:124:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:124:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:124:17: note: 	children 0x8135ae8
Dense.c:124:17: note: node (external) 0x8135ae8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:124:17: note: 	{ j_137, wi_136 }
Dense.c:124:17: note: Cost model analysis: 
Dense.c:124:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:124:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:124:17: missed: not vectorized: vectorization is not profitable.
Dense.c:107:17: note: Costing subgraph: 
Dense.c:107:17: note: node 0x8135e68 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:107:17: note: op template: _24 = (sizetype) j_134;
Dense.c:107:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:107:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:107:17: note: 	children 0x8135d68
Dense.c:107:17: note: node (external) 0x8135d68 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:107:17: note: 	{ j_134, wi_133 }
Dense.c:107:17: note: Cost model analysis: 
Dense.c:107:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:107:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:107:17: missed: not vectorized: vectorization is not profitable.
Dense.c:107:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:102:55: note: ***** Analysis failed with vector mode V8QI
Dense.c:102:55: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:102:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:61:22: missed: couldn't vectorize loop
Dense.c:61:22: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:72:11: optimized: loop vectorized using 32 byte vectors
Dense.c:72:11: optimized: loop vectorized using 16 byte vectors
Dense.c:64:38: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:905:10: missed: not vectorized: no vectype for stmt: _55 = MEM[(__m256_u * {ref-all})_3];
 scalar_type: __m256_u
Dense.c:54:13: note: vectorized 1 loops in function.
Dense.c:78:2: missed: statement clobbers memory: _30 (pretmp_182, _63, 0);
Dense.c:54:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:54:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:164:2: missed: statement clobbers memory: free (_1);
Dense.c:165:2: missed: statement clobbers memory: free (_2);
Dense.c:166:2: missed: statement clobbers memory: free (_3);
Dense.c:167:2: missed: statement clobbers memory: free (_4);
Dense.c:168:2: missed: statement clobbers memory: free (dense_7);
Dense.c:169:2: missed: statement clobbers memory: PULSE_DestroyLayer (this_6(D));
Dense.c:170:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:170:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:184:19: missed: couldn't vectorize loop
Dense.c:184:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:174:13: note: vectorized 0 loops in function.
Dense.c:176:47: missed: statement clobbers memory: dense_35 = malloc (40);
Dense.c:178:36: missed: statement clobbers memory: _5 = aligned_alloc (64, _4);
Dense.c:179:38: missed: statement clobbers memory: _6 = aligned_alloc (64, _4);
Dense.c:180:36: missed: statement clobbers memory: _8 = aligned_alloc (64, _7);
Dense.c:181:35: missed: statement clobbers memory: _9 = aligned_alloc (64, _7);
Dense.c:182:36: missed: statement clobbers memory: _10 = aligned_alloc (64, _7);
Dense.c:185:39: missed: statement clobbers memory: _11 = rand ();
Dense.c:185:73: missed: statement clobbers memory: _63 = sqrt (_18);
Dense.c:197:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:198:4: missed: statement clobbers memory: exit (1);
Dense.c:194:4: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.3_29, n_outputs.2_28, 1, activation_function_51(D), _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:191:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.1_27, n_outputs.0_26, 1, activation_function_51(D), _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:204:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Dense.c:204:9: note: ***** Analysis failed with vector mode V4DI
Dense.c:204:9: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:9:27: missed: couldn't vectorize loop
Dense.c:9:27: missed: not vectorized: unsupported outerloop form.
Dense.c:12:20: missed: couldn't vectorize loop
Dense.c:13:21: missed: not vectorized: complicated access pattern.
Dense.c:6:13: note: vectorized 0 loops in function.
Dense.c:16:2: missed: statement clobbers memory: _30 (pretmp_91, _50, 0);
Dense.c:9:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:9:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:24:27: missed: couldn't vectorize loop
Dense.c:24:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:28:20: optimized: loop vectorized using 32 byte vectors
Dense.c:28:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:28:20: optimized: loop vectorized using 16 byte vectors
Dense.c:28:20: missed: couldn't vectorize loop
Dense.c:30:20: missed: not vectorized: no vectype for stmt: _21 = *_20;
 scalar_type: float
Dense.c:20:13: note: vectorized 1 loops in function.
Dense.c:23:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:24:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:24:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:41:28: missed: couldn't vectorize loop
Dense.c:41:28: missed: not vectorized: unsupported outerloop form.
Dense.c:45:21: optimized: loop vectorized using 32 byte vectors
Dense.c:45:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:45:21: optimized: loop vectorized using 16 byte vectors
Dense.c:37:13: note: vectorized 1 loops in function.
Dense.c:37:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:37:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:41:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:149:19: missed: couldn't vectorize loop
Dense.c:149:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:140:19: missed: couldn't vectorize loop
Dense.c:140:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:133:13: note: vectorized 0 loops in function.
Dense.c:157:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:157:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:102:28: missed: couldn't vectorize loop
Dense.c:102:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:105:21: missed: couldn't vectorize loop
Dense.c:105:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:119:28: missed: couldn't vectorize loop
Dense.c:119:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:122:21: missed: couldn't vectorize loop
Dense.c:122:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:88:19: missed: couldn't vectorize loop
Dense.c:88:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:82:13: note: vectorized 0 loops in function.
Dense.c:85:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:107:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:107:17: note: SLPing BB part
Dense.c:124:17: note: Costing subgraph: 
Dense.c:124:17: note: node 0x83f12e8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:124:17: note: op template: _49 = (sizetype) j_137;
Dense.c:124:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:124:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:124:17: note: 	children 0x83f13e8
Dense.c:124:17: note: node (external) 0x83f13e8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:124:17: note: 	{ j_137, wi_136 }
Dense.c:124:17: note: Cost model analysis: 
Dense.c:124:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:124:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:124:17: missed: not vectorized: vectorization is not profitable.
Dense.c:107:17: note: Costing subgraph: 
Dense.c:107:17: note: node 0x83f14e8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:107:17: note: op template: _24 = (sizetype) j_134;
Dense.c:107:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:107:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:107:17: note: 	children 0x83f15e8
Dense.c:107:17: note: node (external) 0x83f15e8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:107:17: note: 	{ j_134, wi_133 }
Dense.c:107:17: note: Cost model analysis: 
Dense.c:107:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:107:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:107:17: missed: not vectorized: vectorization is not profitable.
Dense.c:107:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:107:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:107:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:107:17: note: SLPing BB part
Dense.c:124:17: note: Costing subgraph: 
Dense.c:124:17: note: node 0x83f14e8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:124:17: note: op template: _49 = (sizetype) j_137;
Dense.c:124:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:124:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:124:17: note: 	children 0x83f12e8
Dense.c:124:17: note: node (external) 0x83f12e8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:124:17: note: 	{ j_137, wi_136 }
Dense.c:124:17: note: Cost model analysis: 
Dense.c:124:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:124:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:124:17: missed: not vectorized: vectorization is not profitable.
Dense.c:107:17: note: Costing subgraph: 
Dense.c:107:17: note: node 0x83f1668 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:107:17: note: op template: _24 = (sizetype) j_134;
Dense.c:107:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:107:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:107:17: note: 	children 0x83f1568
Dense.c:107:17: note: node (external) 0x83f1568 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:107:17: note: 	{ j_134, wi_133 }
Dense.c:107:17: note: Cost model analysis: 
Dense.c:107:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:107:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:107:17: missed: not vectorized: vectorization is not profitable.
Dense.c:107:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:102:55: note: ***** Analysis failed with vector mode V8QI
Dense.c:102:55: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:102:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:61:22: missed: couldn't vectorize loop
Dense.c:76:45: missed: not vectorized: no vectype for stmt: _95 = *_96;
 scalar_type: float
Dense.c:61:22: missed: couldn't vectorize loop
Dense.c:61:22: missed: not vectorized: unsupported outerloop form.
Dense.c:64:38: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:905:10: missed: not vectorized: no vectype for stmt: _42 = MEM[(__m256_u * {ref-all})_3];
 scalar_type: __m256_u
Dense.c:54:13: note: vectorized 0 loops in function.
Dense.c:78:2: missed: statement clobbers memory: _21 (pretmp_136, _49, 0);
Dense.c:79:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:79:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:164:2: missed: statement clobbers memory: free (_1);
Dense.c:165:2: missed: statement clobbers memory: free (_2);
Dense.c:166:2: missed: statement clobbers memory: free (_3);
Dense.c:167:2: missed: statement clobbers memory: free (_4);
Dense.c:168:2: missed: statement clobbers memory: free (dense_7);
Dense.c:169:2: missed: statement clobbers memory: PULSE_DestroyLayer (this_6(D));
Dense.c:170:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:170:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:184:19: missed: couldn't vectorize loop
Dense.c:184:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:174:13: note: vectorized 0 loops in function.
Dense.c:176:47: missed: statement clobbers memory: dense_35 = malloc (40);
Dense.c:178:36: missed: statement clobbers memory: _5 = aligned_alloc (64, _4);
Dense.c:179:38: missed: statement clobbers memory: _6 = aligned_alloc (64, _4);
Dense.c:180:36: missed: statement clobbers memory: _8 = aligned_alloc (64, _7);
Dense.c:181:35: missed: statement clobbers memory: _9 = aligned_alloc (64, _7);
Dense.c:182:36: missed: statement clobbers memory: _10 = aligned_alloc (64, _7);
Dense.c:185:39: missed: statement clobbers memory: _11 = rand ();
Dense.c:185:73: missed: statement clobbers memory: _63 = sqrt (_18);
Dense.c:197:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:198:4: missed: statement clobbers memory: exit (1);
Dense.c:194:4: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.3_29, n_outputs.2_28, 1, activation_function_51(D), _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:191:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.1_27, n_outputs.0_26, 1, activation_function_51(D), _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:204:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Dense.c:204:9: note: ***** Analysis failed with vector mode V4DI
Dense.c:204:9: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:9:27: missed: couldn't vectorize loop
Dense.c:9:27: missed: not vectorized: unsupported outerloop form.
Dense.c:12:20: missed: couldn't vectorize loop
Dense.c:13:21: missed: not vectorized: complicated access pattern.
Dense.c:6:13: note: vectorized 0 loops in function.
Dense.c:16:2: missed: statement clobbers memory: _30 (pretmp_91, _50, 0);
Dense.c:9:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:9:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:24:27: missed: couldn't vectorize loop
Dense.c:24:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:28:20: optimized: loop vectorized using 32 byte vectors
Dense.c:28:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:28:20: optimized: loop vectorized using 16 byte vectors
Dense.c:28:20: missed: couldn't vectorize loop
Dense.c:30:20: missed: not vectorized: no vectype for stmt: _21 = *_20;
 scalar_type: float
Dense.c:20:13: note: vectorized 1 loops in function.
Dense.c:23:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:24:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:24:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:41:28: missed: couldn't vectorize loop
Dense.c:41:28: missed: not vectorized: unsupported outerloop form.
Dense.c:45:21: optimized: loop vectorized using 32 byte vectors
Dense.c:45:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:45:21: optimized: loop vectorized using 16 byte vectors
Dense.c:37:13: note: vectorized 1 loops in function.
Dense.c:37:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:37:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:41:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:149:19: missed: couldn't vectorize loop
Dense.c:149:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:140:19: missed: couldn't vectorize loop
Dense.c:140:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:133:13: note: vectorized 0 loops in function.
Dense.c:157:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:157:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:102:28: missed: couldn't vectorize loop
Dense.c:102:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:105:21: missed: couldn't vectorize loop
Dense.c:105:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:119:28: missed: couldn't vectorize loop
Dense.c:119:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:122:21: missed: couldn't vectorize loop
Dense.c:122:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:88:19: missed: couldn't vectorize loop
Dense.c:88:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:82:13: note: vectorized 0 loops in function.
Dense.c:85:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:107:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:107:17: note: SLPing BB part
Dense.c:124:17: note: Costing subgraph: 
Dense.c:124:17: note: node 0x7bed9e8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:124:17: note: op template: _49 = (sizetype) j_137;
Dense.c:124:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:124:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:124:17: note: 	children 0x7bedae8
Dense.c:124:17: note: node (external) 0x7bedae8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:124:17: note: 	{ j_137, wi_136 }
Dense.c:124:17: note: Cost model analysis: 
Dense.c:124:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:124:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:124:17: missed: not vectorized: vectorization is not profitable.
Dense.c:107:17: note: Costing subgraph: 
Dense.c:107:17: note: node 0x7bedbe8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:107:17: note: op template: _24 = (sizetype) j_134;
Dense.c:107:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:107:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:107:17: note: 	children 0x7bedce8
Dense.c:107:17: note: node (external) 0x7bedce8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:107:17: note: 	{ j_134, wi_133 }
Dense.c:107:17: note: Cost model analysis: 
Dense.c:107:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:107:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:107:17: missed: not vectorized: vectorization is not profitable.
Dense.c:107:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:107:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:107:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:107:17: note: SLPing BB part
Dense.c:124:17: note: Costing subgraph: 
Dense.c:124:17: note: node 0x7bedbe8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:124:17: note: op template: _49 = (sizetype) j_137;
Dense.c:124:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:124:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:124:17: note: 	children 0x7bed9e8
Dense.c:124:17: note: node (external) 0x7bed9e8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:124:17: note: 	{ j_137, wi_136 }
Dense.c:124:17: note: Cost model analysis: 
Dense.c:124:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:124:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:124:17: missed: not vectorized: vectorization is not profitable.
Dense.c:107:17: note: Costing subgraph: 
Dense.c:107:17: note: node 0x7bedd68 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:107:17: note: op template: _24 = (sizetype) j_134;
Dense.c:107:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:107:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:107:17: note: 	children 0x7bedc68
Dense.c:107:17: note: node (external) 0x7bedc68 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:107:17: note: 	{ j_134, wi_133 }
Dense.c:107:17: note: Cost model analysis: 
Dense.c:107:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:107:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:107:17: missed: not vectorized: vectorization is not profitable.
Dense.c:107:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:102:55: note: ***** Analysis failed with vector mode V8QI
Dense.c:102:55: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:102:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:61:22: missed: couldn't vectorize loop
Dense.c:76:45: missed: not vectorized: no vectype for stmt: _102 = *_103;
 scalar_type: float
Dense.c:61:22: missed: couldn't vectorize loop
Dense.c:61:22: missed: not vectorized: unsupported outerloop form.
Dense.c:64:38: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:905:10: missed: not vectorized: no vectype for stmt: _42 = MEM[(__m256_u * {ref-all})_6];
 scalar_type: __m256_u
Dense.c:54:13: note: vectorized 0 loops in function.
Dense.c:78:2: missed: statement clobbers memory: _23 (pretmp_147, _49, 0);
Dense.c:66:14: note: ***** Analysis failed with vector mode V4DI
Dense.c:66:14: note: ***** The result for vector mode V32QI would be the same
Dense.c:66:14: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:66:14: note: ***** Analysis failed with vector mode V16QI
Dense.c:66:14: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:66:14: note: ***** Analysis failed with vector mode V8QI
Dense.c:66:14: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:66:14: note: ***** Analysis failed with vector mode V4QI
Dense.c:164:2: missed: statement clobbers memory: free (_1);
Dense.c:165:2: missed: statement clobbers memory: free (_2);
Dense.c:166:2: missed: statement clobbers memory: free (_3);
Dense.c:167:2: missed: statement clobbers memory: free (_4);
Dense.c:168:2: missed: statement clobbers memory: free (dense_7);
Dense.c:169:2: missed: statement clobbers memory: PULSE_DestroyLayer (this_6(D));
Dense.c:170:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:170:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:184:19: missed: couldn't vectorize loop
Dense.c:184:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:174:13: note: vectorized 0 loops in function.
Dense.c:176:47: missed: statement clobbers memory: dense_35 = malloc (40);
Dense.c:178:36: missed: statement clobbers memory: _5 = aligned_alloc (64, _4);
Dense.c:179:38: missed: statement clobbers memory: _6 = aligned_alloc (64, _4);
Dense.c:180:36: missed: statement clobbers memory: _8 = aligned_alloc (64, _7);
Dense.c:181:35: missed: statement clobbers memory: _9 = aligned_alloc (64, _7);
Dense.c:182:36: missed: statement clobbers memory: _10 = aligned_alloc (64, _7);
Dense.c:185:39: missed: statement clobbers memory: _11 = rand ();
Dense.c:185:73: missed: statement clobbers memory: _63 = sqrt (_18);
Dense.c:197:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:198:4: missed: statement clobbers memory: exit (1);
Dense.c:194:4: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.3_29, n_outputs.2_28, 1, activation_function_51(D), _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:191:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.1_27, n_outputs.0_26, 1, activation_function_51(D), _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:204:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Dense.c:204:9: note: ***** Analysis failed with vector mode V4DI
Dense.c:204:9: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:9:27: missed: couldn't vectorize loop
Dense.c:9:27: missed: not vectorized: unsupported outerloop form.
Dense.c:12:20: missed: couldn't vectorize loop
Dense.c:13:21: missed: not vectorized: complicated access pattern.
Dense.c:6:13: note: vectorized 0 loops in function.
Dense.c:16:2: missed: statement clobbers memory: _30 (pretmp_91, _50, 0);
Dense.c:9:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:9:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:24:27: missed: couldn't vectorize loop
Dense.c:24:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:28:20: optimized: loop vectorized using 32 byte vectors
Dense.c:28:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:28:20: optimized: loop vectorized using 16 byte vectors
Dense.c:28:20: missed: couldn't vectorize loop
Dense.c:30:20: missed: not vectorized: no vectype for stmt: _21 = *_20;
 scalar_type: float
Dense.c:20:13: note: vectorized 1 loops in function.
Dense.c:23:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:24:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:24:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:41:28: missed: couldn't vectorize loop
Dense.c:41:28: missed: not vectorized: unsupported outerloop form.
Dense.c:45:21: optimized: loop vectorized using 32 byte vectors
Dense.c:45:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:45:21: optimized: loop vectorized using 16 byte vectors
Dense.c:37:13: note: vectorized 1 loops in function.
Dense.c:37:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:37:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:41:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:150:19: missed: couldn't vectorize loop
Dense.c:150:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:141:19: missed: couldn't vectorize loop
Dense.c:141:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:134:13: note: vectorized 0 loops in function.
Dense.c:158:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:158:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:103:28: missed: couldn't vectorize loop
Dense.c:103:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:106:21: missed: couldn't vectorize loop
Dense.c:106:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:120:28: missed: couldn't vectorize loop
Dense.c:120:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:123:21: missed: couldn't vectorize loop
Dense.c:123:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:89:19: missed: couldn't vectorize loop
Dense.c:89:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:83:13: note: vectorized 0 loops in function.
Dense.c:86:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:108:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:108:17: note: SLPing BB part
Dense.c:125:17: note: Costing subgraph: 
Dense.c:125:17: note: node 0x7b0e9e8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:125:17: note: op template: _49 = (sizetype) j_137;
Dense.c:125:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:125:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:125:17: note: 	children 0x7b0eae8
Dense.c:125:17: note: node (external) 0x7b0eae8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:125:17: note: 	{ j_137, wi_136 }
Dense.c:125:17: note: Cost model analysis: 
Dense.c:125:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:125:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:125:17: missed: not vectorized: vectorization is not profitable.
Dense.c:108:17: note: Costing subgraph: 
Dense.c:108:17: note: node 0x7b0ebe8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:108:17: note: op template: _24 = (sizetype) j_134;
Dense.c:108:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:108:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:108:17: note: 	children 0x7b0ece8
Dense.c:108:17: note: node (external) 0x7b0ece8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:108:17: note: 	{ j_134, wi_133 }
Dense.c:108:17: note: Cost model analysis: 
Dense.c:108:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:108:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:108:17: missed: not vectorized: vectorization is not profitable.
Dense.c:108:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:108:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:108:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:108:17: note: SLPing BB part
Dense.c:125:17: note: Costing subgraph: 
Dense.c:125:17: note: node 0x7b0ebe8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:125:17: note: op template: _49 = (sizetype) j_137;
Dense.c:125:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:125:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:125:17: note: 	children 0x7b0e9e8
Dense.c:125:17: note: node (external) 0x7b0e9e8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:125:17: note: 	{ j_137, wi_136 }
Dense.c:125:17: note: Cost model analysis: 
Dense.c:125:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:125:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:125:17: missed: not vectorized: vectorization is not profitable.
Dense.c:108:17: note: Costing subgraph: 
Dense.c:108:17: note: node 0x7b0ed68 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:108:17: note: op template: _24 = (sizetype) j_134;
Dense.c:108:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:108:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:108:17: note: 	children 0x7b0ec68
Dense.c:108:17: note: node (external) 0x7b0ec68 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:108:17: note: 	{ j_134, wi_133 }
Dense.c:108:17: note: Cost model analysis: 
Dense.c:108:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:108:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:108:17: missed: not vectorized: vectorization is not profitable.
Dense.c:108:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:103:55: note: ***** Analysis failed with vector mode V8QI
Dense.c:103:55: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:103:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:61:27: missed: couldn't vectorize loop
Dense.c:77:45: missed: not vectorized: no vectype for stmt: _108 = *_109;
 scalar_type: float
Dense.c:61:27: missed: couldn't vectorize loop
Dense.c:61:27: missed: not vectorized: unsupported outerloop form.
Dense.c:64:38: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:905:10: missed: not vectorized: no vectype for stmt: _46 = MEM[(__m256_u * {ref-all})_6];
 scalar_type: __m256_u
Dense.c:54:13: note: vectorized 0 loops in function.
Dense.c:79:2: missed: statement clobbers memory: _25 (pretmp_156, _53, 0);
Dense.c:66:14: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:66:14: note: SLPing BB part
Dense.c:66:14: note: Costing subgraph: 
Dense.c:66:14: note: node 0x7b3ea18 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:66:14: note: op template: _3 = (sizetype) j_68;
Dense.c:66:14: note: 	stmt 0 _3 = (sizetype) j_68;
Dense.c:66:14: note: 	stmt 1 _140 = (sizetype) wi_72;
Dense.c:66:14: note: 	children 0x7b3eb18
Dense.c:66:14: note: node (external) 0x7b3eb18 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:66:14: note: 	{ j_68, wi_72 }
Dense.c:66:14: note: Cost model analysis: 
Dense.c:66:14: note: Scalar 1 and vector 2 loop part do not match up, skipping scalar part
Dense.c:66:14: note: Cost model analysis for part in loop 2:
  Vector cost: 36
  Scalar cost: 8
Dense.c:66:14: missed: not vectorized: vectorization is not profitable.
Dense.c:66:14: note: ***** The result for vector mode V32QI would be the same
Dense.c:66:14: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:66:14: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:66:14: note: SLPing BB part
Dense.c:66:14: note: Costing subgraph: 
Dense.c:66:14: note: node 0x7b3ea18 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:66:14: note: op template: _3 = (sizetype) j_68;
Dense.c:66:14: note: 	stmt 0 _3 = (sizetype) j_68;
Dense.c:66:14: note: 	stmt 1 _140 = (sizetype) wi_72;
Dense.c:66:14: note: 	children 0x7b3ea98
Dense.c:66:14: note: node (external) 0x7b3ea98 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:66:14: note: 	{ j_68, wi_72 }
Dense.c:66:14: note: Cost model analysis: 
Dense.c:66:14: note: Scalar 1 and vector 2 loop part do not match up, skipping scalar part
Dense.c:66:14: note: Cost model analysis for part in loop 2:
  Vector cost: 36
  Scalar cost: 8
Dense.c:66:14: missed: not vectorized: vectorization is not profitable.
Dense.c:66:14: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:61:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:61:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:61:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:165:2: missed: statement clobbers memory: free (_1);
Dense.c:166:2: missed: statement clobbers memory: free (_2);
Dense.c:167:2: missed: statement clobbers memory: free (_3);
Dense.c:168:2: missed: statement clobbers memory: free (_4);
Dense.c:169:2: missed: statement clobbers memory: free (dense_7);
Dense.c:170:2: missed: statement clobbers memory: PULSE_DestroyLayer (this_6(D));
Dense.c:171:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:171:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:185:19: missed: couldn't vectorize loop
Dense.c:185:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:175:13: note: vectorized 0 loops in function.
Dense.c:177:47: missed: statement clobbers memory: dense_35 = malloc (40);
Dense.c:179:36: missed: statement clobbers memory: _5 = aligned_alloc (64, _4);
Dense.c:180:38: missed: statement clobbers memory: _6 = aligned_alloc (64, _4);
Dense.c:181:36: missed: statement clobbers memory: _8 = aligned_alloc (64, _7);
Dense.c:182:35: missed: statement clobbers memory: _9 = aligned_alloc (64, _7);
Dense.c:183:36: missed: statement clobbers memory: _10 = aligned_alloc (64, _7);
Dense.c:186:39: missed: statement clobbers memory: _11 = rand ();
Dense.c:186:73: missed: statement clobbers memory: _63 = sqrt (_18);
Dense.c:198:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:199:4: missed: statement clobbers memory: exit (1);
Dense.c:195:4: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.3_29, n_outputs.2_28, 1, activation_function_51(D), _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:192:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.1_27, n_outputs.0_26, 1, activation_function_51(D), _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:205:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Dense.c:205:9: note: ***** Analysis failed with vector mode V4DI
Dense.c:205:9: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:9:27: missed: couldn't vectorize loop
Dense.c:9:27: missed: not vectorized: unsupported outerloop form.
Dense.c:12:20: missed: couldn't vectorize loop
Dense.c:13:21: missed: not vectorized: complicated access pattern.
Dense.c:6:13: note: vectorized 0 loops in function.
Dense.c:16:2: missed: statement clobbers memory: _30 (pretmp_91, _50, 0);
Dense.c:9:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:9:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:24:27: missed: couldn't vectorize loop
Dense.c:24:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:28:20: optimized: loop vectorized using 32 byte vectors
Dense.c:28:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:28:20: optimized: loop vectorized using 16 byte vectors
Dense.c:28:20: missed: couldn't vectorize loop
Dense.c:30:20: missed: not vectorized: no vectype for stmt: _21 = *_20;
 scalar_type: float
Dense.c:20:13: note: vectorized 1 loops in function.
Dense.c:23:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:24:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:24:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:41:28: missed: couldn't vectorize loop
Dense.c:41:28: missed: not vectorized: unsupported outerloop form.
Dense.c:45:21: optimized: loop vectorized using 32 byte vectors
Dense.c:45:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:45:21: optimized: loop vectorized using 16 byte vectors
Dense.c:37:13: note: vectorized 1 loops in function.
Dense.c:37:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:37:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:41:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:150:19: missed: couldn't vectorize loop
Dense.c:150:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:141:19: missed: couldn't vectorize loop
Dense.c:141:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:134:13: note: vectorized 0 loops in function.
Dense.c:158:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:158:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:103:28: missed: couldn't vectorize loop
Dense.c:103:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:106:21: missed: couldn't vectorize loop
Dense.c:106:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:120:28: missed: couldn't vectorize loop
Dense.c:120:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:123:21: missed: couldn't vectorize loop
Dense.c:123:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:89:19: missed: couldn't vectorize loop
Dense.c:89:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:83:13: note: vectorized 0 loops in function.
Dense.c:86:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:108:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:108:17: note: SLPing BB part
Dense.c:125:17: note: Costing subgraph: 
Dense.c:125:17: note: node 0x75577a8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:125:17: note: op template: _49 = (sizetype) j_137;
Dense.c:125:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:125:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:125:17: note: 	children 0x75578a8
Dense.c:125:17: note: node (external) 0x75578a8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:125:17: note: 	{ j_137, wi_136 }
Dense.c:125:17: note: Cost model analysis: 
Dense.c:125:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:125:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:125:17: missed: not vectorized: vectorization is not profitable.
Dense.c:108:17: note: Costing subgraph: 
Dense.c:108:17: note: node 0x75579a8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:108:17: note: op template: _24 = (sizetype) j_134;
Dense.c:108:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:108:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:108:17: note: 	children 0x7557aa8
Dense.c:108:17: note: node (external) 0x7557aa8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:108:17: note: 	{ j_134, wi_133 }
Dense.c:108:17: note: Cost model analysis: 
Dense.c:108:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:108:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:108:17: missed: not vectorized: vectorization is not profitable.
Dense.c:108:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:108:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:108:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:108:17: note: SLPing BB part
Dense.c:125:17: note: Costing subgraph: 
Dense.c:125:17: note: node 0x75579a8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:125:17: note: op template: _49 = (sizetype) j_137;
Dense.c:125:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:125:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:125:17: note: 	children 0x75577a8
Dense.c:125:17: note: node (external) 0x75577a8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:125:17: note: 	{ j_137, wi_136 }
Dense.c:125:17: note: Cost model analysis: 
Dense.c:125:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:125:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:125:17: missed: not vectorized: vectorization is not profitable.
Dense.c:108:17: note: Costing subgraph: 
Dense.c:108:17: note: node 0x7557b28 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:108:17: note: op template: _24 = (sizetype) j_134;
Dense.c:108:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:108:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:108:17: note: 	children 0x7557a28
Dense.c:108:17: note: node (external) 0x7557a28 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:108:17: note: 	{ j_134, wi_133 }
Dense.c:108:17: note: Cost model analysis: 
Dense.c:108:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:108:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:108:17: missed: not vectorized: vectorization is not profitable.
Dense.c:108:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:103:55: note: ***** Analysis failed with vector mode V8QI
Dense.c:103:55: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:103:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:61:23: missed: couldn't vectorize loop
Dense.c:77:45: missed: not vectorized: no vectype for stmt: _108 = *_109;
 scalar_type: float
Dense.c:61:23: missed: couldn't vectorize loop
Dense.c:61:23: missed: not vectorized: unsupported outerloop form.
Dense.c:64:38: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:905:10: missed: not vectorized: no vectype for stmt: _46 = MEM[(__m256_u * {ref-all})_6];
 scalar_type: __m256_u
Dense.c:54:13: note: vectorized 0 loops in function.
Dense.c:79:2: missed: statement clobbers memory: _25 (pretmp_156, _53, 0);
Dense.c:66:14: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:66:14: note: SLPing BB part
Dense.c:66:14: note: Costing subgraph: 
Dense.c:66:14: note: node 0x75877d8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:66:14: note: op template: _3 = (sizetype) j_69;
Dense.c:66:14: note: 	stmt 0 _3 = (sizetype) j_69;
Dense.c:66:14: note: 	stmt 1 _140 = (sizetype) wi_72;
Dense.c:66:14: note: 	children 0x75878d8
Dense.c:66:14: note: node (external) 0x75878d8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:66:14: note: 	{ j_69, wi_72 }
Dense.c:66:14: note: Cost model analysis: 
Dense.c:66:14: note: Scalar 1 and vector 2 loop part do not match up, skipping scalar part
Dense.c:66:14: note: Cost model analysis for part in loop 2:
  Vector cost: 36
  Scalar cost: 8
Dense.c:66:14: missed: not vectorized: vectorization is not profitable.
Dense.c:66:14: note: ***** The result for vector mode V32QI would be the same
Dense.c:66:14: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:66:14: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:66:14: note: SLPing BB part
Dense.c:66:14: note: Costing subgraph: 
Dense.c:66:14: note: node 0x75877d8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:66:14: note: op template: _3 = (sizetype) j_69;
Dense.c:66:14: note: 	stmt 0 _3 = (sizetype) j_69;
Dense.c:66:14: note: 	stmt 1 _140 = (sizetype) wi_72;
Dense.c:66:14: note: 	children 0x7587858
Dense.c:66:14: note: node (external) 0x7587858 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:66:14: note: 	{ j_69, wi_72 }
Dense.c:66:14: note: Cost model analysis: 
Dense.c:66:14: note: Scalar 1 and vector 2 loop part do not match up, skipping scalar part
Dense.c:66:14: note: Cost model analysis for part in loop 2:
  Vector cost: 36
  Scalar cost: 8
Dense.c:66:14: missed: not vectorized: vectorization is not profitable.
Dense.c:66:14: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:61:50: note: ***** Analysis failed with vector mode V8QI
Dense.c:61:50: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:61:50: note: ***** Analysis failed with vector mode V4QI
Dense.c:165:2: missed: statement clobbers memory: free (_1);
Dense.c:166:2: missed: statement clobbers memory: free (_2);
Dense.c:167:2: missed: statement clobbers memory: free (_3);
Dense.c:168:2: missed: statement clobbers memory: free (_4);
Dense.c:169:2: missed: statement clobbers memory: free (dense_7);
Dense.c:170:2: missed: statement clobbers memory: PULSE_DestroyLayer (this_6(D));
Dense.c:171:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:171:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:185:19: missed: couldn't vectorize loop
Dense.c:185:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:175:13: note: vectorized 0 loops in function.
Dense.c:177:47: missed: statement clobbers memory: dense_35 = malloc (40);
Dense.c:179:36: missed: statement clobbers memory: _5 = aligned_alloc (64, _4);
Dense.c:180:38: missed: statement clobbers memory: _6 = aligned_alloc (64, _4);
Dense.c:181:36: missed: statement clobbers memory: _8 = aligned_alloc (64, _7);
Dense.c:182:35: missed: statement clobbers memory: _9 = aligned_alloc (64, _7);
Dense.c:183:36: missed: statement clobbers memory: _10 = aligned_alloc (64, _7);
Dense.c:186:39: missed: statement clobbers memory: _11 = rand ();
Dense.c:186:73: missed: statement clobbers memory: _63 = sqrt (_18);
Dense.c:198:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:199:4: missed: statement clobbers memory: exit (1);
Dense.c:195:4: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.3_29, n_outputs.2_28, 1, activation_function_51(D), _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:192:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.1_27, n_outputs.0_26, 1, activation_function_51(D), _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:205:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Dense.c:205:9: note: ***** Analysis failed with vector mode V4DI
Dense.c:205:9: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:9:27: missed: couldn't vectorize loop
Dense.c:9:27: missed: not vectorized: unsupported outerloop form.
Dense.c:12:20: missed: couldn't vectorize loop
Dense.c:13:21: missed: not vectorized: complicated access pattern.
Dense.c:6:13: note: vectorized 0 loops in function.
Dense.c:16:2: missed: statement clobbers memory: _30 (pretmp_91, _50, 0);
Dense.c:9:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:9:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:24:27: missed: couldn't vectorize loop
Dense.c:24:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:28:20: optimized: loop vectorized using 32 byte vectors
Dense.c:28:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:28:20: optimized: loop vectorized using 16 byte vectors
Dense.c:28:20: missed: couldn't vectorize loop
Dense.c:30:20: missed: not vectorized: no vectype for stmt: _21 = *_20;
 scalar_type: float
Dense.c:20:13: note: vectorized 1 loops in function.
Dense.c:23:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:24:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:24:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:41:28: missed: couldn't vectorize loop
Dense.c:41:28: missed: not vectorized: unsupported outerloop form.
Dense.c:45:21: optimized: loop vectorized using 32 byte vectors
Dense.c:45:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:45:21: optimized: loop vectorized using 16 byte vectors
Dense.c:37:13: note: vectorized 1 loops in function.
Dense.c:37:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:37:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:41:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:151:19: missed: couldn't vectorize loop
Dense.c:151:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:142:19: missed: couldn't vectorize loop
Dense.c:142:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:135:13: note: vectorized 0 loops in function.
Dense.c:159:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:159:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:104:28: missed: couldn't vectorize loop
Dense.c:104:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:107:21: missed: couldn't vectorize loop
Dense.c:107:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:121:28: missed: couldn't vectorize loop
Dense.c:121:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:124:21: missed: couldn't vectorize loop
Dense.c:124:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:90:19: missed: couldn't vectorize loop
Dense.c:90:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:84:13: note: vectorized 0 loops in function.
Dense.c:87:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:109:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:109:17: note: SLPing BB part
Dense.c:126:17: note: Costing subgraph: 
Dense.c:126:17: note: node 0x8478c18 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:126:17: note: op template: _49 = (sizetype) j_137;
Dense.c:126:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:126:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:126:17: note: 	children 0x8478d18
Dense.c:126:17: note: node (external) 0x8478d18 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:126:17: note: 	{ j_137, wi_136 }
Dense.c:126:17: note: Cost model analysis: 
Dense.c:126:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:126:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:126:17: missed: not vectorized: vectorization is not profitable.
Dense.c:109:17: note: Costing subgraph: 
Dense.c:109:17: note: node 0x8478e18 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:109:17: note: op template: _24 = (sizetype) j_134;
Dense.c:109:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:109:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:109:17: note: 	children 0x8478f18
Dense.c:109:17: note: node (external) 0x8478f18 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:109:17: note: 	{ j_134, wi_133 }
Dense.c:109:17: note: Cost model analysis: 
Dense.c:109:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:109:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:109:17: missed: not vectorized: vectorization is not profitable.
Dense.c:109:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:109:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:109:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:109:17: note: SLPing BB part
Dense.c:126:17: note: Costing subgraph: 
Dense.c:126:17: note: node 0x8478e18 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:126:17: note: op template: _49 = (sizetype) j_137;
Dense.c:126:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:126:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:126:17: note: 	children 0x8478c18
Dense.c:126:17: note: node (external) 0x8478c18 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:126:17: note: 	{ j_137, wi_136 }
Dense.c:126:17: note: Cost model analysis: 
Dense.c:126:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:126:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:126:17: missed: not vectorized: vectorization is not profitable.
Dense.c:109:17: note: Costing subgraph: 
Dense.c:109:17: note: node 0x8478f98 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:109:17: note: op template: _24 = (sizetype) j_134;
Dense.c:109:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:109:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:109:17: note: 	children 0x8478e98
Dense.c:109:17: note: node (external) 0x8478e98 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:109:17: note: 	{ j_134, wi_133 }
Dense.c:109:17: note: Cost model analysis: 
Dense.c:109:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:109:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:109:17: missed: not vectorized: vectorization is not profitable.
Dense.c:109:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:104:55: note: ***** Analysis failed with vector mode V8QI
Dense.c:104:55: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:104:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:61:23: missed: couldn't vectorize loop
Dense.c:61:23: missed: not vectorized: unsupported outerloop form.
Dense.c:65:38: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:905:10: missed: not vectorized: no vectype for stmt: _44 = MEM[(__m256_u * {ref-all})_6];
 scalar_type: __m256_u
Dense.c:54:13: note: vectorized 0 loops in function.
Dense.c:80:2: missed: statement clobbers memory: _25 (pretmp_136, _51, 0);
Dense.c:67:14: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:67:14: note: SLPing BB part
Dense.c:67:14: note: Costing subgraph: 
Dense.c:67:14: note: node 0x84a8c48 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:67:14: note: op template: _3 = (sizetype) j_66;
Dense.c:67:14: note: 	stmt 0 _3 = (sizetype) j_66;
Dense.c:67:14: note: 	stmt 1 _124 = (sizetype) wi_67;
Dense.c:67:14: note: 	children 0x84a8d48
Dense.c:67:14: note: node (external) 0x84a8d48 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:67:14: note: 	{ j_66, wi_67 }
Dense.c:67:14: note: Cost model analysis: 
Dense.c:67:14: note: Scalar 1 and vector 2 loop part do not match up, skipping scalar part
Dense.c:67:14: note: Cost model analysis for part in loop 2:
  Vector cost: 36
  Scalar cost: 8
Dense.c:67:14: missed: not vectorized: vectorization is not profitable.
Dense.c:67:14: note: ***** The result for vector mode V32QI would be the same
Dense.c:67:14: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:67:14: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:67:14: note: SLPing BB part
Dense.c:67:14: note: Costing subgraph: 
Dense.c:67:14: note: node 0x84a8c48 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:67:14: note: op template: _3 = (sizetype) j_66;
Dense.c:67:14: note: 	stmt 0 _3 = (sizetype) j_66;
Dense.c:67:14: note: 	stmt 1 _124 = (sizetype) wi_67;
Dense.c:67:14: note: 	children 0x84a8dc8
Dense.c:67:14: note: node (external) 0x84a8dc8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:67:14: note: 	{ j_66, wi_67 }
Dense.c:67:14: note: Cost model analysis: 
Dense.c:67:14: note: Scalar 1 and vector 2 loop part do not match up, skipping scalar part
Dense.c:67:14: note: Cost model analysis for part in loop 2:
  Vector cost: 36
  Scalar cost: 8
Dense.c:67:14: missed: not vectorized: vectorization is not profitable.
Dense.c:67:14: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:61:50: note: ***** Analysis failed with vector mode V8QI
Dense.c:61:50: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:61:50: note: ***** Analysis failed with vector mode V4QI
Dense.c:166:2: missed: statement clobbers memory: free (_1);
Dense.c:167:2: missed: statement clobbers memory: free (_2);
Dense.c:168:2: missed: statement clobbers memory: free (_3);
Dense.c:169:2: missed: statement clobbers memory: free (_4);
Dense.c:170:2: missed: statement clobbers memory: free (dense_7);
Dense.c:171:2: missed: statement clobbers memory: PULSE_DestroyLayer (this_6(D));
Dense.c:172:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:172:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:186:19: missed: couldn't vectorize loop
Dense.c:186:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:176:13: note: vectorized 0 loops in function.
Dense.c:178:47: missed: statement clobbers memory: dense_35 = malloc (40);
Dense.c:180:36: missed: statement clobbers memory: _5 = aligned_alloc (64, _4);
Dense.c:181:38: missed: statement clobbers memory: _6 = aligned_alloc (64, _4);
Dense.c:182:36: missed: statement clobbers memory: _8 = aligned_alloc (64, _7);
Dense.c:183:35: missed: statement clobbers memory: _9 = aligned_alloc (64, _7);
Dense.c:184:36: missed: statement clobbers memory: _10 = aligned_alloc (64, _7);
Dense.c:187:39: missed: statement clobbers memory: _11 = rand ();
Dense.c:187:73: missed: statement clobbers memory: _63 = sqrt (_18);
Dense.c:199:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:200:4: missed: statement clobbers memory: exit (1);
Dense.c:196:4: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.3_29, n_outputs.2_28, 1, activation_function_51(D), _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:193:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.1_27, n_outputs.0_26, 1, activation_function_51(D), _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:206:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Dense.c:206:9: note: ***** Analysis failed with vector mode V4DI
Dense.c:206:9: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:9:27: missed: couldn't vectorize loop
Dense.c:9:27: missed: not vectorized: unsupported outerloop form.
Dense.c:12:20: missed: couldn't vectorize loop
Dense.c:13:21: missed: not vectorized: complicated access pattern.
Dense.c:6:13: note: vectorized 0 loops in function.
Dense.c:16:2: missed: statement clobbers memory: _30 (pretmp_91, _50, 0);
Dense.c:9:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:9:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:24:27: missed: couldn't vectorize loop
Dense.c:24:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:28:20: optimized: loop vectorized using 32 byte vectors
Dense.c:28:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:28:20: optimized: loop vectorized using 16 byte vectors
Dense.c:28:20: missed: couldn't vectorize loop
Dense.c:30:20: missed: not vectorized: no vectype for stmt: _21 = *_20;
 scalar_type: float
Dense.c:20:13: note: vectorized 1 loops in function.
Dense.c:23:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:24:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:24:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:41:28: missed: couldn't vectorize loop
Dense.c:41:28: missed: not vectorized: unsupported outerloop form.
Dense.c:45:21: optimized: loop vectorized using 32 byte vectors
Dense.c:45:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:45:21: optimized: loop vectorized using 16 byte vectors
Dense.c:37:13: note: vectorized 1 loops in function.
Dense.c:37:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:37:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:41:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:152:19: missed: couldn't vectorize loop
Dense.c:152:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:143:19: missed: couldn't vectorize loop
Dense.c:143:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:136:13: note: vectorized 0 loops in function.
Dense.c:160:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:160:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:105:28: missed: couldn't vectorize loop
Dense.c:105:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:108:21: missed: couldn't vectorize loop
Dense.c:108:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:122:28: missed: couldn't vectorize loop
Dense.c:122:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:125:21: missed: couldn't vectorize loop
Dense.c:125:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:91:19: missed: couldn't vectorize loop
Dense.c:91:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:85:13: note: vectorized 0 loops in function.
Dense.c:88:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:110:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:110:17: note: SLPing BB part
Dense.c:127:17: note: Costing subgraph: 
Dense.c:127:17: note: node 0x8547448 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:127:17: note: op template: _49 = (sizetype) j_137;
Dense.c:127:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:127:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:127:17: note: 	children 0x8547548
Dense.c:127:17: note: node (external) 0x8547548 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:127:17: note: 	{ j_137, wi_136 }
Dense.c:127:17: note: Cost model analysis: 
Dense.c:127:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:127:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:127:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: Costing subgraph: 
Dense.c:110:17: note: node 0x8547648 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:110:17: note: op template: _24 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:110:17: note: 	children 0x8547748
Dense.c:110:17: note: node (external) 0x8547748 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:110:17: note: 	{ j_134, wi_133 }
Dense.c:110:17: note: Cost model analysis: 
Dense.c:110:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:110:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:110:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:110:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:110:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:110:17: note: SLPing BB part
Dense.c:127:17: note: Costing subgraph: 
Dense.c:127:17: note: node 0x8547648 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:127:17: note: op template: _49 = (sizetype) j_137;
Dense.c:127:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:127:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:127:17: note: 	children 0x8547448
Dense.c:127:17: note: node (external) 0x8547448 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:127:17: note: 	{ j_137, wi_136 }
Dense.c:127:17: note: Cost model analysis: 
Dense.c:127:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:127:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:127:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: Costing subgraph: 
Dense.c:110:17: note: node 0x85477c8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:110:17: note: op template: _24 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:110:17: note: 	children 0x85476c8
Dense.c:110:17: note: node (external) 0x85476c8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:110:17: note: 	{ j_134, wi_133 }
Dense.c:110:17: note: Cost model analysis: 
Dense.c:110:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:110:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:110:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:105:55: note: ***** Analysis failed with vector mode V8QI
Dense.c:105:55: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:105:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:62:23: missed: couldn't vectorize loop
Dense.c:62:23: missed: not vectorized: unsupported outerloop form.
Dense.c:66:38: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:905:10: missed: not vectorized: no vectype for stmt: _41 = MEM[(__m256_u * {ref-all})_3];
 scalar_type: __m256_u
Dense.c:54:13: note: vectorized 0 loops in function.
Dense.c:81:2: missed: statement clobbers memory: _21 (pretmp_119, _48, 0);
Dense.c:82:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:82:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:167:2: missed: statement clobbers memory: free (_1);
Dense.c:168:2: missed: statement clobbers memory: free (_2);
Dense.c:169:2: missed: statement clobbers memory: free (_3);
Dense.c:170:2: missed: statement clobbers memory: free (_4);
Dense.c:171:2: missed: statement clobbers memory: free (dense_7);
Dense.c:172:2: missed: statement clobbers memory: PULSE_DestroyLayer (this_6(D));
Dense.c:173:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:173:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:187:19: missed: couldn't vectorize loop
Dense.c:187:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:177:13: note: vectorized 0 loops in function.
Dense.c:179:47: missed: statement clobbers memory: dense_35 = malloc (40);
Dense.c:181:36: missed: statement clobbers memory: _5 = aligned_alloc (64, _4);
Dense.c:182:38: missed: statement clobbers memory: _6 = aligned_alloc (64, _4);
Dense.c:183:36: missed: statement clobbers memory: _8 = aligned_alloc (64, _7);
Dense.c:184:35: missed: statement clobbers memory: _9 = aligned_alloc (64, _7);
Dense.c:185:36: missed: statement clobbers memory: _10 = aligned_alloc (64, _7);
Dense.c:188:39: missed: statement clobbers memory: _11 = rand ();
Dense.c:188:73: missed: statement clobbers memory: _63 = sqrt (_18);
Dense.c:200:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:201:4: missed: statement clobbers memory: exit (1);
Dense.c:197:4: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.3_29, n_outputs.2_28, 1, activation_function_51(D), _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:194:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.1_27, n_outputs.0_26, 1, activation_function_51(D), _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:207:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Dense.c:207:9: note: ***** Analysis failed with vector mode V4DI
Dense.c:207:9: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:9:27: missed: couldn't vectorize loop
Dense.c:9:27: missed: not vectorized: unsupported outerloop form.
Dense.c:12:20: missed: couldn't vectorize loop
Dense.c:13:21: missed: not vectorized: complicated access pattern.
Dense.c:6:13: note: vectorized 0 loops in function.
Dense.c:16:2: missed: statement clobbers memory: _30 (pretmp_91, _50, 0);
Dense.c:9:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:9:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:24:27: missed: couldn't vectorize loop
Dense.c:24:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:28:20: optimized: loop vectorized using 32 byte vectors
Dense.c:28:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:28:20: optimized: loop vectorized using 16 byte vectors
Dense.c:28:20: missed: couldn't vectorize loop
Dense.c:30:20: missed: not vectorized: no vectype for stmt: _21 = *_20;
 scalar_type: float
Dense.c:20:13: note: vectorized 1 loops in function.
Dense.c:23:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:24:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:24:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:41:28: missed: couldn't vectorize loop
Dense.c:41:28: missed: not vectorized: unsupported outerloop form.
Dense.c:45:21: optimized: loop vectorized using 32 byte vectors
Dense.c:45:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:45:21: optimized: loop vectorized using 16 byte vectors
Dense.c:37:13: note: vectorized 1 loops in function.
Dense.c:37:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:37:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:41:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:152:19: missed: couldn't vectorize loop
Dense.c:152:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:143:19: missed: couldn't vectorize loop
Dense.c:143:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:136:13: note: vectorized 0 loops in function.
Dense.c:160:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:160:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:105:28: missed: couldn't vectorize loop
Dense.c:105:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:108:21: missed: couldn't vectorize loop
Dense.c:108:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:122:28: missed: couldn't vectorize loop
Dense.c:122:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:125:21: missed: couldn't vectorize loop
Dense.c:125:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:91:19: missed: couldn't vectorize loop
Dense.c:91:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:85:13: note: vectorized 0 loops in function.
Dense.c:88:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:110:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:110:17: note: SLPing BB part
Dense.c:127:17: note: Costing subgraph: 
Dense.c:127:17: note: node 0x8cfed58 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:127:17: note: op template: _49 = (sizetype) j_137;
Dense.c:127:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:127:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:127:17: note: 	children 0x8cfee58
Dense.c:127:17: note: node (external) 0x8cfee58 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:127:17: note: 	{ j_137, wi_136 }
Dense.c:127:17: note: Cost model analysis: 
Dense.c:127:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:127:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:127:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: Costing subgraph: 
Dense.c:110:17: note: node 0x8cfef58 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:110:17: note: op template: _24 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:110:17: note: 	children 0x8cff058
Dense.c:110:17: note: node (external) 0x8cff058 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:110:17: note: 	{ j_134, wi_133 }
Dense.c:110:17: note: Cost model analysis: 
Dense.c:110:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:110:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:110:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:110:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:110:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:110:17: note: SLPing BB part
Dense.c:127:17: note: Costing subgraph: 
Dense.c:127:17: note: node 0x8cfef58 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:127:17: note: op template: _49 = (sizetype) j_137;
Dense.c:127:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:127:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:127:17: note: 	children 0x8cfed58
Dense.c:127:17: note: node (external) 0x8cfed58 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:127:17: note: 	{ j_137, wi_136 }
Dense.c:127:17: note: Cost model analysis: 
Dense.c:127:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:127:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:127:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: Costing subgraph: 
Dense.c:110:17: note: node 0x8cff0d8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:110:17: note: op template: _24 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:110:17: note: 	children 0x8cfefd8
Dense.c:110:17: note: node (external) 0x8cfefd8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:110:17: note: 	{ j_134, wi_133 }
Dense.c:110:17: note: Cost model analysis: 
Dense.c:110:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:110:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:110:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:105:55: note: ***** Analysis failed with vector mode V8QI
Dense.c:105:55: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:105:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:62:15: missed: couldn't vectorize loop
Dense.c:62:15: missed: not vectorized: unsupported outerloop form.
Dense.c:66:38: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:905:10: missed: not vectorized: no vectype for stmt: _41 = MEM[(__m256_u * {ref-all})_3];
 scalar_type: __m256_u
Dense.c:54:13: note: vectorized 0 loops in function.
Dense.c:81:2: missed: statement clobbers memory: _21 (pretmp_119, _48, 0);
Dense.c:82:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:82:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:167:2: missed: statement clobbers memory: free (_1);
Dense.c:168:2: missed: statement clobbers memory: free (_2);
Dense.c:169:2: missed: statement clobbers memory: free (_3);
Dense.c:170:2: missed: statement clobbers memory: free (_4);
Dense.c:171:2: missed: statement clobbers memory: free (dense_7);
Dense.c:172:2: missed: statement clobbers memory: PULSE_DestroyLayer (this_6(D));
Dense.c:173:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:173:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:187:19: missed: couldn't vectorize loop
Dense.c:187:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:177:13: note: vectorized 0 loops in function.
Dense.c:179:47: missed: statement clobbers memory: dense_35 = malloc (40);
Dense.c:181:36: missed: statement clobbers memory: _5 = aligned_alloc (64, _4);
Dense.c:182:38: missed: statement clobbers memory: _6 = aligned_alloc (64, _4);
Dense.c:183:36: missed: statement clobbers memory: _8 = aligned_alloc (64, _7);
Dense.c:184:35: missed: statement clobbers memory: _9 = aligned_alloc (64, _7);
Dense.c:185:36: missed: statement clobbers memory: _10 = aligned_alloc (64, _7);
Dense.c:188:39: missed: statement clobbers memory: _11 = rand ();
Dense.c:188:73: missed: statement clobbers memory: _63 = sqrt (_18);
Dense.c:200:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:201:4: missed: statement clobbers memory: exit (1);
Dense.c:197:4: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.3_29, n_outputs.2_28, 1, activation_function_51(D), _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:194:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.1_27, n_outputs.0_26, 1, activation_function_51(D), _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:207:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Dense.c:207:9: note: ***** Analysis failed with vector mode V4DI
Dense.c:207:9: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:9:27: missed: couldn't vectorize loop
Dense.c:9:27: missed: not vectorized: unsupported outerloop form.
Dense.c:12:20: missed: couldn't vectorize loop
Dense.c:13:21: missed: not vectorized: complicated access pattern.
Dense.c:6:13: note: vectorized 0 loops in function.
Dense.c:16:2: missed: statement clobbers memory: _30 (pretmp_91, _50, 0);
Dense.c:9:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:9:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:24:27: missed: couldn't vectorize loop
Dense.c:24:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:28:20: optimized: loop vectorized using 32 byte vectors
Dense.c:28:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:28:20: optimized: loop vectorized using 16 byte vectors
Dense.c:28:20: missed: couldn't vectorize loop
Dense.c:30:20: missed: not vectorized: no vectype for stmt: _21 = *_20;
 scalar_type: float
Dense.c:20:13: note: vectorized 1 loops in function.
Dense.c:23:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:24:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:24:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:41:28: missed: couldn't vectorize loop
Dense.c:41:28: missed: not vectorized: unsupported outerloop form.
Dense.c:45:21: optimized: loop vectorized using 32 byte vectors
Dense.c:45:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:45:21: optimized: loop vectorized using 16 byte vectors
Dense.c:37:13: note: vectorized 1 loops in function.
Dense.c:37:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:37:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:41:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:149:19: missed: couldn't vectorize loop
Dense.c:149:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:140:19: missed: couldn't vectorize loop
Dense.c:140:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:133:13: note: vectorized 0 loops in function.
Dense.c:157:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:157:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:102:28: missed: couldn't vectorize loop
Dense.c:102:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:105:21: missed: couldn't vectorize loop
Dense.c:105:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:119:28: missed: couldn't vectorize loop
Dense.c:119:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:122:21: missed: couldn't vectorize loop
Dense.c:122:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:88:19: missed: couldn't vectorize loop
Dense.c:88:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:82:13: note: vectorized 0 loops in function.
Dense.c:85:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:107:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:107:17: note: SLPing BB part
Dense.c:124:17: note: Costing subgraph: 
Dense.c:124:17: note: node 0x73a72d8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:124:17: note: op template: _49 = (sizetype) j_137;
Dense.c:124:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:124:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:124:17: note: 	children 0x73a73d8
Dense.c:124:17: note: node (external) 0x73a73d8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:124:17: note: 	{ j_137, wi_136 }
Dense.c:124:17: note: Cost model analysis: 
Dense.c:124:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:124:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:124:17: missed: not vectorized: vectorization is not profitable.
Dense.c:107:17: note: Costing subgraph: 
Dense.c:107:17: note: node 0x73a74d8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:107:17: note: op template: _24 = (sizetype) j_134;
Dense.c:107:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:107:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:107:17: note: 	children 0x73a75d8
Dense.c:107:17: note: node (external) 0x73a75d8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:107:17: note: 	{ j_134, wi_133 }
Dense.c:107:17: note: Cost model analysis: 
Dense.c:107:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:107:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:107:17: missed: not vectorized: vectorization is not profitable.
Dense.c:107:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:107:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:107:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:107:17: note: SLPing BB part
Dense.c:124:17: note: Costing subgraph: 
Dense.c:124:17: note: node 0x73a74d8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:124:17: note: op template: _49 = (sizetype) j_137;
Dense.c:124:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:124:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:124:17: note: 	children 0x73a72d8
Dense.c:124:17: note: node (external) 0x73a72d8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:124:17: note: 	{ j_137, wi_136 }
Dense.c:124:17: note: Cost model analysis: 
Dense.c:124:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:124:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:124:17: missed: not vectorized: vectorization is not profitable.
Dense.c:107:17: note: Costing subgraph: 
Dense.c:107:17: note: node 0x73a7658 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:107:17: note: op template: _24 = (sizetype) j_134;
Dense.c:107:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:107:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:107:17: note: 	children 0x73a7558
Dense.c:107:17: note: node (external) 0x73a7558 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:107:17: note: 	{ j_134, wi_133 }
Dense.c:107:17: note: Cost model analysis: 
Dense.c:107:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:107:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:107:17: missed: not vectorized: vectorization is not profitable.
Dense.c:107:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:102:55: note: ***** Analysis failed with vector mode V8QI
Dense.c:102:55: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:102:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:61:15: missed: couldn't vectorize loop
Dense.c:61:15: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:74:11: optimized: loop vectorized using 32 byte vectors
Dense.c:74:11: optimized: loop vectorized using 16 byte vectors
Dense.c:65:38: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:881:10: missed: not vectorized: no vectype for stmt: _52 = MEM[(__m256 * {ref-all})w_ptr_81];
 scalar_type: __m256
Dense.c:54:13: note: vectorized 1 loops in function.
Dense.c:78:2: missed: statement clobbers memory: _26 (pretmp_158, _63, 0);
Dense.c:54:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:54:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:164:2: missed: statement clobbers memory: free (_1);
Dense.c:165:2: missed: statement clobbers memory: free (_2);
Dense.c:166:2: missed: statement clobbers memory: free (_3);
Dense.c:167:2: missed: statement clobbers memory: free (_4);
Dense.c:168:2: missed: statement clobbers memory: free (dense_7);
Dense.c:169:2: missed: statement clobbers memory: PULSE_DestroyLayer (this_6(D));
Dense.c:170:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:170:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:184:19: missed: couldn't vectorize loop
Dense.c:184:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:174:13: note: vectorized 0 loops in function.
Dense.c:176:47: missed: statement clobbers memory: dense_35 = malloc (40);
Dense.c:178:36: missed: statement clobbers memory: _5 = aligned_alloc (64, _4);
Dense.c:179:38: missed: statement clobbers memory: _6 = aligned_alloc (64, _4);
Dense.c:180:36: missed: statement clobbers memory: _8 = aligned_alloc (64, _7);
Dense.c:181:35: missed: statement clobbers memory: _9 = aligned_alloc (64, _7);
Dense.c:182:36: missed: statement clobbers memory: _10 = aligned_alloc (64, _7);
Dense.c:185:39: missed: statement clobbers memory: _11 = rand ();
Dense.c:185:73: missed: statement clobbers memory: _63 = sqrt (_18);
Dense.c:197:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:198:4: missed: statement clobbers memory: exit (1);
Dense.c:194:4: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.3_29, n_outputs.2_28, 1, activation_function_51(D), _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:191:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.1_27, n_outputs.0_26, 1, activation_function_51(D), _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:204:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Dense.c:204:9: note: ***** Analysis failed with vector mode V4DI
Dense.c:204:9: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Layer.c:7:34: missed: statement clobbers memory: _3 = aligned_alloc (64, _2);
Layer.c:8:35: missed: statement clobbers memory: _6 = aligned_alloc (64, _5);
Layer.c:9:34: missed: statement clobbers memory: _7 = aligned_alloc (64, _5);
Layer.c:14:19: missed: statement clobbers memory: _8 = PULSE_GetActivationFunctionPtr (activation_function_18(D));
Layer.c:19:9: note: ***** Analysis succeeded with vector mode V8SI
Layer.c:19:9: note: SLPing BB part
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x4d017c8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 0 MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 1 MEM <unsigned int> [(struct PULSE_Layer *)&<retval> + 4B] = optimization_type_17(D);
Layer.c:19:9: note: 	children 0x4d01848
Layer.c:19:9: note: node (external) 0x4d01848 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ type_16(D), optimization_type_17(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x4d018c8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 0 <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 1 <retval>.n_outputs = n_outputs_12(D);
Layer.c:19:9: note: 	children 0x4d01948
Layer.c:19:9: note: node (external) 0x4d01948 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x4d01a48 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 0 <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 1 <retval>.outputs = _6;
Layer.c:19:9: note: 	children 0x4d01ac8
Layer.c:19:9: note: node (external) 0x4d01ac8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	stmt 0 _3 = aligned_alloc (64, _2);
Layer.c:19:9: note: 	stmt 1 _6 = aligned_alloc (64, _5);
Layer.c:19:9: note: 	children 0x4d01b48 0x4d01bc8
Layer.c:19:9: note: node (constant) 0x4d01b48 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 64, 64 }
Layer.c:19:9: note: node 0x4d01bc8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: patt_40 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 0 patt_40 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 1 patt_41 = n_outputs_12(D) w* 4;
Layer.c:19:9: note: 	children 0x4d01c48 0x4d01cc8
Layer.c:19:9: note: node (external) 0x4d01c48 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: node (constant) 0x4d01cc8 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ 4, 4 }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x4d01dc8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: op template: <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 0 <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 1 <retval>.back = back_21(D);
Layer.c:19:9: note: 	stmt 2 <retval>.fix = fix_22(D);
Layer.c:19:9: note: 	stmt 3 <retval>.destroy = destroy_23(D);
Layer.c:19:9: note: 	children 0x4d01e48
Layer.c:19:9: note: node (external) 0x4d01e48 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: 	{ feed_20(D), back_21(D), fix_22(D), destroy_23(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 64
  Scalar cost: 64
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x4d01f48 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 0 <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 1 <retval>.child = 0B;
Layer.c:19:9: note: 	children 0x4d01fc8
Layer.c:19:9: note: node (constant) 0x4d01fc8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ 0B, 0B }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Basic block will be vectorized using SLP
Layer.c:19:9: optimized: basic block part vectorized using 8 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x4d017c8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 0 MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 1 MEM <unsigned int> [(struct PULSE_Layer *)&<retval> + 4B] = optimization_type_17(D);
Layer.c:19:9: note: 	children 0x4d01848
Layer.c:19:9: note: node (external) 0x4d01848 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ type_16(D), optimization_type_17(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: vect_is_simple_use: operand optimization_type_17(D), type of def: external
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>]
Layer.c:19:9: note: created &MEM <unsigned int> [(struct PULSE_Layer *)&<retval>]
Layer.c:19:9: note: add new stmt: MEM <vector(2) unsigned int> [(struct PULSE_Layer *)&<retval>] = _42;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 8 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x4d018c8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 0 <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 1 <retval>.n_outputs = n_outputs_12(D);
Layer.c:19:9: note: 	children 0x4d01948
Layer.c:19:9: note: node (external) 0x4d01948 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: vect_is_simple_use: operand n_outputs_12(D), type of def: external
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: <retval>.n_inputs
Layer.c:19:9: note: created &<retval>.n_inputs
Layer.c:19:9: note: add new stmt: MEM <vector(2) unsigned int> [(unsigned int *)&<retval> + 96B] = _44;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 16 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x4d01a48 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 0 <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 1 <retval>.outputs = _6;
Layer.c:19:9: note: 	children 0x4d01ac8
Layer.c:19:9: note: node (external) 0x4d01ac8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	stmt 0 _3 = aligned_alloc (64, _2);
Layer.c:19:9: note: 	stmt 1 _6 = aligned_alloc (64, _5);
Layer.c:19:9: note: 	children 0x4d01b48 0x4d01bc8
Layer.c:19:9: note: node (constant) 0x4d01b48 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 64, 64 }
Layer.c:19:9: note: node 0x4d01bc8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: patt_40 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 0 patt_40 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 1 patt_41 = n_outputs_12(D) w* 4;
Layer.c:19:9: note: 	children 0x4d01c48 0x4d01cc8
Layer.c:19:9: note: node (external) 0x4d01c48 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: node (constant) 0x4d01cc8 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ 4, 4 }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.inputs = _3;
Layer.c:19:9: note: vect_is_simple_use: operand aligned_alloc (64, _5), type of def: internal
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.inputs
Layer.c:19:9: note: created &<retval>.inputs
Layer.c:19:9: note: add new stmt: MEM <vector(2) long unsigned int> [(float * *)&<retval> + 8B] = _48;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 32 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x4d01dc8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: op template: <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 0 <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 1 <retval>.back = back_21(D);
Layer.c:19:9: note: 	stmt 2 <retval>.fix = fix_22(D);
Layer.c:19:9: note: 	stmt 3 <retval>.destroy = destroy_23(D);
Layer.c:19:9: note: 	children 0x4d01e48
Layer.c:19:9: note: node (external) 0x4d01e48 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: 	{ feed_20(D), back_21(D), fix_22(D), destroy_23(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.feed = feed_20(D);
Layer.c:19:9: note: vect_is_simple_use: operand back_21(D), type of def: external
Layer.c:19:9: note: vect_is_simple_use: operand fix_22(D), type of def: external
Layer.c:19:9: note: vect_is_simple_use: operand destroy_23(D), type of def: external
Layer.c:19:9: note: conflicting alias set types.
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(4) long unsigned int  vectorizing a pointer ref: <retval>.feed
Layer.c:19:9: note: created &<retval>.feed
Layer.c:19:9: note: add new stmt: MEM <vector(4) long unsigned int> [(void *)&<retval> + 32B] = _54;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 16 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x4d01f48 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 0 <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 1 <retval>.child = 0B;
Layer.c:19:9: note: 	children 0x4d01fc8
Layer.c:19:9: note: node (constant) 0x4d01fc8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ 0B, 0B }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.parent = 0B;
Layer.c:19:9: note: vect_is_simple_use: operand 0B, type of def: constant
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.parent
Layer.c:19:9: note: created &<retval>.parent
Layer.c:19:9: note: add new stmt: MEM <vector(2) long unsigned int> [(struct PULSE_Layer * *)&<retval> + 72B] = { 0, 0 };
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: note: ***** The result for vector mode V32QI would be the same
Layer.c:24:2: missed: statement clobbers memory: free (_1);
Layer.c:25:2: missed: statement clobbers memory: free (_2);
Layer.c:26:2: missed: statement clobbers memory: free (_3);
Layer.c:27:1: note: ***** Analysis failed with vector mode V4DI
Layer.c:27:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:9:27: missed: couldn't vectorize loop
Dense.c:9:27: missed: not vectorized: unsupported outerloop form.
Dense.c:12:20: missed: couldn't vectorize loop
Dense.c:13:21: missed: not vectorized: complicated access pattern.
Dense.c:6:13: note: vectorized 0 loops in function.
Dense.c:16:2: missed: statement clobbers memory: _30 (pretmp_91, _50, 0);
Dense.c:9:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:9:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:24:27: missed: couldn't vectorize loop
Dense.c:24:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:28:20: optimized: loop vectorized using 32 byte vectors
Dense.c:28:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:28:20: optimized: loop vectorized using 16 byte vectors
Dense.c:28:20: missed: couldn't vectorize loop
Dense.c:30:20: missed: not vectorized: no vectype for stmt: _21 = *_20;
 scalar_type: float
Dense.c:20:13: note: vectorized 1 loops in function.
Dense.c:23:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:24:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:24:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:41:28: missed: couldn't vectorize loop
Dense.c:41:28: missed: not vectorized: unsupported outerloop form.
Dense.c:45:21: optimized: loop vectorized using 32 byte vectors
Dense.c:45:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:45:21: optimized: loop vectorized using 16 byte vectors
Dense.c:37:13: note: vectorized 1 loops in function.
Dense.c:37:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:37:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:41:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:149:19: missed: couldn't vectorize loop
Dense.c:149:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:140:19: missed: couldn't vectorize loop
Dense.c:140:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:133:13: note: vectorized 0 loops in function.
Dense.c:157:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:157:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:102:28: missed: couldn't vectorize loop
Dense.c:102:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:105:21: missed: couldn't vectorize loop
Dense.c:105:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:119:28: missed: couldn't vectorize loop
Dense.c:119:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:122:21: missed: couldn't vectorize loop
Dense.c:122:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:88:19: missed: couldn't vectorize loop
Dense.c:88:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:82:13: note: vectorized 0 loops in function.
Dense.c:85:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:107:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:107:17: note: SLPing BB part
Dense.c:124:17: note: Costing subgraph: 
Dense.c:124:17: note: node 0x88a43b8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:124:17: note: op template: _49 = (sizetype) j_137;
Dense.c:124:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:124:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:124:17: note: 	children 0x88a44b8
Dense.c:124:17: note: node (external) 0x88a44b8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:124:17: note: 	{ j_137, wi_136 }
Dense.c:124:17: note: Cost model analysis: 
Dense.c:124:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:124:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:124:17: missed: not vectorized: vectorization is not profitable.
Dense.c:107:17: note: Costing subgraph: 
Dense.c:107:17: note: node 0x88a45b8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:107:17: note: op template: _24 = (sizetype) j_134;
Dense.c:107:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:107:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:107:17: note: 	children 0x88a46b8
Dense.c:107:17: note: node (external) 0x88a46b8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:107:17: note: 	{ j_134, wi_133 }
Dense.c:107:17: note: Cost model analysis: 
Dense.c:107:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:107:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:107:17: missed: not vectorized: vectorization is not profitable.
Dense.c:107:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:107:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:107:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:107:17: note: SLPing BB part
Dense.c:124:17: note: Costing subgraph: 
Dense.c:124:17: note: node 0x88a45b8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:124:17: note: op template: _49 = (sizetype) j_137;
Dense.c:124:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:124:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:124:17: note: 	children 0x88a43b8
Dense.c:124:17: note: node (external) 0x88a43b8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:124:17: note: 	{ j_137, wi_136 }
Dense.c:124:17: note: Cost model analysis: 
Dense.c:124:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:124:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:124:17: missed: not vectorized: vectorization is not profitable.
Dense.c:107:17: note: Costing subgraph: 
Dense.c:107:17: note: node 0x88a4738 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:107:17: note: op template: _24 = (sizetype) j_134;
Dense.c:107:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:107:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:107:17: note: 	children 0x88a4638
Dense.c:107:17: note: node (external) 0x88a4638 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:107:17: note: 	{ j_134, wi_133 }
Dense.c:107:17: note: Cost model analysis: 
Dense.c:107:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:107:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:107:17: missed: not vectorized: vectorization is not profitable.
Dense.c:107:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:102:55: note: ***** Analysis failed with vector mode V8QI
Dense.c:102:55: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:102:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:61:15: missed: couldn't vectorize loop
Dense.c:61:15: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:74:11: optimized: loop vectorized using 32 byte vectors
Dense.c:74:11: optimized: loop vectorized using 16 byte vectors
Dense.c:65:11: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:881:10: missed: not vectorized: no vectype for stmt: _52 = MEM[(__m256 * {ref-all})w_ptr_77];
 scalar_type: __m256
Dense.c:54:13: note: vectorized 1 loops in function.
Dense.c:78:2: missed: statement clobbers memory: _25 (pretmp_158, _63, 0);
Dense.c:54:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:54:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:164:2: missed: statement clobbers memory: free (_1);
Dense.c:165:2: missed: statement clobbers memory: free (_2);
Dense.c:166:2: missed: statement clobbers memory: free (_3);
Dense.c:167:2: missed: statement clobbers memory: free (_4);
Dense.c:168:2: missed: statement clobbers memory: free (dense_7);
Dense.c:169:2: missed: statement clobbers memory: PULSE_DestroyLayer (this_6(D));
Dense.c:170:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:170:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:184:19: missed: couldn't vectorize loop
Dense.c:184:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:174:13: note: vectorized 0 loops in function.
Dense.c:176:47: missed: statement clobbers memory: dense_35 = malloc (40);
Dense.c:178:36: missed: statement clobbers memory: _5 = aligned_alloc (64, _4);
Dense.c:179:38: missed: statement clobbers memory: _6 = aligned_alloc (64, _4);
Dense.c:180:36: missed: statement clobbers memory: _8 = aligned_alloc (64, _7);
Dense.c:181:35: missed: statement clobbers memory: _9 = aligned_alloc (64, _7);
Dense.c:182:36: missed: statement clobbers memory: _10 = aligned_alloc (64, _7);
Dense.c:185:39: missed: statement clobbers memory: _11 = rand ();
Dense.c:185:73: missed: statement clobbers memory: _63 = sqrt (_18);
Dense.c:197:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:198:4: missed: statement clobbers memory: exit (1);
Dense.c:194:4: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.3_29, n_outputs.2_28, 1, activation_function_51(D), _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:191:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.1_27, n_outputs.0_26, 1, activation_function_51(D), _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:204:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Dense.c:204:9: note: ***** Analysis failed with vector mode V4DI
Dense.c:204:9: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Activations.c:17:19: optimized: loop vectorized using 32 byte vectors
Activations.c:17:19: optimized: loop vectorized using 16 byte vectors
Activations.c:17:19: optimized: loop vectorized using 32 byte vectors
Activations.c:17:19: optimized: loop vectorized using 16 byte vectors
Activations.c:14:13: note: vectorized 2 loops in function.
Activations.c:14:13: note: ***** Analysis failed with vector mode V8SF
Activations.c:14:13: note: ***** The result for vector mode V32QI would be the same
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V16QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V16QI
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V8QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V8QI
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V4QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V4QI
Activations.c:28:19: missed: couldn't vectorize loop
Activations.c:28:19: missed: not vectorized: unsupported control flow in loop.
Activations.c:28:19: optimized: loop vectorized using 32 byte vectors
Activations.c:28:19: optimized: loop vectorized using 16 byte vectors
Activations.c:25:13: note: vectorized 1 loops in function.
Activations.c:25:13: note: ***** Analysis failed with vector mode V8SF
Activations.c:25:13: note: ***** The result for vector mode V32QI would be the same
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V16QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V16QI
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V8QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V8QI
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V4QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V4QI
Activations.c:38:1: note: ***** Analysis failed with vector mode VOID
Activations.c:5:19: missed: couldn't vectorize loop
Activations.c:9:21: missed: statement clobbers memory: _36 = expf (_18);
Activations.c:5:19: missed: couldn't vectorize loop
Activations.c:9:21: missed: statement clobbers memory: _12 = expf (_11);
Activations.c:3:13: note: vectorized 0 loops in function.
Activations.c:9:21: missed: statement clobbers memory: _12 = expf (_11);
Activations.c:9:21: missed: statement clobbers memory: _36 = expf (_18);
Activations.c:11:1: note: ***** Analysis failed with vector mode V8SF
Activations.c:11:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Activations.c:44:2: note: ***** Analysis failed with vector mode VOID
Layer.c:7:34: missed: statement clobbers memory: _3 = aligned_alloc (64, _2);
Layer.c:8:35: missed: statement clobbers memory: _6 = aligned_alloc (64, _5);
Layer.c:9:34: missed: statement clobbers memory: _7 = aligned_alloc (64, _5);
Layer.c:14:19: missed: statement clobbers memory: _8 = PULSE_GetActivationFunctionPtr (activation_function_18(D));
Layer.c:19:9: note: ***** Analysis succeeded with vector mode V8SI
Layer.c:19:9: note: SLPing BB part
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x4d277f8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 0 MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 1 MEM <unsigned int> [(struct PULSE_Layer *)&<retval> + 4B] = optimization_type_17(D);
Layer.c:19:9: note: 	children 0x4d27878
Layer.c:19:9: note: node (external) 0x4d27878 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ type_16(D), optimization_type_17(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x4d278f8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 0 <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 1 <retval>.n_outputs = n_outputs_12(D);
Layer.c:19:9: note: 	children 0x4d27978
Layer.c:19:9: note: node (external) 0x4d27978 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x4d27a78 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 0 <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 1 <retval>.outputs = _6;
Layer.c:19:9: note: 	children 0x4d27af8
Layer.c:19:9: note: node (external) 0x4d27af8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	stmt 0 _3 = aligned_alloc (64, _2);
Layer.c:19:9: note: 	stmt 1 _6 = aligned_alloc (64, _5);
Layer.c:19:9: note: 	children 0x4d27b78 0x4d27bf8
Layer.c:19:9: note: node (constant) 0x4d27b78 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 64, 64 }
Layer.c:19:9: note: node 0x4d27bf8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: patt_40 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 0 patt_40 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 1 patt_41 = n_outputs_12(D) w* 4;
Layer.c:19:9: note: 	children 0x4d27c78 0x4d27cf8
Layer.c:19:9: note: node (external) 0x4d27c78 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: node (constant) 0x4d27cf8 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ 4, 4 }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x4d27df8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: op template: <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 0 <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 1 <retval>.back = back_21(D);
Layer.c:19:9: note: 	stmt 2 <retval>.fix = fix_22(D);
Layer.c:19:9: note: 	stmt 3 <retval>.destroy = destroy_23(D);
Layer.c:19:9: note: 	children 0x4d27e78
Layer.c:19:9: note: node (external) 0x4d27e78 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: 	{ feed_20(D), back_21(D), fix_22(D), destroy_23(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 64
  Scalar cost: 64
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x4d27f78 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 0 <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 1 <retval>.child = 0B;
Layer.c:19:9: note: 	children 0x4d27ff8
Layer.c:19:9: note: node (constant) 0x4d27ff8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ 0B, 0B }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Basic block will be vectorized using SLP
Layer.c:19:9: optimized: basic block part vectorized using 8 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x4d277f8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 0 MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 1 MEM <unsigned int> [(struct PULSE_Layer *)&<retval> + 4B] = optimization_type_17(D);
Layer.c:19:9: note: 	children 0x4d27878
Layer.c:19:9: note: node (external) 0x4d27878 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ type_16(D), optimization_type_17(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: vect_is_simple_use: operand optimization_type_17(D), type of def: external
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>]
Layer.c:19:9: note: created &MEM <unsigned int> [(struct PULSE_Layer *)&<retval>]
Layer.c:19:9: note: add new stmt: MEM <vector(2) unsigned int> [(struct PULSE_Layer *)&<retval>] = _42;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 8 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x4d278f8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 0 <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 1 <retval>.n_outputs = n_outputs_12(D);
Layer.c:19:9: note: 	children 0x4d27978
Layer.c:19:9: note: node (external) 0x4d27978 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: vect_is_simple_use: operand n_outputs_12(D), type of def: external
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: <retval>.n_inputs
Layer.c:19:9: note: created &<retval>.n_inputs
Layer.c:19:9: note: add new stmt: MEM <vector(2) unsigned int> [(unsigned int *)&<retval> + 96B] = _44;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 16 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x4d27a78 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 0 <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 1 <retval>.outputs = _6;
Layer.c:19:9: note: 	children 0x4d27af8
Layer.c:19:9: note: node (external) 0x4d27af8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	stmt 0 _3 = aligned_alloc (64, _2);
Layer.c:19:9: note: 	stmt 1 _6 = aligned_alloc (64, _5);
Layer.c:19:9: note: 	children 0x4d27b78 0x4d27bf8
Layer.c:19:9: note: node (constant) 0x4d27b78 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 64, 64 }
Layer.c:19:9: note: node 0x4d27bf8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: patt_40 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 0 patt_40 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 1 patt_41 = n_outputs_12(D) w* 4;
Layer.c:19:9: note: 	children 0x4d27c78 0x4d27cf8
Layer.c:19:9: note: node (external) 0x4d27c78 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: node (constant) 0x4d27cf8 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ 4, 4 }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.inputs = _3;
Layer.c:19:9: note: vect_is_simple_use: operand aligned_alloc (64, _5), type of def: internal
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.inputs
Layer.c:19:9: note: created &<retval>.inputs
Layer.c:19:9: note: add new stmt: MEM <vector(2) long unsigned int> [(float * *)&<retval> + 8B] = _48;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 32 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x4d27df8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: op template: <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 0 <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 1 <retval>.back = back_21(D);
Layer.c:19:9: note: 	stmt 2 <retval>.fix = fix_22(D);
Layer.c:19:9: note: 	stmt 3 <retval>.destroy = destroy_23(D);
Layer.c:19:9: note: 	children 0x4d27e78
Layer.c:19:9: note: node (external) 0x4d27e78 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: 	{ feed_20(D), back_21(D), fix_22(D), destroy_23(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.feed = feed_20(D);
Layer.c:19:9: note: vect_is_simple_use: operand back_21(D), type of def: external
Layer.c:19:9: note: vect_is_simple_use: operand fix_22(D), type of def: external
Layer.c:19:9: note: vect_is_simple_use: operand destroy_23(D), type of def: external
Layer.c:19:9: note: conflicting alias set types.
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(4) long unsigned int  vectorizing a pointer ref: <retval>.feed
Layer.c:19:9: note: created &<retval>.feed
Layer.c:19:9: note: add new stmt: MEM <vector(4) long unsigned int> [(void *)&<retval> + 32B] = _54;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 16 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x4d27f78 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 0 <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 1 <retval>.child = 0B;
Layer.c:19:9: note: 	children 0x4d27ff8
Layer.c:19:9: note: node (constant) 0x4d27ff8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ 0B, 0B }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.parent = 0B;
Layer.c:19:9: note: vect_is_simple_use: operand 0B, type of def: constant
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.parent
Layer.c:19:9: note: created &<retval>.parent
Layer.c:19:9: note: add new stmt: MEM <vector(2) long unsigned int> [(struct PULSE_Layer * *)&<retval> + 72B] = { 0, 0 };
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: note: ***** The result for vector mode V32QI would be the same
Layer.c:24:2: missed: statement clobbers memory: free (_1);
Layer.c:25:2: missed: statement clobbers memory: free (_2);
Layer.c:26:2: missed: statement clobbers memory: free (_3);
Layer.c:27:1: note: ***** Analysis failed with vector mode V4DI
Layer.c:27:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:9:27: missed: couldn't vectorize loop
Dense.c:9:27: missed: not vectorized: unsupported outerloop form.
Dense.c:12:20: missed: couldn't vectorize loop
Dense.c:13:21: missed: not vectorized: complicated access pattern.
Dense.c:6:13: note: vectorized 0 loops in function.
Dense.c:16:2: missed: statement clobbers memory: _30 (pretmp_91, _50, 0);
Dense.c:9:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:9:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:24:27: missed: couldn't vectorize loop
Dense.c:24:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:28:20: optimized: loop vectorized using 32 byte vectors
Dense.c:28:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:28:20: optimized: loop vectorized using 16 byte vectors
Dense.c:28:20: missed: couldn't vectorize loop
Dense.c:30:20: missed: not vectorized: no vectype for stmt: _21 = *_20;
 scalar_type: float
Dense.c:20:13: note: vectorized 1 loops in function.
Dense.c:23:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:24:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:24:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:41:28: missed: couldn't vectorize loop
Dense.c:41:28: missed: not vectorized: unsupported outerloop form.
Dense.c:45:21: optimized: loop vectorized using 32 byte vectors
Dense.c:45:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:45:21: optimized: loop vectorized using 16 byte vectors
Dense.c:37:13: note: vectorized 1 loops in function.
Dense.c:37:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:37:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:41:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:149:19: missed: couldn't vectorize loop
Dense.c:149:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:140:19: missed: couldn't vectorize loop
Dense.c:140:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:133:13: note: vectorized 0 loops in function.
Dense.c:157:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:157:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:102:28: missed: couldn't vectorize loop
Dense.c:102:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:105:21: missed: couldn't vectorize loop
Dense.c:105:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:119:28: missed: couldn't vectorize loop
Dense.c:119:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:122:21: missed: couldn't vectorize loop
Dense.c:122:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:88:19: missed: couldn't vectorize loop
Dense.c:88:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:82:13: note: vectorized 0 loops in function.
Dense.c:85:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:107:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:107:17: note: SLPing BB part
Dense.c:124:17: note: Costing subgraph: 
Dense.c:124:17: note: node 0x8698168 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:124:17: note: op template: _49 = (sizetype) j_137;
Dense.c:124:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:124:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:124:17: note: 	children 0x8698268
Dense.c:124:17: note: node (external) 0x8698268 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:124:17: note: 	{ j_137, wi_136 }
Dense.c:124:17: note: Cost model analysis: 
Dense.c:124:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:124:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:124:17: missed: not vectorized: vectorization is not profitable.
Dense.c:107:17: note: Costing subgraph: 
Dense.c:107:17: note: node 0x8698368 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:107:17: note: op template: _24 = (sizetype) j_134;
Dense.c:107:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:107:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:107:17: note: 	children 0x8698468
Dense.c:107:17: note: node (external) 0x8698468 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:107:17: note: 	{ j_134, wi_133 }
Dense.c:107:17: note: Cost model analysis: 
Dense.c:107:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:107:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:107:17: missed: not vectorized: vectorization is not profitable.
Dense.c:107:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:107:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:107:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:107:17: note: SLPing BB part
Dense.c:124:17: note: Costing subgraph: 
Dense.c:124:17: note: node 0x8698368 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:124:17: note: op template: _49 = (sizetype) j_137;
Dense.c:124:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:124:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:124:17: note: 	children 0x8698168
Dense.c:124:17: note: node (external) 0x8698168 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:124:17: note: 	{ j_137, wi_136 }
Dense.c:124:17: note: Cost model analysis: 
Dense.c:124:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:124:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:124:17: missed: not vectorized: vectorization is not profitable.
Dense.c:107:17: note: Costing subgraph: 
Dense.c:107:17: note: node 0x86984e8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:107:17: note: op template: _24 = (sizetype) j_134;
Dense.c:107:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:107:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:107:17: note: 	children 0x86983e8
Dense.c:107:17: note: node (external) 0x86983e8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:107:17: note: 	{ j_134, wi_133 }
Dense.c:107:17: note: Cost model analysis: 
Dense.c:107:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:107:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:107:17: missed: not vectorized: vectorization is not profitable.
Dense.c:107:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:102:55: note: ***** Analysis failed with vector mode V8QI
Dense.c:102:55: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:102:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:61:15: missed: couldn't vectorize loop
Dense.c:61:15: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:74:11: optimized: loop vectorized using 32 byte vectors
Dense.c:74:11: optimized: loop vectorized using 16 byte vectors
Dense.c:65:11: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:881:10: missed: not vectorized: no vectype for stmt: _52 = MEM[(__m256 * {ref-all})w_ptr_77];
 scalar_type: __m256
Dense.c:54:13: note: vectorized 1 loops in function.
Dense.c:78:2: missed: statement clobbers memory: _25 (pretmp_158, _63, 0);
Dense.c:54:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:54:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:164:2: missed: statement clobbers memory: free (_1);
Dense.c:165:2: missed: statement clobbers memory: free (_2);
Dense.c:166:2: missed: statement clobbers memory: free (_3);
Dense.c:167:2: missed: statement clobbers memory: free (_4);
Dense.c:168:2: missed: statement clobbers memory: free (dense_7);
Dense.c:169:2: missed: statement clobbers memory: PULSE_DestroyLayer (this_6(D));
Dense.c:170:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:170:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:184:19: missed: couldn't vectorize loop
Dense.c:184:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:174:13: note: vectorized 0 loops in function.
Dense.c:176:47: missed: statement clobbers memory: dense_35 = malloc (40);
Dense.c:178:36: missed: statement clobbers memory: _5 = aligned_alloc (64, _4);
Dense.c:179:38: missed: statement clobbers memory: _6 = aligned_alloc (64, _4);
Dense.c:180:36: missed: statement clobbers memory: _8 = aligned_alloc (64, _7);
Dense.c:181:35: missed: statement clobbers memory: _9 = aligned_alloc (64, _7);
Dense.c:182:36: missed: statement clobbers memory: _10 = aligned_alloc (64, _7);
Dense.c:185:39: missed: statement clobbers memory: _11 = rand ();
Dense.c:185:73: missed: statement clobbers memory: _63 = sqrt (_18);
Dense.c:197:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:198:4: missed: statement clobbers memory: exit (1);
Dense.c:194:4: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.3_29, n_outputs.2_28, 1, activation_function_51(D), _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:191:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.1_27, n_outputs.0_26, 1, activation_function_51(D), _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:204:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Dense.c:204:9: note: ***** Analysis failed with vector mode V4DI
Dense.c:204:9: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Activations.c:17:19: optimized: loop vectorized using 32 byte vectors
Activations.c:17:19: optimized: loop vectorized using 16 byte vectors
Activations.c:17:19: optimized: loop vectorized using 32 byte vectors
Activations.c:17:19: optimized: loop vectorized using 16 byte vectors
Activations.c:14:13: note: vectorized 2 loops in function.
Activations.c:14:13: note: ***** Analysis failed with vector mode V8SF
Activations.c:14:13: note: ***** The result for vector mode V32QI would be the same
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V16QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V16QI
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V8QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V8QI
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V4QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V4QI
Activations.c:28:19: missed: couldn't vectorize loop
Activations.c:28:19: missed: not vectorized: unsupported control flow in loop.
Activations.c:28:19: optimized: loop vectorized using 32 byte vectors
Activations.c:28:19: optimized: loop vectorized using 16 byte vectors
Activations.c:25:13: note: vectorized 1 loops in function.
Activations.c:25:13: note: ***** Analysis failed with vector mode V8SF
Activations.c:25:13: note: ***** The result for vector mode V32QI would be the same
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V16QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V16QI
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V8QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V8QI
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V4QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V4QI
Activations.c:38:1: note: ***** Analysis failed with vector mode VOID
Activations.c:5:19: missed: couldn't vectorize loop
Activations.c:9:21: missed: statement clobbers memory: _36 = expf (_18);
Activations.c:5:19: missed: couldn't vectorize loop
Activations.c:9:21: missed: statement clobbers memory: _12 = expf (_11);
Activations.c:3:13: note: vectorized 0 loops in function.
Activations.c:9:21: missed: statement clobbers memory: _12 = expf (_11);
Activations.c:9:21: missed: statement clobbers memory: _36 = expf (_18);
Activations.c:11:1: note: ***** Analysis failed with vector mode V8SF
Activations.c:11:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Activations.c:44:2: note: ***** Analysis failed with vector mode VOID
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:4:18: note: vectorized 0 loops in function.
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_4, inputs_15, _3);
PULSE.c:8:2: missed: statement clobbers memory: _5 (layer_17);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_12, pretmp_26, _9);
PULSE.c:13:28: note: ***** Analysis failed with vector mode V8SI
PULSE.c:13:28: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:22:2: missed: statement clobbers memory: _1 (layer_10(D));
PULSE.c:22:2: missed: statement clobbers memory: _14 (_2);
PULSE.c:22:2: missed: statement clobbers memory: _21 (_15);
PULSE.c:22:2: missed: statement clobbers memory: _28 (_22);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_29);
PULSE.c:26:3: missed: statement clobbers memory: memset (_34, 0, _32);
PULSE.c:26:3: missed: statement clobbers memory: memset (_27, 0, _25);
PULSE.c:26:3: missed: statement clobbers memory: memset (_20, 0, _18);
PULSE.c:26:3: missed: statement clobbers memory: memset (_7, 0, _5);
PULSE.c:28:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:28:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:32:6: note: vectorized 1 loops in function.
PULSE.c:34:8: missed: statement clobbers memory: _1 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_2);
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _9 = rand ();
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8SI
PULSE.c:32:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:61:16: missed: couldn't vectorize loop
PULSE.c:61:16: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:64:17: missed: couldn't vectorize loop
PULSE.c:64:17: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:73:19: missed: couldn't vectorize loop
PULSE.c:73:19: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _64 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:53:22: missed: couldn't vectorize loop
PULSE.c:53:22: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:47:6: note: vectorized 1 loops in function.
PULSE.c:48:1: missed: statement clobbers memory: saved_stack.7_35 = __builtin_stack_save ();
PULSE.c:49:46: missed: statement clobbers memory: _1 = PULSE_GetLossFunctionPtr (loss_function_36(D));
PULSE.c:60:10: missed: statement clobbers memory: random.4_42 = __builtin_alloca_with_align (_4, 32);
PULSE.c:34:8: missed: statement clobbers memory: _56 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_57);
PULSE.c:39:29: missed: statement clobbers memory: _64 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _67 = rand ();
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_93, inputs_88, _92);
PULSE.c:8:2: missed: statement clobbers memory: _94 (layer_89);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_100, _99, _98);
PULSE.c:67:11: missed: statement clobbers memory: loss_51 = PULSE_GetLoss_38 (_17, _16, _12, _11);
PULSE.c:22:2: missed: statement clobbers memory: _81 (output_30);
PULSE.c:22:2: missed: statement clobbers memory: _103 (_82);
PULSE.c:22:2: missed: statement clobbers memory: _110 (_104);
PULSE.c:22:2: missed: statement clobbers memory: _117 (_111);
PULSE.c:22:2: missed: statement clobbers memory: _124 (_118);
PULSE.c:22:2: missed: statement clobbers memory: _131 (_125);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_132);
PULSE.c:26:3: missed: statement clobbers memory: memset (_137, 0, _135);
PULSE.c:26:3: missed: statement clobbers memory: memset (_130, 0, _128);
PULSE.c:26:3: missed: statement clobbers memory: memset (_123, 0, _121);
PULSE.c:26:3: missed: statement clobbers memory: memset (_116, 0, _114);
PULSE.c:26:3: missed: statement clobbers memory: memset (_109, 0, _107);
PULSE.c:26:3: missed: statement clobbers memory: memset (_87, 0, _85);
PULSE.c:75:6: missed: statement clobbers memory: _21 (current_183, args);
PULSE.c:80:4: missed: statement clobbers memory: printf ("Epoch: %d Item: %d Loss: %.10f\r", i_181, j_182, _22);
PULSE.c:47:6: missed: statement clobbers memory: __builtin_stack_restore (saved_stack.7_35);
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4DI
PULSE.c:47:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:89:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:89:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:94:8: missed: couldn't vectorize loop
PULSE.c:94:8: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:91:6: note: vectorized 0 loops in function.
PULSE.c:96:3: missed: statement clobbers memory: _1 (current_10);
PULSE.c:99:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:99:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Loss.c:15:19: optimized: loop vectorized using 32 byte vectors
Loss.c:15:19: optimized:  loop versioned for vectorization because of possible aliasing
Loss.c:15:19: optimized: loop vectorized using 16 byte vectors
Loss.c:12:23: note: vectorized 1 loops in function.
Loss.c:12:23: note: ***** Analysis failed with vector mode V8SF
Loss.c:12:23: note: ***** The result for vector mode V32QI would be the same
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V16QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V16QI
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V8QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V8QI
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V4QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V4QI
Loss.c:7:19: missed: couldn't vectorize loop
Loss.c:8:38: missed: not vectorized: unsupported use in stmt.
Loss.c:4:23: note: vectorized 0 loops in function.
Loss.c:9:13: note: ***** Analysis failed with vector mode V8SF
Loss.c:9:13: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Loss.c:23:2: note: ***** Analysis failed with vector mode VOID
Dense.c:9:27: missed: couldn't vectorize loop
Dense.c:9:27: missed: not vectorized: unsupported outerloop form.
Dense.c:12:20: missed: couldn't vectorize loop
Dense.c:13:21: missed: not vectorized: complicated access pattern.
Dense.c:6:13: note: vectorized 0 loops in function.
Dense.c:16:2: missed: statement clobbers memory: _30 (pretmp_91, _50, 0);
Dense.c:9:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:9:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:24:27: missed: couldn't vectorize loop
Dense.c:24:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:28:20: optimized: loop vectorized using 32 byte vectors
Dense.c:28:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:28:20: optimized: loop vectorized using 16 byte vectors
Dense.c:28:20: missed: couldn't vectorize loop
Dense.c:30:20: missed: not vectorized: no vectype for stmt: _21 = *_20;
 scalar_type: float
Dense.c:20:13: note: vectorized 1 loops in function.
Dense.c:23:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:24:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:24:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:41:28: missed: couldn't vectorize loop
Dense.c:41:28: missed: not vectorized: unsupported outerloop form.
Dense.c:45:21: optimized: loop vectorized using 32 byte vectors
Dense.c:45:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:45:21: optimized: loop vectorized using 16 byte vectors
Dense.c:37:13: note: vectorized 1 loops in function.
Dense.c:37:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:37:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:41:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:151:19: missed: couldn't vectorize loop
Dense.c:151:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:142:19: missed: couldn't vectorize loop
Dense.c:142:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:135:13: note: vectorized 0 loops in function.
Dense.c:159:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:159:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:104:28: missed: couldn't vectorize loop
Dense.c:104:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:107:21: missed: couldn't vectorize loop
Dense.c:107:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:121:28: missed: couldn't vectorize loop
Dense.c:121:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:124:21: missed: couldn't vectorize loop
Dense.c:124:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:90:19: missed: couldn't vectorize loop
Dense.c:90:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:84:13: note: vectorized 0 loops in function.
Dense.c:87:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:109:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:109:17: note: SLPing BB part
Dense.c:126:17: note: Costing subgraph: 
Dense.c:126:17: note: node 0x8963178 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:126:17: note: op template: _49 = (sizetype) j_137;
Dense.c:126:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:126:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:126:17: note: 	children 0x8963278
Dense.c:126:17: note: node (external) 0x8963278 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:126:17: note: 	{ j_137, wi_136 }
Dense.c:126:17: note: Cost model analysis: 
Dense.c:126:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:126:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:126:17: missed: not vectorized: vectorization is not profitable.
Dense.c:109:17: note: Costing subgraph: 
Dense.c:109:17: note: node 0x8963378 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:109:17: note: op template: _24 = (sizetype) j_134;
Dense.c:109:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:109:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:109:17: note: 	children 0x8963478
Dense.c:109:17: note: node (external) 0x8963478 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:109:17: note: 	{ j_134, wi_133 }
Dense.c:109:17: note: Cost model analysis: 
Dense.c:109:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:109:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:109:17: missed: not vectorized: vectorization is not profitable.
Dense.c:109:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:109:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:109:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:109:17: note: SLPing BB part
Dense.c:126:17: note: Costing subgraph: 
Dense.c:126:17: note: node 0x8963378 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:126:17: note: op template: _49 = (sizetype) j_137;
Dense.c:126:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:126:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:126:17: note: 	children 0x8963178
Dense.c:126:17: note: node (external) 0x8963178 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:126:17: note: 	{ j_137, wi_136 }
Dense.c:126:17: note: Cost model analysis: 
Dense.c:126:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:126:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:126:17: missed: not vectorized: vectorization is not profitable.
Dense.c:109:17: note: Costing subgraph: 
Dense.c:109:17: note: node 0x89634f8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:109:17: note: op template: _24 = (sizetype) j_134;
Dense.c:109:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:109:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:109:17: note: 	children 0x89633f8
Dense.c:109:17: note: node (external) 0x89633f8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:109:17: note: 	{ j_134, wi_133 }
Dense.c:109:17: note: Cost model analysis: 
Dense.c:109:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:109:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:109:17: missed: not vectorized: vectorization is not profitable.
Dense.c:109:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:104:55: note: ***** Analysis failed with vector mode V8QI
Dense.c:104:55: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:104:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:166:2: missed: statement clobbers memory: free (_1);
Dense.c:167:2: missed: statement clobbers memory: free (_2);
Dense.c:168:2: missed: statement clobbers memory: free (_3);
Dense.c:169:2: missed: statement clobbers memory: free (_4);
Dense.c:170:2: missed: statement clobbers memory: free (dense_7);
Dense.c:171:2: missed: statement clobbers memory: PULSE_DestroyLayer (this_6(D));
Dense.c:172:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:172:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Include/PULSE_SIMD.h:101:20: missed: couldn't vectorize loop
Include/PULSE_SIMD.h:101:20: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Include/PULSE_SIMD.h:104:21: missed: couldn't vectorize loop
Include/PULSE_SIMD.h:104:21: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Include/PULSE_SIMD.h:129:23: optimized: loop vectorized using 32 byte vectors
Include/PULSE_SIMD.h:129:23: optimized: loop vectorized using 16 byte vectors
Include/PULSE_SIMD.h:121:23: missed: couldn't vectorize loop
Include/PULSE_SIMD.h:123:18: missed: not vectorized: no vectype for stmt: _47 = localM2[m_180];
 scalar_type: __m256
Include/PULSE_SIMD.h:88:13: note: vectorized 1 loops in function.
Include/PULSE_SIMD.h:109:19: note: ***** Analysis succeeded with vector mode V8SF
Include/PULSE_SIMD.h:109:19: note: SLPing BB part
Include/PULSE_SIMD.h:112:22: note: Costing subgraph: 
Include/PULSE_SIMD.h:112:22: note: node 0x8827d58 (max_nunits=8, refcnt=1) vector(8) float
Include/PULSE_SIMD.h:112:22: note: op template: localDst[0][0] = 0.0;
Include/PULSE_SIMD.h:112:22: note: 	stmt 0 localDst[0][0] = 0.0;
Include/PULSE_SIMD.h:112:22: note: 	stmt 1 localDst[0][1] = 0.0;
Include/PULSE_SIMD.h:112:22: note: 	stmt 2 localDst[0][2] = 0.0;
Include/PULSE_SIMD.h:112:22: note: 	stmt 3 localDst[0][3] = 0.0;
Include/PULSE_SIMD.h:112:22: note: 	stmt 4 localDst[0][4] = 0.0;
Include/PULSE_SIMD.h:112:22: note: 	stmt 5 localDst[0][5] = 0.0;
Include/PULSE_SIMD.h:112:22: note: 	stmt 6 localDst[0][6] = 0.0;
Include/PULSE_SIMD.h:112:22: note: 	stmt 7 localDst[0][7] = 0.0;
Include/PULSE_SIMD.h:112:22: note: 	children 0x8827dd8
Include/PULSE_SIMD.h:112:22: note: node (constant) 0x8827dd8 (max_nunits=1, refcnt=1) vector(8) float
Include/PULSE_SIMD.h:112:22: note: 	{ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 }
Include/PULSE_SIMD.h:112:22: note: Cost model analysis: 
Include/PULSE_SIMD.h:112:22: note: Cost model analysis for part in loop 3:
  Vector cost: 40
  Scalar cost: 128
Include/PULSE_SIMD.h:109:19: note: Costing subgraph: 
Include/PULSE_SIMD.h:109:19: note: node 0x8827e58 (max_nunits=2, refcnt=1) vector(2) sizetype
Include/PULSE_SIMD.h:109:19: note: op template: _136 = (sizetype) k_179;
Include/PULSE_SIMD.h:109:19: note: 	stmt 0 _136 = (sizetype) k_179;
Include/PULSE_SIMD.h:109:19: note: 	stmt 1 _144 = (sizetype) _143;
Include/PULSE_SIMD.h:109:19: note: 	children 0x8827f58
Include/PULSE_SIMD.h:109:19: note: node (external) 0x8827f58 (max_nunits=1, refcnt=1) vector(2) int
Include/PULSE_SIMD.h:109:19: note: 	{ k_179, _143 }
Include/PULSE_SIMD.h:109:19: note: node 0x8827fd8 (max_nunits=2, refcnt=1) vector(2) sizetype
Include/PULSE_SIMD.h:109:19: note: op template: _136 = (sizetype) k_179;
Include/PULSE_SIMD.h:109:19: note: 	stmt 0 _136 = (sizetype) k_179;
Include/PULSE_SIMD.h:109:19: note: 	stmt 1 _173 = (sizetype) _176;
Include/PULSE_SIMD.h:109:19: note: 	children 0x88280d8
Include/PULSE_SIMD.h:109:19: note: node (external) 0x88280d8 (max_nunits=1, refcnt=1) vector(2) int
Include/PULSE_SIMD.h:109:19: note: 	{ k_179, _176 }
Include/PULSE_SIMD.h:109:19: note: node 0x8828158 (max_nunits=2, refcnt=1) vector(2) sizetype
Include/PULSE_SIMD.h:109:19: note: op template: _136 = (sizetype) k_179;
Include/PULSE_SIMD.h:109:19: note: 	stmt 0 _136 = (sizetype) k_179;
Include/PULSE_SIMD.h:109:19: note: 	stmt 1 _406 = (sizetype) _441;
Include/PULSE_SIMD.h:109:19: note: 	children 0x8828258
Include/PULSE_SIMD.h:109:19: note: node (external) 0x8828258 (max_nunits=1, refcnt=1) vector(2) int
Include/PULSE_SIMD.h:109:19: note: 	{ k_179, _441 }
Include/PULSE_SIMD.h:109:19: note: node 0x88282d8 (max_nunits=2, refcnt=1) vector(2) sizetype
Include/PULSE_SIMD.h:109:19: note: op template: _136 = (sizetype) k_179;
Include/PULSE_SIMD.h:109:19: note: 	stmt 0 _136 = (sizetype) k_179;
Include/PULSE_SIMD.h:109:19: note: 	stmt 1 _251 = (sizetype) _204;
Include/PULSE_SIMD.h:109:19: note: 	children 0x88283d8
Include/PULSE_SIMD.h:109:19: note: node (external) 0x88283d8 (max_nunits=1, refcnt=1) vector(2) int
Include/PULSE_SIMD.h:109:19: note: 	{ k_179, _204 }
Include/PULSE_SIMD.h:109:19: note: node 0x8828458 (max_nunits=2, refcnt=1) vector(2) sizetype
Include/PULSE_SIMD.h:109:19: note: op template: _136 = (sizetype) k_179;
Include/PULSE_SIMD.h:109:19: note: 	stmt 0 _136 = (sizetype) k_179;
Include/PULSE_SIMD.h:109:19: note: 	stmt 1 _291 = (sizetype) _290;
Include/PULSE_SIMD.h:109:19: note: 	children 0x8828558
Include/PULSE_SIMD.h:109:19: note: node (external) 0x8828558 (max_nunits=1, refcnt=1) vector(2) int
Include/PULSE_SIMD.h:109:19: note: 	{ k_179, _290 }
Include/PULSE_SIMD.h:109:19: note: node 0x88285d8 (max_nunits=2, refcnt=1) vector(2) sizetype
Include/PULSE_SIMD.h:109:19: note: op template: _136 = (sizetype) k_179;
Include/PULSE_SIMD.h:109:19: note: 	stmt 0 _136 = (sizetype) k_179;
Include/PULSE_SIMD.h:109:19: note: 	stmt 1 _309 = (sizetype) _308;
Include/PULSE_SIMD.h:109:19: note: 	children 0x88286d8
Include/PULSE_SIMD.h:109:19: note: node (external) 0x88286d8 (max_nunits=1, refcnt=1) vector(2) int
Include/PULSE_SIMD.h:109:19: note: 	{ k_179, _308 }
Include/PULSE_SIMD.h:109:19: note: node 0x8828758 (max_nunits=2, refcnt=1) vector(2) sizetype
Include/PULSE_SIMD.h:109:19: note: op template: _136 = (sizetype) k_179;
Include/PULSE_SIMD.h:109:19: note: 	stmt 0 _136 = (sizetype) k_179;
Include/PULSE_SIMD.h:109:19: note: 	stmt 1 _349 = (sizetype) _348;
Include/PULSE_SIMD.h:109:19: note: 	children 0x8828858
Include/PULSE_SIMD.h:109:19: note: node (external) 0x8828858 (max_nunits=1, refcnt=1) vector(2) int
Include/PULSE_SIMD.h:109:19: note: 	{ k_179, _348 }
Include/PULSE_SIMD.h:109:19: note: node 0x88288d8 (max_nunits=2, refcnt=1) vector(2) sizetype
Include/PULSE_SIMD.h:109:19: note: op template: _136 = (sizetype) k_179;
Include/PULSE_SIMD.h:109:19: note: 	stmt 0 _136 = (sizetype) k_179;
Include/PULSE_SIMD.h:109:19: note: 	stmt 1 _412 = (sizetype) _411;
Include/PULSE_SIMD.h:109:19: note: 	children 0x88289d8
Include/PULSE_SIMD.h:109:19: note: node (external) 0x88289d8 (max_nunits=1, refcnt=1) vector(2) int
Include/PULSE_SIMD.h:109:19: note: 	{ k_179, _411 }
Include/PULSE_SIMD.h:109:19: note: Cost model analysis: 
Include/PULSE_SIMD.h:109:19: note: Cost model analysis for part in loop 2:
  Vector cost: 4
  Scalar cost: 32
Include/PULSE_SIMD.h:109:19: note: Cost model analysis for part in loop 3:
  Vector cost: 304
  Scalar cost: 36
Include/PULSE_SIMD.h:109:19: missed: not vectorized: vectorization is not profitable.
Include/PULSE_SIMD.h:109:19: note: Basic block will be vectorized using SLP
Include/PULSE_SIMD.h:112:22: optimized: basic block part vectorized using 32 byte vectors
Include/PULSE_SIMD.h:112:22: note: Vectorizing SLP tree:
Include/PULSE_SIMD.h:112:22: note: node 0x8827d58 (max_nunits=8, refcnt=1) vector(8) float
Include/PULSE_SIMD.h:112:22: note: op template: localDst[0][0] = 0.0;
Include/PULSE_SIMD.h:112:22: note: 	stmt 0 localDst[0][0] = 0.0;
Include/PULSE_SIMD.h:112:22: note: 	stmt 1 localDst[0][1] = 0.0;
Include/PULSE_SIMD.h:112:22: note: 	stmt 2 localDst[0][2] = 0.0;
Include/PULSE_SIMD.h:112:22: note: 	stmt 3 localDst[0][3] = 0.0;
Include/PULSE_SIMD.h:112:22: note: 	stmt 4 localDst[0][4] = 0.0;
Include/PULSE_SIMD.h:112:22: note: 	stmt 5 localDst[0][5] = 0.0;
Include/PULSE_SIMD.h:112:22: note: 	stmt 6 localDst[0][6] = 0.0;
Include/PULSE_SIMD.h:112:22: note: 	stmt 7 localDst[0][7] = 0.0;
Include/PULSE_SIMD.h:112:22: note: 	children 0x8827dd8
Include/PULSE_SIMD.h:112:22: note: node (constant) 0x8827dd8 (max_nunits=1, refcnt=1) vector(8) float
Include/PULSE_SIMD.h:112:22: note: 	{ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 }
Include/PULSE_SIMD.h:112:22: note: ------>vectorizing SLP node starting from: localDst[0][0] = 0.0;
Include/PULSE_SIMD.h:112:22: note: vect_is_simple_use: operand 0.0, type of def: constant
Include/PULSE_SIMD.h:112:22: note: vect_is_simple_use: operand 0.0, type of def: constant
Include/PULSE_SIMD.h:112:22: note: vect_is_simple_use: operand 0.0, type of def: constant
Include/PULSE_SIMD.h:112:22: note: vect_is_simple_use: operand 0.0, type of def: constant
Include/PULSE_SIMD.h:112:22: note: vect_is_simple_use: operand 0.0, type of def: constant
Include/PULSE_SIMD.h:112:22: note: vect_is_simple_use: operand 0.0, type of def: constant
Include/PULSE_SIMD.h:112:22: note: vect_is_simple_use: operand 0.0, type of def: constant
Include/PULSE_SIMD.h:112:22: note: transform store. ncopies = 1
Include/PULSE_SIMD.h:112:22: note: create vector_type-pointer variable to type: vector(8) float  vectorizing a pointer ref: localDst[0][0]
Include/PULSE_SIMD.h:112:22: note: created &localDst[0][0]
Include/PULSE_SIMD.h:112:22: note: add new stmt: MEM <vector(8) float> [(float *)&localDst] = { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 };
Include/PULSE_SIMD.h:112:22: note: vectorizing stmts using SLP.
Include/PULSE_SIMD.h:109:19: note: ***** The result for vector mode V32QI would be the same
Dense.c:57:2: missed: statement clobbers memory: memcpy (_5, _4, _3);
Dense.c:58:2: missed: statement clobbers memory: __PULSE_SIMD_MxTM.constprop (_12, _11, _10, _9, _7);
Dense.c:80:2: missed: statement clobbers memory: _13 (_10, _8, 0);
Dense.c:81:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:81:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:186:19: missed: couldn't vectorize loop
Dense.c:186:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:176:13: note: vectorized 0 loops in function.
Dense.c:178:47: missed: statement clobbers memory: dense_35 = malloc (40);
Dense.c:180:36: missed: statement clobbers memory: _5 = aligned_alloc (64, _4);
Dense.c:181:38: missed: statement clobbers memory: _6 = aligned_alloc (64, _4);
Dense.c:182:36: missed: statement clobbers memory: _8 = aligned_alloc (64, _7);
Dense.c:183:35: missed: statement clobbers memory: _9 = aligned_alloc (64, _7);
Dense.c:184:36: missed: statement clobbers memory: _10 = aligned_alloc (64, _7);
Dense.c:187:39: missed: statement clobbers memory: _11 = rand ();
Dense.c:187:73: missed: statement clobbers memory: _63 = sqrt (_18);
Dense.c:199:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:200:4: missed: statement clobbers memory: exit (1);
Dense.c:196:4: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.3_29, n_outputs.2_28, 1, activation_function_51(D), _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:193:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.1_27, n_outputs.0_26, 1, activation_function_51(D), _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:206:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Dense.c:206:9: note: ***** Analysis failed with vector mode V4DI
Dense.c:206:9: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Layer.c:7:34: missed: statement clobbers memory: _3 = aligned_alloc (64, _2);
Layer.c:8:35: missed: statement clobbers memory: _6 = aligned_alloc (64, _5);
Layer.c:9:34: missed: statement clobbers memory: _7 = aligned_alloc (64, _5);
Layer.c:14:19: missed: statement clobbers memory: _8 = PULSE_GetActivationFunctionPtr (activation_function_18(D));
Layer.c:19:9: note: ***** Analysis succeeded with vector mode V8SI
Layer.c:19:9: note: SLPing BB part
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x47cf7c8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 0 MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 1 MEM <unsigned int> [(struct PULSE_Layer *)&<retval> + 4B] = optimization_type_17(D);
Layer.c:19:9: note: 	children 0x47cf848
Layer.c:19:9: note: node (external) 0x47cf848 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ type_16(D), optimization_type_17(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x47cf8c8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 0 <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 1 <retval>.n_outputs = n_outputs_12(D);
Layer.c:19:9: note: 	children 0x47cf948
Layer.c:19:9: note: node (external) 0x47cf948 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x47cfa48 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 0 <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 1 <retval>.outputs = _6;
Layer.c:19:9: note: 	children 0x47cfac8
Layer.c:19:9: note: node (external) 0x47cfac8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	stmt 0 _3 = aligned_alloc (64, _2);
Layer.c:19:9: note: 	stmt 1 _6 = aligned_alloc (64, _5);
Layer.c:19:9: note: 	children 0x47cfb48 0x47cfbc8
Layer.c:19:9: note: node (constant) 0x47cfb48 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 64, 64 }
Layer.c:19:9: note: node 0x47cfbc8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: patt_40 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 0 patt_40 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 1 patt_41 = n_outputs_12(D) w* 4;
Layer.c:19:9: note: 	children 0x47cfc48 0x47cfcc8
Layer.c:19:9: note: node (external) 0x47cfc48 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: node (constant) 0x47cfcc8 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ 4, 4 }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x47cfdc8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: op template: <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 0 <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 1 <retval>.back = back_21(D);
Layer.c:19:9: note: 	stmt 2 <retval>.fix = fix_22(D);
Layer.c:19:9: note: 	stmt 3 <retval>.destroy = destroy_23(D);
Layer.c:19:9: note: 	children 0x47cfe48
Layer.c:19:9: note: node (external) 0x47cfe48 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: 	{ feed_20(D), back_21(D), fix_22(D), destroy_23(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 64
  Scalar cost: 64
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x47cff48 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 0 <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 1 <retval>.child = 0B;
Layer.c:19:9: note: 	children 0x47cffc8
Layer.c:19:9: note: node (constant) 0x47cffc8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ 0B, 0B }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Basic block will be vectorized using SLP
Layer.c:19:9: optimized: basic block part vectorized using 8 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x47cf7c8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 0 MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 1 MEM <unsigned int> [(struct PULSE_Layer *)&<retval> + 4B] = optimization_type_17(D);
Layer.c:19:9: note: 	children 0x47cf848
Layer.c:19:9: note: node (external) 0x47cf848 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ type_16(D), optimization_type_17(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: vect_is_simple_use: operand optimization_type_17(D), type of def: external
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>]
Layer.c:19:9: note: created &MEM <unsigned int> [(struct PULSE_Layer *)&<retval>]
Layer.c:19:9: note: add new stmt: MEM <vector(2) unsigned int> [(struct PULSE_Layer *)&<retval>] = _42;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 8 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x47cf8c8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 0 <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 1 <retval>.n_outputs = n_outputs_12(D);
Layer.c:19:9: note: 	children 0x47cf948
Layer.c:19:9: note: node (external) 0x47cf948 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: vect_is_simple_use: operand n_outputs_12(D), type of def: external
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: <retval>.n_inputs
Layer.c:19:9: note: created &<retval>.n_inputs
Layer.c:19:9: note: add new stmt: MEM <vector(2) unsigned int> [(unsigned int *)&<retval> + 96B] = _44;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 16 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x47cfa48 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 0 <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 1 <retval>.outputs = _6;
Layer.c:19:9: note: 	children 0x47cfac8
Layer.c:19:9: note: node (external) 0x47cfac8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	stmt 0 _3 = aligned_alloc (64, _2);
Layer.c:19:9: note: 	stmt 1 _6 = aligned_alloc (64, _5);
Layer.c:19:9: note: 	children 0x47cfb48 0x47cfbc8
Layer.c:19:9: note: node (constant) 0x47cfb48 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 64, 64 }
Layer.c:19:9: note: node 0x47cfbc8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: patt_40 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 0 patt_40 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 1 patt_41 = n_outputs_12(D) w* 4;
Layer.c:19:9: note: 	children 0x47cfc48 0x47cfcc8
Layer.c:19:9: note: node (external) 0x47cfc48 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: node (constant) 0x47cfcc8 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ 4, 4 }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.inputs = _3;
Layer.c:19:9: note: vect_is_simple_use: operand aligned_alloc (64, _5), type of def: internal
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.inputs
Layer.c:19:9: note: created &<retval>.inputs
Layer.c:19:9: note: add new stmt: MEM <vector(2) long unsigned int> [(float * *)&<retval> + 8B] = _48;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 32 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x47cfdc8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: op template: <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 0 <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 1 <retval>.back = back_21(D);
Layer.c:19:9: note: 	stmt 2 <retval>.fix = fix_22(D);
Layer.c:19:9: note: 	stmt 3 <retval>.destroy = destroy_23(D);
Layer.c:19:9: note: 	children 0x47cfe48
Layer.c:19:9: note: node (external) 0x47cfe48 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: 	{ feed_20(D), back_21(D), fix_22(D), destroy_23(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.feed = feed_20(D);
Layer.c:19:9: note: vect_is_simple_use: operand back_21(D), type of def: external
Layer.c:19:9: note: vect_is_simple_use: operand fix_22(D), type of def: external
Layer.c:19:9: note: vect_is_simple_use: operand destroy_23(D), type of def: external
Layer.c:19:9: note: conflicting alias set types.
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(4) long unsigned int  vectorizing a pointer ref: <retval>.feed
Layer.c:19:9: note: created &<retval>.feed
Layer.c:19:9: note: add new stmt: MEM <vector(4) long unsigned int> [(void *)&<retval> + 32B] = _54;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 16 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x47cff48 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 0 <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 1 <retval>.child = 0B;
Layer.c:19:9: note: 	children 0x47cffc8
Layer.c:19:9: note: node (constant) 0x47cffc8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ 0B, 0B }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.parent = 0B;
Layer.c:19:9: note: vect_is_simple_use: operand 0B, type of def: constant
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.parent
Layer.c:19:9: note: created &<retval>.parent
Layer.c:19:9: note: add new stmt: MEM <vector(2) long unsigned int> [(struct PULSE_Layer * *)&<retval> + 72B] = { 0, 0 };
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: note: ***** The result for vector mode V32QI would be the same
Layer.c:24:2: missed: statement clobbers memory: free (_1);
Layer.c:25:2: missed: statement clobbers memory: free (_2);
Layer.c:26:2: missed: statement clobbers memory: free (_3);
Layer.c:27:1: note: ***** Analysis failed with vector mode V4DI
Layer.c:27:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:9:27: missed: couldn't vectorize loop
Dense.c:9:27: missed: not vectorized: unsupported outerloop form.
Dense.c:12:20: missed: couldn't vectorize loop
Dense.c:13:21: missed: not vectorized: complicated access pattern.
Dense.c:6:13: note: vectorized 0 loops in function.
Dense.c:16:2: missed: statement clobbers memory: _30 (pretmp_91, _50, 0);
Dense.c:9:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:9:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:24:27: missed: couldn't vectorize loop
Dense.c:24:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:28:20: optimized: loop vectorized using 32 byte vectors
Dense.c:28:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:28:20: optimized: loop vectorized using 16 byte vectors
Dense.c:28:20: missed: couldn't vectorize loop
Dense.c:30:20: missed: not vectorized: no vectype for stmt: _21 = *_20;
 scalar_type: float
Dense.c:20:13: note: vectorized 1 loops in function.
Dense.c:23:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:24:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:24:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:41:28: missed: couldn't vectorize loop
Dense.c:41:28: missed: not vectorized: unsupported outerloop form.
Dense.c:45:21: optimized: loop vectorized using 32 byte vectors
Dense.c:45:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:45:21: optimized: loop vectorized using 16 byte vectors
Dense.c:37:13: note: vectorized 1 loops in function.
Dense.c:37:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:37:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:41:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:151:19: missed: couldn't vectorize loop
Dense.c:151:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:142:19: missed: couldn't vectorize loop
Dense.c:142:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:135:13: note: vectorized 0 loops in function.
Dense.c:159:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:159:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:104:28: missed: couldn't vectorize loop
Dense.c:104:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:107:21: missed: couldn't vectorize loop
Dense.c:107:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:121:28: missed: couldn't vectorize loop
Dense.c:121:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:124:21: missed: couldn't vectorize loop
Dense.c:124:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:90:19: missed: couldn't vectorize loop
Dense.c:90:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:84:13: note: vectorized 0 loops in function.
Dense.c:87:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:109:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:109:17: note: SLPing BB part
Dense.c:126:17: note: Costing subgraph: 
Dense.c:126:17: note: node 0x8998da8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:126:17: note: op template: _49 = (sizetype) j_137;
Dense.c:126:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:126:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:126:17: note: 	children 0x8998ea8
Dense.c:126:17: note: node (external) 0x8998ea8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:126:17: note: 	{ j_137, wi_136 }
Dense.c:126:17: note: Cost model analysis: 
Dense.c:126:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:126:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:126:17: missed: not vectorized: vectorization is not profitable.
Dense.c:109:17: note: Costing subgraph: 
Dense.c:109:17: note: node 0x8998fa8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:109:17: note: op template: _24 = (sizetype) j_134;
Dense.c:109:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:109:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:109:17: note: 	children 0x89990a8
Dense.c:109:17: note: node (external) 0x89990a8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:109:17: note: 	{ j_134, wi_133 }
Dense.c:109:17: note: Cost model analysis: 
Dense.c:109:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:109:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:109:17: missed: not vectorized: vectorization is not profitable.
Dense.c:109:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:109:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:109:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:109:17: note: SLPing BB part
Dense.c:126:17: note: Costing subgraph: 
Dense.c:126:17: note: node 0x8998fa8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:126:17: note: op template: _49 = (sizetype) j_137;
Dense.c:126:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:126:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:126:17: note: 	children 0x8998da8
Dense.c:126:17: note: node (external) 0x8998da8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:126:17: note: 	{ j_137, wi_136 }
Dense.c:126:17: note: Cost model analysis: 
Dense.c:126:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:126:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:126:17: missed: not vectorized: vectorization is not profitable.
Dense.c:109:17: note: Costing subgraph: 
Dense.c:109:17: note: node 0x8999128 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:109:17: note: op template: _24 = (sizetype) j_134;
Dense.c:109:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:109:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:109:17: note: 	children 0x8999028
Dense.c:109:17: note: node (external) 0x8999028 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:109:17: note: 	{ j_134, wi_133 }
Dense.c:109:17: note: Cost model analysis: 
Dense.c:109:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:109:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:109:17: missed: not vectorized: vectorization is not profitable.
Dense.c:109:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:104:55: note: ***** Analysis failed with vector mode V8QI
Dense.c:104:55: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:104:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:166:2: missed: statement clobbers memory: free (_1);
Dense.c:167:2: missed: statement clobbers memory: free (_2);
Dense.c:168:2: missed: statement clobbers memory: free (_3);
Dense.c:169:2: missed: statement clobbers memory: free (_4);
Dense.c:170:2: missed: statement clobbers memory: free (dense_7);
Dense.c:171:2: missed: statement clobbers memory: PULSE_DestroyLayer (this_6(D));
Dense.c:172:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:172:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Include/PULSE_SIMD.h:98:20: missed: couldn't vectorize loop
Include/PULSE_SIMD.h:98:20: missed: not vectorized: multiple nested loops.
Include/PULSE_SIMD.h:101:21: missed: couldn't vectorize loop
Include/PULSE_SIMD.h:101:21: missed: not vectorized: multiple nested loops.
Include/PULSE_SIMD.h:103:22: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:905:10: missed: not vectorized: no vectype for stmt: _179 = MEM[(__m256_u * {ref-all})_178];
 scalar_type: __m256_u
Include/PULSE_SIMD.h:105:23: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:905:10: missed: not vectorized: no vectype for stmt: _179 = MEM[(__m256_u * {ref-all})_178];
 scalar_type: __m256_u
Dense.c:54:13: note: vectorized 0 loops in function.
Dense.c:57:2: missed: statement clobbers memory: memcpy (_5, _4, _3);
Dense.c:80:2: missed: statement clobbers memory: _13 (_10, _8, 0);
Include/PULSE_SIMD.h:111:8: note: ***** Analysis succeeded with vector mode V4DI
Include/PULSE_SIMD.h:111:8: note: SLPing BB part
Include/PULSE_SIMD.h:110:13: note: Costing subgraph: 
Include/PULSE_SIMD.h:110:13: note: node 0x8978e88 (max_nunits=2, refcnt=1) vector(2) sizetype
Include/PULSE_SIMD.h:110:13: note: op template: _174 = (sizetype) _173;
Include/PULSE_SIMD.h:110:13: note: 	stmt 0 _174 = (sizetype) _173;
Include/PULSE_SIMD.h:110:13: note: 	stmt 1 _243 = (sizetype) k_22;
Include/PULSE_SIMD.h:110:13: note: 	children 0x8978f88
Include/PULSE_SIMD.h:110:13: note: node (external) 0x8978f88 (max_nunits=1, refcnt=1) vector(2) int
Include/PULSE_SIMD.h:110:13: note: 	{ _173, k_22 }
Include/PULSE_SIMD.h:110:13: note: node 0x8979088 (max_nunits=2, refcnt=1) vector(2) sizetype
Include/PULSE_SIMD.h:110:13: note: op template: _182 = (sizetype) _181;
Include/PULSE_SIMD.h:110:13: note: 	stmt 0 _182 = (sizetype) _181;
Include/PULSE_SIMD.h:110:13: note: 	stmt 1 _243 = (sizetype) k_22;
Include/PULSE_SIMD.h:110:13: note: 	children 0x8979188
Include/PULSE_SIMD.h:110:13: note: node (external) 0x8979188 (max_nunits=1, refcnt=1) vector(2) int
Include/PULSE_SIMD.h:110:13: note: 	{ _181, k_22 }
Include/PULSE_SIMD.h:110:13: note: Cost model analysis: 
Include/PULSE_SIMD.h:110:13: note: Cost model analysis for part in loop 8:
  Vector cost: 8
  Scalar cost: 4
Include/PULSE_SIMD.h:110:13: missed: not vectorized: vectorization is not profitable.
Include/PULSE_SIMD.h:111:8: note: Costing subgraph: 
Include/PULSE_SIMD.h:111:8: note: node 0x8979288 (max_nunits=2, refcnt=1) vector(2) sizetype
Include/PULSE_SIMD.h:111:8: note: op template: _197 = (sizetype) _196;
Include/PULSE_SIMD.h:111:8: note: 	stmt 0 _197 = (sizetype) _196;
Include/PULSE_SIMD.h:111:8: note: 	stmt 1 _199 = (sizetype) _198;
Include/PULSE_SIMD.h:111:8: note: 	children 0x8979388
Include/PULSE_SIMD.h:111:8: note: node (external) 0x8979388 (max_nunits=1, refcnt=1) vector(2) int
Include/PULSE_SIMD.h:111:8: note: 	{ _196, _198 }
Include/PULSE_SIMD.h:111:8: note: Cost model analysis: 
Include/PULSE_SIMD.h:111:8: note: Cost model analysis for part in loop 9:
  Vector cost: 20
  Scalar cost: 4
Include/PULSE_SIMD.h:111:8: missed: not vectorized: vectorization is not profitable.
Include/PULSE_SIMD.h:111:8: note: ***** The result for vector mode V32QI would be the same
Include/PULSE_SIMD.h:111:8: note: ***** Re-trying analysis with vector mode V16QI
Include/PULSE_SIMD.h:111:8: note: ***** Analysis succeeded with vector mode V16QI
Include/PULSE_SIMD.h:111:8: note: SLPing BB part
Include/PULSE_SIMD.h:110:13: note: Costing subgraph: 
Include/PULSE_SIMD.h:110:13: note: node 0x8979088 (max_nunits=2, refcnt=1) vector(2) sizetype
Include/PULSE_SIMD.h:110:13: note: op template: _174 = (sizetype) _173;
Include/PULSE_SIMD.h:110:13: note: 	stmt 0 _174 = (sizetype) _173;
Include/PULSE_SIMD.h:110:13: note: 	stmt 1 _243 = (sizetype) k_22;
Include/PULSE_SIMD.h:110:13: note: 	children 0x8978e88
Include/PULSE_SIMD.h:110:13: note: node (external) 0x8978e88 (max_nunits=1, refcnt=1) vector(2) int
Include/PULSE_SIMD.h:110:13: note: 	{ _173, k_22 }
Include/PULSE_SIMD.h:110:13: note: node 0x8979108 (max_nunits=2, refcnt=1) vector(2) sizetype
Include/PULSE_SIMD.h:110:13: note: op template: _182 = (sizetype) _181;
Include/PULSE_SIMD.h:110:13: note: 	stmt 0 _182 = (sizetype) _181;
Include/PULSE_SIMD.h:110:13: note: 	stmt 1 _243 = (sizetype) k_22;
Include/PULSE_SIMD.h:110:13: note: 	children 0x8978f08
Include/PULSE_SIMD.h:110:13: note: node (external) 0x8978f08 (max_nunits=1, refcnt=1) vector(2) int
Include/PULSE_SIMD.h:110:13: note: 	{ _181, k_22 }
Include/PULSE_SIMD.h:110:13: note: Cost model analysis: 
Include/PULSE_SIMD.h:110:13: note: Cost model analysis for part in loop 8:
  Vector cost: 8
  Scalar cost: 4
Include/PULSE_SIMD.h:110:13: missed: not vectorized: vectorization is not profitable.
Include/PULSE_SIMD.h:111:8: note: Costing subgraph: 
Include/PULSE_SIMD.h:111:8: note: node 0x8979308 (max_nunits=2, refcnt=1) vector(2) sizetype
Include/PULSE_SIMD.h:111:8: note: op template: _197 = (sizetype) _196;
Include/PULSE_SIMD.h:111:8: note: 	stmt 0 _197 = (sizetype) _196;
Include/PULSE_SIMD.h:111:8: note: 	stmt 1 _199 = (sizetype) _198;
Include/PULSE_SIMD.h:111:8: note: 	children 0x8979008
Include/PULSE_SIMD.h:111:8: note: node (external) 0x8979008 (max_nunits=1, refcnt=1) vector(2) int
Include/PULSE_SIMD.h:111:8: note: 	{ _196, _198 }
Include/PULSE_SIMD.h:111:8: note: Cost model analysis: 
Include/PULSE_SIMD.h:111:8: note: Cost model analysis for part in loop 9:
  Vector cost: 20
  Scalar cost: 4
Include/PULSE_SIMD.h:111:8: missed: not vectorized: vectorization is not profitable.
Include/PULSE_SIMD.h:111:8: note: ***** Re-trying analysis with vector mode V8QI
Include/PULSE_SIMD.h:111:8: note: ***** Analysis failed with vector mode V8QI
Include/PULSE_SIMD.h:111:8: note: ***** Re-trying analysis with vector mode V4QI
Include/PULSE_SIMD.h:111:8: note: ***** Analysis failed with vector mode V4QI
Dense.c:186:19: missed: couldn't vectorize loop
Dense.c:186:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:176:13: note: vectorized 0 loops in function.
Dense.c:178:47: missed: statement clobbers memory: dense_35 = malloc (40);
Dense.c:180:36: missed: statement clobbers memory: _5 = aligned_alloc (64, _4);
Dense.c:181:38: missed: statement clobbers memory: _6 = aligned_alloc (64, _4);
Dense.c:182:36: missed: statement clobbers memory: _8 = aligned_alloc (64, _7);
Dense.c:183:35: missed: statement clobbers memory: _9 = aligned_alloc (64, _7);
Dense.c:184:36: missed: statement clobbers memory: _10 = aligned_alloc (64, _7);
Dense.c:187:39: missed: statement clobbers memory: _11 = rand ();
Dense.c:187:73: missed: statement clobbers memory: _63 = sqrt (_18);
Dense.c:199:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:200:4: missed: statement clobbers memory: exit (1);
Dense.c:196:4: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.3_29, n_outputs.2_28, 1, activation_function_51(D), _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:193:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.1_27, n_outputs.0_26, 1, activation_function_51(D), _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:206:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Dense.c:206:9: note: ***** Analysis failed with vector mode V4DI
Dense.c:206:9: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Activations.c:17:19: optimized: loop vectorized using 32 byte vectors
Activations.c:17:19: optimized: loop vectorized using 16 byte vectors
Activations.c:17:19: optimized: loop vectorized using 32 byte vectors
Activations.c:17:19: optimized: loop vectorized using 16 byte vectors
Activations.c:14:13: note: vectorized 2 loops in function.
Activations.c:14:13: note: ***** Analysis failed with vector mode V8SF
Activations.c:14:13: note: ***** The result for vector mode V32QI would be the same
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V16QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V16QI
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V8QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V8QI
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V4QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V4QI
Activations.c:28:19: missed: couldn't vectorize loop
Activations.c:28:19: missed: not vectorized: unsupported control flow in loop.
Activations.c:28:19: optimized: loop vectorized using 32 byte vectors
Activations.c:28:19: optimized: loop vectorized using 16 byte vectors
Activations.c:25:13: note: vectorized 1 loops in function.
Activations.c:25:13: note: ***** Analysis failed with vector mode V8SF
Activations.c:25:13: note: ***** The result for vector mode V32QI would be the same
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V16QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V16QI
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V8QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V8QI
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V4QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V4QI
Activations.c:38:1: note: ***** Analysis failed with vector mode VOID
Activations.c:5:19: missed: couldn't vectorize loop
Activations.c:9:21: missed: statement clobbers memory: _36 = expf (_18);
Activations.c:5:19: missed: couldn't vectorize loop
Activations.c:9:21: missed: statement clobbers memory: _12 = expf (_11);
Activations.c:3:13: note: vectorized 0 loops in function.
Activations.c:9:21: missed: statement clobbers memory: _12 = expf (_11);
Activations.c:9:21: missed: statement clobbers memory: _36 = expf (_18);
Activations.c:11:1: note: ***** Analysis failed with vector mode V8SF
Activations.c:11:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Activations.c:44:2: note: ***** Analysis failed with vector mode VOID
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:4:18: note: vectorized 0 loops in function.
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_4, inputs_15, _3);
PULSE.c:8:2: missed: statement clobbers memory: _5 (layer_17);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_12, pretmp_26, _9);
PULSE.c:13:28: note: ***** Analysis failed with vector mode V8SI
PULSE.c:13:28: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:22:2: missed: statement clobbers memory: _1 (layer_10(D));
PULSE.c:22:2: missed: statement clobbers memory: _14 (_2);
PULSE.c:22:2: missed: statement clobbers memory: _21 (_15);
PULSE.c:22:2: missed: statement clobbers memory: _28 (_22);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_29);
PULSE.c:26:3: missed: statement clobbers memory: memset (_34, 0, _32);
PULSE.c:26:3: missed: statement clobbers memory: memset (_27, 0, _25);
PULSE.c:26:3: missed: statement clobbers memory: memset (_20, 0, _18);
PULSE.c:26:3: missed: statement clobbers memory: memset (_7, 0, _5);
PULSE.c:28:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:28:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:32:6: note: vectorized 1 loops in function.
PULSE.c:34:8: missed: statement clobbers memory: _1 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_2);
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _9 = rand ();
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8SI
PULSE.c:32:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:61:16: missed: couldn't vectorize loop
PULSE.c:61:16: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:64:17: missed: couldn't vectorize loop
PULSE.c:64:17: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:73:19: missed: couldn't vectorize loop
PULSE.c:73:19: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _64 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:53:22: missed: couldn't vectorize loop
PULSE.c:53:22: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:47:6: note: vectorized 1 loops in function.
PULSE.c:48:1: missed: statement clobbers memory: saved_stack.7_35 = __builtin_stack_save ();
PULSE.c:49:46: missed: statement clobbers memory: _1 = PULSE_GetLossFunctionPtr (loss_function_36(D));
PULSE.c:60:10: missed: statement clobbers memory: random.4_42 = __builtin_alloca_with_align (_4, 32);
PULSE.c:34:8: missed: statement clobbers memory: _56 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_57);
PULSE.c:39:29: missed: statement clobbers memory: _64 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _67 = rand ();
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_93, inputs_88, _92);
PULSE.c:8:2: missed: statement clobbers memory: _94 (layer_89);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_100, _99, _98);
PULSE.c:67:11: missed: statement clobbers memory: loss_51 = PULSE_GetLoss_38 (_17, _16, _12, _11);
PULSE.c:22:2: missed: statement clobbers memory: _81 (output_30);
PULSE.c:22:2: missed: statement clobbers memory: _103 (_82);
PULSE.c:22:2: missed: statement clobbers memory: _110 (_104);
PULSE.c:22:2: missed: statement clobbers memory: _117 (_111);
PULSE.c:22:2: missed: statement clobbers memory: _124 (_118);
PULSE.c:22:2: missed: statement clobbers memory: _131 (_125);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_132);
PULSE.c:26:3: missed: statement clobbers memory: memset (_137, 0, _135);
PULSE.c:26:3: missed: statement clobbers memory: memset (_130, 0, _128);
PULSE.c:26:3: missed: statement clobbers memory: memset (_123, 0, _121);
PULSE.c:26:3: missed: statement clobbers memory: memset (_116, 0, _114);
PULSE.c:26:3: missed: statement clobbers memory: memset (_109, 0, _107);
PULSE.c:26:3: missed: statement clobbers memory: memset (_87, 0, _85);
PULSE.c:75:6: missed: statement clobbers memory: _21 (current_183, args);
PULSE.c:80:4: missed: statement clobbers memory: printf ("Epoch: %d Item: %d Loss: %.10f\r", i_181, j_182, _22);
PULSE.c:47:6: missed: statement clobbers memory: __builtin_stack_restore (saved_stack.7_35);
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4DI
PULSE.c:47:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:89:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:89:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:94:8: missed: couldn't vectorize loop
PULSE.c:94:8: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:91:6: note: vectorized 0 loops in function.
PULSE.c:96:3: missed: statement clobbers memory: _1 (current_10);
PULSE.c:99:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:99:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Loss.c:15:19: optimized: loop vectorized using 32 byte vectors
Loss.c:15:19: optimized:  loop versioned for vectorization because of possible aliasing
Loss.c:15:19: optimized: loop vectorized using 16 byte vectors
Loss.c:12:23: note: vectorized 1 loops in function.
Loss.c:12:23: note: ***** Analysis failed with vector mode V8SF
Loss.c:12:23: note: ***** The result for vector mode V32QI would be the same
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V16QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V16QI
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V8QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V8QI
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V4QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V4QI
Loss.c:7:19: missed: couldn't vectorize loop
Loss.c:8:38: missed: not vectorized: unsupported use in stmt.
Loss.c:4:23: note: vectorized 0 loops in function.
Loss.c:9:13: note: ***** Analysis failed with vector mode V8SF
Loss.c:9:13: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Loss.c:23:2: note: ***** Analysis failed with vector mode VOID
Layer.c:7:34: missed: statement clobbers memory: _3 = aligned_alloc (64, _2);
Layer.c:8:35: missed: statement clobbers memory: _6 = aligned_alloc (64, _5);
Layer.c:9:34: missed: statement clobbers memory: _7 = aligned_alloc (64, _5);
Layer.c:14:19: missed: statement clobbers memory: _8 = PULSE_GetActivationFunctionPtr (activation_function_18(D));
Layer.c:19:9: note: ***** Analysis succeeded with vector mode V8SI
Layer.c:19:9: note: SLPing BB part
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x423f7c8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 0 MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 1 MEM <unsigned int> [(struct PULSE_Layer *)&<retval> + 4B] = optimization_type_17(D);
Layer.c:19:9: note: 	children 0x423f848
Layer.c:19:9: note: node (external) 0x423f848 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ type_16(D), optimization_type_17(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x423f8c8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 0 <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 1 <retval>.n_outputs = n_outputs_12(D);
Layer.c:19:9: note: 	children 0x423f948
Layer.c:19:9: note: node (external) 0x423f948 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x423fa48 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 0 <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 1 <retval>.outputs = _6;
Layer.c:19:9: note: 	children 0x423fac8
Layer.c:19:9: note: node (external) 0x423fac8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	stmt 0 _3 = aligned_alloc (64, _2);
Layer.c:19:9: note: 	stmt 1 _6 = aligned_alloc (64, _5);
Layer.c:19:9: note: 	children 0x423fb48 0x423fbc8
Layer.c:19:9: note: node (constant) 0x423fb48 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 64, 64 }
Layer.c:19:9: note: node 0x423fbc8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: patt_40 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 0 patt_40 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 1 patt_41 = n_outputs_12(D) w* 4;
Layer.c:19:9: note: 	children 0x423fc48 0x423fcc8
Layer.c:19:9: note: node (external) 0x423fc48 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: node (constant) 0x423fcc8 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ 4, 4 }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x423fdc8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: op template: <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 0 <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 1 <retval>.back = back_21(D);
Layer.c:19:9: note: 	stmt 2 <retval>.fix = fix_22(D);
Layer.c:19:9: note: 	stmt 3 <retval>.destroy = destroy_23(D);
Layer.c:19:9: note: 	children 0x423fe48
Layer.c:19:9: note: node (external) 0x423fe48 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: 	{ feed_20(D), back_21(D), fix_22(D), destroy_23(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 64
  Scalar cost: 64
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x423ff48 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 0 <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 1 <retval>.child = 0B;
Layer.c:19:9: note: 	children 0x423ffc8
Layer.c:19:9: note: node (constant) 0x423ffc8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ 0B, 0B }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Basic block will be vectorized using SLP
Layer.c:19:9: optimized: basic block part vectorized using 8 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x423f7c8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 0 MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 1 MEM <unsigned int> [(struct PULSE_Layer *)&<retval> + 4B] = optimization_type_17(D);
Layer.c:19:9: note: 	children 0x423f848
Layer.c:19:9: note: node (external) 0x423f848 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ type_16(D), optimization_type_17(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: vect_is_simple_use: operand optimization_type_17(D), type of def: external
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>]
Layer.c:19:9: note: created &MEM <unsigned int> [(struct PULSE_Layer *)&<retval>]
Layer.c:19:9: note: add new stmt: MEM <vector(2) unsigned int> [(struct PULSE_Layer *)&<retval>] = _42;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 8 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x423f8c8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 0 <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 1 <retval>.n_outputs = n_outputs_12(D);
Layer.c:19:9: note: 	children 0x423f948
Layer.c:19:9: note: node (external) 0x423f948 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: vect_is_simple_use: operand n_outputs_12(D), type of def: external
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: <retval>.n_inputs
Layer.c:19:9: note: created &<retval>.n_inputs
Layer.c:19:9: note: add new stmt: MEM <vector(2) unsigned int> [(unsigned int *)&<retval> + 96B] = _44;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 16 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x423fa48 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 0 <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 1 <retval>.outputs = _6;
Layer.c:19:9: note: 	children 0x423fac8
Layer.c:19:9: note: node (external) 0x423fac8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	stmt 0 _3 = aligned_alloc (64, _2);
Layer.c:19:9: note: 	stmt 1 _6 = aligned_alloc (64, _5);
Layer.c:19:9: note: 	children 0x423fb48 0x423fbc8
Layer.c:19:9: note: node (constant) 0x423fb48 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 64, 64 }
Layer.c:19:9: note: node 0x423fbc8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: patt_40 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 0 patt_40 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 1 patt_41 = n_outputs_12(D) w* 4;
Layer.c:19:9: note: 	children 0x423fc48 0x423fcc8
Layer.c:19:9: note: node (external) 0x423fc48 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: node (constant) 0x423fcc8 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ 4, 4 }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.inputs = _3;
Layer.c:19:9: note: vect_is_simple_use: operand aligned_alloc (64, _5), type of def: internal
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.inputs
Layer.c:19:9: note: created &<retval>.inputs
Layer.c:19:9: note: add new stmt: MEM <vector(2) long unsigned int> [(float * *)&<retval> + 8B] = _48;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 32 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x423fdc8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: op template: <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 0 <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 1 <retval>.back = back_21(D);
Layer.c:19:9: note: 	stmt 2 <retval>.fix = fix_22(D);
Layer.c:19:9: note: 	stmt 3 <retval>.destroy = destroy_23(D);
Layer.c:19:9: note: 	children 0x423fe48
Layer.c:19:9: note: node (external) 0x423fe48 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: 	{ feed_20(D), back_21(D), fix_22(D), destroy_23(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.feed = feed_20(D);
Layer.c:19:9: note: vect_is_simple_use: operand back_21(D), type of def: external
Layer.c:19:9: note: vect_is_simple_use: operand fix_22(D), type of def: external
Layer.c:19:9: note: vect_is_simple_use: operand destroy_23(D), type of def: external
Layer.c:19:9: note: conflicting alias set types.
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(4) long unsigned int  vectorizing a pointer ref: <retval>.feed
Layer.c:19:9: note: created &<retval>.feed
Layer.c:19:9: note: add new stmt: MEM <vector(4) long unsigned int> [(void *)&<retval> + 32B] = _54;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 16 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x423ff48 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 0 <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 1 <retval>.child = 0B;
Layer.c:19:9: note: 	children 0x423ffc8
Layer.c:19:9: note: node (constant) 0x423ffc8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ 0B, 0B }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.parent = 0B;
Layer.c:19:9: note: vect_is_simple_use: operand 0B, type of def: constant
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.parent
Layer.c:19:9: note: created &<retval>.parent
Layer.c:19:9: note: add new stmt: MEM <vector(2) long unsigned int> [(struct PULSE_Layer * *)&<retval> + 72B] = { 0, 0 };
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: note: ***** The result for vector mode V32QI would be the same
Layer.c:24:2: missed: statement clobbers memory: free (_1);
Layer.c:25:2: missed: statement clobbers memory: free (_2);
Layer.c:26:2: missed: statement clobbers memory: free (_3);
Layer.c:27:1: note: ***** Analysis failed with vector mode V4DI
Layer.c:27:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:9:27: missed: couldn't vectorize loop
Dense.c:9:27: missed: not vectorized: unsupported outerloop form.
Dense.c:12:20: missed: couldn't vectorize loop
Dense.c:13:21: missed: not vectorized: complicated access pattern.
Dense.c:6:13: note: vectorized 0 loops in function.
Dense.c:16:2: missed: statement clobbers memory: _30 (pretmp_91, _50, 0);
Dense.c:9:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:9:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:24:27: missed: couldn't vectorize loop
Dense.c:24:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:28:20: optimized: loop vectorized using 32 byte vectors
Dense.c:28:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:28:20: optimized: loop vectorized using 16 byte vectors
Dense.c:28:20: missed: couldn't vectorize loop
Dense.c:30:20: missed: not vectorized: no vectype for stmt: _21 = *_20;
 scalar_type: float
Dense.c:20:13: note: vectorized 1 loops in function.
Dense.c:23:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:24:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:24:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:41:28: missed: couldn't vectorize loop
Dense.c:41:28: missed: not vectorized: unsupported outerloop form.
Dense.c:45:21: optimized: loop vectorized using 32 byte vectors
Dense.c:45:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:45:21: optimized: loop vectorized using 16 byte vectors
Dense.c:37:13: note: vectorized 1 loops in function.
Dense.c:37:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:37:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:41:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:151:19: missed: couldn't vectorize loop
Dense.c:151:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:142:19: missed: couldn't vectorize loop
Dense.c:142:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:135:13: note: vectorized 0 loops in function.
Dense.c:159:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:159:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:104:28: missed: couldn't vectorize loop
Dense.c:104:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:107:21: missed: couldn't vectorize loop
Dense.c:107:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:121:28: missed: couldn't vectorize loop
Dense.c:121:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:124:21: missed: couldn't vectorize loop
Dense.c:124:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:90:19: missed: couldn't vectorize loop
Dense.c:90:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:84:13: note: vectorized 0 loops in function.
Dense.c:87:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:109:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:109:17: note: SLPing BB part
Dense.c:126:17: note: Costing subgraph: 
Dense.c:126:17: note: node 0x7c279d8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:126:17: note: op template: _49 = (sizetype) j_137;
Dense.c:126:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:126:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:126:17: note: 	children 0x7c27ad8
Dense.c:126:17: note: node (external) 0x7c27ad8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:126:17: note: 	{ j_137, wi_136 }
Dense.c:126:17: note: Cost model analysis: 
Dense.c:126:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:126:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:126:17: missed: not vectorized: vectorization is not profitable.
Dense.c:109:17: note: Costing subgraph: 
Dense.c:109:17: note: node 0x7c27bd8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:109:17: note: op template: _24 = (sizetype) j_134;
Dense.c:109:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:109:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:109:17: note: 	children 0x7c27cd8
Dense.c:109:17: note: node (external) 0x7c27cd8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:109:17: note: 	{ j_134, wi_133 }
Dense.c:109:17: note: Cost model analysis: 
Dense.c:109:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:109:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:109:17: missed: not vectorized: vectorization is not profitable.
Dense.c:109:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:109:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:109:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:109:17: note: SLPing BB part
Dense.c:126:17: note: Costing subgraph: 
Dense.c:126:17: note: node 0x7c27bd8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:126:17: note: op template: _49 = (sizetype) j_137;
Dense.c:126:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:126:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:126:17: note: 	children 0x7c279d8
Dense.c:126:17: note: node (external) 0x7c279d8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:126:17: note: 	{ j_137, wi_136 }
Dense.c:126:17: note: Cost model analysis: 
Dense.c:126:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:126:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:126:17: missed: not vectorized: vectorization is not profitable.
Dense.c:109:17: note: Costing subgraph: 
Dense.c:109:17: note: node 0x7c27d58 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:109:17: note: op template: _24 = (sizetype) j_134;
Dense.c:109:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:109:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:109:17: note: 	children 0x7c27c58
Dense.c:109:17: note: node (external) 0x7c27c58 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:109:17: note: 	{ j_134, wi_133 }
Dense.c:109:17: note: Cost model analysis: 
Dense.c:109:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:109:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:109:17: missed: not vectorized: vectorization is not profitable.
Dense.c:109:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:104:55: note: ***** Analysis failed with vector mode V8QI
Dense.c:104:55: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:104:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:166:2: missed: statement clobbers memory: free (_1);
Dense.c:167:2: missed: statement clobbers memory: free (_2);
Dense.c:168:2: missed: statement clobbers memory: free (_3);
Dense.c:169:2: missed: statement clobbers memory: free (_4);
Dense.c:170:2: missed: statement clobbers memory: free (dense_7);
Dense.c:171:2: missed: statement clobbers memory: PULSE_DestroyLayer (this_6(D));
Dense.c:172:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:172:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Include/PULSE_SIMD.h:98:20: missed: couldn't vectorize loop
Include/PULSE_SIMD.h:98:20: missed: not vectorized: multiple nested loops.
Include/PULSE_SIMD.h:101:21: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:905:10: missed: not vectorized: no vectype for stmt: _187 = MEM[(__m256_u * {ref-all})_186];
 scalar_type: __m256_u
Include/PULSE_SIMD.h:105:23: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:905:10: missed: not vectorized: no vectype for stmt: _187 = MEM[(__m256_u * {ref-all})_186];
 scalar_type: __m256_u
Dense.c:54:13: note: vectorized 0 loops in function.
Dense.c:57:2: missed: statement clobbers memory: memcpy (_5, _4, _3);
Dense.c:80:2: missed: statement clobbers memory: _13 (_10, _8, 0);
Include/PULSE_SIMD.h:110:13: note: ***** Analysis succeeded with vector mode V4DI
Include/PULSE_SIMD.h:110:13: note: SLPing BB part
Include/PULSE_SIMD.h:110:13: note: Costing subgraph: 
Include/PULSE_SIMD.h:110:13: note: node 0x7bf7128 (max_nunits=2, refcnt=1) vector(2) sizetype
Include/PULSE_SIMD.h:110:13: note: op template: _183 = (sizetype) k_174;
Include/PULSE_SIMD.h:110:13: note: 	stmt 0 _183 = (sizetype) k_174;
Include/PULSE_SIMD.h:110:13: note: 	stmt 1 _190 = (sizetype) _189;
Include/PULSE_SIMD.h:110:13: note: 	children 0x7bf7228
Include/PULSE_SIMD.h:110:13: note: node (external) 0x7bf7228 (max_nunits=1, refcnt=1) vector(2) int
Include/PULSE_SIMD.h:110:13: note: 	{ k_174, _189 }
Include/PULSE_SIMD.h:110:13: note: Cost model analysis: 
Include/PULSE_SIMD.h:110:13: note: Cost model analysis for part in loop 7:
  Vector cost: 4
  Scalar cost: 4
Include/PULSE_SIMD.h:110:13: note: Cost model analysis for part in loop 8:
  Vector cost: 36
  Scalar cost: 8
Include/PULSE_SIMD.h:110:13: missed: not vectorized: vectorization is not profitable.
Include/PULSE_SIMD.h:110:13: note: ***** The result for vector mode V32QI would be the same
Include/PULSE_SIMD.h:110:13: note: ***** Re-trying analysis with vector mode V16QI
Include/PULSE_SIMD.h:110:13: note: ***** Analysis succeeded with vector mode V16QI
Include/PULSE_SIMD.h:110:13: note: SLPing BB part
Include/PULSE_SIMD.h:110:13: note: Costing subgraph: 
Include/PULSE_SIMD.h:110:13: note: node 0x7bf71a8 (max_nunits=2, refcnt=1) vector(2) sizetype
Include/PULSE_SIMD.h:110:13: note: op template: _183 = (sizetype) k_174;
Include/PULSE_SIMD.h:110:13: note: 	stmt 0 _183 = (sizetype) k_174;
Include/PULSE_SIMD.h:110:13: note: 	stmt 1 _190 = (sizetype) _189;
Include/PULSE_SIMD.h:110:13: note: 	children 0x7bf7028
Include/PULSE_SIMD.h:110:13: note: node (external) 0x7bf7028 (max_nunits=1, refcnt=1) vector(2) int
Include/PULSE_SIMD.h:110:13: note: 	{ k_174, _189 }
Include/PULSE_SIMD.h:110:13: note: Cost model analysis: 
Include/PULSE_SIMD.h:110:13: note: Cost model analysis for part in loop 7:
  Vector cost: 4
  Scalar cost: 4
Include/PULSE_SIMD.h:110:13: note: Cost model analysis for part in loop 8:
  Vector cost: 36
  Scalar cost: 8
Include/PULSE_SIMD.h:110:13: missed: not vectorized: vectorization is not profitable.
Include/PULSE_SIMD.h:110:13: note: ***** Re-trying analysis with vector mode V8QI
Include/PULSE_SIMD.h:111:8: note: ***** Analysis failed with vector mode V8QI
Include/PULSE_SIMD.h:111:8: note: ***** Re-trying analysis with vector mode V4QI
Include/PULSE_SIMD.h:111:8: note: ***** Analysis failed with vector mode V4QI
Dense.c:186:19: missed: couldn't vectorize loop
Dense.c:186:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:176:13: note: vectorized 0 loops in function.
Dense.c:178:47: missed: statement clobbers memory: dense_35 = malloc (40);
Dense.c:180:36: missed: statement clobbers memory: _5 = aligned_alloc (64, _4);
Dense.c:181:38: missed: statement clobbers memory: _6 = aligned_alloc (64, _4);
Dense.c:182:36: missed: statement clobbers memory: _8 = aligned_alloc (64, _7);
Dense.c:183:35: missed: statement clobbers memory: _9 = aligned_alloc (64, _7);
Dense.c:184:36: missed: statement clobbers memory: _10 = aligned_alloc (64, _7);
Dense.c:187:39: missed: statement clobbers memory: _11 = rand ();
Dense.c:187:73: missed: statement clobbers memory: _63 = sqrt (_18);
Dense.c:199:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:200:4: missed: statement clobbers memory: exit (1);
Dense.c:196:4: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.3_29, n_outputs.2_28, 1, activation_function_51(D), _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:193:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.1_27, n_outputs.0_26, 1, activation_function_51(D), _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:206:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Dense.c:206:9: note: ***** Analysis failed with vector mode V4DI
Dense.c:206:9: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Activations.c:17:19: optimized: loop vectorized using 32 byte vectors
Activations.c:17:19: optimized: loop vectorized using 16 byte vectors
Activations.c:17:19: optimized: loop vectorized using 32 byte vectors
Activations.c:17:19: optimized: loop vectorized using 16 byte vectors
Activations.c:14:13: note: vectorized 2 loops in function.
Activations.c:14:13: note: ***** Analysis failed with vector mode V8SF
Activations.c:14:13: note: ***** The result for vector mode V32QI would be the same
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V16QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V16QI
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V8QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V8QI
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V4QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V4QI
Activations.c:28:19: missed: couldn't vectorize loop
Activations.c:28:19: missed: not vectorized: unsupported control flow in loop.
Activations.c:28:19: optimized: loop vectorized using 32 byte vectors
Activations.c:28:19: optimized: loop vectorized using 16 byte vectors
Activations.c:25:13: note: vectorized 1 loops in function.
Activations.c:25:13: note: ***** Analysis failed with vector mode V8SF
Activations.c:25:13: note: ***** The result for vector mode V32QI would be the same
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V16QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V16QI
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V8QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V8QI
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V4QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V4QI
Activations.c:38:1: note: ***** Analysis failed with vector mode VOID
Activations.c:5:19: missed: couldn't vectorize loop
Activations.c:9:21: missed: statement clobbers memory: _36 = expf (_18);
Activations.c:5:19: missed: couldn't vectorize loop
Activations.c:9:21: missed: statement clobbers memory: _12 = expf (_11);
Activations.c:3:13: note: vectorized 0 loops in function.
Activations.c:9:21: missed: statement clobbers memory: _12 = expf (_11);
Activations.c:9:21: missed: statement clobbers memory: _36 = expf (_18);
Activations.c:11:1: note: ***** Analysis failed with vector mode V8SF
Activations.c:11:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Activations.c:44:2: note: ***** Analysis failed with vector mode VOID
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:4:18: note: vectorized 0 loops in function.
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_4, inputs_15, _3);
PULSE.c:8:2: missed: statement clobbers memory: _5 (layer_17);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_12, pretmp_26, _9);
PULSE.c:13:28: note: ***** Analysis failed with vector mode V8SI
PULSE.c:13:28: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:22:2: missed: statement clobbers memory: _1 (layer_10(D));
PULSE.c:22:2: missed: statement clobbers memory: _14 (_2);
PULSE.c:22:2: missed: statement clobbers memory: _21 (_15);
PULSE.c:22:2: missed: statement clobbers memory: _28 (_22);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_29);
PULSE.c:26:3: missed: statement clobbers memory: memset (_34, 0, _32);
PULSE.c:26:3: missed: statement clobbers memory: memset (_27, 0, _25);
PULSE.c:26:3: missed: statement clobbers memory: memset (_20, 0, _18);
PULSE.c:26:3: missed: statement clobbers memory: memset (_7, 0, _5);
PULSE.c:28:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:28:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:32:6: note: vectorized 1 loops in function.
PULSE.c:34:8: missed: statement clobbers memory: _1 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_2);
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _9 = rand ();
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8SI
PULSE.c:32:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:61:16: missed: couldn't vectorize loop
PULSE.c:61:16: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:64:17: missed: couldn't vectorize loop
PULSE.c:64:17: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:73:19: missed: couldn't vectorize loop
PULSE.c:73:19: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _64 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:53:22: missed: couldn't vectorize loop
PULSE.c:53:22: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:47:6: note: vectorized 1 loops in function.
PULSE.c:48:1: missed: statement clobbers memory: saved_stack.7_35 = __builtin_stack_save ();
PULSE.c:49:46: missed: statement clobbers memory: _1 = PULSE_GetLossFunctionPtr (loss_function_36(D));
PULSE.c:60:10: missed: statement clobbers memory: random.4_42 = __builtin_alloca_with_align (_4, 32);
PULSE.c:34:8: missed: statement clobbers memory: _56 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_57);
PULSE.c:39:29: missed: statement clobbers memory: _64 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _67 = rand ();
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_93, inputs_88, _92);
PULSE.c:8:2: missed: statement clobbers memory: _94 (layer_89);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_100, _99, _98);
PULSE.c:67:11: missed: statement clobbers memory: loss_51 = PULSE_GetLoss_38 (_17, _16, _12, _11);
PULSE.c:22:2: missed: statement clobbers memory: _81 (output_30);
PULSE.c:22:2: missed: statement clobbers memory: _103 (_82);
PULSE.c:22:2: missed: statement clobbers memory: _110 (_104);
PULSE.c:22:2: missed: statement clobbers memory: _117 (_111);
PULSE.c:22:2: missed: statement clobbers memory: _124 (_118);
PULSE.c:22:2: missed: statement clobbers memory: _131 (_125);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_132);
PULSE.c:26:3: missed: statement clobbers memory: memset (_137, 0, _135);
PULSE.c:26:3: missed: statement clobbers memory: memset (_130, 0, _128);
PULSE.c:26:3: missed: statement clobbers memory: memset (_123, 0, _121);
PULSE.c:26:3: missed: statement clobbers memory: memset (_116, 0, _114);
PULSE.c:26:3: missed: statement clobbers memory: memset (_109, 0, _107);
PULSE.c:26:3: missed: statement clobbers memory: memset (_87, 0, _85);
PULSE.c:75:6: missed: statement clobbers memory: _21 (current_183, args);
PULSE.c:80:4: missed: statement clobbers memory: printf ("Epoch: %d Item: %d Loss: %.10f\r", i_181, j_182, _22);
PULSE.c:47:6: missed: statement clobbers memory: __builtin_stack_restore (saved_stack.7_35);
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4DI
PULSE.c:47:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:89:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:89:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:94:8: missed: couldn't vectorize loop
PULSE.c:94:8: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:91:6: note: vectorized 0 loops in function.
PULSE.c:96:3: missed: statement clobbers memory: _1 (current_10);
PULSE.c:99:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:99:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Loss.c:15:19: optimized: loop vectorized using 32 byte vectors
Loss.c:15:19: optimized:  loop versioned for vectorization because of possible aliasing
Loss.c:15:19: optimized: loop vectorized using 16 byte vectors
Loss.c:12:23: note: vectorized 1 loops in function.
Loss.c:12:23: note: ***** Analysis failed with vector mode V8SF
Loss.c:12:23: note: ***** The result for vector mode V32QI would be the same
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V16QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V16QI
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V8QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V8QI
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V4QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V4QI
Loss.c:7:19: missed: couldn't vectorize loop
Loss.c:8:38: missed: not vectorized: unsupported use in stmt.
Loss.c:4:23: note: vectorized 0 loops in function.
Loss.c:9:13: note: ***** Analysis failed with vector mode V8SF
Loss.c:9:13: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Loss.c:23:2: note: ***** Analysis failed with vector mode VOID
Dense.c:9:27: missed: couldn't vectorize loop
Dense.c:9:27: missed: not vectorized: unsupported outerloop form.
Dense.c:12:20: missed: couldn't vectorize loop
Dense.c:13:21: missed: not vectorized: complicated access pattern.
Dense.c:6:13: note: vectorized 0 loops in function.
Dense.c:16:2: missed: statement clobbers memory: _30 (pretmp_91, _50, 0);
Dense.c:9:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:9:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:24:27: missed: couldn't vectorize loop
Dense.c:24:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:28:20: optimized: loop vectorized using 32 byte vectors
Dense.c:28:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:28:20: optimized: loop vectorized using 16 byte vectors
Dense.c:28:20: missed: couldn't vectorize loop
Dense.c:30:20: missed: not vectorized: no vectype for stmt: _21 = *_20;
 scalar_type: float
Dense.c:20:13: note: vectorized 1 loops in function.
Dense.c:23:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:24:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:24:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:41:28: missed: couldn't vectorize loop
Dense.c:41:28: missed: not vectorized: unsupported outerloop form.
Dense.c:45:21: optimized: loop vectorized using 32 byte vectors
Dense.c:45:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:45:21: optimized: loop vectorized using 16 byte vectors
Dense.c:37:13: note: vectorized 1 loops in function.
Dense.c:37:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:37:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:41:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:150:19: missed: couldn't vectorize loop
Dense.c:150:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:141:19: missed: couldn't vectorize loop
Dense.c:141:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:134:13: note: vectorized 0 loops in function.
Dense.c:158:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:158:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:103:28: missed: couldn't vectorize loop
Dense.c:103:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:106:21: missed: couldn't vectorize loop
Dense.c:106:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:120:28: missed: couldn't vectorize loop
Dense.c:120:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:123:21: missed: couldn't vectorize loop
Dense.c:123:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:89:19: missed: couldn't vectorize loop
Dense.c:89:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:83:13: note: vectorized 0 loops in function.
Dense.c:86:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:108:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:108:17: note: SLPing BB part
Dense.c:125:17: note: Costing subgraph: 
Dense.c:125:17: note: node 0x7c8c878 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:125:17: note: op template: _49 = (sizetype) j_137;
Dense.c:125:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:125:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:125:17: note: 	children 0x7c8c978
Dense.c:125:17: note: node (external) 0x7c8c978 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:125:17: note: 	{ j_137, wi_136 }
Dense.c:125:17: note: Cost model analysis: 
Dense.c:125:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:125:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:125:17: missed: not vectorized: vectorization is not profitable.
Dense.c:108:17: note: Costing subgraph: 
Dense.c:108:17: note: node 0x7c8ca78 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:108:17: note: op template: _24 = (sizetype) j_134;
Dense.c:108:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:108:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:108:17: note: 	children 0x7c8cb78
Dense.c:108:17: note: node (external) 0x7c8cb78 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:108:17: note: 	{ j_134, wi_133 }
Dense.c:108:17: note: Cost model analysis: 
Dense.c:108:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:108:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:108:17: missed: not vectorized: vectorization is not profitable.
Dense.c:108:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:108:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:108:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:108:17: note: SLPing BB part
Dense.c:125:17: note: Costing subgraph: 
Dense.c:125:17: note: node 0x7c8ca78 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:125:17: note: op template: _49 = (sizetype) j_137;
Dense.c:125:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:125:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:125:17: note: 	children 0x7c8c878
Dense.c:125:17: note: node (external) 0x7c8c878 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:125:17: note: 	{ j_137, wi_136 }
Dense.c:125:17: note: Cost model analysis: 
Dense.c:125:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:125:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:125:17: missed: not vectorized: vectorization is not profitable.
Dense.c:108:17: note: Costing subgraph: 
Dense.c:108:17: note: node 0x7c8cbf8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:108:17: note: op template: _24 = (sizetype) j_134;
Dense.c:108:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:108:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:108:17: note: 	children 0x7c8caf8
Dense.c:108:17: note: node (external) 0x7c8caf8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:108:17: note: 	{ j_134, wi_133 }
Dense.c:108:17: note: Cost model analysis: 
Dense.c:108:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:108:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:108:17: missed: not vectorized: vectorization is not profitable.
Dense.c:108:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:103:55: note: ***** Analysis failed with vector mode V8QI
Dense.c:103:55: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:103:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:62:15: missed: couldn't vectorize loop
Dense.c:62:15: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:75:11: optimized: loop vectorized using 32 byte vectors
Dense.c:75:11: optimized: loop vectorized using 16 byte vectors
Dense.c:66:11: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:881:10: missed: not vectorized: no vectype for stmt: _56 = MEM[(__m256 * {ref-all})w_ptr_81];
 scalar_type: __m256
Dense.c:54:13: note: vectorized 1 loops in function.
Dense.c:57:2: missed: statement clobbers memory: memcpy (_5, _4, _3);
Dense.c:79:2: missed: statement clobbers memory: _28 (pretmp_162, _67, 0);
Dense.c:54:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:54:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:165:2: missed: statement clobbers memory: free (_1);
Dense.c:166:2: missed: statement clobbers memory: free (_2);
Dense.c:167:2: missed: statement clobbers memory: free (_3);
Dense.c:168:2: missed: statement clobbers memory: free (_4);
Dense.c:169:2: missed: statement clobbers memory: free (dense_7);
Dense.c:170:2: missed: statement clobbers memory: PULSE_DestroyLayer (this_6(D));
Dense.c:171:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:171:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:185:19: missed: couldn't vectorize loop
Dense.c:185:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:175:13: note: vectorized 0 loops in function.
Dense.c:177:47: missed: statement clobbers memory: dense_35 = malloc (40);
Dense.c:179:36: missed: statement clobbers memory: _5 = aligned_alloc (64, _4);
Dense.c:180:38: missed: statement clobbers memory: _6 = aligned_alloc (64, _4);
Dense.c:181:36: missed: statement clobbers memory: _8 = aligned_alloc (64, _7);
Dense.c:182:35: missed: statement clobbers memory: _9 = aligned_alloc (64, _7);
Dense.c:183:36: missed: statement clobbers memory: _10 = aligned_alloc (64, _7);
Dense.c:186:39: missed: statement clobbers memory: _11 = rand ();
Dense.c:186:73: missed: statement clobbers memory: _63 = sqrt (_18);
Dense.c:198:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:199:4: missed: statement clobbers memory: exit (1);
Dense.c:195:4: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.3_29, n_outputs.2_28, 1, activation_function_51(D), _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:192:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.1_27, n_outputs.0_26, 1, activation_function_51(D), _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:205:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Dense.c:205:9: note: ***** Analysis failed with vector mode V4DI
Dense.c:205:9: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:9:27: missed: couldn't vectorize loop
Dense.c:9:27: missed: not vectorized: unsupported outerloop form.
Dense.c:12:20: missed: couldn't vectorize loop
Dense.c:13:21: missed: not vectorized: complicated access pattern.
Dense.c:6:13: note: vectorized 0 loops in function.
Dense.c:16:2: missed: statement clobbers memory: _30 (pretmp_91, _50, 0);
Dense.c:9:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:9:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:24:27: missed: couldn't vectorize loop
Dense.c:24:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:28:20: optimized: loop vectorized using 32 byte vectors
Dense.c:28:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:28:20: optimized: loop vectorized using 16 byte vectors
Dense.c:28:20: missed: couldn't vectorize loop
Dense.c:30:20: missed: not vectorized: no vectype for stmt: _21 = *_20;
 scalar_type: float
Dense.c:20:13: note: vectorized 1 loops in function.
Dense.c:23:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:24:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:24:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:41:28: missed: couldn't vectorize loop
Dense.c:41:28: missed: not vectorized: unsupported outerloop form.
Dense.c:45:21: optimized: loop vectorized using 32 byte vectors
Dense.c:45:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:45:21: optimized: loop vectorized using 16 byte vectors
Dense.c:37:13: note: vectorized 1 loops in function.
Dense.c:37:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:37:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:41:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:144:3: missed: couldn't vectorize loop
Dense.c:144:3: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:157:19: missed: couldn't vectorize loop
Dense.c:157:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:151:10: optimized: loop vectorized using 32 byte vectors
Dense.c:151:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:151:10: optimized: loop vectorized using 16 byte vectors
Dense.c:134:13: note: vectorized 1 loops in function.
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_9, _47);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_11, { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 });
Dense.c:134:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:134:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:134:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:134:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:134:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:134:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:134:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:134:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:103:28: missed: couldn't vectorize loop
Dense.c:103:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:106:21: missed: couldn't vectorize loop
Dense.c:106:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:120:28: missed: couldn't vectorize loop
Dense.c:120:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:123:21: missed: couldn't vectorize loop
Dense.c:123:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:89:19: missed: couldn't vectorize loop
Dense.c:89:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:83:13: note: vectorized 0 loops in function.
Dense.c:86:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:108:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:108:17: note: SLPing BB part
Dense.c:125:17: note: Costing subgraph: 
Dense.c:125:17: note: node 0x7191b78 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:125:17: note: op template: _49 = (sizetype) j_137;
Dense.c:125:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:125:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:125:17: note: 	children 0x7191c78
Dense.c:125:17: note: node (external) 0x7191c78 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:125:17: note: 	{ j_137, wi_136 }
Dense.c:125:17: note: Cost model analysis: 
Dense.c:125:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:125:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:125:17: missed: not vectorized: vectorization is not profitable.
Dense.c:108:17: note: Costing subgraph: 
Dense.c:108:17: note: node 0x7191d78 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:108:17: note: op template: _24 = (sizetype) j_134;
Dense.c:108:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:108:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:108:17: note: 	children 0x7191e78
Dense.c:108:17: note: node (external) 0x7191e78 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:108:17: note: 	{ j_134, wi_133 }
Dense.c:108:17: note: Cost model analysis: 
Dense.c:108:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:108:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:108:17: missed: not vectorized: vectorization is not profitable.
Dense.c:108:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:108:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:108:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:108:17: note: SLPing BB part
Dense.c:125:17: note: Costing subgraph: 
Dense.c:125:17: note: node 0x7191d78 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:125:17: note: op template: _49 = (sizetype) j_137;
Dense.c:125:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:125:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:125:17: note: 	children 0x7191b78
Dense.c:125:17: note: node (external) 0x7191b78 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:125:17: note: 	{ j_137, wi_136 }
Dense.c:125:17: note: Cost model analysis: 
Dense.c:125:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:125:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:125:17: missed: not vectorized: vectorization is not profitable.
Dense.c:108:17: note: Costing subgraph: 
Dense.c:108:17: note: node 0x7191ef8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:108:17: note: op template: _24 = (sizetype) j_134;
Dense.c:108:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:108:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:108:17: note: 	children 0x7191df8
Dense.c:108:17: note: node (external) 0x7191df8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:108:17: note: 	{ j_134, wi_133 }
Dense.c:108:17: note: Cost model analysis: 
Dense.c:108:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:108:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:108:17: missed: not vectorized: vectorization is not profitable.
Dense.c:108:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:103:55: note: ***** Analysis failed with vector mode V8QI
Dense.c:103:55: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:103:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:62:15: missed: couldn't vectorize loop
Dense.c:62:15: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:75:11: optimized: loop vectorized using 32 byte vectors
Dense.c:75:11: optimized: loop vectorized using 16 byte vectors
Dense.c:66:11: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:881:10: missed: not vectorized: no vectype for stmt: _56 = MEM[(__m256 * {ref-all})w_ptr_81];
 scalar_type: __m256
Dense.c:54:13: note: vectorized 1 loops in function.
Dense.c:57:2: missed: statement clobbers memory: memcpy (_5, _4, _3);
Dense.c:79:2: missed: statement clobbers memory: _28 (pretmp_162, _67, 0);
Dense.c:54:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:54:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:172:2: missed: statement clobbers memory: free (_1);
Dense.c:173:2: missed: statement clobbers memory: free (_2);
Dense.c:174:2: missed: statement clobbers memory: free (_3);
Dense.c:175:2: missed: statement clobbers memory: free (_4);
Dense.c:176:2: missed: statement clobbers memory: free (dense_7);
Dense.c:177:2: missed: statement clobbers memory: PULSE_DestroyLayer (this_6(D));
Dense.c:178:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:178:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:192:19: missed: couldn't vectorize loop
Dense.c:192:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:182:13: note: vectorized 0 loops in function.
Dense.c:184:47: missed: statement clobbers memory: dense_35 = malloc (40);
Dense.c:186:36: missed: statement clobbers memory: _5 = aligned_alloc (64, _4);
Dense.c:187:38: missed: statement clobbers memory: _6 = aligned_alloc (64, _4);
Dense.c:188:36: missed: statement clobbers memory: _8 = aligned_alloc (64, _7);
Dense.c:189:35: missed: statement clobbers memory: _9 = aligned_alloc (64, _7);
Dense.c:190:36: missed: statement clobbers memory: _10 = aligned_alloc (64, _7);
Dense.c:193:39: missed: statement clobbers memory: _11 = rand ();
Dense.c:193:73: missed: statement clobbers memory: _63 = sqrt (_18);
Dense.c:205:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:206:4: missed: statement clobbers memory: exit (1);
Dense.c:202:4: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.3_29, n_outputs.2_28, 1, activation_function_51(D), _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:199:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.1_27, n_outputs.0_26, 1, activation_function_51(D), _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:212:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Dense.c:212:9: note: ***** Analysis failed with vector mode V4DI
Dense.c:212:9: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:9:27: missed: couldn't vectorize loop
Dense.c:9:27: missed: not vectorized: unsupported outerloop form.
Dense.c:12:20: missed: couldn't vectorize loop
Dense.c:13:21: missed: not vectorized: complicated access pattern.
Dense.c:6:13: note: vectorized 0 loops in function.
Dense.c:16:2: missed: statement clobbers memory: _30 (pretmp_91, _50, 0);
Dense.c:9:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:9:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:24:27: missed: couldn't vectorize loop
Dense.c:24:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:28:20: optimized: loop vectorized using 32 byte vectors
Dense.c:28:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:28:20: optimized: loop vectorized using 16 byte vectors
Dense.c:28:20: missed: couldn't vectorize loop
Dense.c:30:20: missed: not vectorized: no vectype for stmt: _21 = *_20;
 scalar_type: float
Dense.c:20:13: note: vectorized 1 loops in function.
Dense.c:23:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:24:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:24:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:41:28: missed: couldn't vectorize loop
Dense.c:41:28: missed: not vectorized: unsupported outerloop form.
Dense.c:45:21: optimized: loop vectorized using 32 byte vectors
Dense.c:45:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:45:21: optimized: loop vectorized using 16 byte vectors
Dense.c:37:13: note: vectorized 1 loops in function.
Dense.c:37:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:37:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:41:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:158:19: missed: couldn't vectorize loop
Dense.c:158:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:152:10: optimized: loop vectorized using 32 byte vectors
Dense.c:152:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:152:10: optimized: loop vectorized using 16 byte vectors
Dense.c:142:10: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_12, _53);
Dense.c:134:13: note: vectorized 1 loops in function.
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_12, _53);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_16, { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 });
Dense.c:134:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:134:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:134:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:134:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:134:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:134:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:134:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:134:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:103:28: missed: couldn't vectorize loop
Dense.c:103:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:106:21: missed: couldn't vectorize loop
Dense.c:106:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:120:28: missed: couldn't vectorize loop
Dense.c:120:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:123:21: missed: couldn't vectorize loop
Dense.c:123:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:89:19: missed: couldn't vectorize loop
Dense.c:89:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:83:13: note: vectorized 0 loops in function.
Dense.c:86:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:108:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:108:17: note: SLPing BB part
Dense.c:125:17: note: Costing subgraph: 
Dense.c:125:17: note: node 0x8bf5388 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:125:17: note: op template: _49 = (sizetype) j_137;
Dense.c:125:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:125:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:125:17: note: 	children 0x8bf5488
Dense.c:125:17: note: node (external) 0x8bf5488 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:125:17: note: 	{ j_137, wi_136 }
Dense.c:125:17: note: Cost model analysis: 
Dense.c:125:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:125:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:125:17: missed: not vectorized: vectorization is not profitable.
Dense.c:108:17: note: Costing subgraph: 
Dense.c:108:17: note: node 0x8bf5588 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:108:17: note: op template: _24 = (sizetype) j_134;
Dense.c:108:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:108:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:108:17: note: 	children 0x8bf5688
Dense.c:108:17: note: node (external) 0x8bf5688 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:108:17: note: 	{ j_134, wi_133 }
Dense.c:108:17: note: Cost model analysis: 
Dense.c:108:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:108:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:108:17: missed: not vectorized: vectorization is not profitable.
Dense.c:108:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:108:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:108:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:108:17: note: SLPing BB part
Dense.c:125:17: note: Costing subgraph: 
Dense.c:125:17: note: node 0x8bf5588 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:125:17: note: op template: _49 = (sizetype) j_137;
Dense.c:125:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:125:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:125:17: note: 	children 0x8bf5388
Dense.c:125:17: note: node (external) 0x8bf5388 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:125:17: note: 	{ j_137, wi_136 }
Dense.c:125:17: note: Cost model analysis: 
Dense.c:125:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:125:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:125:17: missed: not vectorized: vectorization is not profitable.
Dense.c:108:17: note: Costing subgraph: 
Dense.c:108:17: note: node 0x8bf5708 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:108:17: note: op template: _24 = (sizetype) j_134;
Dense.c:108:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:108:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:108:17: note: 	children 0x8bf5608
Dense.c:108:17: note: node (external) 0x8bf5608 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:108:17: note: 	{ j_134, wi_133 }
Dense.c:108:17: note: Cost model analysis: 
Dense.c:108:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:108:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:108:17: missed: not vectorized: vectorization is not profitable.
Dense.c:108:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:103:55: note: ***** Analysis failed with vector mode V8QI
Dense.c:103:55: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:103:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:62:15: missed: couldn't vectorize loop
Dense.c:62:15: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:75:11: optimized: loop vectorized using 32 byte vectors
Dense.c:75:11: optimized: loop vectorized using 16 byte vectors
Dense.c:66:11: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:881:10: missed: not vectorized: no vectype for stmt: _56 = MEM[(__m256 * {ref-all})w_ptr_81];
 scalar_type: __m256
Dense.c:54:13: note: vectorized 1 loops in function.
Dense.c:57:2: missed: statement clobbers memory: memcpy (_5, _4, _3);
Dense.c:79:2: missed: statement clobbers memory: _28 (pretmp_162, _67, 0);
Dense.c:54:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:54:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:173:2: missed: statement clobbers memory: free (_1);
Dense.c:174:2: missed: statement clobbers memory: free (_2);
Dense.c:175:2: missed: statement clobbers memory: free (_3);
Dense.c:176:2: missed: statement clobbers memory: free (_4);
Dense.c:177:2: missed: statement clobbers memory: free (dense_7);
Dense.c:178:2: missed: statement clobbers memory: PULSE_DestroyLayer (this_6(D));
Dense.c:179:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:179:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:193:19: missed: couldn't vectorize loop
Dense.c:193:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:183:13: note: vectorized 0 loops in function.
Dense.c:185:47: missed: statement clobbers memory: dense_35 = malloc (40);
Dense.c:187:36: missed: statement clobbers memory: _5 = aligned_alloc (64, _4);
Dense.c:188:38: missed: statement clobbers memory: _6 = aligned_alloc (64, _4);
Dense.c:189:36: missed: statement clobbers memory: _8 = aligned_alloc (64, _7);
Dense.c:190:35: missed: statement clobbers memory: _9 = aligned_alloc (64, _7);
Dense.c:191:36: missed: statement clobbers memory: _10 = aligned_alloc (64, _7);
Dense.c:194:39: missed: statement clobbers memory: _11 = rand ();
Dense.c:194:73: missed: statement clobbers memory: _63 = sqrt (_18);
Dense.c:206:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:207:4: missed: statement clobbers memory: exit (1);
Dense.c:203:4: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.3_29, n_outputs.2_28, 1, activation_function_51(D), _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:200:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.1_27, n_outputs.0_26, 1, activation_function_51(D), _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:213:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Dense.c:213:9: note: ***** Analysis failed with vector mode V4DI
Dense.c:213:9: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:9:27: missed: couldn't vectorize loop
Dense.c:9:27: missed: not vectorized: unsupported outerloop form.
Dense.c:12:20: missed: couldn't vectorize loop
Dense.c:13:21: missed: not vectorized: complicated access pattern.
Dense.c:6:13: note: vectorized 0 loops in function.
Dense.c:16:2: missed: statement clobbers memory: _30 (pretmp_91, _50, 0);
Dense.c:9:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:9:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:24:27: missed: couldn't vectorize loop
Dense.c:24:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:28:20: optimized: loop vectorized using 32 byte vectors
Dense.c:28:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:28:20: optimized: loop vectorized using 16 byte vectors
Dense.c:28:20: missed: couldn't vectorize loop
Dense.c:30:20: missed: not vectorized: no vectype for stmt: _21 = *_20;
 scalar_type: float
Dense.c:20:13: note: vectorized 1 loops in function.
Dense.c:23:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:24:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:24:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:41:28: missed: couldn't vectorize loop
Dense.c:41:28: missed: not vectorized: unsupported outerloop form.
Dense.c:45:21: optimized: loop vectorized using 32 byte vectors
Dense.c:45:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:45:21: optimized: loop vectorized using 16 byte vectors
Dense.c:37:13: note: vectorized 1 loops in function.
Dense.c:37:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:37:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:41:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:168:10: optimized: loop vectorized using 32 byte vectors
Dense.c:168:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:168:10: optimized: loop vectorized using 16 byte vectors
Dense.c:159:10: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_34, _77);
Dense.c:152:10: optimized: loop vectorized using 32 byte vectors
Dense.c:152:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:152:10: optimized: loop vectorized using 16 byte vectors
Dense.c:143:10: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_15, _69);
Dense.c:134:13: note: vectorized 2 loops in function.
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_15, _69);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_19, { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 });
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_34, _77);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_38, { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 });
Dense.c:134:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:134:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:134:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:134:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:134:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:134:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:134:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:134:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:103:28: missed: couldn't vectorize loop
Dense.c:103:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:106:21: missed: couldn't vectorize loop
Dense.c:106:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:120:28: missed: couldn't vectorize loop
Dense.c:120:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:123:21: missed: couldn't vectorize loop
Dense.c:123:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:89:19: missed: couldn't vectorize loop
Dense.c:89:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:83:13: note: vectorized 0 loops in function.
Dense.c:86:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:108:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:108:17: note: SLPing BB part
Dense.c:125:17: note: Costing subgraph: 
Dense.c:125:17: note: node 0x86658e8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:125:17: note: op template: _49 = (sizetype) j_137;
Dense.c:125:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:125:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:125:17: note: 	children 0x86659e8
Dense.c:125:17: note: node (external) 0x86659e8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:125:17: note: 	{ j_137, wi_136 }
Dense.c:125:17: note: Cost model analysis: 
Dense.c:125:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:125:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:125:17: missed: not vectorized: vectorization is not profitable.
Dense.c:108:17: note: Costing subgraph: 
Dense.c:108:17: note: node 0x8665ae8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:108:17: note: op template: _24 = (sizetype) j_134;
Dense.c:108:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:108:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:108:17: note: 	children 0x8665be8
Dense.c:108:17: note: node (external) 0x8665be8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:108:17: note: 	{ j_134, wi_133 }
Dense.c:108:17: note: Cost model analysis: 
Dense.c:108:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:108:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:108:17: missed: not vectorized: vectorization is not profitable.
Dense.c:108:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:108:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:108:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:108:17: note: SLPing BB part
Dense.c:125:17: note: Costing subgraph: 
Dense.c:125:17: note: node 0x8665ae8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:125:17: note: op template: _49 = (sizetype) j_137;
Dense.c:125:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:125:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:125:17: note: 	children 0x86658e8
Dense.c:125:17: note: node (external) 0x86658e8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:125:17: note: 	{ j_137, wi_136 }
Dense.c:125:17: note: Cost model analysis: 
Dense.c:125:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:125:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:125:17: missed: not vectorized: vectorization is not profitable.
Dense.c:108:17: note: Costing subgraph: 
Dense.c:108:17: note: node 0x8665c68 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:108:17: note: op template: _24 = (sizetype) j_134;
Dense.c:108:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:108:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:108:17: note: 	children 0x8665b68
Dense.c:108:17: note: node (external) 0x8665b68 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:108:17: note: 	{ j_134, wi_133 }
Dense.c:108:17: note: Cost model analysis: 
Dense.c:108:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:108:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:108:17: missed: not vectorized: vectorization is not profitable.
Dense.c:108:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:103:55: note: ***** Analysis failed with vector mode V8QI
Dense.c:103:55: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:103:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:62:15: missed: couldn't vectorize loop
Dense.c:62:15: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:75:11: optimized: loop vectorized using 32 byte vectors
Dense.c:75:11: optimized: loop vectorized using 16 byte vectors
Dense.c:66:11: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:881:10: missed: not vectorized: no vectype for stmt: _56 = MEM[(__m256 * {ref-all})w_ptr_81];
 scalar_type: __m256
Dense.c:54:13: note: vectorized 1 loops in function.
Dense.c:57:2: missed: statement clobbers memory: memcpy (_5, _4, _3);
Dense.c:79:2: missed: statement clobbers memory: _28 (pretmp_162, _67, 0);
Dense.c:54:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:54:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:191:2: missed: statement clobbers memory: free (_1);
Dense.c:192:2: missed: statement clobbers memory: free (_2);
Dense.c:193:2: missed: statement clobbers memory: free (_3);
Dense.c:194:2: missed: statement clobbers memory: free (_4);
Dense.c:195:2: missed: statement clobbers memory: free (dense_7);
Dense.c:196:2: missed: statement clobbers memory: PULSE_DestroyLayer (this_6(D));
Dense.c:197:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:197:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:211:19: missed: couldn't vectorize loop
Dense.c:211:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:201:13: note: vectorized 0 loops in function.
Dense.c:203:47: missed: statement clobbers memory: dense_35 = malloc (40);
Dense.c:205:36: missed: statement clobbers memory: _5 = aligned_alloc (64, _4);
Dense.c:206:38: missed: statement clobbers memory: _6 = aligned_alloc (64, _4);
Dense.c:207:36: missed: statement clobbers memory: _8 = aligned_alloc (64, _7);
Dense.c:208:35: missed: statement clobbers memory: _9 = aligned_alloc (64, _7);
Dense.c:209:36: missed: statement clobbers memory: _10 = aligned_alloc (64, _7);
Dense.c:212:39: missed: statement clobbers memory: _11 = rand ();
Dense.c:212:73: missed: statement clobbers memory: _63 = sqrt (_18);
Dense.c:224:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:225:4: missed: statement clobbers memory: exit (1);
Dense.c:221:4: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.3_29, n_outputs.2_28, 1, activation_function_51(D), _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:218:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.1_27, n_outputs.0_26, 1, activation_function_51(D), _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:231:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Dense.c:231:9: note: ***** Analysis failed with vector mode V4DI
Dense.c:231:9: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:9:27: missed: couldn't vectorize loop
Dense.c:9:27: missed: not vectorized: unsupported outerloop form.
Dense.c:12:20: missed: couldn't vectorize loop
Dense.c:13:21: missed: not vectorized: complicated access pattern.
Dense.c:6:13: note: vectorized 0 loops in function.
Dense.c:16:2: missed: statement clobbers memory: _30 (pretmp_91, _50, 0);
Dense.c:9:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:9:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:24:27: missed: couldn't vectorize loop
Dense.c:24:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:28:20: optimized: loop vectorized using 32 byte vectors
Dense.c:28:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:28:20: optimized: loop vectorized using 16 byte vectors
Dense.c:28:20: missed: couldn't vectorize loop
Dense.c:30:20: missed: not vectorized: no vectype for stmt: _21 = *_20;
 scalar_type: float
Dense.c:20:13: note: vectorized 1 loops in function.
Dense.c:23:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:24:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:24:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:41:28: missed: couldn't vectorize loop
Dense.c:41:28: missed: not vectorized: unsupported outerloop form.
Dense.c:45:21: optimized: loop vectorized using 32 byte vectors
Dense.c:45:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:45:21: optimized: loop vectorized using 16 byte vectors
Dense.c:37:13: note: vectorized 1 loops in function.
Dense.c:37:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:37:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:41:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:177:10: optimized: loop vectorized using 32 byte vectors
Dense.c:177:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:177:10: optimized: loop vectorized using 16 byte vectors
Dense.c:168:10: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_34, _77);
Dense.c:161:10: optimized: loop vectorized using 32 byte vectors
Dense.c:161:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:161:10: optimized: loop vectorized using 16 byte vectors
Dense.c:152:10: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_15, _69);
Dense.c:143:13: note: vectorized 2 loops in function.
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_15, _69);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_19, { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 });
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_34, _77);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_38, { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 });
Dense.c:143:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:143:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:143:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:143:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:143:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:143:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:143:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:143:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:112:24: missed: couldn't vectorize loop
Dense.c:112:24: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:115:17: missed: couldn't vectorize loop
Dense.c:115:17: missed: not vectorized: number of iterations cannot be computed.
Dense.c:129:24: missed: couldn't vectorize loop
Dense.c:129:24: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:132:17: missed: couldn't vectorize loop
Dense.c:132:17: missed: not vectorized: number of iterations cannot be computed.
Dense.c:103:10: optimized: loop vectorized using 32 byte vectors
Dense.c:103:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:103:10: optimized: loop vectorized using 16 byte vectors
Dense.c:91:10: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_13, _102);
Dense.c:83:13: note: vectorized 1 loops in function.
Dense.c:86:2: missed: statement clobbers memory: _1 (_3, _2, 1);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_13, _102);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_15, _103);
Dense.c:117:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:117:17: note: SLPing BB part
Dense.c:134:17: note: Costing subgraph: 
Dense.c:134:17: note: node 0x84d15f8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:134:17: note: op template: _66 = (sizetype) j_162;
Dense.c:134:17: note: 	stmt 0 _66 = (sizetype) j_162;
Dense.c:134:17: note: 	stmt 1 _257 = (sizetype) wi_164;
Dense.c:134:17: note: 	children 0x84d16f8
Dense.c:134:17: note: node (external) 0x84d16f8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:134:17: note: 	{ j_162, wi_164 }
Dense.c:134:17: note: Cost model analysis: 
Dense.c:134:17: note: Scalar 3 and vector 4 loop part do not match up, skipping scalar part
Dense.c:134:17: note: Cost model analysis for part in loop 4:
  Vector cost: 36
  Scalar cost: 8
Dense.c:134:17: missed: not vectorized: vectorization is not profitable.
Dense.c:117:17: note: Costing subgraph: 
Dense.c:117:17: note: node 0x84d17f8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:117:17: note: op template: _41 = (sizetype) j_161;
Dense.c:117:17: note: 	stmt 0 _41 = (sizetype) j_161;
Dense.c:117:17: note: 	stmt 1 _277 = (sizetype) wi_163;
Dense.c:117:17: note: 	children 0x84d18f8
Dense.c:117:17: note: node (external) 0x84d18f8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:117:17: note: 	{ j_161, wi_163 }
Dense.c:117:17: note: Cost model analysis: 
Dense.c:117:17: note: Scalar 5 and vector 6 loop part do not match up, skipping scalar part
Dense.c:117:17: note: Cost model analysis for part in loop 6:
  Vector cost: 36
  Scalar cost: 8
Dense.c:117:17: missed: not vectorized: vectorization is not profitable.
Dense.c:117:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:117:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:117:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:117:17: note: SLPing BB part
Dense.c:134:17: note: Costing subgraph: 
Dense.c:134:17: note: node 0x84d1678 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:134:17: note: op template: _66 = (sizetype) j_162;
Dense.c:134:17: note: 	stmt 0 _66 = (sizetype) j_162;
Dense.c:134:17: note: 	stmt 1 _257 = (sizetype) wi_164;
Dense.c:134:17: note: 	children 0x84d1978
Dense.c:134:17: note: node (external) 0x84d1978 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:134:17: note: 	{ j_162, wi_164 }
Dense.c:134:17: note: Cost model analysis: 
Dense.c:134:17: note: Scalar 3 and vector 4 loop part do not match up, skipping scalar part
Dense.c:134:17: note: Cost model analysis for part in loop 4:
  Vector cost: 36
  Scalar cost: 8
Dense.c:134:17: missed: not vectorized: vectorization is not profitable.
Dense.c:117:17: note: Costing subgraph: 
Dense.c:117:17: note: node 0x84d0f78 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:117:17: note: op template: _41 = (sizetype) j_161;
Dense.c:117:17: note: 	stmt 0 _41 = (sizetype) j_161;
Dense.c:117:17: note: 	stmt 1 _277 = (sizetype) wi_163;
Dense.c:117:17: note: 	children 0x84d19f8
Dense.c:117:17: note: node (external) 0x84d19f8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:117:17: note: 	{ j_161, wi_163 }
Dense.c:117:17: note: Cost model analysis: 
Dense.c:117:17: note: Scalar 5 and vector 6 loop part do not match up, skipping scalar part
Dense.c:117:17: note: Cost model analysis for part in loop 6:
  Vector cost: 36
  Scalar cost: 8
Dense.c:117:17: missed: not vectorized: vectorization is not profitable.
Dense.c:117:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:83:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:83:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:112:51: note: ***** Analysis failed with vector mode V4QI
Dense.c:62:15: missed: couldn't vectorize loop
Dense.c:62:15: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:75:11: optimized: loop vectorized using 32 byte vectors
Dense.c:75:11: optimized: loop vectorized using 16 byte vectors
Dense.c:66:11: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:881:10: missed: not vectorized: no vectype for stmt: _56 = MEM[(__m256 * {ref-all})w_ptr_81];
 scalar_type: __m256
Dense.c:54:13: note: vectorized 1 loops in function.
Dense.c:57:2: missed: statement clobbers memory: memcpy (_5, _4, _3);
Dense.c:79:2: missed: statement clobbers memory: _28 (pretmp_162, _67, 0);
Dense.c:54:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:54:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:189:2: missed: statement clobbers memory: free (_1);
Dense.c:190:2: missed: statement clobbers memory: free (_2);
Dense.c:191:2: missed: statement clobbers memory: free (_3);
Dense.c:192:2: missed: statement clobbers memory: free (_4);
Dense.c:193:2: missed: statement clobbers memory: free (dense_7);
Dense.c:194:2: missed: statement clobbers memory: PULSE_DestroyLayer (this_6(D));
Dense.c:195:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:195:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:209:19: missed: couldn't vectorize loop
Dense.c:209:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:199:13: note: vectorized 0 loops in function.
Dense.c:201:47: missed: statement clobbers memory: dense_35 = malloc (40);
Dense.c:203:36: missed: statement clobbers memory: _5 = aligned_alloc (64, _4);
Dense.c:204:38: missed: statement clobbers memory: _6 = aligned_alloc (64, _4);
Dense.c:205:36: missed: statement clobbers memory: _8 = aligned_alloc (64, _7);
Dense.c:206:35: missed: statement clobbers memory: _9 = aligned_alloc (64, _7);
Dense.c:207:36: missed: statement clobbers memory: _10 = aligned_alloc (64, _7);
Dense.c:210:39: missed: statement clobbers memory: _11 = rand ();
Dense.c:210:73: missed: statement clobbers memory: _63 = sqrt (_18);
Dense.c:222:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:223:4: missed: statement clobbers memory: exit (1);
Dense.c:219:4: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.3_29, n_outputs.2_28, 1, activation_function_51(D), _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:216:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.1_27, n_outputs.0_26, 1, activation_function_51(D), _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:229:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Dense.c:229:9: note: ***** Analysis failed with vector mode V4DI
Dense.c:229:9: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:9:27: missed: couldn't vectorize loop
Dense.c:9:27: missed: not vectorized: unsupported outerloop form.
Dense.c:12:20: missed: couldn't vectorize loop
Dense.c:13:21: missed: not vectorized: complicated access pattern.
Dense.c:6:13: note: vectorized 0 loops in function.
Dense.c:16:2: missed: statement clobbers memory: _30 (pretmp_91, _50, 0);
Dense.c:9:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:9:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:24:27: missed: couldn't vectorize loop
Dense.c:24:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:28:20: optimized: loop vectorized using 32 byte vectors
Dense.c:28:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:28:20: optimized: loop vectorized using 16 byte vectors
Dense.c:28:20: missed: couldn't vectorize loop
Dense.c:30:20: missed: not vectorized: no vectype for stmt: _21 = *_20;
 scalar_type: float
Dense.c:20:13: note: vectorized 1 loops in function.
Dense.c:23:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:24:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:24:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:41:28: missed: couldn't vectorize loop
Dense.c:41:28: missed: not vectorized: unsupported outerloop form.
Dense.c:45:21: optimized: loop vectorized using 32 byte vectors
Dense.c:45:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:45:21: optimized: loop vectorized using 16 byte vectors
Dense.c:37:13: note: vectorized 1 loops in function.
Dense.c:37:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:37:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:41:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:177:10: optimized: loop vectorized using 32 byte vectors
Dense.c:177:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:177:10: optimized: loop vectorized using 16 byte vectors
Dense.c:168:10: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_34, _77);
Dense.c:161:10: optimized: loop vectorized using 32 byte vectors
Dense.c:161:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:161:10: optimized: loop vectorized using 16 byte vectors
Dense.c:152:10: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_15, _69);
Dense.c:143:13: note: vectorized 2 loops in function.
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_15, _69);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_19, { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 });
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_34, _77);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_38, { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 });
Dense.c:143:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:143:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:143:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:143:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:143:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:143:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:143:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:143:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:112:24: missed: couldn't vectorize loop
Dense.c:112:24: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:115:17: missed: couldn't vectorize loop
Dense.c:115:17: missed: not vectorized: number of iterations cannot be computed.
Dense.c:129:24: missed: couldn't vectorize loop
Dense.c:129:24: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:132:17: missed: couldn't vectorize loop
Dense.c:132:17: missed: not vectorized: number of iterations cannot be computed.
Dense.c:103:10: optimized: loop vectorized using 32 byte vectors
Dense.c:103:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:103:10: optimized: loop vectorized using 16 byte vectors
Dense.c:91:10: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_13, _102);
Dense.c:83:13: note: vectorized 1 loops in function.
Dense.c:86:2: missed: statement clobbers memory: _1 (_3, _2, 1);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_13, _102);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_15, _103);
Dense.c:117:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:117:17: note: SLPing BB part
Dense.c:134:17: note: Costing subgraph: 
Dense.c:134:17: note: node 0x874ae78 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:134:17: note: op template: _66 = (sizetype) j_162;
Dense.c:134:17: note: 	stmt 0 _66 = (sizetype) j_162;
Dense.c:134:17: note: 	stmt 1 _259 = (sizetype) wi_164;
Dense.c:134:17: note: 	children 0x874af78
Dense.c:134:17: note: node (external) 0x874af78 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:134:17: note: 	{ j_162, wi_164 }
Dense.c:134:17: note: Cost model analysis: 
Dense.c:134:17: note: Scalar 3 and vector 4 loop part do not match up, skipping scalar part
Dense.c:134:17: note: Cost model analysis for part in loop 4:
  Vector cost: 36
  Scalar cost: 8
Dense.c:134:17: missed: not vectorized: vectorization is not profitable.
Dense.c:117:17: note: Costing subgraph: 
Dense.c:117:17: note: node 0x874b078 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:117:17: note: op template: _41 = (sizetype) j_161;
Dense.c:117:17: note: 	stmt 0 _41 = (sizetype) j_161;
Dense.c:117:17: note: 	stmt 1 _279 = (sizetype) wi_163;
Dense.c:117:17: note: 	children 0x874b178
Dense.c:117:17: note: node (external) 0x874b178 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:117:17: note: 	{ j_161, wi_163 }
Dense.c:117:17: note: Cost model analysis: 
Dense.c:117:17: note: Scalar 5 and vector 6 loop part do not match up, skipping scalar part
Dense.c:117:17: note: Cost model analysis for part in loop 6:
  Vector cost: 36
  Scalar cost: 8
Dense.c:117:17: missed: not vectorized: vectorization is not profitable.
Dense.c:117:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:117:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:117:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:117:17: note: SLPing BB part
Dense.c:134:17: note: Costing subgraph: 
Dense.c:134:17: note: node 0x874ac78 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:134:17: note: op template: _66 = (sizetype) j_162;
Dense.c:134:17: note: 	stmt 0 _66 = (sizetype) j_162;
Dense.c:134:17: note: 	stmt 1 _259 = (sizetype) wi_164;
Dense.c:134:17: note: 	children 0x874b0f8
Dense.c:134:17: note: node (external) 0x874b0f8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:134:17: note: 	{ j_162, wi_164 }
Dense.c:134:17: note: Cost model analysis: 
Dense.c:134:17: note: Scalar 3 and vector 4 loop part do not match up, skipping scalar part
Dense.c:134:17: note: Cost model analysis for part in loop 4:
  Vector cost: 36
  Scalar cost: 8
Dense.c:134:17: missed: not vectorized: vectorization is not profitable.
Dense.c:117:17: note: Costing subgraph: 
Dense.c:117:17: note: node 0x874abf8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:117:17: note: op template: _41 = (sizetype) j_161;
Dense.c:117:17: note: 	stmt 0 _41 = (sizetype) j_161;
Dense.c:117:17: note: 	stmt 1 _279 = (sizetype) wi_163;
Dense.c:117:17: note: 	children 0x874b278
Dense.c:117:17: note: node (external) 0x874b278 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:117:17: note: 	{ j_161, wi_163 }
Dense.c:117:17: note: Cost model analysis: 
Dense.c:117:17: note: Scalar 5 and vector 6 loop part do not match up, skipping scalar part
Dense.c:117:17: note: Cost model analysis for part in loop 6:
  Vector cost: 36
  Scalar cost: 8
Dense.c:117:17: missed: not vectorized: vectorization is not profitable.
Dense.c:117:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:83:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:83:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:112:51: note: ***** Analysis failed with vector mode V4QI
Dense.c:62:15: missed: couldn't vectorize loop
Dense.c:62:15: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:75:11: optimized: loop vectorized using 32 byte vectors
Dense.c:75:11: optimized: loop vectorized using 16 byte vectors
Dense.c:66:11: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:881:10: missed: not vectorized: no vectype for stmt: _56 = MEM[(__m256 * {ref-all})w_ptr_81];
 scalar_type: __m256
Dense.c:54:13: note: vectorized 1 loops in function.
Dense.c:57:2: missed: statement clobbers memory: memcpy (_5, _4, _3);
Dense.c:79:2: missed: statement clobbers memory: _28 (pretmp_162, _67, 0);
Dense.c:54:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:54:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:189:2: missed: statement clobbers memory: free (_1);
Dense.c:190:2: missed: statement clobbers memory: free (_2);
Dense.c:191:2: missed: statement clobbers memory: free (_3);
Dense.c:192:2: missed: statement clobbers memory: free (_4);
Dense.c:193:2: missed: statement clobbers memory: free (dense_7);
Dense.c:194:2: missed: statement clobbers memory: PULSE_DestroyLayer (this_6(D));
Dense.c:195:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:195:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:209:19: missed: couldn't vectorize loop
Dense.c:209:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:199:13: note: vectorized 0 loops in function.
Dense.c:201:47: missed: statement clobbers memory: dense_35 = malloc (40);
Dense.c:203:36: missed: statement clobbers memory: _5 = aligned_alloc (64, _4);
Dense.c:204:38: missed: statement clobbers memory: _6 = aligned_alloc (64, _4);
Dense.c:205:36: missed: statement clobbers memory: _8 = aligned_alloc (64, _7);
Dense.c:206:35: missed: statement clobbers memory: _9 = aligned_alloc (64, _7);
Dense.c:207:36: missed: statement clobbers memory: _10 = aligned_alloc (64, _7);
Dense.c:210:39: missed: statement clobbers memory: _11 = rand ();
Dense.c:210:73: missed: statement clobbers memory: _63 = sqrt (_18);
Dense.c:222:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:223:4: missed: statement clobbers memory: exit (1);
Dense.c:219:4: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.3_29, n_outputs.2_28, 1, activation_function_51(D), _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:216:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.1_27, n_outputs.0_26, 1, activation_function_51(D), _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:229:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Dense.c:229:9: note: ***** Analysis failed with vector mode V4DI
Dense.c:229:9: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:9:27: missed: couldn't vectorize loop
Dense.c:9:27: missed: not vectorized: unsupported outerloop form.
Dense.c:12:20: missed: couldn't vectorize loop
Dense.c:13:21: missed: not vectorized: complicated access pattern.
Dense.c:6:13: note: vectorized 0 loops in function.
Dense.c:16:2: missed: statement clobbers memory: _30 (pretmp_91, _50, 0);
Dense.c:9:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:9:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:24:27: missed: couldn't vectorize loop
Dense.c:24:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:28:20: optimized: loop vectorized using 32 byte vectors
Dense.c:28:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:28:20: optimized: loop vectorized using 16 byte vectors
Dense.c:28:20: missed: couldn't vectorize loop
Dense.c:30:20: missed: not vectorized: no vectype for stmt: _21 = *_20;
 scalar_type: float
Dense.c:20:13: note: vectorized 1 loops in function.
Dense.c:23:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:24:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:24:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:41:28: missed: couldn't vectorize loop
Dense.c:41:28: missed: not vectorized: unsupported outerloop form.
Dense.c:45:21: optimized: loop vectorized using 32 byte vectors
Dense.c:45:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:45:21: optimized: loop vectorized using 16 byte vectors
Dense.c:37:13: note: vectorized 1 loops in function.
Dense.c:37:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:37:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:41:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:189:10: optimized: loop vectorized using 32 byte vectors
Dense.c:189:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:189:10: optimized: loop vectorized using 16 byte vectors
Dense.c:180:10: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_34, _77);
Dense.c:173:10: optimized: loop vectorized using 32 byte vectors
Dense.c:173:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:173:10: optimized: loop vectorized using 16 byte vectors
Dense.c:164:10: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_15, _69);
Dense.c:155:13: note: vectorized 2 loops in function.
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_15, _69);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_19, { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 });
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_34, _77);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_38, { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 });
Dense.c:155:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:155:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:155:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:155:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:155:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:155:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:155:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:155:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:124:24: missed: couldn't vectorize loop
Dense.c:124:24: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:127:17: missed: couldn't vectorize loop
Dense.c:127:17: missed: not vectorized: number of iterations cannot be computed.
Dense.c:141:24: missed: couldn't vectorize loop
Dense.c:141:24: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:144:17: missed: couldn't vectorize loop
Dense.c:144:17: missed: not vectorized: number of iterations cannot be computed.
Dense.c:109:15: missed: couldn't vectorize loop
Dense.c:109:15: missed: not vectorized: number of iterations cannot be computed.
Dense.c:83:13: note: vectorized 0 loops in function.
Dense.c:86:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:129:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:129:17: note: SLPing BB part
Dense.c:146:17: note: Costing subgraph: 
Dense.c:146:17: note: node 0x75015f8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:146:17: note: op template: _49 = (sizetype) j_135;
Dense.c:146:17: note: 	stmt 0 _49 = (sizetype) j_135;
Dense.c:146:17: note: 	stmt 1 _209 = (sizetype) wi_137;
Dense.c:146:17: note: 	children 0x75016f8
Dense.c:146:17: note: node (external) 0x75016f8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:146:17: note: 	{ j_135, wi_137 }
Dense.c:146:17: note: Cost model analysis: 
Dense.c:146:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:146:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:146:17: missed: not vectorized: vectorization is not profitable.
Dense.c:129:17: note: Costing subgraph: 
Dense.c:129:17: note: node 0x75017f8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:129:17: note: op template: _24 = (sizetype) j_134;
Dense.c:129:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:129:17: note: 	stmt 1 _229 = (sizetype) wi_136;
Dense.c:129:17: note: 	children 0x75018f8
Dense.c:129:17: note: node (external) 0x75018f8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:129:17: note: 	{ j_134, wi_136 }
Dense.c:129:17: note: Cost model analysis: 
Dense.c:129:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:129:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:129:17: missed: not vectorized: vectorization is not profitable.
Dense.c:129:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:129:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:129:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:129:17: note: SLPing BB part
Dense.c:146:17: note: Costing subgraph: 
Dense.c:146:17: note: node 0x75017f8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:146:17: note: op template: _49 = (sizetype) j_135;
Dense.c:146:17: note: 	stmt 0 _49 = (sizetype) j_135;
Dense.c:146:17: note: 	stmt 1 _209 = (sizetype) wi_137;
Dense.c:146:17: note: 	children 0x75015f8
Dense.c:146:17: note: node (external) 0x75015f8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:146:17: note: 	{ j_135, wi_137 }
Dense.c:146:17: note: Cost model analysis: 
Dense.c:146:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:146:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:146:17: missed: not vectorized: vectorization is not profitable.
Dense.c:129:17: note: Costing subgraph: 
Dense.c:129:17: note: node 0x7501978 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:129:17: note: op template: _24 = (sizetype) j_134;
Dense.c:129:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:129:17: note: 	stmt 1 _229 = (sizetype) wi_136;
Dense.c:129:17: note: 	children 0x7501878
Dense.c:129:17: note: node (external) 0x7501878 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:129:17: note: 	{ j_134, wi_136 }
Dense.c:129:17: note: Cost model analysis: 
Dense.c:129:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:129:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:129:17: missed: not vectorized: vectorization is not profitable.
Dense.c:129:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:124:51: note: ***** Analysis failed with vector mode V8QI
Dense.c:124:51: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:124:51: note: ***** Analysis failed with vector mode V4QI
Dense.c:62:15: missed: couldn't vectorize loop
Dense.c:62:15: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:75:11: optimized: loop vectorized using 32 byte vectors
Dense.c:75:11: optimized: loop vectorized using 16 byte vectors
Dense.c:66:11: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:881:10: missed: not vectorized: no vectype for stmt: _56 = MEM[(__m256 * {ref-all})w_ptr_81];
 scalar_type: __m256
Dense.c:54:13: note: vectorized 1 loops in function.
Dense.c:57:2: missed: statement clobbers memory: memcpy (_5, _4, _3);
Dense.c:79:2: missed: statement clobbers memory: _28 (pretmp_162, _67, 0);
Dense.c:54:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:54:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:201:2: missed: statement clobbers memory: free (_1);
Dense.c:202:2: missed: statement clobbers memory: free (_2);
Dense.c:203:2: missed: statement clobbers memory: free (_3);
Dense.c:204:2: missed: statement clobbers memory: free (_4);
Dense.c:205:2: missed: statement clobbers memory: free (dense_7);
Dense.c:206:2: missed: statement clobbers memory: PULSE_DestroyLayer (this_6(D));
Dense.c:207:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:207:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:221:19: missed: couldn't vectorize loop
Dense.c:221:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:211:13: note: vectorized 0 loops in function.
Dense.c:213:47: missed: statement clobbers memory: dense_35 = malloc (40);
Dense.c:215:36: missed: statement clobbers memory: _5 = aligned_alloc (64, _4);
Dense.c:216:38: missed: statement clobbers memory: _6 = aligned_alloc (64, _4);
Dense.c:217:36: missed: statement clobbers memory: _8 = aligned_alloc (64, _7);
Dense.c:218:35: missed: statement clobbers memory: _9 = aligned_alloc (64, _7);
Dense.c:219:36: missed: statement clobbers memory: _10 = aligned_alloc (64, _7);
Dense.c:222:39: missed: statement clobbers memory: _11 = rand ();
Dense.c:222:73: missed: statement clobbers memory: _63 = sqrt (_18);
Dense.c:234:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:235:4: missed: statement clobbers memory: exit (1);
Dense.c:231:4: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.3_29, n_outputs.2_28, 1, activation_function_51(D), _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:228:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.1_27, n_outputs.0_26, 1, activation_function_51(D), _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:241:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Dense.c:241:9: note: ***** Analysis failed with vector mode V4DI
Dense.c:241:9: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:9:27: missed: couldn't vectorize loop
Dense.c:9:27: missed: not vectorized: unsupported outerloop form.
Dense.c:12:20: missed: couldn't vectorize loop
Dense.c:13:21: missed: not vectorized: complicated access pattern.
Dense.c:6:13: note: vectorized 0 loops in function.
Dense.c:16:2: missed: statement clobbers memory: _30 (pretmp_91, _50, 0);
Dense.c:9:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:9:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:24:27: missed: couldn't vectorize loop
Dense.c:24:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:28:20: optimized: loop vectorized using 32 byte vectors
Dense.c:28:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:28:20: optimized: loop vectorized using 16 byte vectors
Dense.c:28:20: missed: couldn't vectorize loop
Dense.c:30:20: missed: not vectorized: no vectype for stmt: _21 = *_20;
 scalar_type: float
Dense.c:20:13: note: vectorized 1 loops in function.
Dense.c:23:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:24:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:24:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:41:28: missed: couldn't vectorize loop
Dense.c:41:28: missed: not vectorized: unsupported outerloop form.
Dense.c:45:21: optimized: loop vectorized using 32 byte vectors
Dense.c:45:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:45:21: optimized: loop vectorized using 16 byte vectors
Dense.c:37:13: note: vectorized 1 loops in function.
Dense.c:37:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:37:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:41:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:172:19: missed: couldn't vectorize loop
Dense.c:172:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:163:19: missed: couldn't vectorize loop
Dense.c:163:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:156:13: note: vectorized 0 loops in function.
Dense.c:180:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:180:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:124:24: missed: couldn't vectorize loop
Dense.c:124:24: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:127:17: missed: couldn't vectorize loop
Dense.c:127:17: missed: not vectorized: number of iterations cannot be computed.
Dense.c:141:24: missed: couldn't vectorize loop
Dense.c:141:24: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:144:17: missed: couldn't vectorize loop
Dense.c:144:17: missed: not vectorized: number of iterations cannot be computed.
Dense.c:109:15: missed: couldn't vectorize loop
Dense.c:109:15: missed: not vectorized: number of iterations cannot be computed.
Dense.c:83:13: note: vectorized 0 loops in function.
Dense.c:86:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:129:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:129:17: note: SLPing BB part
Dense.c:146:17: note: Costing subgraph: 
Dense.c:146:17: note: node 0x83ea3a8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:146:17: note: op template: _49 = (sizetype) j_135;
Dense.c:146:17: note: 	stmt 0 _49 = (sizetype) j_135;
Dense.c:146:17: note: 	stmt 1 _209 = (sizetype) wi_137;
Dense.c:146:17: note: 	children 0x83ea4a8
Dense.c:146:17: note: node (external) 0x83ea4a8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:146:17: note: 	{ j_135, wi_137 }
Dense.c:146:17: note: Cost model analysis: 
Dense.c:146:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:146:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:146:17: missed: not vectorized: vectorization is not profitable.
Dense.c:129:17: note: Costing subgraph: 
Dense.c:129:17: note: node 0x83ea5a8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:129:17: note: op template: _24 = (sizetype) j_134;
Dense.c:129:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:129:17: note: 	stmt 1 _229 = (sizetype) wi_136;
Dense.c:129:17: note: 	children 0x83ea6a8
Dense.c:129:17: note: node (external) 0x83ea6a8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:129:17: note: 	{ j_134, wi_136 }
Dense.c:129:17: note: Cost model analysis: 
Dense.c:129:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:129:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:129:17: missed: not vectorized: vectorization is not profitable.
Dense.c:129:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:129:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:129:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:129:17: note: SLPing BB part
Dense.c:146:17: note: Costing subgraph: 
Dense.c:146:17: note: node 0x83ea5a8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:146:17: note: op template: _49 = (sizetype) j_135;
Dense.c:146:17: note: 	stmt 0 _49 = (sizetype) j_135;
Dense.c:146:17: note: 	stmt 1 _209 = (sizetype) wi_137;
Dense.c:146:17: note: 	children 0x83ea3a8
Dense.c:146:17: note: node (external) 0x83ea3a8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:146:17: note: 	{ j_135, wi_137 }
Dense.c:146:17: note: Cost model analysis: 
Dense.c:146:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:146:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:146:17: missed: not vectorized: vectorization is not profitable.
Dense.c:129:17: note: Costing subgraph: 
Dense.c:129:17: note: node 0x83ea728 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:129:17: note: op template: _24 = (sizetype) j_134;
Dense.c:129:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:129:17: note: 	stmt 1 _229 = (sizetype) wi_136;
Dense.c:129:17: note: 	children 0x83ea628
Dense.c:129:17: note: node (external) 0x83ea628 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:129:17: note: 	{ j_134, wi_136 }
Dense.c:129:17: note: Cost model analysis: 
Dense.c:129:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:129:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:129:17: missed: not vectorized: vectorization is not profitable.
Dense.c:129:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:124:51: note: ***** Analysis failed with vector mode V8QI
Dense.c:124:51: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:124:51: note: ***** Analysis failed with vector mode V4QI
Dense.c:62:15: missed: couldn't vectorize loop
Dense.c:62:15: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:75:11: optimized: loop vectorized using 32 byte vectors
Dense.c:75:11: optimized: loop vectorized using 16 byte vectors
Dense.c:66:11: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:881:10: missed: not vectorized: no vectype for stmt: _56 = MEM[(__m256 * {ref-all})w_ptr_81];
 scalar_type: __m256
Dense.c:54:13: note: vectorized 1 loops in function.
Dense.c:57:2: missed: statement clobbers memory: memcpy (_5, _4, _3);
Dense.c:79:2: missed: statement clobbers memory: _28 (pretmp_162, _67, 0);
Dense.c:54:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:54:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:229:2: missed: statement clobbers memory: free (_1);
Dense.c:230:2: missed: statement clobbers memory: free (_2);
Dense.c:231:2: missed: statement clobbers memory: free (_3);
Dense.c:232:2: missed: statement clobbers memory: free (_4);
Dense.c:233:2: missed: statement clobbers memory: free (dense_7);
Dense.c:234:2: missed: statement clobbers memory: PULSE_DestroyLayer (this_6(D));
Dense.c:235:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:235:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:249:19: missed: couldn't vectorize loop
Dense.c:249:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:239:13: note: vectorized 0 loops in function.
Dense.c:241:47: missed: statement clobbers memory: dense_35 = malloc (40);
Dense.c:243:36: missed: statement clobbers memory: _5 = aligned_alloc (64, _4);
Dense.c:244:38: missed: statement clobbers memory: _6 = aligned_alloc (64, _4);
Dense.c:245:36: missed: statement clobbers memory: _8 = aligned_alloc (64, _7);
Dense.c:246:35: missed: statement clobbers memory: _9 = aligned_alloc (64, _7);
Dense.c:247:36: missed: statement clobbers memory: _10 = aligned_alloc (64, _7);
Dense.c:250:39: missed: statement clobbers memory: _11 = rand ();
Dense.c:250:73: missed: statement clobbers memory: _63 = sqrt (_18);
Dense.c:262:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:263:4: missed: statement clobbers memory: exit (1);
Dense.c:259:4: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.3_29, n_outputs.2_28, 1, activation_function_51(D), _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:256:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.1_27, n_outputs.0_26, 1, activation_function_51(D), _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:269:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Dense.c:269:9: note: ***** Analysis failed with vector mode V4DI
Dense.c:269:9: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:9:27: missed: couldn't vectorize loop
Dense.c:9:27: missed: not vectorized: unsupported outerloop form.
Dense.c:12:20: missed: couldn't vectorize loop
Dense.c:13:21: missed: not vectorized: complicated access pattern.
Dense.c:6:13: note: vectorized 0 loops in function.
Dense.c:16:2: missed: statement clobbers memory: _30 (pretmp_91, _50, 0);
Dense.c:9:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:9:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:24:27: missed: couldn't vectorize loop
Dense.c:24:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:28:20: optimized: loop vectorized using 32 byte vectors
Dense.c:28:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:28:20: optimized: loop vectorized using 16 byte vectors
Dense.c:28:20: missed: couldn't vectorize loop
Dense.c:30:20: missed: not vectorized: no vectype for stmt: _21 = *_20;
 scalar_type: float
Dense.c:20:13: note: vectorized 1 loops in function.
Dense.c:23:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:24:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:24:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:41:28: missed: couldn't vectorize loop
Dense.c:41:28: missed: not vectorized: unsupported outerloop form.
Dense.c:45:21: optimized: loop vectorized using 32 byte vectors
Dense.c:45:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:45:21: optimized: loop vectorized using 16 byte vectors
Dense.c:37:13: note: vectorized 1 loops in function.
Dense.c:37:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:37:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:41:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:217:10: optimized: loop vectorized using 32 byte vectors
Dense.c:217:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:217:10: optimized: loop vectorized using 16 byte vectors
Dense.c:208:10: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_34, _77);
Dense.c:201:10: optimized: loop vectorized using 32 byte vectors
Dense.c:201:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:201:10: optimized: loop vectorized using 16 byte vectors
Dense.c:192:10: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_15, _69);
Dense.c:183:13: note: vectorized 2 loops in function.
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_15, _69);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_19, { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 });
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_34, _77);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_38, { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 });
Dense.c:183:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:183:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:183:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:183:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:183:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:183:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:183:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:183:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:124:24: missed: couldn't vectorize loop
Dense.c:124:24: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:127:17: missed: couldn't vectorize loop
Dense.c:127:17: missed: not vectorized: number of iterations cannot be computed.
Dense.c:141:24: missed: couldn't vectorize loop
Dense.c:141:24: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:144:17: missed: couldn't vectorize loop
Dense.c:144:17: missed: not vectorized: number of iterations cannot be computed.
Dense.c:109:15: missed: couldn't vectorize loop
Dense.c:109:15: missed: not vectorized: number of iterations cannot be computed.
Dense.c:83:13: note: vectorized 0 loops in function.
Dense.c:86:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:129:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:129:17: note: SLPing BB part
Dense.c:146:17: note: Costing subgraph: 
Dense.c:146:17: note: node 0x88de558 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:146:17: note: op template: _49 = (sizetype) j_135;
Dense.c:146:17: note: 	stmt 0 _49 = (sizetype) j_135;
Dense.c:146:17: note: 	stmt 1 _209 = (sizetype) wi_137;
Dense.c:146:17: note: 	children 0x88de658
Dense.c:146:17: note: node (external) 0x88de658 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:146:17: note: 	{ j_135, wi_137 }
Dense.c:146:17: note: Cost model analysis: 
Dense.c:146:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:146:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:146:17: missed: not vectorized: vectorization is not profitable.
Dense.c:129:17: note: Costing subgraph: 
Dense.c:129:17: note: node 0x88de758 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:129:17: note: op template: _24 = (sizetype) j_134;
Dense.c:129:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:129:17: note: 	stmt 1 _229 = (sizetype) wi_136;
Dense.c:129:17: note: 	children 0x88de858
Dense.c:129:17: note: node (external) 0x88de858 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:129:17: note: 	{ j_134, wi_136 }
Dense.c:129:17: note: Cost model analysis: 
Dense.c:129:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:129:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:129:17: missed: not vectorized: vectorization is not profitable.
Dense.c:129:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:129:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:129:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:129:17: note: SLPing BB part
Dense.c:146:17: note: Costing subgraph: 
Dense.c:146:17: note: node 0x88de758 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:146:17: note: op template: _49 = (sizetype) j_135;
Dense.c:146:17: note: 	stmt 0 _49 = (sizetype) j_135;
Dense.c:146:17: note: 	stmt 1 _209 = (sizetype) wi_137;
Dense.c:146:17: note: 	children 0x88de558
Dense.c:146:17: note: node (external) 0x88de558 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:146:17: note: 	{ j_135, wi_137 }
Dense.c:146:17: note: Cost model analysis: 
Dense.c:146:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:146:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:146:17: missed: not vectorized: vectorization is not profitable.
Dense.c:129:17: note: Costing subgraph: 
Dense.c:129:17: note: node 0x88de8d8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:129:17: note: op template: _24 = (sizetype) j_134;
Dense.c:129:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:129:17: note: 	stmt 1 _229 = (sizetype) wi_136;
Dense.c:129:17: note: 	children 0x88de7d8
Dense.c:129:17: note: node (external) 0x88de7d8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:129:17: note: 	{ j_134, wi_136 }
Dense.c:129:17: note: Cost model analysis: 
Dense.c:129:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:129:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:129:17: missed: not vectorized: vectorization is not profitable.
Dense.c:129:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:124:51: note: ***** Analysis failed with vector mode V8QI
Dense.c:124:51: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:124:51: note: ***** Analysis failed with vector mode V4QI
Dense.c:62:15: missed: couldn't vectorize loop
Dense.c:62:15: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:75:11: optimized: loop vectorized using 32 byte vectors
Dense.c:75:11: optimized: loop vectorized using 16 byte vectors
Dense.c:66:11: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:881:10: missed: not vectorized: no vectype for stmt: _56 = MEM[(__m256 * {ref-all})w_ptr_81];
 scalar_type: __m256
Dense.c:54:13: note: vectorized 1 loops in function.
Dense.c:57:2: missed: statement clobbers memory: memcpy (_5, _4, _3);
Dense.c:79:2: missed: statement clobbers memory: _28 (pretmp_162, _67, 0);
Dense.c:54:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:54:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:229:2: missed: statement clobbers memory: free (_1);
Dense.c:230:2: missed: statement clobbers memory: free (_2);
Dense.c:231:2: missed: statement clobbers memory: free (_3);
Dense.c:232:2: missed: statement clobbers memory: free (_4);
Dense.c:233:2: missed: statement clobbers memory: free (dense_7);
Dense.c:234:2: missed: statement clobbers memory: PULSE_DestroyLayer (this_6(D));
Dense.c:235:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:235:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:249:19: missed: couldn't vectorize loop
Dense.c:249:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:239:13: note: vectorized 0 loops in function.
Dense.c:241:47: missed: statement clobbers memory: dense_35 = malloc (40);
Dense.c:243:36: missed: statement clobbers memory: _5 = aligned_alloc (64, _4);
Dense.c:244:38: missed: statement clobbers memory: _6 = aligned_alloc (64, _4);
Dense.c:245:36: missed: statement clobbers memory: _8 = aligned_alloc (64, _7);
Dense.c:246:35: missed: statement clobbers memory: _9 = aligned_alloc (64, _7);
Dense.c:247:36: missed: statement clobbers memory: _10 = aligned_alloc (64, _7);
Dense.c:250:39: missed: statement clobbers memory: _11 = rand ();
Dense.c:250:73: missed: statement clobbers memory: _63 = sqrt (_18);
Dense.c:262:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:263:4: missed: statement clobbers memory: exit (1);
Dense.c:259:4: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.3_29, n_outputs.2_28, 1, activation_function_51(D), _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:256:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.1_27, n_outputs.0_26, 1, activation_function_51(D), _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:269:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Dense.c:269:9: note: ***** Analysis failed with vector mode V4DI
Dense.c:269:9: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:9:27: missed: couldn't vectorize loop
Dense.c:9:27: missed: not vectorized: unsupported outerloop form.
Dense.c:12:20: missed: couldn't vectorize loop
Dense.c:13:21: missed: not vectorized: complicated access pattern.
Dense.c:6:13: note: vectorized 0 loops in function.
Dense.c:16:2: missed: statement clobbers memory: _30 (pretmp_91, _50, 0);
Dense.c:9:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:9:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:24:27: missed: couldn't vectorize loop
Dense.c:24:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:28:20: optimized: loop vectorized using 32 byte vectors
Dense.c:28:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:28:20: optimized: loop vectorized using 16 byte vectors
Dense.c:28:20: missed: couldn't vectorize loop
Dense.c:30:20: missed: not vectorized: no vectype for stmt: _21 = *_20;
 scalar_type: float
Dense.c:20:13: note: vectorized 1 loops in function.
Dense.c:23:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:24:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:24:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:41:28: missed: couldn't vectorize loop
Dense.c:41:28: missed: not vectorized: unsupported outerloop form.
Dense.c:45:21: optimized: loop vectorized using 32 byte vectors
Dense.c:45:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:45:21: optimized: loop vectorized using 16 byte vectors
Dense.c:37:13: note: vectorized 1 loops in function.
Dense.c:37:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:37:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:41:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:189:10: optimized: loop vectorized using 32 byte vectors
Dense.c:189:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:189:10: optimized: loop vectorized using 16 byte vectors
Dense.c:180:10: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_34, _77);
Dense.c:173:10: optimized: loop vectorized using 32 byte vectors
Dense.c:173:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:173:10: optimized: loop vectorized using 16 byte vectors
Dense.c:164:10: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_15, _69);
Dense.c:155:13: note: vectorized 2 loops in function.
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_15, _69);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_19, { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 });
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_34, _77);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_38, { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 });
Dense.c:155:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:155:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:155:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:155:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:155:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:155:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:155:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:155:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:124:24: missed: couldn't vectorize loop
Dense.c:124:24: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:127:17: missed: couldn't vectorize loop
Dense.c:127:17: missed: not vectorized: number of iterations cannot be computed.
Dense.c:141:24: missed: couldn't vectorize loop
Dense.c:141:24: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:144:17: missed: couldn't vectorize loop
Dense.c:144:17: missed: not vectorized: number of iterations cannot be computed.
Dense.c:103:10: optimized: loop vectorized using 32 byte vectors
Dense.c:103:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:103:10: optimized: loop vectorized using 16 byte vectors
Dense.c:91:10: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_13, _102);
Dense.c:83:13: note: vectorized 1 loops in function.
Dense.c:86:2: missed: statement clobbers memory: _1 (_3, _2, 1);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_13, _102);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_15, _103);
Dense.c:129:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:129:17: note: SLPing BB part
Dense.c:146:17: note: Costing subgraph: 
Dense.c:146:17: note: node 0x7524318 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:146:17: note: op template: _66 = (sizetype) j_162;
Dense.c:146:17: note: 	stmt 0 _66 = (sizetype) j_162;
Dense.c:146:17: note: 	stmt 1 _259 = (sizetype) wi_164;
Dense.c:146:17: note: 	children 0x7524418
Dense.c:146:17: note: node (external) 0x7524418 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:146:17: note: 	{ j_162, wi_164 }
Dense.c:146:17: note: Cost model analysis: 
Dense.c:146:17: note: Scalar 3 and vector 4 loop part do not match up, skipping scalar part
Dense.c:146:17: note: Cost model analysis for part in loop 4:
  Vector cost: 36
  Scalar cost: 8
Dense.c:146:17: missed: not vectorized: vectorization is not profitable.
Dense.c:129:17: note: Costing subgraph: 
Dense.c:129:17: note: node 0x7524518 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:129:17: note: op template: _41 = (sizetype) j_161;
Dense.c:129:17: note: 	stmt 0 _41 = (sizetype) j_161;
Dense.c:129:17: note: 	stmt 1 _279 = (sizetype) wi_163;
Dense.c:129:17: note: 	children 0x7524618
Dense.c:129:17: note: node (external) 0x7524618 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:129:17: note: 	{ j_161, wi_163 }
Dense.c:129:17: note: Cost model analysis: 
Dense.c:129:17: note: Scalar 5 and vector 6 loop part do not match up, skipping scalar part
Dense.c:129:17: note: Cost model analysis for part in loop 6:
  Vector cost: 36
  Scalar cost: 8
Dense.c:129:17: missed: not vectorized: vectorization is not profitable.
Dense.c:129:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:129:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:129:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:129:17: note: SLPing BB part
Dense.c:146:17: note: Costing subgraph: 
Dense.c:146:17: note: node 0x7524118 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:146:17: note: op template: _66 = (sizetype) j_162;
Dense.c:146:17: note: 	stmt 0 _66 = (sizetype) j_162;
Dense.c:146:17: note: 	stmt 1 _259 = (sizetype) wi_164;
Dense.c:146:17: note: 	children 0x7524598
Dense.c:146:17: note: node (external) 0x7524598 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:146:17: note: 	{ j_162, wi_164 }
Dense.c:146:17: note: Cost model analysis: 
Dense.c:146:17: note: Scalar 3 and vector 4 loop part do not match up, skipping scalar part
Dense.c:146:17: note: Cost model analysis for part in loop 4:
  Vector cost: 36
  Scalar cost: 8
Dense.c:146:17: missed: not vectorized: vectorization is not profitable.
Dense.c:129:17: note: Costing subgraph: 
Dense.c:129:17: note: node 0x7524098 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:129:17: note: op template: _41 = (sizetype) j_161;
Dense.c:129:17: note: 	stmt 0 _41 = (sizetype) j_161;
Dense.c:129:17: note: 	stmt 1 _279 = (sizetype) wi_163;
Dense.c:129:17: note: 	children 0x7524718
Dense.c:129:17: note: node (external) 0x7524718 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:129:17: note: 	{ j_161, wi_163 }
Dense.c:129:17: note: Cost model analysis: 
Dense.c:129:17: note: Scalar 5 and vector 6 loop part do not match up, skipping scalar part
Dense.c:129:17: note: Cost model analysis for part in loop 6:
  Vector cost: 36
  Scalar cost: 8
Dense.c:129:17: missed: not vectorized: vectorization is not profitable.
Dense.c:129:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:83:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:83:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:124:51: note: ***** Analysis failed with vector mode V4QI
Dense.c:62:15: missed: couldn't vectorize loop
Dense.c:62:15: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:75:11: optimized: loop vectorized using 32 byte vectors
Dense.c:75:11: optimized: loop vectorized using 16 byte vectors
Dense.c:66:11: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:881:10: missed: not vectorized: no vectype for stmt: _56 = MEM[(__m256 * {ref-all})w_ptr_81];
 scalar_type: __m256
Dense.c:54:13: note: vectorized 1 loops in function.
Dense.c:57:2: missed: statement clobbers memory: memcpy (_5, _4, _3);
Dense.c:79:2: missed: statement clobbers memory: _28 (pretmp_162, _67, 0);
Dense.c:54:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:54:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:201:2: missed: statement clobbers memory: free (_1);
Dense.c:202:2: missed: statement clobbers memory: free (_2);
Dense.c:203:2: missed: statement clobbers memory: free (_3);
Dense.c:204:2: missed: statement clobbers memory: free (_4);
Dense.c:205:2: missed: statement clobbers memory: free (dense_7);
Dense.c:206:2: missed: statement clobbers memory: PULSE_DestroyLayer (this_6(D));
Dense.c:207:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:207:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:221:19: missed: couldn't vectorize loop
Dense.c:221:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:211:13: note: vectorized 0 loops in function.
Dense.c:213:47: missed: statement clobbers memory: dense_35 = malloc (40);
Dense.c:215:36: missed: statement clobbers memory: _5 = aligned_alloc (64, _4);
Dense.c:216:38: missed: statement clobbers memory: _6 = aligned_alloc (64, _4);
Dense.c:217:36: missed: statement clobbers memory: _8 = aligned_alloc (64, _7);
Dense.c:218:35: missed: statement clobbers memory: _9 = aligned_alloc (64, _7);
Dense.c:219:36: missed: statement clobbers memory: _10 = aligned_alloc (64, _7);
Dense.c:222:39: missed: statement clobbers memory: _11 = rand ();
Dense.c:222:73: missed: statement clobbers memory: _63 = sqrt (_18);
Dense.c:234:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:235:4: missed: statement clobbers memory: exit (1);
Dense.c:231:4: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.3_29, n_outputs.2_28, 1, activation_function_51(D), _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:228:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.1_27, n_outputs.0_26, 1, activation_function_51(D), _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:241:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Dense.c:241:9: note: ***** Analysis failed with vector mode V4DI
Dense.c:241:9: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:9:27: missed: couldn't vectorize loop
Dense.c:9:27: missed: not vectorized: unsupported outerloop form.
Dense.c:12:20: missed: couldn't vectorize loop
Dense.c:13:21: missed: not vectorized: complicated access pattern.
Dense.c:6:13: note: vectorized 0 loops in function.
Dense.c:16:2: missed: statement clobbers memory: _30 (pretmp_91, _50, 0);
Dense.c:9:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:9:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:24:27: missed: couldn't vectorize loop
Dense.c:24:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:28:20: optimized: loop vectorized using 32 byte vectors
Dense.c:28:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:28:20: optimized: loop vectorized using 16 byte vectors
Dense.c:28:20: missed: couldn't vectorize loop
Dense.c:30:20: missed: not vectorized: no vectype for stmt: _21 = *_20;
 scalar_type: float
Dense.c:20:13: note: vectorized 1 loops in function.
Dense.c:23:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:24:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:24:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:41:28: missed: couldn't vectorize loop
Dense.c:41:28: missed: not vectorized: unsupported outerloop form.
Dense.c:45:21: optimized: loop vectorized using 32 byte vectors
Dense.c:45:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:45:21: optimized: loop vectorized using 16 byte vectors
Dense.c:37:13: note: vectorized 1 loops in function.
Dense.c:37:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:37:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:41:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:170:10: optimized: loop vectorized using 32 byte vectors
Dense.c:170:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:170:10: optimized: loop vectorized using 16 byte vectors
Dense.c:161:10: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_34, _77);
Dense.c:154:10: optimized: loop vectorized using 32 byte vectors
Dense.c:154:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:154:10: optimized: loop vectorized using 16 byte vectors
Dense.c:145:10: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_15, _69);
Dense.c:136:13: note: vectorized 2 loops in function.
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_15, _69);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_19, { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 });
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_34, _77);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_38, { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 });
Dense.c:136:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:136:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:105:24: missed: couldn't vectorize loop
Dense.c:105:24: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:108:17: missed: couldn't vectorize loop
Dense.c:108:17: missed: not vectorized: number of iterations cannot be computed.
Dense.c:122:24: missed: couldn't vectorize loop
Dense.c:122:24: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:125:17: missed: couldn't vectorize loop
Dense.c:125:17: missed: not vectorized: number of iterations cannot be computed.
Dense.c:90:15: missed: couldn't vectorize loop
Dense.c:90:15: missed: not vectorized: number of iterations cannot be computed.
Dense.c:83:13: note: vectorized 0 loops in function.
Dense.c:86:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:110:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:110:17: note: SLPing BB part
Dense.c:127:17: note: Costing subgraph: 
Dense.c:127:17: note: node 0x83e9b58 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:127:17: note: op template: _49 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 0 _49 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 1 _209 = (sizetype) wi_137;
Dense.c:127:17: note: 	children 0x83e9c58
Dense.c:127:17: note: node (external) 0x83e9c58 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:127:17: note: 	{ j_135, wi_137 }
Dense.c:127:17: note: Cost model analysis: 
Dense.c:127:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:127:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:127:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: Costing subgraph: 
Dense.c:110:17: note: node 0x83e9d58 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:110:17: note: op template: _24 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 1 _229 = (sizetype) wi_136;
Dense.c:110:17: note: 	children 0x83e9e58
Dense.c:110:17: note: node (external) 0x83e9e58 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:110:17: note: 	{ j_134, wi_136 }
Dense.c:110:17: note: Cost model analysis: 
Dense.c:110:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:110:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:110:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:110:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:110:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:110:17: note: SLPing BB part
Dense.c:127:17: note: Costing subgraph: 
Dense.c:127:17: note: node 0x83e9d58 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:127:17: note: op template: _49 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 0 _49 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 1 _209 = (sizetype) wi_137;
Dense.c:127:17: note: 	children 0x83e9b58
Dense.c:127:17: note: node (external) 0x83e9b58 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:127:17: note: 	{ j_135, wi_137 }
Dense.c:127:17: note: Cost model analysis: 
Dense.c:127:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:127:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:127:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: Costing subgraph: 
Dense.c:110:17: note: node 0x83e9ed8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:110:17: note: op template: _24 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 1 _229 = (sizetype) wi_136;
Dense.c:110:17: note: 	children 0x83e9dd8
Dense.c:110:17: note: node (external) 0x83e9dd8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:110:17: note: 	{ j_134, wi_136 }
Dense.c:110:17: note: Cost model analysis: 
Dense.c:110:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:110:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:110:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:105:51: note: ***** Analysis failed with vector mode V8QI
Dense.c:105:51: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:105:51: note: ***** Analysis failed with vector mode V4QI
Dense.c:62:15: missed: couldn't vectorize loop
Dense.c:62:15: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:75:11: optimized: loop vectorized using 32 byte vectors
Dense.c:75:11: optimized: loop vectorized using 16 byte vectors
Dense.c:66:11: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:881:10: missed: not vectorized: no vectype for stmt: _56 = MEM[(__m256 * {ref-all})w_ptr_81];
 scalar_type: __m256
Dense.c:54:13: note: vectorized 1 loops in function.
Dense.c:57:2: missed: statement clobbers memory: memcpy (_5, _4, _3);
Dense.c:79:2: missed: statement clobbers memory: _28 (pretmp_162, _67, 0);
Dense.c:54:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:54:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:182:2: missed: statement clobbers memory: free (_1);
Dense.c:183:2: missed: statement clobbers memory: free (_2);
Dense.c:184:2: missed: statement clobbers memory: free (_3);
Dense.c:185:2: missed: statement clobbers memory: free (_4);
Dense.c:186:2: missed: statement clobbers memory: free (dense_7);
Dense.c:187:2: missed: statement clobbers memory: PULSE_DestroyLayer (this_6(D));
Dense.c:188:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:188:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:202:19: missed: couldn't vectorize loop
Dense.c:202:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:192:13: note: vectorized 0 loops in function.
Dense.c:194:47: missed: statement clobbers memory: dense_35 = malloc (40);
Dense.c:196:36: missed: statement clobbers memory: _5 = aligned_alloc (64, _4);
Dense.c:197:38: missed: statement clobbers memory: _6 = aligned_alloc (64, _4);
Dense.c:198:36: missed: statement clobbers memory: _8 = aligned_alloc (64, _7);
Dense.c:199:35: missed: statement clobbers memory: _9 = aligned_alloc (64, _7);
Dense.c:200:36: missed: statement clobbers memory: _10 = aligned_alloc (64, _7);
Dense.c:203:39: missed: statement clobbers memory: _11 = rand ();
Dense.c:203:73: missed: statement clobbers memory: _63 = sqrt (_18);
Dense.c:215:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:216:4: missed: statement clobbers memory: exit (1);
Dense.c:212:4: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.3_29, n_outputs.2_28, 1, activation_function_51(D), _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:209:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.1_27, n_outputs.0_26, 1, activation_function_51(D), _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:222:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Dense.c:222:9: note: ***** Analysis failed with vector mode V4DI
Dense.c:222:9: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:4:18: note: vectorized 0 loops in function.
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_4, inputs_15, _3);
PULSE.c:8:2: missed: statement clobbers memory: _5 (layer_17);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_12, pretmp_26, _9);
PULSE.c:13:28: note: ***** Analysis failed with vector mode V8SI
PULSE.c:13:28: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:22:2: missed: statement clobbers memory: _1 (layer_10(D));
PULSE.c:22:2: missed: statement clobbers memory: _14 (_2);
PULSE.c:22:2: missed: statement clobbers memory: _21 (_15);
PULSE.c:22:2: missed: statement clobbers memory: _28 (_22);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_29);
PULSE.c:26:3: missed: statement clobbers memory: memset (_34, 0, _32);
PULSE.c:26:3: missed: statement clobbers memory: memset (_27, 0, _25);
PULSE.c:26:3: missed: statement clobbers memory: memset (_20, 0, _18);
PULSE.c:26:3: missed: statement clobbers memory: memset (_7, 0, _5);
PULSE.c:28:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:28:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:32:6: note: vectorized 1 loops in function.
PULSE.c:34:8: missed: statement clobbers memory: _1 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_2);
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _9 = rand ();
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8SI
PULSE.c:32:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:61:16: missed: couldn't vectorize loop
PULSE.c:61:16: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:64:17: missed: couldn't vectorize loop
PULSE.c:64:17: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:73:19: missed: couldn't vectorize loop
PULSE.c:73:19: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _67 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:53:22: missed: couldn't vectorize loop
PULSE.c:53:22: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:47:6: note: vectorized 1 loops in function.
PULSE.c:48:1: missed: statement clobbers memory: saved_stack.7_37 = __builtin_stack_save ();
PULSE.c:49:46: missed: statement clobbers memory: _1 = PULSE_GetLossFunctionPtr (loss_function_38(D));
PULSE.c:60:10: missed: statement clobbers memory: random.4_44 = __builtin_alloca_with_align (_4, 32);
PULSE.c:34:8: missed: statement clobbers memory: _59 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_60);
PULSE.c:39:29: missed: statement clobbers memory: _67 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _70 = rand ();
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_96, inputs_91, _95);
PULSE.c:8:2: missed: statement clobbers memory: _97 (layer_92);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_103, _102, _101);
PULSE.c:67:11: missed: statement clobbers memory: loss_53 = PULSE_GetLoss_40 (_17, _16, _12, _11);
PULSE.c:22:2: missed: statement clobbers memory: _84 (output_32);
PULSE.c:22:2: missed: statement clobbers memory: _106 (_85);
PULSE.c:22:2: missed: statement clobbers memory: _113 (_107);
PULSE.c:22:2: missed: statement clobbers memory: _120 (_114);
PULSE.c:22:2: missed: statement clobbers memory: _127 (_121);
PULSE.c:22:2: missed: statement clobbers memory: _134 (_128);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_135);
PULSE.c:26:3: missed: statement clobbers memory: memset (_140, 0, _138);
PULSE.c:26:3: missed: statement clobbers memory: memset (_133, 0, _131);
PULSE.c:26:3: missed: statement clobbers memory: memset (_126, 0, _124);
PULSE.c:26:3: missed: statement clobbers memory: memset (_119, 0, _117);
PULSE.c:26:3: missed: statement clobbers memory: memset (_112, 0, _110);
PULSE.c:26:3: missed: statement clobbers memory: memset (_90, 0, _88);
PULSE.c:75:6: missed: statement clobbers memory: _21 (current_188, args);
PULSE.c:81:4: missed: statement clobbers memory: printf ("Epoch: %d Item: %d Loss: %.10f Batch Loss: %.10f\r", i_185, j_186, _23, _22);
PULSE.c:47:6: missed: statement clobbers memory: __builtin_stack_restore (saved_stack.7_37);
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4DI
PULSE.c:47:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:91:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:91:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:96:8: missed: couldn't vectorize loop
PULSE.c:96:8: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:93:6: note: vectorized 0 loops in function.
PULSE.c:98:3: missed: statement clobbers memory: _1 (current_10);
PULSE.c:101:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:101:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:4:18: note: vectorized 0 loops in function.
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_4, inputs_15, _3);
PULSE.c:8:2: missed: statement clobbers memory: _5 (layer_17);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_12, pretmp_26, _9);
PULSE.c:13:28: note: ***** Analysis failed with vector mode V8SI
PULSE.c:13:28: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:22:2: missed: statement clobbers memory: _1 (layer_10(D));
PULSE.c:22:2: missed: statement clobbers memory: _14 (_2);
PULSE.c:22:2: missed: statement clobbers memory: _21 (_15);
PULSE.c:22:2: missed: statement clobbers memory: _28 (_22);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_29);
PULSE.c:26:3: missed: statement clobbers memory: memset (_34, 0, _32);
PULSE.c:26:3: missed: statement clobbers memory: memset (_27, 0, _25);
PULSE.c:26:3: missed: statement clobbers memory: memset (_20, 0, _18);
PULSE.c:26:3: missed: statement clobbers memory: memset (_7, 0, _5);
PULSE.c:28:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:28:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:32:6: note: vectorized 1 loops in function.
PULSE.c:34:8: missed: statement clobbers memory: _1 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_2);
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _9 = rand ();
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8SI
PULSE.c:32:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:61:16: missed: couldn't vectorize loop
PULSE.c:61:16: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:64:17: missed: couldn't vectorize loop
PULSE.c:64:17: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:73:19: missed: couldn't vectorize loop
PULSE.c:73:19: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:53:22: missed: couldn't vectorize loop
PULSE.c:53:22: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:47:6: note: vectorized 1 loops in function.
PULSE.c:48:1: missed: statement clobbers memory: saved_stack.7_39 = __builtin_stack_save ();
PULSE.c:49:46: missed: statement clobbers memory: _1 = PULSE_GetLossFunctionPtr (loss_function_40(D));
PULSE.c:60:10: missed: statement clobbers memory: random.4_46 = __builtin_alloca_with_align (_4, 32);
PULSE.c:34:8: missed: statement clobbers memory: _61 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_62);
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _72 = rand ();
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_98, inputs_93, _97);
PULSE.c:8:2: missed: statement clobbers memory: _99 (layer_94);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_105, _104, _103);
PULSE.c:67:11: missed: statement clobbers memory: loss_55 = PULSE_GetLoss_42 (_17, _16, _12, _11);
PULSE.c:22:2: missed: statement clobbers memory: _86 (output_34);
PULSE.c:22:2: missed: statement clobbers memory: _108 (_87);
PULSE.c:22:2: missed: statement clobbers memory: _115 (_109);
PULSE.c:22:2: missed: statement clobbers memory: _122 (_116);
PULSE.c:22:2: missed: statement clobbers memory: _129 (_123);
PULSE.c:22:2: missed: statement clobbers memory: _136 (_130);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_137);
PULSE.c:26:3: missed: statement clobbers memory: memset (_142, 0, _140);
PULSE.c:26:3: missed: statement clobbers memory: memset (_135, 0, _133);
PULSE.c:26:3: missed: statement clobbers memory: memset (_128, 0, _126);
PULSE.c:26:3: missed: statement clobbers memory: memset (_121, 0, _119);
PULSE.c:26:3: missed: statement clobbers memory: memset (_114, 0, _112);
PULSE.c:26:3: missed: statement clobbers memory: memset (_92, 0, _90);
PULSE.c:75:6: missed: statement clobbers memory: _21 (current_191, args);
PULSE.c:81:4: missed: statement clobbers memory: printf ("Epoch: %d Item: %d Loss: %.10f Batch Loss: %.10f\r", i_188, j_189, _25, _24);
PULSE.c:47:6: missed: statement clobbers memory: __builtin_stack_restore (saved_stack.7_39);
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4DI
PULSE.c:47:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:91:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:91:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:96:8: missed: couldn't vectorize loop
PULSE.c:96:8: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:93:6: note: vectorized 0 loops in function.
PULSE.c:98:3: missed: statement clobbers memory: _1 (current_10);
PULSE.c:101:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:101:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:4:18: note: vectorized 0 loops in function.
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_4, inputs_15, _3);
PULSE.c:8:2: missed: statement clobbers memory: _5 (layer_17);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_12, pretmp_26, _9);
PULSE.c:13:28: note: ***** Analysis failed with vector mode V8SI
PULSE.c:13:28: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:22:2: missed: statement clobbers memory: _1 (layer_10(D));
PULSE.c:22:2: missed: statement clobbers memory: _14 (_2);
PULSE.c:22:2: missed: statement clobbers memory: _21 (_15);
PULSE.c:22:2: missed: statement clobbers memory: _28 (_22);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_29);
PULSE.c:26:3: missed: statement clobbers memory: memset (_34, 0, _32);
PULSE.c:26:3: missed: statement clobbers memory: memset (_27, 0, _25);
PULSE.c:26:3: missed: statement clobbers memory: memset (_20, 0, _18);
PULSE.c:26:3: missed: statement clobbers memory: memset (_7, 0, _5);
PULSE.c:28:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:28:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:32:6: note: vectorized 1 loops in function.
PULSE.c:34:8: missed: statement clobbers memory: _1 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_2);
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _9 = rand ();
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8SI
PULSE.c:32:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:61:16: missed: couldn't vectorize loop
PULSE.c:61:16: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:64:17: missed: couldn't vectorize loop
PULSE.c:64:17: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:73:19: missed: couldn't vectorize loop
PULSE.c:73:19: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:53:22: missed: couldn't vectorize loop
PULSE.c:53:22: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:47:6: note: vectorized 1 loops in function.
PULSE.c:48:1: missed: statement clobbers memory: saved_stack.7_39 = __builtin_stack_save ();
PULSE.c:49:46: missed: statement clobbers memory: _1 = PULSE_GetLossFunctionPtr (loss_function_40(D));
PULSE.c:60:10: missed: statement clobbers memory: random.4_46 = __builtin_alloca_with_align (_4, 32);
PULSE.c:34:8: missed: statement clobbers memory: _61 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_62);
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _72 = rand ();
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_98, inputs_93, _97);
PULSE.c:8:2: missed: statement clobbers memory: _99 (layer_94);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_105, _104, _103);
PULSE.c:67:11: missed: statement clobbers memory: loss_55 = PULSE_GetLoss_42 (_17, _16, _12, _11);
PULSE.c:22:2: missed: statement clobbers memory: _86 (output_34);
PULSE.c:22:2: missed: statement clobbers memory: _108 (_87);
PULSE.c:22:2: missed: statement clobbers memory: _115 (_109);
PULSE.c:22:2: missed: statement clobbers memory: _122 (_116);
PULSE.c:22:2: missed: statement clobbers memory: _129 (_123);
PULSE.c:22:2: missed: statement clobbers memory: _136 (_130);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_137);
PULSE.c:26:3: missed: statement clobbers memory: memset (_142, 0, _140);
PULSE.c:26:3: missed: statement clobbers memory: memset (_135, 0, _133);
PULSE.c:26:3: missed: statement clobbers memory: memset (_128, 0, _126);
PULSE.c:26:3: missed: statement clobbers memory: memset (_121, 0, _119);
PULSE.c:26:3: missed: statement clobbers memory: memset (_114, 0, _112);
PULSE.c:26:3: missed: statement clobbers memory: memset (_92, 0, _90);
PULSE.c:75:6: missed: statement clobbers memory: _21 (current_191, args);
PULSE.c:81:4: missed: statement clobbers memory: printf ("Epoch: %d Item: %d Loss: %.10f BatchLoss: %.10f\r", i_188, j_189, _25, _24);
PULSE.c:47:6: missed: statement clobbers memory: __builtin_stack_restore (saved_stack.7_39);
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4DI
PULSE.c:47:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:91:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:91:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:96:8: missed: couldn't vectorize loop
PULSE.c:96:8: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:93:6: note: vectorized 0 loops in function.
PULSE.c:98:3: missed: statement clobbers memory: _1 (current_10);
PULSE.c:101:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:101:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:4:18: note: vectorized 0 loops in function.
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_4, inputs_15, _3);
PULSE.c:8:2: missed: statement clobbers memory: _5 (layer_17);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_12, pretmp_26, _9);
PULSE.c:13:28: note: ***** Analysis failed with vector mode V8SI
PULSE.c:13:28: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:22:2: missed: statement clobbers memory: _1 (layer_10(D));
PULSE.c:22:2: missed: statement clobbers memory: _14 (_2);
PULSE.c:22:2: missed: statement clobbers memory: _21 (_15);
PULSE.c:22:2: missed: statement clobbers memory: _28 (_22);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_29);
PULSE.c:26:3: missed: statement clobbers memory: memset (_34, 0, _32);
PULSE.c:26:3: missed: statement clobbers memory: memset (_27, 0, _25);
PULSE.c:26:3: missed: statement clobbers memory: memset (_20, 0, _18);
PULSE.c:26:3: missed: statement clobbers memory: memset (_7, 0, _5);
PULSE.c:28:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:28:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:32:6: note: vectorized 1 loops in function.
PULSE.c:34:8: missed: statement clobbers memory: _1 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_2);
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _9 = rand ();
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8SI
PULSE.c:32:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:61:16: missed: couldn't vectorize loop
PULSE.c:61:16: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:64:17: missed: couldn't vectorize loop
PULSE.c:64:17: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:73:19: missed: couldn't vectorize loop
PULSE.c:73:19: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:53:22: missed: couldn't vectorize loop
PULSE.c:53:22: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:47:6: note: vectorized 1 loops in function.
PULSE.c:48:1: missed: statement clobbers memory: saved_stack.7_39 = __builtin_stack_save ();
PULSE.c:49:46: missed: statement clobbers memory: _1 = PULSE_GetLossFunctionPtr (loss_function_40(D));
PULSE.c:60:10: missed: statement clobbers memory: random.4_46 = __builtin_alloca_with_align (_4, 32);
PULSE.c:34:8: missed: statement clobbers memory: _61 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_62);
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _72 = rand ();
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_98, inputs_93, _97);
PULSE.c:8:2: missed: statement clobbers memory: _99 (layer_94);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_105, _104, _103);
PULSE.c:67:11: missed: statement clobbers memory: loss_55 = PULSE_GetLoss_42 (_17, _16, _12, _11);
PULSE.c:22:2: missed: statement clobbers memory: _86 (output_34);
PULSE.c:22:2: missed: statement clobbers memory: _108 (_87);
PULSE.c:22:2: missed: statement clobbers memory: _115 (_109);
PULSE.c:22:2: missed: statement clobbers memory: _122 (_116);
PULSE.c:22:2: missed: statement clobbers memory: _129 (_123);
PULSE.c:22:2: missed: statement clobbers memory: _136 (_130);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_137);
PULSE.c:26:3: missed: statement clobbers memory: memset (_142, 0, _140);
PULSE.c:26:3: missed: statement clobbers memory: memset (_135, 0, _133);
PULSE.c:26:3: missed: statement clobbers memory: memset (_128, 0, _126);
PULSE.c:26:3: missed: statement clobbers memory: memset (_121, 0, _119);
PULSE.c:26:3: missed: statement clobbers memory: memset (_114, 0, _112);
PULSE.c:26:3: missed: statement clobbers memory: memset (_92, 0, _90);
PULSE.c:75:6: missed: statement clobbers memory: _21 (current_191, args);
PULSE.c:81:4: missed: statement clobbers memory: printf ("Epoch: %d | Item: %d | Loss: %.10f | Batch Loss: %.10f\r", i_188, j_189, _25, _24);
PULSE.c:47:6: missed: statement clobbers memory: __builtin_stack_restore (saved_stack.7_39);
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4DI
PULSE.c:47:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:91:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:91:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:96:8: missed: couldn't vectorize loop
PULSE.c:96:8: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:93:6: note: vectorized 0 loops in function.
PULSE.c:98:3: missed: statement clobbers memory: _1 (current_10);
PULSE.c:101:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:101:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Layer.c:7:34: missed: statement clobbers memory: _3 = aligned_alloc (64, _2);
Layer.c:8:35: missed: statement clobbers memory: _6 = aligned_alloc (64, _5);
Layer.c:9:34: missed: statement clobbers memory: _7 = aligned_alloc (64, _5);
Layer.c:14:19: missed: statement clobbers memory: _8 = PULSE_GetActivationFunctionPtr (activation_function_18(D));
Layer.c:19:9: note: ***** Analysis succeeded with vector mode V8SI
Layer.c:19:9: note: SLPing BB part
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x50157c8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 0 MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 1 MEM <unsigned int> [(struct PULSE_Layer *)&<retval> + 4B] = optimization_type_17(D);
Layer.c:19:9: note: 	children 0x5015848
Layer.c:19:9: note: node (external) 0x5015848 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ type_16(D), optimization_type_17(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x50158c8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 0 <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 1 <retval>.n_outputs = n_outputs_12(D);
Layer.c:19:9: note: 	children 0x5015948
Layer.c:19:9: note: node (external) 0x5015948 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x5015a48 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 0 <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 1 <retval>.outputs = _6;
Layer.c:19:9: note: 	children 0x5015ac8
Layer.c:19:9: note: node (external) 0x5015ac8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	stmt 0 _3 = aligned_alloc (64, _2);
Layer.c:19:9: note: 	stmt 1 _6 = aligned_alloc (64, _5);
Layer.c:19:9: note: 	children 0x5015b48 0x5015bc8
Layer.c:19:9: note: node (constant) 0x5015b48 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 64, 64 }
Layer.c:19:9: note: node 0x5015bc8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: patt_40 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 0 patt_40 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 1 patt_41 = n_outputs_12(D) w* 4;
Layer.c:19:9: note: 	children 0x5015c48 0x5015cc8
Layer.c:19:9: note: node (external) 0x5015c48 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: node (constant) 0x5015cc8 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ 4, 4 }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x5015dc8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: op template: <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 0 <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 1 <retval>.back = back_21(D);
Layer.c:19:9: note: 	stmt 2 <retval>.fix = fix_22(D);
Layer.c:19:9: note: 	stmt 3 <retval>.destroy = destroy_23(D);
Layer.c:19:9: note: 	children 0x5015e48
Layer.c:19:9: note: node (external) 0x5015e48 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: 	{ feed_20(D), back_21(D), fix_22(D), destroy_23(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 64
  Scalar cost: 64
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x5015f48 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 0 <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 1 <retval>.child = 0B;
Layer.c:19:9: note: 	children 0x5015fc8
Layer.c:19:9: note: node (constant) 0x5015fc8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ 0B, 0B }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Basic block will be vectorized using SLP
Layer.c:19:9: optimized: basic block part vectorized using 8 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x50157c8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 0 MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 1 MEM <unsigned int> [(struct PULSE_Layer *)&<retval> + 4B] = optimization_type_17(D);
Layer.c:19:9: note: 	children 0x5015848
Layer.c:19:9: note: node (external) 0x5015848 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ type_16(D), optimization_type_17(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: vect_is_simple_use: operand optimization_type_17(D), type of def: external
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>]
Layer.c:19:9: note: created &MEM <unsigned int> [(struct PULSE_Layer *)&<retval>]
Layer.c:19:9: note: add new stmt: MEM <vector(2) unsigned int> [(struct PULSE_Layer *)&<retval>] = _42;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 8 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x50158c8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 0 <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 1 <retval>.n_outputs = n_outputs_12(D);
Layer.c:19:9: note: 	children 0x5015948
Layer.c:19:9: note: node (external) 0x5015948 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: vect_is_simple_use: operand n_outputs_12(D), type of def: external
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: <retval>.n_inputs
Layer.c:19:9: note: created &<retval>.n_inputs
Layer.c:19:9: note: add new stmt: MEM <vector(2) unsigned int> [(unsigned int *)&<retval> + 96B] = _44;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 16 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x5015a48 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 0 <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 1 <retval>.outputs = _6;
Layer.c:19:9: note: 	children 0x5015ac8
Layer.c:19:9: note: node (external) 0x5015ac8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	stmt 0 _3 = aligned_alloc (64, _2);
Layer.c:19:9: note: 	stmt 1 _6 = aligned_alloc (64, _5);
Layer.c:19:9: note: 	children 0x5015b48 0x5015bc8
Layer.c:19:9: note: node (constant) 0x5015b48 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 64, 64 }
Layer.c:19:9: note: node 0x5015bc8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: patt_40 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 0 patt_40 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 1 patt_41 = n_outputs_12(D) w* 4;
Layer.c:19:9: note: 	children 0x5015c48 0x5015cc8
Layer.c:19:9: note: node (external) 0x5015c48 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: node (constant) 0x5015cc8 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ 4, 4 }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.inputs = _3;
Layer.c:19:9: note: vect_is_simple_use: operand aligned_alloc (64, _5), type of def: internal
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.inputs
Layer.c:19:9: note: created &<retval>.inputs
Layer.c:19:9: note: add new stmt: MEM <vector(2) long unsigned int> [(float * *)&<retval> + 8B] = _48;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 32 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x5015dc8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: op template: <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 0 <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 1 <retval>.back = back_21(D);
Layer.c:19:9: note: 	stmt 2 <retval>.fix = fix_22(D);
Layer.c:19:9: note: 	stmt 3 <retval>.destroy = destroy_23(D);
Layer.c:19:9: note: 	children 0x5015e48
Layer.c:19:9: note: node (external) 0x5015e48 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: 	{ feed_20(D), back_21(D), fix_22(D), destroy_23(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.feed = feed_20(D);
Layer.c:19:9: note: vect_is_simple_use: operand back_21(D), type of def: external
Layer.c:19:9: note: vect_is_simple_use: operand fix_22(D), type of def: external
Layer.c:19:9: note: vect_is_simple_use: operand destroy_23(D), type of def: external
Layer.c:19:9: note: conflicting alias set types.
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(4) long unsigned int  vectorizing a pointer ref: <retval>.feed
Layer.c:19:9: note: created &<retval>.feed
Layer.c:19:9: note: add new stmt: MEM <vector(4) long unsigned int> [(void *)&<retval> + 32B] = _54;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 16 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x5015f48 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 0 <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 1 <retval>.child = 0B;
Layer.c:19:9: note: 	children 0x5015fc8
Layer.c:19:9: note: node (constant) 0x5015fc8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ 0B, 0B }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.parent = 0B;
Layer.c:19:9: note: vect_is_simple_use: operand 0B, type of def: constant
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.parent
Layer.c:19:9: note: created &<retval>.parent
Layer.c:19:9: note: add new stmt: MEM <vector(2) long unsigned int> [(struct PULSE_Layer * *)&<retval> + 72B] = { 0, 0 };
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: note: ***** The result for vector mode V32QI would be the same
Layer.c:24:2: missed: statement clobbers memory: free (_1);
Layer.c:25:2: missed: statement clobbers memory: free (_2);
Layer.c:26:2: missed: statement clobbers memory: free (_3);
Layer.c:27:1: note: ***** Analysis failed with vector mode V4DI
Layer.c:27:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:9:27: missed: couldn't vectorize loop
Dense.c:9:27: missed: not vectorized: unsupported outerloop form.
Dense.c:12:20: missed: couldn't vectorize loop
Dense.c:13:21: missed: not vectorized: complicated access pattern.
Dense.c:6:13: note: vectorized 0 loops in function.
Dense.c:16:2: missed: statement clobbers memory: _30 (pretmp_91, _50, 0);
Dense.c:9:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:9:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:24:27: missed: couldn't vectorize loop
Dense.c:24:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:28:20: optimized: loop vectorized using 32 byte vectors
Dense.c:28:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:28:20: optimized: loop vectorized using 16 byte vectors
Dense.c:28:20: missed: couldn't vectorize loop
Dense.c:30:20: missed: not vectorized: no vectype for stmt: _21 = *_20;
 scalar_type: float
Dense.c:20:13: note: vectorized 1 loops in function.
Dense.c:23:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:24:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:24:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:41:28: missed: couldn't vectorize loop
Dense.c:41:28: missed: not vectorized: unsupported outerloop form.
Dense.c:45:21: optimized: loop vectorized using 32 byte vectors
Dense.c:45:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:45:21: optimized: loop vectorized using 16 byte vectors
Dense.c:37:13: note: vectorized 1 loops in function.
Dense.c:37:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:37:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:41:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:170:10: optimized: loop vectorized using 32 byte vectors
Dense.c:170:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:170:10: optimized: loop vectorized using 16 byte vectors
Dense.c:161:10: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_34, _77);
Dense.c:154:10: optimized: loop vectorized using 32 byte vectors
Dense.c:154:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:154:10: optimized: loop vectorized using 16 byte vectors
Dense.c:145:10: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_15, _69);
Dense.c:136:13: note: vectorized 2 loops in function.
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_15, _69);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_19, { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 });
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_34, _77);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_38, { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 });
Dense.c:136:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:136:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:105:24: missed: couldn't vectorize loop
Dense.c:105:24: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:108:17: missed: couldn't vectorize loop
Dense.c:108:17: missed: not vectorized: number of iterations cannot be computed.
Dense.c:122:24: missed: couldn't vectorize loop
Dense.c:122:24: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:125:17: missed: couldn't vectorize loop
Dense.c:125:17: missed: not vectorized: number of iterations cannot be computed.
Dense.c:90:15: missed: couldn't vectorize loop
Dense.c:90:15: missed: not vectorized: number of iterations cannot be computed.
Dense.c:83:13: note: vectorized 0 loops in function.
Dense.c:86:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:110:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:110:17: note: SLPing BB part
Dense.c:127:17: note: Costing subgraph: 
Dense.c:127:17: note: node 0x807b0f8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:127:17: note: op template: _49 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 0 _49 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 1 _209 = (sizetype) wi_137;
Dense.c:127:17: note: 	children 0x807b1f8
Dense.c:127:17: note: node (external) 0x807b1f8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:127:17: note: 	{ j_135, wi_137 }
Dense.c:127:17: note: Cost model analysis: 
Dense.c:127:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:127:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:127:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: Costing subgraph: 
Dense.c:110:17: note: node 0x807b2f8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:110:17: note: op template: _24 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 1 _229 = (sizetype) wi_136;
Dense.c:110:17: note: 	children 0x807b3f8
Dense.c:110:17: note: node (external) 0x807b3f8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:110:17: note: 	{ j_134, wi_136 }
Dense.c:110:17: note: Cost model analysis: 
Dense.c:110:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:110:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:110:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:110:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:110:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:110:17: note: SLPing BB part
Dense.c:127:17: note: Costing subgraph: 
Dense.c:127:17: note: node 0x807b2f8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:127:17: note: op template: _49 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 0 _49 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 1 _209 = (sizetype) wi_137;
Dense.c:127:17: note: 	children 0x807b0f8
Dense.c:127:17: note: node (external) 0x807b0f8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:127:17: note: 	{ j_135, wi_137 }
Dense.c:127:17: note: Cost model analysis: 
Dense.c:127:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:127:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:127:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: Costing subgraph: 
Dense.c:110:17: note: node 0x807b478 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:110:17: note: op template: _24 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 1 _229 = (sizetype) wi_136;
Dense.c:110:17: note: 	children 0x807b378
Dense.c:110:17: note: node (external) 0x807b378 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:110:17: note: 	{ j_134, wi_136 }
Dense.c:110:17: note: Cost model analysis: 
Dense.c:110:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:110:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:110:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:105:51: note: ***** Analysis failed with vector mode V8QI
Dense.c:105:51: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:105:51: note: ***** Analysis failed with vector mode V4QI
Dense.c:62:15: missed: couldn't vectorize loop
Dense.c:62:15: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:75:11: optimized: loop vectorized using 32 byte vectors
Dense.c:75:11: optimized: loop vectorized using 16 byte vectors
Dense.c:66:11: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:881:10: missed: not vectorized: no vectype for stmt: _56 = MEM[(__m256 * {ref-all})w_ptr_81];
 scalar_type: __m256
Dense.c:54:13: note: vectorized 1 loops in function.
Dense.c:57:2: missed: statement clobbers memory: memcpy (_5, _4, _3);
Dense.c:79:2: missed: statement clobbers memory: _28 (pretmp_162, _67, 0);
Dense.c:54:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:54:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:182:2: missed: statement clobbers memory: free (_1);
Dense.c:183:2: missed: statement clobbers memory: free (_2);
Dense.c:184:2: missed: statement clobbers memory: free (_3);
Dense.c:185:2: missed: statement clobbers memory: free (_4);
Dense.c:186:2: missed: statement clobbers memory: free (dense_7);
Dense.c:187:2: missed: statement clobbers memory: PULSE_DestroyLayer (this_6(D));
Dense.c:188:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:188:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:202:19: missed: couldn't vectorize loop
Dense.c:202:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:192:13: note: vectorized 0 loops in function.
Dense.c:194:47: missed: statement clobbers memory: dense_35 = malloc (40);
Dense.c:196:36: missed: statement clobbers memory: _5 = aligned_alloc (64, _4);
Dense.c:197:38: missed: statement clobbers memory: _6 = aligned_alloc (64, _4);
Dense.c:198:36: missed: statement clobbers memory: _8 = aligned_alloc (64, _7);
Dense.c:199:35: missed: statement clobbers memory: _9 = aligned_alloc (64, _7);
Dense.c:200:36: missed: statement clobbers memory: _10 = aligned_alloc (64, _7);
Dense.c:203:39: missed: statement clobbers memory: _11 = rand ();
Dense.c:203:73: missed: statement clobbers memory: _63 = sqrt (_18);
Dense.c:215:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:216:4: missed: statement clobbers memory: exit (1);
Dense.c:212:4: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.3_29, n_outputs.2_28, 1, activation_function_51(D), _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:209:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.1_27, n_outputs.0_26, 1, activation_function_51(D), _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:222:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Dense.c:222:9: note: ***** Analysis failed with vector mode V4DI
Dense.c:222:9: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Activations.c:17:19: optimized: loop vectorized using 32 byte vectors
Activations.c:17:19: optimized: loop vectorized using 16 byte vectors
Activations.c:17:19: optimized: loop vectorized using 32 byte vectors
Activations.c:17:19: optimized: loop vectorized using 16 byte vectors
Activations.c:14:13: note: vectorized 2 loops in function.
Activations.c:14:13: note: ***** Analysis failed with vector mode V8SF
Activations.c:14:13: note: ***** The result for vector mode V32QI would be the same
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V16QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V16QI
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V8QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V8QI
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V4QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V4QI
Activations.c:28:19: missed: couldn't vectorize loop
Activations.c:28:19: missed: not vectorized: unsupported control flow in loop.
Activations.c:28:19: optimized: loop vectorized using 32 byte vectors
Activations.c:28:19: optimized: loop vectorized using 16 byte vectors
Activations.c:25:13: note: vectorized 1 loops in function.
Activations.c:25:13: note: ***** Analysis failed with vector mode V8SF
Activations.c:25:13: note: ***** The result for vector mode V32QI would be the same
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V16QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V16QI
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V8QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V8QI
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V4QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V4QI
Activations.c:38:1: note: ***** Analysis failed with vector mode VOID
Activations.c:5:19: missed: couldn't vectorize loop
Activations.c:9:21: missed: statement clobbers memory: _36 = expf (_18);
Activations.c:5:19: missed: couldn't vectorize loop
Activations.c:9:21: missed: statement clobbers memory: _12 = expf (_11);
Activations.c:3:13: note: vectorized 0 loops in function.
Activations.c:9:21: missed: statement clobbers memory: _12 = expf (_11);
Activations.c:9:21: missed: statement clobbers memory: _36 = expf (_18);
Activations.c:11:1: note: ***** Analysis failed with vector mode V8SF
Activations.c:11:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Activations.c:44:2: note: ***** Analysis failed with vector mode VOID
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:4:18: note: vectorized 0 loops in function.
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_4, inputs_15, _3);
PULSE.c:8:2: missed: statement clobbers memory: _5 (layer_17);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_12, pretmp_26, _9);
PULSE.c:13:28: note: ***** Analysis failed with vector mode V8SI
PULSE.c:13:28: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:22:2: missed: statement clobbers memory: _1 (layer_10(D));
PULSE.c:22:2: missed: statement clobbers memory: _14 (_2);
PULSE.c:22:2: missed: statement clobbers memory: _21 (_15);
PULSE.c:22:2: missed: statement clobbers memory: _28 (_22);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_29);
PULSE.c:26:3: missed: statement clobbers memory: memset (_34, 0, _32);
PULSE.c:26:3: missed: statement clobbers memory: memset (_27, 0, _25);
PULSE.c:26:3: missed: statement clobbers memory: memset (_20, 0, _18);
PULSE.c:26:3: missed: statement clobbers memory: memset (_7, 0, _5);
PULSE.c:28:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:28:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:32:6: note: vectorized 1 loops in function.
PULSE.c:34:8: missed: statement clobbers memory: _1 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_2);
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _9 = rand ();
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8SI
PULSE.c:32:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:61:16: missed: couldn't vectorize loop
PULSE.c:61:16: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:64:17: missed: couldn't vectorize loop
PULSE.c:64:17: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:73:19: missed: couldn't vectorize loop
PULSE.c:73:19: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:53:22: missed: couldn't vectorize loop
PULSE.c:53:22: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:47:6: note: vectorized 1 loops in function.
PULSE.c:48:1: missed: statement clobbers memory: saved_stack.7_39 = __builtin_stack_save ();
PULSE.c:49:46: missed: statement clobbers memory: _1 = PULSE_GetLossFunctionPtr (loss_function_40(D));
PULSE.c:60:10: missed: statement clobbers memory: random.4_46 = __builtin_alloca_with_align (_4, 32);
PULSE.c:34:8: missed: statement clobbers memory: _61 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_62);
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _72 = rand ();
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_98, inputs_93, _97);
PULSE.c:8:2: missed: statement clobbers memory: _99 (layer_94);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_105, _104, _103);
PULSE.c:67:11: missed: statement clobbers memory: loss_55 = PULSE_GetLoss_42 (_17, _16, _12, _11);
PULSE.c:22:2: missed: statement clobbers memory: _86 (output_34);
PULSE.c:22:2: missed: statement clobbers memory: _108 (_87);
PULSE.c:22:2: missed: statement clobbers memory: _115 (_109);
PULSE.c:22:2: missed: statement clobbers memory: _122 (_116);
PULSE.c:22:2: missed: statement clobbers memory: _129 (_123);
PULSE.c:22:2: missed: statement clobbers memory: _136 (_130);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_137);
PULSE.c:26:3: missed: statement clobbers memory: memset (_142, 0, _140);
PULSE.c:26:3: missed: statement clobbers memory: memset (_135, 0, _133);
PULSE.c:26:3: missed: statement clobbers memory: memset (_128, 0, _126);
PULSE.c:26:3: missed: statement clobbers memory: memset (_121, 0, _119);
PULSE.c:26:3: missed: statement clobbers memory: memset (_114, 0, _112);
PULSE.c:26:3: missed: statement clobbers memory: memset (_92, 0, _90);
PULSE.c:75:6: missed: statement clobbers memory: _21 (current_191, args);
PULSE.c:81:4: missed: statement clobbers memory: printf ("Epoch: %d | Item: %d | Loss: %.10f | Batch Loss: %.10f\r", i_188, j_189, _25, _24);
PULSE.c:47:6: missed: statement clobbers memory: __builtin_stack_restore (saved_stack.7_39);
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4DI
PULSE.c:47:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:91:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:91:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:96:8: missed: couldn't vectorize loop
PULSE.c:96:8: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:93:6: note: vectorized 0 loops in function.
PULSE.c:98:3: missed: statement clobbers memory: _1 (current_10);
PULSE.c:101:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:101:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Loss.c:15:19: optimized: loop vectorized using 32 byte vectors
Loss.c:15:19: optimized:  loop versioned for vectorization because of possible aliasing
Loss.c:15:19: optimized: loop vectorized using 16 byte vectors
Loss.c:12:23: note: vectorized 1 loops in function.
Loss.c:12:23: note: ***** Analysis failed with vector mode V8SF
Loss.c:12:23: note: ***** The result for vector mode V32QI would be the same
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V16QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V16QI
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V8QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V8QI
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V4QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V4QI
Loss.c:7:19: missed: couldn't vectorize loop
Loss.c:8:38: missed: not vectorized: unsupported use in stmt.
Loss.c:4:23: note: vectorized 0 loops in function.
Loss.c:9:13: note: ***** Analysis failed with vector mode V8SF
Loss.c:9:13: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Loss.c:23:2: note: ***** Analysis failed with vector mode VOID
Layer.c:7:34: missed: statement clobbers memory: _3 = aligned_alloc (64, _2);
Layer.c:8:35: missed: statement clobbers memory: _6 = aligned_alloc (64, _5);
Layer.c:9:34: missed: statement clobbers memory: _7 = aligned_alloc (64, _5);
Layer.c:14:19: missed: statement clobbers memory: _8 = PULSE_GetActivationFunctionPtr (activation_function_18(D));
Layer.c:19:9: note: ***** Analysis succeeded with vector mode V8SI
Layer.c:19:9: note: SLPing BB part
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x3a8a7c8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 0 MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 1 MEM <unsigned int> [(struct PULSE_Layer *)&<retval> + 4B] = optimization_type_17(D);
Layer.c:19:9: note: 	children 0x3a8a848
Layer.c:19:9: note: node (external) 0x3a8a848 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ type_16(D), optimization_type_17(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x3a8a8c8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 0 <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 1 <retval>.n_outputs = n_outputs_12(D);
Layer.c:19:9: note: 	children 0x3a8a948
Layer.c:19:9: note: node (external) 0x3a8a948 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x3a8aa48 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 0 <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 1 <retval>.outputs = _6;
Layer.c:19:9: note: 	children 0x3a8aac8
Layer.c:19:9: note: node (external) 0x3a8aac8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	stmt 0 _3 = aligned_alloc (64, _2);
Layer.c:19:9: note: 	stmt 1 _6 = aligned_alloc (64, _5);
Layer.c:19:9: note: 	children 0x3a8ab48 0x3a8abc8
Layer.c:19:9: note: node (constant) 0x3a8ab48 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 64, 64 }
Layer.c:19:9: note: node 0x3a8abc8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: patt_40 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 0 patt_40 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 1 patt_41 = n_outputs_12(D) w* 4;
Layer.c:19:9: note: 	children 0x3a8ac48 0x3a8acc8
Layer.c:19:9: note: node (external) 0x3a8ac48 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: node (constant) 0x3a8acc8 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ 4, 4 }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x3a8adc8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: op template: <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 0 <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 1 <retval>.back = back_21(D);
Layer.c:19:9: note: 	stmt 2 <retval>.fix = fix_22(D);
Layer.c:19:9: note: 	stmt 3 <retval>.destroy = destroy_23(D);
Layer.c:19:9: note: 	children 0x3a8ae48
Layer.c:19:9: note: node (external) 0x3a8ae48 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: 	{ feed_20(D), back_21(D), fix_22(D), destroy_23(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 64
  Scalar cost: 64
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x3a8af48 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 0 <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 1 <retval>.child = 0B;
Layer.c:19:9: note: 	children 0x3a8afc8
Layer.c:19:9: note: node (constant) 0x3a8afc8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ 0B, 0B }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Basic block will be vectorized using SLP
Layer.c:19:9: optimized: basic block part vectorized using 8 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x3a8a7c8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 0 MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 1 MEM <unsigned int> [(struct PULSE_Layer *)&<retval> + 4B] = optimization_type_17(D);
Layer.c:19:9: note: 	children 0x3a8a848
Layer.c:19:9: note: node (external) 0x3a8a848 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ type_16(D), optimization_type_17(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: vect_is_simple_use: operand optimization_type_17(D), type of def: external
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>]
Layer.c:19:9: note: created &MEM <unsigned int> [(struct PULSE_Layer *)&<retval>]
Layer.c:19:9: note: add new stmt: MEM <vector(2) unsigned int> [(struct PULSE_Layer *)&<retval>] = _42;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 8 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x3a8a8c8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 0 <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 1 <retval>.n_outputs = n_outputs_12(D);
Layer.c:19:9: note: 	children 0x3a8a948
Layer.c:19:9: note: node (external) 0x3a8a948 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: vect_is_simple_use: operand n_outputs_12(D), type of def: external
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: <retval>.n_inputs
Layer.c:19:9: note: created &<retval>.n_inputs
Layer.c:19:9: note: add new stmt: MEM <vector(2) unsigned int> [(unsigned int *)&<retval> + 96B] = _44;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 16 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x3a8aa48 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 0 <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 1 <retval>.outputs = _6;
Layer.c:19:9: note: 	children 0x3a8aac8
Layer.c:19:9: note: node (external) 0x3a8aac8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	stmt 0 _3 = aligned_alloc (64, _2);
Layer.c:19:9: note: 	stmt 1 _6 = aligned_alloc (64, _5);
Layer.c:19:9: note: 	children 0x3a8ab48 0x3a8abc8
Layer.c:19:9: note: node (constant) 0x3a8ab48 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 64, 64 }
Layer.c:19:9: note: node 0x3a8abc8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: patt_40 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 0 patt_40 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 1 patt_41 = n_outputs_12(D) w* 4;
Layer.c:19:9: note: 	children 0x3a8ac48 0x3a8acc8
Layer.c:19:9: note: node (external) 0x3a8ac48 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: node (constant) 0x3a8acc8 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ 4, 4 }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.inputs = _3;
Layer.c:19:9: note: vect_is_simple_use: operand aligned_alloc (64, _5), type of def: internal
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.inputs
Layer.c:19:9: note: created &<retval>.inputs
Layer.c:19:9: note: add new stmt: MEM <vector(2) long unsigned int> [(float * *)&<retval> + 8B] = _48;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 32 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x3a8adc8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: op template: <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 0 <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 1 <retval>.back = back_21(D);
Layer.c:19:9: note: 	stmt 2 <retval>.fix = fix_22(D);
Layer.c:19:9: note: 	stmt 3 <retval>.destroy = destroy_23(D);
Layer.c:19:9: note: 	children 0x3a8ae48
Layer.c:19:9: note: node (external) 0x3a8ae48 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: 	{ feed_20(D), back_21(D), fix_22(D), destroy_23(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.feed = feed_20(D);
Layer.c:19:9: note: vect_is_simple_use: operand back_21(D), type of def: external
Layer.c:19:9: note: vect_is_simple_use: operand fix_22(D), type of def: external
Layer.c:19:9: note: vect_is_simple_use: operand destroy_23(D), type of def: external
Layer.c:19:9: note: conflicting alias set types.
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(4) long unsigned int  vectorizing a pointer ref: <retval>.feed
Layer.c:19:9: note: created &<retval>.feed
Layer.c:19:9: note: add new stmt: MEM <vector(4) long unsigned int> [(void *)&<retval> + 32B] = _54;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 16 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x3a8af48 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 0 <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 1 <retval>.child = 0B;
Layer.c:19:9: note: 	children 0x3a8afc8
Layer.c:19:9: note: node (constant) 0x3a8afc8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ 0B, 0B }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.parent = 0B;
Layer.c:19:9: note: vect_is_simple_use: operand 0B, type of def: constant
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.parent
Layer.c:19:9: note: created &<retval>.parent
Layer.c:19:9: note: add new stmt: MEM <vector(2) long unsigned int> [(struct PULSE_Layer * *)&<retval> + 72B] = { 0, 0 };
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: note: ***** The result for vector mode V32QI would be the same
Layer.c:24:2: missed: statement clobbers memory: free (_1);
Layer.c:25:2: missed: statement clobbers memory: free (_2);
Layer.c:26:2: missed: statement clobbers memory: free (_3);
Layer.c:27:1: note: ***** Analysis failed with vector mode V4DI
Layer.c:27:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:9:27: missed: couldn't vectorize loop
Dense.c:9:27: missed: not vectorized: unsupported outerloop form.
Dense.c:12:20: missed: couldn't vectorize loop
Dense.c:13:21: missed: not vectorized: complicated access pattern.
Dense.c:6:13: note: vectorized 0 loops in function.
Dense.c:16:2: missed: statement clobbers memory: _30 (pretmp_91, _50, 0);
Dense.c:9:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:9:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:24:27: missed: couldn't vectorize loop
Dense.c:24:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:28:20: optimized: loop vectorized using 32 byte vectors
Dense.c:28:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:28:20: optimized: loop vectorized using 16 byte vectors
Dense.c:28:20: missed: couldn't vectorize loop
Dense.c:30:20: missed: not vectorized: no vectype for stmt: _21 = *_20;
 scalar_type: float
Dense.c:20:13: note: vectorized 1 loops in function.
Dense.c:23:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:24:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:24:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:41:28: missed: couldn't vectorize loop
Dense.c:41:28: missed: not vectorized: unsupported outerloop form.
Dense.c:45:21: optimized: loop vectorized using 32 byte vectors
Dense.c:45:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:45:21: optimized: loop vectorized using 16 byte vectors
Dense.c:37:13: note: vectorized 1 loops in function.
Dense.c:37:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:37:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:41:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:170:10: optimized: loop vectorized using 32 byte vectors
Dense.c:170:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:170:10: optimized: loop vectorized using 16 byte vectors
Dense.c:161:10: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_34, _77);
Dense.c:154:10: optimized: loop vectorized using 32 byte vectors
Dense.c:154:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:154:10: optimized: loop vectorized using 16 byte vectors
Dense.c:145:10: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_15, _69);
Dense.c:136:13: note: vectorized 2 loops in function.
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_15, _69);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_19, { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 });
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_34, _77);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_38, { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 });
Dense.c:136:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:136:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:105:24: missed: couldn't vectorize loop
Dense.c:105:24: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:108:17: missed: couldn't vectorize loop
Dense.c:108:17: missed: not vectorized: number of iterations cannot be computed.
Dense.c:122:24: missed: couldn't vectorize loop
Dense.c:122:24: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:125:17: missed: couldn't vectorize loop
Dense.c:125:17: missed: not vectorized: number of iterations cannot be computed.
Dense.c:90:15: missed: couldn't vectorize loop
Dense.c:90:15: missed: not vectorized: number of iterations cannot be computed.
Dense.c:83:13: note: vectorized 0 loops in function.
Dense.c:86:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:110:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:110:17: note: SLPing BB part
Dense.c:127:17: note: Costing subgraph: 
Dense.c:127:17: note: node 0x784e1f8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:127:17: note: op template: _49 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 0 _49 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 1 _209 = (sizetype) wi_137;
Dense.c:127:17: note: 	children 0x784e2f8
Dense.c:127:17: note: node (external) 0x784e2f8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:127:17: note: 	{ j_135, wi_137 }
Dense.c:127:17: note: Cost model analysis: 
Dense.c:127:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:127:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:127:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: Costing subgraph: 
Dense.c:110:17: note: node 0x784e3f8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:110:17: note: op template: _24 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 1 _229 = (sizetype) wi_136;
Dense.c:110:17: note: 	children 0x784e4f8
Dense.c:110:17: note: node (external) 0x784e4f8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:110:17: note: 	{ j_134, wi_136 }
Dense.c:110:17: note: Cost model analysis: 
Dense.c:110:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:110:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:110:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:110:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:110:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:110:17: note: SLPing BB part
Dense.c:127:17: note: Costing subgraph: 
Dense.c:127:17: note: node 0x784e3f8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:127:17: note: op template: _49 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 0 _49 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 1 _209 = (sizetype) wi_137;
Dense.c:127:17: note: 	children 0x784e1f8
Dense.c:127:17: note: node (external) 0x784e1f8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:127:17: note: 	{ j_135, wi_137 }
Dense.c:127:17: note: Cost model analysis: 
Dense.c:127:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:127:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:127:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: Costing subgraph: 
Dense.c:110:17: note: node 0x784e578 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:110:17: note: op template: _24 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 1 _229 = (sizetype) wi_136;
Dense.c:110:17: note: 	children 0x784e478
Dense.c:110:17: note: node (external) 0x784e478 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:110:17: note: 	{ j_134, wi_136 }
Dense.c:110:17: note: Cost model analysis: 
Dense.c:110:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:110:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:110:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:105:51: note: ***** Analysis failed with vector mode V8QI
Dense.c:105:51: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:105:51: note: ***** Analysis failed with vector mode V4QI
Dense.c:62:15: missed: couldn't vectorize loop
Dense.c:62:15: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:75:11: optimized: loop vectorized using 32 byte vectors
Dense.c:75:11: optimized: loop vectorized using 16 byte vectors
Dense.c:66:11: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:881:10: missed: not vectorized: no vectype for stmt: _56 = MEM[(__m256 * {ref-all})w_ptr_81];
 scalar_type: __m256
Dense.c:54:13: note: vectorized 1 loops in function.
Dense.c:57:2: missed: statement clobbers memory: memcpy (_5, _4, _3);
Dense.c:79:2: missed: statement clobbers memory: _28 (pretmp_162, _67, 0);
Dense.c:54:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:54:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:182:2: missed: statement clobbers memory: free (_1);
Dense.c:183:2: missed: statement clobbers memory: free (_2);
Dense.c:184:2: missed: statement clobbers memory: free (_3);
Dense.c:185:2: missed: statement clobbers memory: free (_4);
Dense.c:186:2: missed: statement clobbers memory: free (dense_7);
Dense.c:187:2: missed: statement clobbers memory: PULSE_DestroyLayer (this_6(D));
Dense.c:188:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:188:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:202:19: missed: couldn't vectorize loop
Dense.c:202:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:192:13: note: vectorized 0 loops in function.
Dense.c:194:47: missed: statement clobbers memory: dense_35 = malloc (40);
Dense.c:196:36: missed: statement clobbers memory: _5 = aligned_alloc (64, _4);
Dense.c:197:38: missed: statement clobbers memory: _6 = aligned_alloc (64, _4);
Dense.c:198:36: missed: statement clobbers memory: _8 = aligned_alloc (64, _7);
Dense.c:199:35: missed: statement clobbers memory: _9 = aligned_alloc (64, _7);
Dense.c:200:36: missed: statement clobbers memory: _10 = aligned_alloc (64, _7);
Dense.c:203:39: missed: statement clobbers memory: _11 = rand ();
Dense.c:203:73: missed: statement clobbers memory: _63 = sqrt (_18);
Dense.c:215:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:216:4: missed: statement clobbers memory: exit (1);
Dense.c:212:4: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.3_29, n_outputs.2_28, 1, activation_function_51(D), _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:209:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.1_27, n_outputs.0_26, 1, activation_function_51(D), _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:222:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Dense.c:222:9: note: ***** Analysis failed with vector mode V4DI
Dense.c:222:9: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:4:18: note: vectorized 0 loops in function.
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_4, inputs_15, _3);
PULSE.c:8:2: missed: statement clobbers memory: _5 (layer_17);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_12, pretmp_26, _9);
PULSE.c:13:28: note: ***** Analysis failed with vector mode V8SI
PULSE.c:13:28: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:22:2: missed: statement clobbers memory: _1 (layer_10(D));
PULSE.c:22:2: missed: statement clobbers memory: _14 (_2);
PULSE.c:22:2: missed: statement clobbers memory: _21 (_15);
PULSE.c:22:2: missed: statement clobbers memory: _28 (_22);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_29);
PULSE.c:26:3: missed: statement clobbers memory: memset (_34, 0, _32);
PULSE.c:26:3: missed: statement clobbers memory: memset (_27, 0, _25);
PULSE.c:26:3: missed: statement clobbers memory: memset (_20, 0, _18);
PULSE.c:26:3: missed: statement clobbers memory: memset (_7, 0, _5);
PULSE.c:28:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:28:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:32:6: note: vectorized 1 loops in function.
PULSE.c:34:8: missed: statement clobbers memory: _1 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_2);
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _9 = rand ();
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8SI
PULSE.c:32:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:61:16: missed: couldn't vectorize loop
PULSE.c:61:16: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:64:17: missed: couldn't vectorize loop
PULSE.c:64:17: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:73:19: missed: couldn't vectorize loop
PULSE.c:73:19: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:53:22: missed: couldn't vectorize loop
PULSE.c:53:22: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:47:6: note: vectorized 1 loops in function.
PULSE.c:48:1: missed: statement clobbers memory: saved_stack.7_39 = __builtin_stack_save ();
PULSE.c:49:46: missed: statement clobbers memory: _1 = PULSE_GetLossFunctionPtr (loss_function_40(D));
PULSE.c:60:10: missed: statement clobbers memory: random.4_46 = __builtin_alloca_with_align (_4, 32);
PULSE.c:34:8: missed: statement clobbers memory: _61 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_62);
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _72 = rand ();
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_98, inputs_93, _97);
PULSE.c:8:2: missed: statement clobbers memory: _99 (layer_94);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_105, _104, _103);
PULSE.c:67:11: missed: statement clobbers memory: loss_55 = PULSE_GetLoss_42 (_17, _16, _12, _11);
PULSE.c:22:2: missed: statement clobbers memory: _86 (output_34);
PULSE.c:22:2: missed: statement clobbers memory: _108 (_87);
PULSE.c:22:2: missed: statement clobbers memory: _115 (_109);
PULSE.c:22:2: missed: statement clobbers memory: _122 (_116);
PULSE.c:22:2: missed: statement clobbers memory: _129 (_123);
PULSE.c:22:2: missed: statement clobbers memory: _136 (_130);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_137);
PULSE.c:26:3: missed: statement clobbers memory: memset (_142, 0, _140);
PULSE.c:26:3: missed: statement clobbers memory: memset (_135, 0, _133);
PULSE.c:26:3: missed: statement clobbers memory: memset (_128, 0, _126);
PULSE.c:26:3: missed: statement clobbers memory: memset (_121, 0, _119);
PULSE.c:26:3: missed: statement clobbers memory: memset (_114, 0, _112);
PULSE.c:26:3: missed: statement clobbers memory: memset (_92, 0, _90);
PULSE.c:75:6: missed: statement clobbers memory: _21 (current_191, args);
PULSE.c:81:4: missed: statement clobbers memory: printf ("Epoch: %d | Item: %d | Loss: %.10f | Batch Loss: %.10f\r", i_188, j_189, _25, _24);
PULSE.c:47:6: missed: statement clobbers memory: __builtin_stack_restore (saved_stack.7_39);
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4DI
PULSE.c:47:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:91:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:91:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:99:20: missed: couldn't vectorize loop
PULSE.c:99:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:99:20: missed: couldn't vectorize loop
PULSE.c:99:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:93:15: note: vectorized 0 loops in function.
PULSE.c:97:2: missed: statement clobbers memory: __builtin_va_start (&layers, 0);
PULSE.c:98:44: missed: statement clobbers memory: layers_list_27 = malloc (_3);
PULSE.c:107:22: missed: statement clobbers memory: *_12 = PULSE_CreateDenseLayer (_9, _7, args$8_51, args$12_63); [return slot optimization]
PULSE.c:107:22: missed: statement clobbers memory: *_76 = PULSE_CreateDenseLayer (_79, _80, args$8_82, args$12_81); [return slot optimization]
PULSE.c:113:2: missed: statement clobbers memory: __builtin_va_end (&layers);
PULSE.c:114:9: note: ***** Analysis failed with vector mode V8SI
PULSE.c:114:9: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:120:8: missed: couldn't vectorize loop
PULSE.c:120:8: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:117:6: note: vectorized 0 loops in function.
PULSE.c:122:3: missed: statement clobbers memory: _1 (current_11);
PULSE.c:125:2: missed: statement clobbers memory: free (layer_4(D));
PULSE.c:126:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:126:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Layer.c:7:34: missed: statement clobbers memory: _3 = aligned_alloc (64, _2);
Layer.c:8:35: missed: statement clobbers memory: _6 = aligned_alloc (64, _5);
Layer.c:9:34: missed: statement clobbers memory: _7 = aligned_alloc (64, _5);
Layer.c:14:19: missed: statement clobbers memory: _8 = PULSE_GetActivationFunctionPtr (activation_function_18(D));
Layer.c:19:9: note: ***** Analysis succeeded with vector mode V8SI
Layer.c:19:9: note: SLPing BB part
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x30647f8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 0 MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 1 MEM <unsigned int> [(struct PULSE_Layer *)&<retval> + 4B] = optimization_type_17(D);
Layer.c:19:9: note: 	children 0x3064878
Layer.c:19:9: note: node (external) 0x3064878 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ type_16(D), optimization_type_17(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x30648f8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 0 <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 1 <retval>.n_outputs = n_outputs_12(D);
Layer.c:19:9: note: 	children 0x3064978
Layer.c:19:9: note: node (external) 0x3064978 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x3064a78 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 0 <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 1 <retval>.outputs = _6;
Layer.c:19:9: note: 	children 0x3064af8
Layer.c:19:9: note: node (external) 0x3064af8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	stmt 0 _3 = aligned_alloc (64, _2);
Layer.c:19:9: note: 	stmt 1 _6 = aligned_alloc (64, _5);
Layer.c:19:9: note: 	children 0x3064b78 0x3064bf8
Layer.c:19:9: note: node (constant) 0x3064b78 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 64, 64 }
Layer.c:19:9: note: node 0x3064bf8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: patt_40 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 0 patt_40 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 1 patt_41 = n_outputs_12(D) w* 4;
Layer.c:19:9: note: 	children 0x3064c78 0x3064cf8
Layer.c:19:9: note: node (external) 0x3064c78 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: node (constant) 0x3064cf8 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ 4, 4 }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x3064df8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: op template: <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 0 <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 1 <retval>.back = back_21(D);
Layer.c:19:9: note: 	stmt 2 <retval>.fix = fix_22(D);
Layer.c:19:9: note: 	stmt 3 <retval>.destroy = destroy_23(D);
Layer.c:19:9: note: 	children 0x3064e78
Layer.c:19:9: note: node (external) 0x3064e78 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: 	{ feed_20(D), back_21(D), fix_22(D), destroy_23(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 64
  Scalar cost: 64
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x3064f78 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 0 <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 1 <retval>.child = 0B;
Layer.c:19:9: note: 	children 0x3064ff8
Layer.c:19:9: note: node (constant) 0x3064ff8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ 0B, 0B }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Basic block will be vectorized using SLP
Layer.c:19:9: optimized: basic block part vectorized using 8 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x30647f8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 0 MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 1 MEM <unsigned int> [(struct PULSE_Layer *)&<retval> + 4B] = optimization_type_17(D);
Layer.c:19:9: note: 	children 0x3064878
Layer.c:19:9: note: node (external) 0x3064878 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ type_16(D), optimization_type_17(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: vect_is_simple_use: operand optimization_type_17(D), type of def: external
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>]
Layer.c:19:9: note: created &MEM <unsigned int> [(struct PULSE_Layer *)&<retval>]
Layer.c:19:9: note: add new stmt: MEM <vector(2) unsigned int> [(struct PULSE_Layer *)&<retval>] = _42;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 8 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x30648f8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 0 <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 1 <retval>.n_outputs = n_outputs_12(D);
Layer.c:19:9: note: 	children 0x3064978
Layer.c:19:9: note: node (external) 0x3064978 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: vect_is_simple_use: operand n_outputs_12(D), type of def: external
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: <retval>.n_inputs
Layer.c:19:9: note: created &<retval>.n_inputs
Layer.c:19:9: note: add new stmt: MEM <vector(2) unsigned int> [(unsigned int *)&<retval> + 96B] = _44;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 16 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x3064a78 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 0 <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 1 <retval>.outputs = _6;
Layer.c:19:9: note: 	children 0x3064af8
Layer.c:19:9: note: node (external) 0x3064af8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	stmt 0 _3 = aligned_alloc (64, _2);
Layer.c:19:9: note: 	stmt 1 _6 = aligned_alloc (64, _5);
Layer.c:19:9: note: 	children 0x3064b78 0x3064bf8
Layer.c:19:9: note: node (constant) 0x3064b78 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 64, 64 }
Layer.c:19:9: note: node 0x3064bf8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: patt_40 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 0 patt_40 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 1 patt_41 = n_outputs_12(D) w* 4;
Layer.c:19:9: note: 	children 0x3064c78 0x3064cf8
Layer.c:19:9: note: node (external) 0x3064c78 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: node (constant) 0x3064cf8 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ 4, 4 }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.inputs = _3;
Layer.c:19:9: note: vect_is_simple_use: operand aligned_alloc (64, _5), type of def: internal
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.inputs
Layer.c:19:9: note: created &<retval>.inputs
Layer.c:19:9: note: add new stmt: MEM <vector(2) long unsigned int> [(float * *)&<retval> + 8B] = _48;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 32 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x3064df8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: op template: <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 0 <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 1 <retval>.back = back_21(D);
Layer.c:19:9: note: 	stmt 2 <retval>.fix = fix_22(D);
Layer.c:19:9: note: 	stmt 3 <retval>.destroy = destroy_23(D);
Layer.c:19:9: note: 	children 0x3064e78
Layer.c:19:9: note: node (external) 0x3064e78 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: 	{ feed_20(D), back_21(D), fix_22(D), destroy_23(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.feed = feed_20(D);
Layer.c:19:9: note: vect_is_simple_use: operand back_21(D), type of def: external
Layer.c:19:9: note: vect_is_simple_use: operand fix_22(D), type of def: external
Layer.c:19:9: note: vect_is_simple_use: operand destroy_23(D), type of def: external
Layer.c:19:9: note: conflicting alias set types.
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(4) long unsigned int  vectorizing a pointer ref: <retval>.feed
Layer.c:19:9: note: created &<retval>.feed
Layer.c:19:9: note: add new stmt: MEM <vector(4) long unsigned int> [(void *)&<retval> + 32B] = _54;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 16 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x3064f78 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 0 <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 1 <retval>.child = 0B;
Layer.c:19:9: note: 	children 0x3064ff8
Layer.c:19:9: note: node (constant) 0x3064ff8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ 0B, 0B }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.parent = 0B;
Layer.c:19:9: note: vect_is_simple_use: operand 0B, type of def: constant
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.parent
Layer.c:19:9: note: created &<retval>.parent
Layer.c:19:9: note: add new stmt: MEM <vector(2) long unsigned int> [(struct PULSE_Layer * *)&<retval> + 72B] = { 0, 0 };
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: note: ***** The result for vector mode V32QI would be the same
Layer.c:24:2: missed: statement clobbers memory: free (_1);
Layer.c:25:2: missed: statement clobbers memory: free (_2);
Layer.c:26:2: missed: statement clobbers memory: free (_3);
Layer.c:27:1: note: ***** Analysis failed with vector mode V4DI
Layer.c:27:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:9:27: missed: couldn't vectorize loop
Dense.c:9:27: missed: not vectorized: unsupported outerloop form.
Dense.c:12:20: missed: couldn't vectorize loop
Dense.c:13:21: missed: not vectorized: complicated access pattern.
Dense.c:6:13: note: vectorized 0 loops in function.
Dense.c:16:2: missed: statement clobbers memory: _30 (pretmp_91, _50, 0);
Dense.c:9:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:9:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:24:27: missed: couldn't vectorize loop
Dense.c:24:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:28:20: optimized: loop vectorized using 32 byte vectors
Dense.c:28:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:28:20: optimized: loop vectorized using 16 byte vectors
Dense.c:28:20: missed: couldn't vectorize loop
Dense.c:30:20: missed: not vectorized: no vectype for stmt: _21 = *_20;
 scalar_type: float
Dense.c:20:13: note: vectorized 1 loops in function.
Dense.c:23:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:24:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:24:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:41:28: missed: couldn't vectorize loop
Dense.c:41:28: missed: not vectorized: unsupported outerloop form.
Dense.c:45:21: optimized: loop vectorized using 32 byte vectors
Dense.c:45:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:45:21: optimized: loop vectorized using 16 byte vectors
Dense.c:37:13: note: vectorized 1 loops in function.
Dense.c:37:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:37:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:41:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:170:10: optimized: loop vectorized using 32 byte vectors
Dense.c:170:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:170:10: optimized: loop vectorized using 16 byte vectors
Dense.c:161:10: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_34, _77);
Dense.c:154:10: optimized: loop vectorized using 32 byte vectors
Dense.c:154:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:154:10: optimized: loop vectorized using 16 byte vectors
Dense.c:145:10: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_15, _69);
Dense.c:136:13: note: vectorized 2 loops in function.
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_15, _69);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_19, { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 });
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_34, _77);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_38, { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 });
Dense.c:136:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:136:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:105:24: missed: couldn't vectorize loop
Dense.c:105:24: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:108:17: missed: couldn't vectorize loop
Dense.c:108:17: missed: not vectorized: number of iterations cannot be computed.
Dense.c:122:24: missed: couldn't vectorize loop
Dense.c:122:24: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:125:17: missed: couldn't vectorize loop
Dense.c:125:17: missed: not vectorized: number of iterations cannot be computed.
Dense.c:90:15: missed: couldn't vectorize loop
Dense.c:90:15: missed: not vectorized: number of iterations cannot be computed.
Dense.c:83:13: note: vectorized 0 loops in function.
Dense.c:86:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:110:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:110:17: note: SLPing BB part
Dense.c:127:17: note: Costing subgraph: 
Dense.c:127:17: note: node 0x84add68 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:127:17: note: op template: _49 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 0 _49 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 1 _209 = (sizetype) wi_137;
Dense.c:127:17: note: 	children 0x84ade68
Dense.c:127:17: note: node (external) 0x84ade68 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:127:17: note: 	{ j_135, wi_137 }
Dense.c:127:17: note: Cost model analysis: 
Dense.c:127:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:127:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:127:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: Costing subgraph: 
Dense.c:110:17: note: node 0x84adf68 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:110:17: note: op template: _24 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 1 _229 = (sizetype) wi_136;
Dense.c:110:17: note: 	children 0x84ae068
Dense.c:110:17: note: node (external) 0x84ae068 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:110:17: note: 	{ j_134, wi_136 }
Dense.c:110:17: note: Cost model analysis: 
Dense.c:110:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:110:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:110:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:110:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:110:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:110:17: note: SLPing BB part
Dense.c:127:17: note: Costing subgraph: 
Dense.c:127:17: note: node 0x84adf68 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:127:17: note: op template: _49 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 0 _49 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 1 _209 = (sizetype) wi_137;
Dense.c:127:17: note: 	children 0x84add68
Dense.c:127:17: note: node (external) 0x84add68 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:127:17: note: 	{ j_135, wi_137 }
Dense.c:127:17: note: Cost model analysis: 
Dense.c:127:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:127:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:127:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: Costing subgraph: 
Dense.c:110:17: note: node 0x84ae0e8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:110:17: note: op template: _24 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 1 _229 = (sizetype) wi_136;
Dense.c:110:17: note: 	children 0x84adfe8
Dense.c:110:17: note: node (external) 0x84adfe8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:110:17: note: 	{ j_134, wi_136 }
Dense.c:110:17: note: Cost model analysis: 
Dense.c:110:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:110:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:110:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:105:51: note: ***** Analysis failed with vector mode V8QI
Dense.c:105:51: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:105:51: note: ***** Analysis failed with vector mode V4QI
Dense.c:62:15: missed: couldn't vectorize loop
Dense.c:62:15: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:75:11: optimized: loop vectorized using 32 byte vectors
Dense.c:75:11: optimized: loop vectorized using 16 byte vectors
Dense.c:66:11: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:881:10: missed: not vectorized: no vectype for stmt: _56 = MEM[(__m256 * {ref-all})w_ptr_81];
 scalar_type: __m256
Dense.c:54:13: note: vectorized 1 loops in function.
Dense.c:57:2: missed: statement clobbers memory: memcpy (_5, _4, _3);
Dense.c:79:2: missed: statement clobbers memory: _28 (pretmp_162, _67, 0);
Dense.c:54:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:54:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:182:2: missed: statement clobbers memory: free (_1);
Dense.c:183:2: missed: statement clobbers memory: free (_2);
Dense.c:184:2: missed: statement clobbers memory: free (_3);
Dense.c:185:2: missed: statement clobbers memory: free (_4);
Dense.c:186:2: missed: statement clobbers memory: free (dense_7);
Dense.c:187:2: missed: statement clobbers memory: PULSE_DestroyLayer (this_6(D));
Dense.c:188:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:188:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:202:19: missed: couldn't vectorize loop
Dense.c:202:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:192:13: note: vectorized 0 loops in function.
Dense.c:194:47: missed: statement clobbers memory: dense_35 = malloc (40);
Dense.c:196:36: missed: statement clobbers memory: _5 = aligned_alloc (64, _4);
Dense.c:197:38: missed: statement clobbers memory: _6 = aligned_alloc (64, _4);
Dense.c:198:36: missed: statement clobbers memory: _8 = aligned_alloc (64, _7);
Dense.c:199:35: missed: statement clobbers memory: _9 = aligned_alloc (64, _7);
Dense.c:200:36: missed: statement clobbers memory: _10 = aligned_alloc (64, _7);
Dense.c:203:39: missed: statement clobbers memory: _11 = rand ();
Dense.c:203:73: missed: statement clobbers memory: _63 = sqrt (_18);
Dense.c:215:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:216:4: missed: statement clobbers memory: exit (1);
Dense.c:212:4: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.3_29, n_outputs.2_28, 0, activation_function_51(D), _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:209:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.1_27, n_outputs.0_26, 0, activation_function_51(D), _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:222:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Dense.c:222:9: note: ***** Analysis failed with vector mode V4DI
Dense.c:222:9: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Activations.c:17:19: optimized: loop vectorized using 32 byte vectors
Activations.c:17:19: optimized: loop vectorized using 16 byte vectors
Activations.c:17:19: optimized: loop vectorized using 32 byte vectors
Activations.c:17:19: optimized: loop vectorized using 16 byte vectors
Activations.c:14:13: note: vectorized 2 loops in function.
Activations.c:14:13: note: ***** Analysis failed with vector mode V8SF
Activations.c:14:13: note: ***** The result for vector mode V32QI would be the same
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V16QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V16QI
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V8QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V8QI
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V4QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V4QI
Activations.c:28:19: missed: couldn't vectorize loop
Activations.c:28:19: missed: not vectorized: unsupported control flow in loop.
Activations.c:28:19: optimized: loop vectorized using 32 byte vectors
Activations.c:28:19: optimized: loop vectorized using 16 byte vectors
Activations.c:25:13: note: vectorized 1 loops in function.
Activations.c:25:13: note: ***** Analysis failed with vector mode V8SF
Activations.c:25:13: note: ***** The result for vector mode V32QI would be the same
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V16QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V16QI
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V8QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V8QI
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V4QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V4QI
Activations.c:38:1: note: ***** Analysis failed with vector mode VOID
Activations.c:5:19: missed: couldn't vectorize loop
Activations.c:9:21: missed: statement clobbers memory: _36 = expf (_18);
Activations.c:5:19: missed: couldn't vectorize loop
Activations.c:9:21: missed: statement clobbers memory: _12 = expf (_11);
Activations.c:3:13: note: vectorized 0 loops in function.
Activations.c:9:21: missed: statement clobbers memory: _12 = expf (_11);
Activations.c:9:21: missed: statement clobbers memory: _36 = expf (_18);
Activations.c:11:1: note: ***** Analysis failed with vector mode V8SF
Activations.c:11:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Activations.c:44:2: note: ***** Analysis failed with vector mode VOID
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:4:18: note: vectorized 0 loops in function.
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_4, inputs_15, _3);
PULSE.c:8:2: missed: statement clobbers memory: _5 (layer_17);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_12, pretmp_26, _9);
PULSE.c:13:28: note: ***** Analysis failed with vector mode V8SI
PULSE.c:13:28: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:22:2: missed: statement clobbers memory: _1 (layer_10(D));
PULSE.c:22:2: missed: statement clobbers memory: _14 (_2);
PULSE.c:22:2: missed: statement clobbers memory: _21 (_15);
PULSE.c:22:2: missed: statement clobbers memory: _28 (_22);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_29);
PULSE.c:26:3: missed: statement clobbers memory: memset (_34, 0, _32);
PULSE.c:26:3: missed: statement clobbers memory: memset (_27, 0, _25);
PULSE.c:26:3: missed: statement clobbers memory: memset (_20, 0, _18);
PULSE.c:26:3: missed: statement clobbers memory: memset (_7, 0, _5);
PULSE.c:28:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:28:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:32:6: note: vectorized 1 loops in function.
PULSE.c:34:8: missed: statement clobbers memory: _1 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_2);
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _9 = rand ();
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8SI
PULSE.c:32:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:61:16: missed: couldn't vectorize loop
PULSE.c:61:16: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:64:17: missed: couldn't vectorize loop
PULSE.c:64:17: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:73:19: missed: couldn't vectorize loop
PULSE.c:73:19: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:53:22: missed: couldn't vectorize loop
PULSE.c:53:22: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:47:6: note: vectorized 1 loops in function.
PULSE.c:48:1: missed: statement clobbers memory: saved_stack.7_39 = __builtin_stack_save ();
PULSE.c:49:46: missed: statement clobbers memory: _1 = PULSE_GetLossFunctionPtr (loss_function_40(D));
PULSE.c:60:10: missed: statement clobbers memory: random.4_46 = __builtin_alloca_with_align (_4, 32);
PULSE.c:34:8: missed: statement clobbers memory: _61 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_62);
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _72 = rand ();
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_98, inputs_93, _97);
PULSE.c:8:2: missed: statement clobbers memory: _99 (layer_94);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_105, _104, _103);
PULSE.c:67:11: missed: statement clobbers memory: loss_55 = PULSE_GetLoss_42 (_17, _16, _12, _11);
PULSE.c:22:2: missed: statement clobbers memory: _86 (output_34);
PULSE.c:22:2: missed: statement clobbers memory: _108 (_87);
PULSE.c:22:2: missed: statement clobbers memory: _115 (_109);
PULSE.c:22:2: missed: statement clobbers memory: _122 (_116);
PULSE.c:22:2: missed: statement clobbers memory: _129 (_123);
PULSE.c:22:2: missed: statement clobbers memory: _136 (_130);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_137);
PULSE.c:26:3: missed: statement clobbers memory: memset (_142, 0, _140);
PULSE.c:26:3: missed: statement clobbers memory: memset (_135, 0, _133);
PULSE.c:26:3: missed: statement clobbers memory: memset (_128, 0, _126);
PULSE.c:26:3: missed: statement clobbers memory: memset (_121, 0, _119);
PULSE.c:26:3: missed: statement clobbers memory: memset (_114, 0, _112);
PULSE.c:26:3: missed: statement clobbers memory: memset (_92, 0, _90);
PULSE.c:75:6: missed: statement clobbers memory: _21 (current_191, args);
PULSE.c:81:4: missed: statement clobbers memory: printf ("Epoch: %d | Item: %d | Loss: %.10f | Batch Loss: %.10f\r", i_188, j_189, _25, _24);
PULSE.c:47:6: missed: statement clobbers memory: __builtin_stack_restore (saved_stack.7_39);
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4DI
PULSE.c:47:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:91:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:91:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:99:20: missed: couldn't vectorize loop
PULSE.c:99:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:99:20: missed: couldn't vectorize loop
PULSE.c:99:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:93:15: note: vectorized 0 loops in function.
PULSE.c:97:2: missed: statement clobbers memory: __builtin_va_start (&layers, 0);
PULSE.c:98:44: missed: statement clobbers memory: layers_list_27 = malloc (_3);
PULSE.c:107:22: missed: statement clobbers memory: *_12 = PULSE_CreateDenseLayer (_9, _7, args$8_51, args$12_63); [return slot optimization]
PULSE.c:107:22: missed: statement clobbers memory: *_76 = PULSE_CreateDenseLayer (_79, _80, args$8_82, args$12_81); [return slot optimization]
PULSE.c:113:2: missed: statement clobbers memory: __builtin_va_end (&layers);
PULSE.c:114:9: note: ***** Analysis failed with vector mode V8SI
PULSE.c:114:9: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:120:8: missed: couldn't vectorize loop
PULSE.c:120:8: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:117:6: note: vectorized 0 loops in function.
PULSE.c:122:3: missed: statement clobbers memory: _1 (current_11);
PULSE.c:125:2: missed: statement clobbers memory: free (layer_4(D));
PULSE.c:126:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:126:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Loss.c:15:19: optimized: loop vectorized using 32 byte vectors
Loss.c:15:19: optimized:  loop versioned for vectorization because of possible aliasing
Loss.c:15:19: optimized: loop vectorized using 16 byte vectors
Loss.c:12:23: note: vectorized 1 loops in function.
Loss.c:12:23: note: ***** Analysis failed with vector mode V8SF
Loss.c:12:23: note: ***** The result for vector mode V32QI would be the same
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V16QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V16QI
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V8QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V8QI
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V4QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V4QI
Loss.c:7:19: missed: couldn't vectorize loop
Loss.c:8:38: missed: not vectorized: unsupported use in stmt.
Loss.c:4:23: note: vectorized 0 loops in function.
Loss.c:9:13: note: ***** Analysis failed with vector mode V8SF
Loss.c:9:13: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Loss.c:23:2: note: ***** Analysis failed with vector mode VOID
Layer.c:7:34: missed: statement clobbers memory: _3 = aligned_alloc (64, _2);
Layer.c:8:35: missed: statement clobbers memory: _6 = aligned_alloc (64, _5);
Layer.c:9:34: missed: statement clobbers memory: _7 = aligned_alloc (64, _5);
Layer.c:14:19: missed: statement clobbers memory: _8 = PULSE_GetActivationFunctionPtr (activation_function_18(D));
Layer.c:19:9: note: ***** Analysis succeeded with vector mode V8SI
Layer.c:19:9: note: SLPing BB part
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x42629c8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 0 MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 1 MEM <unsigned int> [(struct PULSE_Layer *)&<retval> + 4B] = optimization_type_17(D);
Layer.c:19:9: note: 	children 0x4262a48
Layer.c:19:9: note: node (external) 0x4262a48 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ type_16(D), optimization_type_17(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x4262ac8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 0 <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 1 <retval>.n_outputs = n_outputs_12(D);
Layer.c:19:9: note: 	children 0x4262b48
Layer.c:19:9: note: node (external) 0x4262b48 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x4262c48 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 0 <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 1 <retval>.outputs = _6;
Layer.c:19:9: note: 	children 0x4262cc8
Layer.c:19:9: note: node (external) 0x4262cc8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	stmt 0 _3 = aligned_alloc (64, _2);
Layer.c:19:9: note: 	stmt 1 _6 = aligned_alloc (64, _5);
Layer.c:19:9: note: 	children 0x4262d48 0x4262dc8
Layer.c:19:9: note: node (constant) 0x4262d48 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 64, 64 }
Layer.c:19:9: note: node 0x4262dc8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: patt_40 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 0 patt_40 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 1 patt_41 = n_outputs_12(D) w* 4;
Layer.c:19:9: note: 	children 0x4262e48 0x4262ec8
Layer.c:19:9: note: node (external) 0x4262e48 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: node (constant) 0x4262ec8 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ 4, 4 }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x4262fc8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: op template: <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 0 <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 1 <retval>.back = back_21(D);
Layer.c:19:9: note: 	stmt 2 <retval>.fix = fix_22(D);
Layer.c:19:9: note: 	stmt 3 <retval>.destroy = destroy_23(D);
Layer.c:19:9: note: 	children 0x4263048
Layer.c:19:9: note: node (external) 0x4263048 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: 	{ feed_20(D), back_21(D), fix_22(D), destroy_23(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 64
  Scalar cost: 64
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x4263148 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 0 <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 1 <retval>.child = 0B;
Layer.c:19:9: note: 	children 0x42631c8
Layer.c:19:9: note: node (constant) 0x42631c8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ 0B, 0B }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Basic block will be vectorized using SLP
Layer.c:19:9: optimized: basic block part vectorized using 8 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x42629c8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 0 MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 1 MEM <unsigned int> [(struct PULSE_Layer *)&<retval> + 4B] = optimization_type_17(D);
Layer.c:19:9: note: 	children 0x4262a48
Layer.c:19:9: note: node (external) 0x4262a48 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ type_16(D), optimization_type_17(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: vect_is_simple_use: operand optimization_type_17(D), type of def: external
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>]
Layer.c:19:9: note: created &MEM <unsigned int> [(struct PULSE_Layer *)&<retval>]
Layer.c:19:9: note: add new stmt: MEM <vector(2) unsigned int> [(struct PULSE_Layer *)&<retval>] = _42;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 8 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x4262ac8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 0 <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 1 <retval>.n_outputs = n_outputs_12(D);
Layer.c:19:9: note: 	children 0x4262b48
Layer.c:19:9: note: node (external) 0x4262b48 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: vect_is_simple_use: operand n_outputs_12(D), type of def: external
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: <retval>.n_inputs
Layer.c:19:9: note: created &<retval>.n_inputs
Layer.c:19:9: note: add new stmt: MEM <vector(2) unsigned int> [(unsigned int *)&<retval> + 96B] = _44;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 16 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x4262c48 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 0 <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 1 <retval>.outputs = _6;
Layer.c:19:9: note: 	children 0x4262cc8
Layer.c:19:9: note: node (external) 0x4262cc8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	stmt 0 _3 = aligned_alloc (64, _2);
Layer.c:19:9: note: 	stmt 1 _6 = aligned_alloc (64, _5);
Layer.c:19:9: note: 	children 0x4262d48 0x4262dc8
Layer.c:19:9: note: node (constant) 0x4262d48 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 64, 64 }
Layer.c:19:9: note: node 0x4262dc8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: patt_40 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 0 patt_40 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 1 patt_41 = n_outputs_12(D) w* 4;
Layer.c:19:9: note: 	children 0x4262e48 0x4262ec8
Layer.c:19:9: note: node (external) 0x4262e48 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: node (constant) 0x4262ec8 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ 4, 4 }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.inputs = _3;
Layer.c:19:9: note: vect_is_simple_use: operand aligned_alloc (64, _5), type of def: internal
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.inputs
Layer.c:19:9: note: created &<retval>.inputs
Layer.c:19:9: note: add new stmt: MEM <vector(2) long unsigned int> [(float * *)&<retval> + 8B] = _48;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 32 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x4262fc8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: op template: <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 0 <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 1 <retval>.back = back_21(D);
Layer.c:19:9: note: 	stmt 2 <retval>.fix = fix_22(D);
Layer.c:19:9: note: 	stmt 3 <retval>.destroy = destroy_23(D);
Layer.c:19:9: note: 	children 0x4263048
Layer.c:19:9: note: node (external) 0x4263048 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: 	{ feed_20(D), back_21(D), fix_22(D), destroy_23(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.feed = feed_20(D);
Layer.c:19:9: note: vect_is_simple_use: operand back_21(D), type of def: external
Layer.c:19:9: note: vect_is_simple_use: operand fix_22(D), type of def: external
Layer.c:19:9: note: vect_is_simple_use: operand destroy_23(D), type of def: external
Layer.c:19:9: note: conflicting alias set types.
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(4) long unsigned int  vectorizing a pointer ref: <retval>.feed
Layer.c:19:9: note: created &<retval>.feed
Layer.c:19:9: note: add new stmt: MEM <vector(4) long unsigned int> [(void *)&<retval> + 32B] = _54;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 16 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x4263148 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 0 <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 1 <retval>.child = 0B;
Layer.c:19:9: note: 	children 0x42631c8
Layer.c:19:9: note: node (constant) 0x42631c8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ 0B, 0B }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.parent = 0B;
Layer.c:19:9: note: vect_is_simple_use: operand 0B, type of def: constant
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.parent
Layer.c:19:9: note: created &<retval>.parent
Layer.c:19:9: note: add new stmt: MEM <vector(2) long unsigned int> [(struct PULSE_Layer * *)&<retval> + 72B] = { 0, 0 };
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: note: ***** The result for vector mode V32QI would be the same
Layer.c:24:2: missed: statement clobbers memory: free (_1);
Layer.c:25:2: missed: statement clobbers memory: free (_2);
Layer.c:26:2: missed: statement clobbers memory: free (_3);
Layer.c:27:1: note: ***** Analysis failed with vector mode V4DI
Layer.c:27:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:9:27: missed: couldn't vectorize loop
Dense.c:9:27: missed: not vectorized: unsupported outerloop form.
Dense.c:12:20: missed: couldn't vectorize loop
Dense.c:13:21: missed: not vectorized: complicated access pattern.
Dense.c:6:13: note: vectorized 0 loops in function.
Dense.c:16:2: missed: statement clobbers memory: _30 (pretmp_91, _50, 0);
Dense.c:9:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:9:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:24:27: missed: couldn't vectorize loop
Dense.c:24:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:28:20: optimized: loop vectorized using 32 byte vectors
Dense.c:28:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:28:20: optimized: loop vectorized using 16 byte vectors
Dense.c:28:20: missed: couldn't vectorize loop
Dense.c:30:20: missed: not vectorized: no vectype for stmt: _21 = *_20;
 scalar_type: float
Dense.c:20:13: note: vectorized 1 loops in function.
Dense.c:23:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:24:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:24:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:41:28: missed: couldn't vectorize loop
Dense.c:41:28: missed: not vectorized: unsupported outerloop form.
Dense.c:45:21: optimized: loop vectorized using 32 byte vectors
Dense.c:45:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:45:21: optimized: loop vectorized using 16 byte vectors
Dense.c:37:13: note: vectorized 1 loops in function.
Dense.c:37:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:37:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:41:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:170:10: optimized: loop vectorized using 32 byte vectors
Dense.c:170:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:170:10: optimized: loop vectorized using 16 byte vectors
Dense.c:161:10: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_34, _77);
Dense.c:154:10: optimized: loop vectorized using 32 byte vectors
Dense.c:154:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:154:10: optimized: loop vectorized using 16 byte vectors
Dense.c:145:10: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_15, _69);
Dense.c:136:13: note: vectorized 2 loops in function.
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_15, _69);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_19, { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 });
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_34, _77);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_38, { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 });
Dense.c:136:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:136:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:105:24: missed: couldn't vectorize loop
Dense.c:105:24: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:108:17: missed: couldn't vectorize loop
Dense.c:108:17: missed: not vectorized: number of iterations cannot be computed.
Dense.c:122:24: missed: couldn't vectorize loop
Dense.c:122:24: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:125:17: missed: couldn't vectorize loop
Dense.c:125:17: missed: not vectorized: number of iterations cannot be computed.
Dense.c:90:15: missed: couldn't vectorize loop
Dense.c:90:15: missed: not vectorized: number of iterations cannot be computed.
Dense.c:83:13: note: vectorized 0 loops in function.
Dense.c:86:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:110:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:110:17: note: SLPing BB part
Dense.c:127:17: note: Costing subgraph: 
Dense.c:127:17: note: node 0x863d218 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:127:17: note: op template: _49 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 0 _49 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 1 _209 = (sizetype) wi_137;
Dense.c:127:17: note: 	children 0x863d318
Dense.c:127:17: note: node (external) 0x863d318 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:127:17: note: 	{ j_135, wi_137 }
Dense.c:127:17: note: Cost model analysis: 
Dense.c:127:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:127:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:127:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: Costing subgraph: 
Dense.c:110:17: note: node 0x863d418 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:110:17: note: op template: _24 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 1 _229 = (sizetype) wi_136;
Dense.c:110:17: note: 	children 0x863d518
Dense.c:110:17: note: node (external) 0x863d518 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:110:17: note: 	{ j_134, wi_136 }
Dense.c:110:17: note: Cost model analysis: 
Dense.c:110:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:110:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:110:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:110:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:110:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:110:17: note: SLPing BB part
Dense.c:127:17: note: Costing subgraph: 
Dense.c:127:17: note: node 0x863d418 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:127:17: note: op template: _49 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 0 _49 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 1 _209 = (sizetype) wi_137;
Dense.c:127:17: note: 	children 0x863d218
Dense.c:127:17: note: node (external) 0x863d218 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:127:17: note: 	{ j_135, wi_137 }
Dense.c:127:17: note: Cost model analysis: 
Dense.c:127:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:127:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:127:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: Costing subgraph: 
Dense.c:110:17: note: node 0x863d598 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:110:17: note: op template: _24 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 1 _229 = (sizetype) wi_136;
Dense.c:110:17: note: 	children 0x863d498
Dense.c:110:17: note: node (external) 0x863d498 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:110:17: note: 	{ j_134, wi_136 }
Dense.c:110:17: note: Cost model analysis: 
Dense.c:110:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:110:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:110:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:105:51: note: ***** Analysis failed with vector mode V8QI
Dense.c:105:51: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:105:51: note: ***** Analysis failed with vector mode V4QI
Dense.c:62:15: missed: couldn't vectorize loop
Dense.c:62:15: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:75:11: optimized: loop vectorized using 32 byte vectors
Dense.c:75:11: optimized: loop vectorized using 16 byte vectors
Dense.c:66:11: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:881:10: missed: not vectorized: no vectype for stmt: _56 = MEM[(__m256 * {ref-all})w_ptr_81];
 scalar_type: __m256
Dense.c:54:13: note: vectorized 1 loops in function.
Dense.c:57:2: missed: statement clobbers memory: memcpy (_5, _4, _3);
Dense.c:79:2: missed: statement clobbers memory: _28 (pretmp_162, _67, 0);
Dense.c:54:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:54:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:182:2: missed: statement clobbers memory: free (_1);
Dense.c:183:2: missed: statement clobbers memory: free (_2);
Dense.c:184:2: missed: statement clobbers memory: free (_3);
Dense.c:185:2: missed: statement clobbers memory: free (_4);
Dense.c:186:2: missed: statement clobbers memory: free (dense_7);
Dense.c:187:2: missed: statement clobbers memory: PULSE_DestroyLayer (this_6(D));
Dense.c:188:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:188:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:202:19: missed: couldn't vectorize loop
Dense.c:202:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:192:13: note: vectorized 0 loops in function.
Dense.c:194:47: missed: statement clobbers memory: dense_35 = malloc (40);
Dense.c:196:36: missed: statement clobbers memory: _5 = aligned_alloc (64, _4);
Dense.c:197:38: missed: statement clobbers memory: _6 = aligned_alloc (64, _4);
Dense.c:198:36: missed: statement clobbers memory: _8 = aligned_alloc (64, _7);
Dense.c:199:35: missed: statement clobbers memory: _9 = aligned_alloc (64, _7);
Dense.c:200:36: missed: statement clobbers memory: _10 = aligned_alloc (64, _7);
Dense.c:203:39: missed: statement clobbers memory: _11 = rand ();
Dense.c:203:73: missed: statement clobbers memory: _63 = sqrt (_18);
Dense.c:215:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:216:4: missed: statement clobbers memory: exit (1);
Dense.c:212:4: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.3_29, n_outputs.2_28, 0, activation_function_51(D), _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:209:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.1_27, n_outputs.0_26, 0, activation_function_51(D), _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:222:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Dense.c:222:9: note: ***** Analysis failed with vector mode V4DI
Dense.c:222:9: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Activations.c:17:19: optimized: loop vectorized using 32 byte vectors
Activations.c:17:19: optimized: loop vectorized using 16 byte vectors
Activations.c:17:19: optimized: loop vectorized using 32 byte vectors
Activations.c:17:19: optimized: loop vectorized using 16 byte vectors
Activations.c:14:13: note: vectorized 2 loops in function.
Activations.c:14:13: note: ***** Analysis failed with vector mode V8SF
Activations.c:14:13: note: ***** The result for vector mode V32QI would be the same
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V16QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V16QI
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V8QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V8QI
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V4QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V4QI
Activations.c:28:19: missed: couldn't vectorize loop
Activations.c:28:19: missed: not vectorized: unsupported control flow in loop.
Activations.c:28:19: optimized: loop vectorized using 32 byte vectors
Activations.c:28:19: optimized: loop vectorized using 16 byte vectors
Activations.c:25:13: note: vectorized 1 loops in function.
Activations.c:25:13: note: ***** Analysis failed with vector mode V8SF
Activations.c:25:13: note: ***** The result for vector mode V32QI would be the same
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V16QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V16QI
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V8QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V8QI
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V4QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V4QI
Activations.c:38:1: note: ***** Analysis failed with vector mode VOID
Activations.c:5:19: missed: couldn't vectorize loop
Activations.c:9:21: missed: statement clobbers memory: _36 = expf (_18);
Activations.c:5:19: missed: couldn't vectorize loop
Activations.c:9:21: missed: statement clobbers memory: _12 = expf (_11);
Activations.c:3:13: note: vectorized 0 loops in function.
Activations.c:9:21: missed: statement clobbers memory: _12 = expf (_11);
Activations.c:9:21: missed: statement clobbers memory: _36 = expf (_18);
Activations.c:11:1: note: ***** Analysis failed with vector mode V8SF
Activations.c:11:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Activations.c:44:2: note: ***** Analysis failed with vector mode VOID
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:4:18: note: vectorized 0 loops in function.
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_4, inputs_15, _3);
PULSE.c:8:2: missed: statement clobbers memory: _5 (layer_17);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_12, pretmp_26, _9);
PULSE.c:13:28: note: ***** Analysis failed with vector mode V8SI
PULSE.c:13:28: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:22:2: missed: statement clobbers memory: _1 (layer_10(D));
PULSE.c:22:2: missed: statement clobbers memory: _14 (_2);
PULSE.c:22:2: missed: statement clobbers memory: _21 (_15);
PULSE.c:22:2: missed: statement clobbers memory: _28 (_22);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_29);
PULSE.c:26:3: missed: statement clobbers memory: memset (_34, 0, _32);
PULSE.c:26:3: missed: statement clobbers memory: memset (_27, 0, _25);
PULSE.c:26:3: missed: statement clobbers memory: memset (_20, 0, _18);
PULSE.c:26:3: missed: statement clobbers memory: memset (_7, 0, _5);
PULSE.c:28:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:28:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:32:6: note: vectorized 1 loops in function.
PULSE.c:34:8: missed: statement clobbers memory: _1 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_2);
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _9 = rand ();
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8SI
PULSE.c:32:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:61:16: missed: couldn't vectorize loop
PULSE.c:61:16: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:64:17: missed: couldn't vectorize loop
PULSE.c:64:17: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:73:19: missed: couldn't vectorize loop
PULSE.c:73:19: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:53:22: missed: couldn't vectorize loop
PULSE.c:53:22: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:47:6: note: vectorized 1 loops in function.
PULSE.c:48:1: missed: statement clobbers memory: saved_stack.7_39 = __builtin_stack_save ();
PULSE.c:49:46: missed: statement clobbers memory: _1 = PULSE_GetLossFunctionPtr (loss_function_40(D));
PULSE.c:60:10: missed: statement clobbers memory: random.4_46 = __builtin_alloca_with_align (_4, 32);
PULSE.c:34:8: missed: statement clobbers memory: _61 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_62);
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _72 = rand ();
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_98, inputs_93, _97);
PULSE.c:8:2: missed: statement clobbers memory: _99 (layer_94);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_105, _104, _103);
PULSE.c:67:11: missed: statement clobbers memory: loss_55 = PULSE_GetLoss_42 (_17, _16, _12, _11);
PULSE.c:22:2: missed: statement clobbers memory: _86 (output_34);
PULSE.c:22:2: missed: statement clobbers memory: _108 (_87);
PULSE.c:22:2: missed: statement clobbers memory: _115 (_109);
PULSE.c:22:2: missed: statement clobbers memory: _122 (_116);
PULSE.c:22:2: missed: statement clobbers memory: _129 (_123);
PULSE.c:22:2: missed: statement clobbers memory: _136 (_130);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_137);
PULSE.c:26:3: missed: statement clobbers memory: memset (_142, 0, _140);
PULSE.c:26:3: missed: statement clobbers memory: memset (_135, 0, _133);
PULSE.c:26:3: missed: statement clobbers memory: memset (_128, 0, _126);
PULSE.c:26:3: missed: statement clobbers memory: memset (_121, 0, _119);
PULSE.c:26:3: missed: statement clobbers memory: memset (_114, 0, _112);
PULSE.c:26:3: missed: statement clobbers memory: memset (_92, 0, _90);
PULSE.c:75:6: missed: statement clobbers memory: _21 (current_191, args);
PULSE.c:81:4: missed: statement clobbers memory: printf ("Epoch: %d | Item: %d | Loss: %.10f | Batch Loss: %.10f\r", i_188, j_189, _25, _24);
PULSE.c:47:6: missed: statement clobbers memory: __builtin_stack_restore (saved_stack.7_39);
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4DI
PULSE.c:47:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:91:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:91:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:99:20: missed: couldn't vectorize loop
PULSE.c:99:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:99:20: missed: couldn't vectorize loop
PULSE.c:99:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:93:15: note: vectorized 0 loops in function.
PULSE.c:97:2: missed: statement clobbers memory: __builtin_va_start (&layers, 0);
PULSE.c:98:44: missed: statement clobbers memory: layers_list_27 = malloc (_3);
PULSE.c:106:22: missed: statement clobbers memory: *_12 = PULSE_CreateDenseLayer (_9, _7, args$8_51, args$12_63); [return slot optimization]
PULSE.c:106:22: missed: statement clobbers memory: *_76 = PULSE_CreateDenseLayer (_79, _80, args$8_82, args$12_81); [return slot optimization]
PULSE.c:112:2: missed: statement clobbers memory: __builtin_va_end (&layers);
PULSE.c:113:9: note: ***** Analysis failed with vector mode V8SI
PULSE.c:113:9: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:119:8: missed: couldn't vectorize loop
PULSE.c:119:8: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:116:6: note: vectorized 0 loops in function.
PULSE.c:121:3: missed: statement clobbers memory: _1 (current_11);
PULSE.c:124:2: missed: statement clobbers memory: free (layer_4(D));
PULSE.c:125:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:125:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Loss.c:15:19: optimized: loop vectorized using 32 byte vectors
Loss.c:15:19: optimized:  loop versioned for vectorization because of possible aliasing
Loss.c:15:19: optimized: loop vectorized using 16 byte vectors
Loss.c:12:23: note: vectorized 1 loops in function.
Loss.c:12:23: note: ***** Analysis failed with vector mode V8SF
Loss.c:12:23: note: ***** The result for vector mode V32QI would be the same
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V16QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V16QI
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V8QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V8QI
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V4QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V4QI
Loss.c:7:19: missed: couldn't vectorize loop
Loss.c:8:38: missed: not vectorized: unsupported use in stmt.
Loss.c:4:23: note: vectorized 0 loops in function.
Loss.c:9:13: note: ***** Analysis failed with vector mode V8SF
Loss.c:9:13: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Loss.c:23:2: note: ***** Analysis failed with vector mode VOID
Dense.c:9:27: missed: couldn't vectorize loop
Dense.c:9:27: missed: not vectorized: unsupported outerloop form.
Dense.c:12:20: missed: couldn't vectorize loop
Dense.c:13:21: missed: not vectorized: complicated access pattern.
Dense.c:6:13: note: vectorized 0 loops in function.
Dense.c:16:2: missed: statement clobbers memory: _30 (pretmp_91, _50, 0);
Dense.c:9:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:9:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:24:27: missed: couldn't vectorize loop
Dense.c:24:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:28:20: optimized: loop vectorized using 32 byte vectors
Dense.c:28:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:28:20: optimized: loop vectorized using 16 byte vectors
Dense.c:28:20: missed: couldn't vectorize loop
Dense.c:30:20: missed: not vectorized: no vectype for stmt: _21 = *_20;
 scalar_type: float
Dense.c:20:13: note: vectorized 1 loops in function.
Dense.c:23:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:24:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:24:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:41:28: missed: couldn't vectorize loop
Dense.c:41:28: missed: not vectorized: unsupported outerloop form.
Dense.c:45:21: optimized: loop vectorized using 32 byte vectors
Dense.c:45:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:45:21: optimized: loop vectorized using 16 byte vectors
Dense.c:37:13: note: vectorized 1 loops in function.
Dense.c:37:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:37:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:41:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:170:10: optimized: loop vectorized using 32 byte vectors
Dense.c:170:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:170:10: optimized: loop vectorized using 16 byte vectors
Dense.c:161:10: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_34, _77);
Dense.c:154:10: optimized: loop vectorized using 32 byte vectors
Dense.c:154:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:154:10: optimized: loop vectorized using 16 byte vectors
Dense.c:145:10: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_15, _69);
Dense.c:136:13: note: vectorized 2 loops in function.
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_15, _69);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_19, { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 });
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_34, _77);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_38, { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 });
Dense.c:136:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:136:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:105:24: missed: couldn't vectorize loop
Dense.c:105:24: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:108:17: missed: couldn't vectorize loop
Dense.c:108:17: missed: not vectorized: number of iterations cannot be computed.
Dense.c:122:24: missed: couldn't vectorize loop
Dense.c:122:24: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:125:17: missed: couldn't vectorize loop
Dense.c:125:17: missed: not vectorized: number of iterations cannot be computed.
Dense.c:90:15: missed: couldn't vectorize loop
Dense.c:90:15: missed: not vectorized: number of iterations cannot be computed.
Dense.c:83:13: note: vectorized 0 loops in function.
Dense.c:86:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:110:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:110:17: note: SLPing BB part
Dense.c:127:17: note: Costing subgraph: 
Dense.c:127:17: note: node 0x89bcea8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:127:17: note: op template: _49 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 0 _49 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 1 _209 = (sizetype) wi_137;
Dense.c:127:17: note: 	children 0x89bcfa8
Dense.c:127:17: note: node (external) 0x89bcfa8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:127:17: note: 	{ j_135, wi_137 }
Dense.c:127:17: note: Cost model analysis: 
Dense.c:127:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:127:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:127:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: Costing subgraph: 
Dense.c:110:17: note: node 0x89bd0a8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:110:17: note: op template: _24 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 1 _229 = (sizetype) wi_136;
Dense.c:110:17: note: 	children 0x89bd1a8
Dense.c:110:17: note: node (external) 0x89bd1a8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:110:17: note: 	{ j_134, wi_136 }
Dense.c:110:17: note: Cost model analysis: 
Dense.c:110:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:110:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:110:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:110:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:110:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:110:17: note: SLPing BB part
Dense.c:127:17: note: Costing subgraph: 
Dense.c:127:17: note: node 0x89bd0a8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:127:17: note: op template: _49 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 0 _49 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 1 _209 = (sizetype) wi_137;
Dense.c:127:17: note: 	children 0x89bcea8
Dense.c:127:17: note: node (external) 0x89bcea8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:127:17: note: 	{ j_135, wi_137 }
Dense.c:127:17: note: Cost model analysis: 
Dense.c:127:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:127:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:127:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: Costing subgraph: 
Dense.c:110:17: note: node 0x89bd228 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:110:17: note: op template: _24 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 1 _229 = (sizetype) wi_136;
Dense.c:110:17: note: 	children 0x89bd128
Dense.c:110:17: note: node (external) 0x89bd128 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:110:17: note: 	{ j_134, wi_136 }
Dense.c:110:17: note: Cost model analysis: 
Dense.c:110:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:110:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:110:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:105:51: note: ***** Analysis failed with vector mode V8QI
Dense.c:105:51: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:105:51: note: ***** Analysis failed with vector mode V4QI
Dense.c:62:15: missed: couldn't vectorize loop
Dense.c:62:15: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:75:11: optimized: loop vectorized using 32 byte vectors
Dense.c:75:11: optimized: loop vectorized using 16 byte vectors
Dense.c:66:11: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:881:10: missed: not vectorized: no vectype for stmt: _56 = MEM[(__m256 * {ref-all})w_ptr_81];
 scalar_type: __m256
Dense.c:54:13: note: vectorized 1 loops in function.
Dense.c:57:2: missed: statement clobbers memory: memcpy (_5, _4, _3);
Dense.c:79:2: missed: statement clobbers memory: _28 (pretmp_162, _67, 0);
Dense.c:54:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:54:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:182:2: missed: statement clobbers memory: free (_1);
Dense.c:183:2: missed: statement clobbers memory: free (_2);
Dense.c:184:2: missed: statement clobbers memory: free (_3);
Dense.c:185:2: missed: statement clobbers memory: free (_4);
Dense.c:186:2: missed: statement clobbers memory: free (dense_7);
Dense.c:187:2: missed: statement clobbers memory: PULSE_DestroyLayer (this_6(D));
Dense.c:188:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:188:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:202:19: missed: couldn't vectorize loop
Dense.c:202:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:192:13: note: vectorized 0 loops in function.
Dense.c:194:47: missed: statement clobbers memory: dense_32 = malloc (40);
Dense.c:196:36: missed: statement clobbers memory: _5 = aligned_alloc (64, _4);
Dense.c:197:38: missed: statement clobbers memory: _6 = aligned_alloc (64, _4);
Dense.c:198:36: missed: statement clobbers memory: _8 = aligned_alloc (64, _7);
Dense.c:199:35: missed: statement clobbers memory: _9 = aligned_alloc (64, _7);
Dense.c:200:36: missed: statement clobbers memory: _10 = aligned_alloc (64, _7);
Dense.c:203:39: missed: statement clobbers memory: _11 = rand ();
Dense.c:203:73: missed: statement clobbers memory: _60 = sqrt (_18);
Dense.c:215:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:216:4: missed: statement clobbers memory: exit (1);
Dense.c:212:4: missed: statement clobbers memory: layer = PULSE_CreateLayer (args$n_inputs_43, args$n_outputs_54, 0, args$8_55, _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:209:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (args$n_inputs_43, args$n_outputs_54, 0, args$8_55, _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:222:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Dense.c:203:112: note: ***** Analysis failed with vector mode V8SI
Dense.c:203:112: note: ***** The result for vector mode V32QI would be the same
Dense.c:203:112: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:203:112: note: ***** Analysis failed with vector mode V16QI
Dense.c:203:112: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:203:112: note: ***** Analysis failed with vector mode V8QI
Dense.c:203:112: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:203:112: note: ***** Analysis failed with vector mode V4QI
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:4:18: note: vectorized 0 loops in function.
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_4, inputs_15, _3);
PULSE.c:8:2: missed: statement clobbers memory: _5 (layer_17);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_12, pretmp_26, _9);
PULSE.c:13:28: note: ***** Analysis failed with vector mode V8SI
PULSE.c:13:28: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:22:2: missed: statement clobbers memory: _1 (layer_10(D));
PULSE.c:22:2: missed: statement clobbers memory: _14 (_2);
PULSE.c:22:2: missed: statement clobbers memory: _21 (_15);
PULSE.c:22:2: missed: statement clobbers memory: _28 (_22);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_29);
PULSE.c:26:3: missed: statement clobbers memory: memset (_34, 0, _32);
PULSE.c:26:3: missed: statement clobbers memory: memset (_27, 0, _25);
PULSE.c:26:3: missed: statement clobbers memory: memset (_20, 0, _18);
PULSE.c:26:3: missed: statement clobbers memory: memset (_7, 0, _5);
PULSE.c:28:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:28:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:32:6: note: vectorized 1 loops in function.
PULSE.c:34:8: missed: statement clobbers memory: _1 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_2);
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _9 = rand ();
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8SI
PULSE.c:32:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:61:16: missed: couldn't vectorize loop
PULSE.c:61:16: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:64:17: missed: couldn't vectorize loop
PULSE.c:64:17: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:73:19: missed: couldn't vectorize loop
PULSE.c:73:19: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:53:22: missed: couldn't vectorize loop
PULSE.c:53:22: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:47:6: note: vectorized 1 loops in function.
PULSE.c:48:1: missed: statement clobbers memory: saved_stack.7_39 = __builtin_stack_save ();
PULSE.c:49:46: missed: statement clobbers memory: _1 = PULSE_GetLossFunctionPtr (loss_function_40(D));
PULSE.c:60:10: missed: statement clobbers memory: random.4_46 = __builtin_alloca_with_align (_4, 32);
PULSE.c:34:8: missed: statement clobbers memory: _61 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_62);
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _72 = rand ();
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_98, inputs_93, _97);
PULSE.c:8:2: missed: statement clobbers memory: _99 (layer_94);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_105, _104, _103);
PULSE.c:67:11: missed: statement clobbers memory: loss_55 = PULSE_GetLoss_42 (_17, _16, _12, _11);
PULSE.c:22:2: missed: statement clobbers memory: _86 (output_34);
PULSE.c:22:2: missed: statement clobbers memory: _108 (_87);
PULSE.c:22:2: missed: statement clobbers memory: _115 (_109);
PULSE.c:22:2: missed: statement clobbers memory: _122 (_116);
PULSE.c:22:2: missed: statement clobbers memory: _129 (_123);
PULSE.c:22:2: missed: statement clobbers memory: _136 (_130);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_137);
PULSE.c:26:3: missed: statement clobbers memory: memset (_142, 0, _140);
PULSE.c:26:3: missed: statement clobbers memory: memset (_135, 0, _133);
PULSE.c:26:3: missed: statement clobbers memory: memset (_128, 0, _126);
PULSE.c:26:3: missed: statement clobbers memory: memset (_121, 0, _119);
PULSE.c:26:3: missed: statement clobbers memory: memset (_114, 0, _112);
PULSE.c:26:3: missed: statement clobbers memory: memset (_92, 0, _90);
PULSE.c:75:6: missed: statement clobbers memory: _21 (current_191, args);
PULSE.c:81:4: missed: statement clobbers memory: printf ("Epoch: %d | Item: %d | Loss: %.10f | Batch Loss: %.10f\r", i_188, j_189, _25, _24);
PULSE.c:47:6: missed: statement clobbers memory: __builtin_stack_restore (saved_stack.7_39);
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4DI
PULSE.c:47:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:91:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:91:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:99:20: missed: couldn't vectorize loop
PULSE.c:99:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:99:20: missed: couldn't vectorize loop
PULSE.c:99:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:93:15: note: vectorized 0 loops in function.
PULSE.c:97:2: missed: statement clobbers memory: __builtin_va_start (&layers, 0);
PULSE.c:98:44: missed: statement clobbers memory: layers_list_21 = malloc (_3);
PULSE.c:105:67: missed: not vectorized: more than one data ref in stmt: D.6448 = MEM[(struct PULSE_DenseLayerArgs * {ref-all})addr.104_34];
PULSE.c:105:22: missed: statement clobbers memory: *_6 = PULSE_CreateDenseLayer (D.6448); [return slot optimization]
PULSE.c:105:67: missed: not vectorized: more than one data ref in stmt: D.6448 = MEM[(struct PULSE_DenseLayerArgs * {ref-all})addr.104_52];
PULSE.c:105:22: missed: statement clobbers memory: *_37 = PULSE_CreateDenseLayer (D.6448); [return slot optimization]
PULSE.c:111:2: missed: statement clobbers memory: __builtin_va_end (&layers);
PULSE.c:112:9: note: ***** Analysis failed with vector mode V8SI
PULSE.c:112:9: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:118:8: missed: couldn't vectorize loop
PULSE.c:118:8: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:115:6: note: vectorized 0 loops in function.
PULSE.c:120:3: missed: statement clobbers memory: _1 (current_11);
PULSE.c:123:2: missed: statement clobbers memory: free (layer_4(D));
PULSE.c:124:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:124:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Layer.c:7:34: missed: statement clobbers memory: _3 = aligned_alloc (64, _2);
Layer.c:8:35: missed: statement clobbers memory: _6 = aligned_alloc (64, _5);
Layer.c:9:34: missed: statement clobbers memory: _7 = aligned_alloc (64, _5);
Layer.c:14:19: missed: statement clobbers memory: _8 = PULSE_GetActivationFunctionPtr (activation_function_18(D));
Layer.c:19:9: note: ***** Analysis succeeded with vector mode V8SI
Layer.c:19:9: note: SLPing BB part
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x487d3c8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 0 MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 1 MEM <unsigned int> [(struct PULSE_Layer *)&<retval> + 4B] = optimization_type_17(D);
Layer.c:19:9: note: 	children 0x487d448
Layer.c:19:9: note: node (external) 0x487d448 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ type_16(D), optimization_type_17(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x487d4c8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 0 <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 1 <retval>.n_outputs = n_outputs_12(D);
Layer.c:19:9: note: 	children 0x487d548
Layer.c:19:9: note: node (external) 0x487d548 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x487d648 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 0 <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 1 <retval>.outputs = _6;
Layer.c:19:9: note: 	children 0x487d6c8
Layer.c:19:9: note: node (external) 0x487d6c8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	stmt 0 _3 = aligned_alloc (64, _2);
Layer.c:19:9: note: 	stmt 1 _6 = aligned_alloc (64, _5);
Layer.c:19:9: note: 	children 0x487d748 0x487d7c8
Layer.c:19:9: note: node (constant) 0x487d748 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 64, 64 }
Layer.c:19:9: note: node 0x487d7c8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: patt_38 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 0 patt_38 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 1 patt_39 = n_outputs_12(D) w* 4;
Layer.c:19:9: note: 	children 0x487d848 0x487d8c8
Layer.c:19:9: note: node (external) 0x487d848 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: node (constant) 0x487d8c8 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ 4, 4 }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x487d9c8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: op template: <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 0 <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 1 <retval>.back = back_21(D);
Layer.c:19:9: note: 	stmt 2 <retval>.fix = fix_22(D);
Layer.c:19:9: note: 	stmt 3 <retval>.destroy = destroy_23(D);
Layer.c:19:9: note: 	children 0x487da48
Layer.c:19:9: note: node (external) 0x487da48 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: 	{ feed_20(D), back_21(D), fix_22(D), destroy_23(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 64
  Scalar cost: 64
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x487dac8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 0 <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 1 <retval>.child = 0B;
Layer.c:19:9: note: 	children 0x487db48
Layer.c:19:9: note: node (constant) 0x487db48 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ 0B, 0B }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Basic block will be vectorized using SLP
Layer.c:19:9: optimized: basic block part vectorized using 8 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x487d3c8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 0 MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 1 MEM <unsigned int> [(struct PULSE_Layer *)&<retval> + 4B] = optimization_type_17(D);
Layer.c:19:9: note: 	children 0x487d448
Layer.c:19:9: note: node (external) 0x487d448 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ type_16(D), optimization_type_17(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: vect_is_simple_use: operand optimization_type_17(D), type of def: external
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>]
Layer.c:19:9: note: created &MEM <unsigned int> [(struct PULSE_Layer *)&<retval>]
Layer.c:19:9: note: add new stmt: MEM <vector(2) unsigned int> [(struct PULSE_Layer *)&<retval>] = _40;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 8 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x487d4c8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 0 <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 1 <retval>.n_outputs = n_outputs_12(D);
Layer.c:19:9: note: 	children 0x487d548
Layer.c:19:9: note: node (external) 0x487d548 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: vect_is_simple_use: operand n_outputs_12(D), type of def: external
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: <retval>.n_inputs
Layer.c:19:9: note: created &<retval>.n_inputs
Layer.c:19:9: note: add new stmt: MEM <vector(2) unsigned int> [(unsigned int *)&<retval> + 128B] = _42;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 16 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x487d648 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 0 <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 1 <retval>.outputs = _6;
Layer.c:19:9: note: 	children 0x487d6c8
Layer.c:19:9: note: node (external) 0x487d6c8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	stmt 0 _3 = aligned_alloc (64, _2);
Layer.c:19:9: note: 	stmt 1 _6 = aligned_alloc (64, _5);
Layer.c:19:9: note: 	children 0x487d748 0x487d7c8
Layer.c:19:9: note: node (constant) 0x487d748 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 64, 64 }
Layer.c:19:9: note: node 0x487d7c8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: patt_38 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 0 patt_38 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 1 patt_39 = n_outputs_12(D) w* 4;
Layer.c:19:9: note: 	children 0x487d848 0x487d8c8
Layer.c:19:9: note: node (external) 0x487d848 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: node (constant) 0x487d8c8 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ 4, 4 }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.inputs = _3;
Layer.c:19:9: note: vect_is_simple_use: operand aligned_alloc (64, _5), type of def: internal
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.inputs
Layer.c:19:9: note: created &<retval>.inputs
Layer.c:19:9: note: add new stmt: MEM <vector(2) long unsigned int> [(float * *)&<retval> + 8B] = _46;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 32 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x487d9c8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: op template: <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 0 <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 1 <retval>.back = back_21(D);
Layer.c:19:9: note: 	stmt 2 <retval>.fix = fix_22(D);
Layer.c:19:9: note: 	stmt 3 <retval>.destroy = destroy_23(D);
Layer.c:19:9: note: 	children 0x487da48
Layer.c:19:9: note: node (external) 0x487da48 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: 	{ feed_20(D), back_21(D), fix_22(D), destroy_23(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.feed = feed_20(D);
Layer.c:19:9: note: vect_is_simple_use: operand back_21(D), type of def: external
Layer.c:19:9: note: vect_is_simple_use: operand fix_22(D), type of def: external
Layer.c:19:9: note: vect_is_simple_use: operand destroy_23(D), type of def: external
Layer.c:19:9: note: conflicting alias set types.
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(4) long unsigned int  vectorizing a pointer ref: <retval>.feed
Layer.c:19:9: note: created &<retval>.feed
Layer.c:19:9: note: add new stmt: MEM <vector(4) long unsigned int> [(void *)&<retval> + 32B] = _52;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 16 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x487dac8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 0 <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 1 <retval>.child = 0B;
Layer.c:19:9: note: 	children 0x487db48
Layer.c:19:9: note: node (constant) 0x487db48 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ 0B, 0B }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.parent = 0B;
Layer.c:19:9: note: vect_is_simple_use: operand 0B, type of def: constant
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.parent
Layer.c:19:9: note: created &<retval>.parent
Layer.c:19:9: note: add new stmt: MEM <vector(2) long unsigned int> [(struct PULSE_Layer * *)&<retval> + 72B] = { 0, 0 };
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: note: ***** The result for vector mode V32QI would be the same
Layer.c:24:2: missed: statement clobbers memory: free (_1);
Layer.c:25:2: missed: statement clobbers memory: free (_2);
Layer.c:26:2: missed: statement clobbers memory: free (_3);
Layer.c:27:1: note: ***** Analysis failed with vector mode V4DI
Layer.c:27:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:9:27: missed: couldn't vectorize loop
Dense.c:9:27: missed: not vectorized: unsupported outerloop form.
Dense.c:12:20: missed: couldn't vectorize loop
Dense.c:13:21: missed: not vectorized: complicated access pattern.
Dense.c:6:13: note: vectorized 0 loops in function.
Dense.c:16:2: missed: statement clobbers memory: _28 (pretmp_91, _51, 0);
Dense.c:9:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:9:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:24:27: missed: couldn't vectorize loop
Dense.c:24:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:28:20: optimized: loop vectorized using 32 byte vectors
Dense.c:28:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:28:20: optimized: loop vectorized using 16 byte vectors
Dense.c:28:20: missed: couldn't vectorize loop
Dense.c:30:19: missed: not vectorized: no vectype for stmt: _22 = *_21;
 scalar_type: float
Dense.c:20:13: note: vectorized 1 loops in function.
Dense.c:23:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:24:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:24:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:41:28: missed: couldn't vectorize loop
Dense.c:41:28: missed: not vectorized: unsupported outerloop form.
Dense.c:45:21: optimized: loop vectorized using 32 byte vectors
Dense.c:45:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:45:21: optimized: loop vectorized using 16 byte vectors
Dense.c:37:13: note: vectorized 1 loops in function.
Dense.c:37:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:37:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:41:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:188:1: note: ***** Analysis failed with vector mode VOID
Dense.c:203:19: missed: couldn't vectorize loop
Dense.c:203:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:192:13: note: vectorized 0 loops in function.
Dense.c:197:35: missed: statement clobbers memory: _5 = aligned_alloc (64, _4);
Dense.c:198:37: missed: statement clobbers memory: _6 = aligned_alloc (64, _4);
Dense.c:199:35: missed: statement clobbers memory: _8 = aligned_alloc (64, _7);
Dense.c:200:34: missed: statement clobbers memory: _9 = aligned_alloc (64, _7);
Dense.c:201:35: missed: statement clobbers memory: _10 = aligned_alloc (64, _7);
Dense.c:204:38: missed: statement clobbers memory: _11 = rand ();
Dense.c:204:72: missed: statement clobbers memory: _56 = sqrt (_18);
Dense.c:216:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:217:4: missed: statement clobbers memory: exit (1);
Dense.c:210:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (args$n_inputs_37, args$n_outputs_47, 0, _27, _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:223:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Dense.c:223:9: note: ***** Analysis succeeded with vector mode V8SI
Dense.c:223:9: note: SLPing BB part
Dense.c:223:9: note: Costing subgraph: 
Dense.c:223:9: note: node 0x75ddf98 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Dense.c:223:9: note: op template: MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = _5;
Dense.c:223:9: note: 	stmt 0 MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = _5;
Dense.c:223:9: note: 	stmt 1 MEM <float *> [(struct PULSE_Layer *)&layer + 96B] = _8;
Dense.c:223:9: note: 	stmt 2 MEM <float *> [(struct PULSE_Layer *)&layer + 104B] = _9;
Dense.c:223:9: note: 	stmt 3 MEM <float *> [(struct PULSE_Layer *)&layer + 112B] = _10;
Dense.c:223:9: note: 	children 0x75de018
Dense.c:223:9: note: node (external) 0x75de018 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Dense.c:223:9: note: 	stmt 0 _5 = aligned_alloc (64, _4);
Dense.c:223:9: note: 	stmt 1 _8 = aligned_alloc (64, _7);
Dense.c:223:9: note: 	stmt 2 _9 = aligned_alloc (64, _7);
Dense.c:223:9: note: 	stmt 3 _10 = aligned_alloc (64, _7);
Dense.c:223:9: note: 	children 0x75de098 0x75de198
Dense.c:223:9: note: node (constant) 0x75de098 (max_nunits=1, refcnt=1)
Dense.c:223:9: note: 	{ 64, 64, 64, 64 }
Dense.c:223:9: note: node (external) 0x75de198 (max_nunits=1, refcnt=1)
Dense.c:223:9: note: 	{ _4, _7, _7, _7 }
Dense.c:223:9: note: Cost model analysis: 
Dense.c:223:9: note: Cost model analysis for part in loop 0:
  Vector cost: 64
  Scalar cost: 64
Dense.c:223:9: note: Basic block will be vectorized using SLP
Dense.c:223:9: optimized: basic block part vectorized using 32 byte vectors
Dense.c:223:9: note: Vectorizing SLP tree:
Dense.c:223:9: note: node 0x75ddf98 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Dense.c:223:9: note: op template: MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = _5;
Dense.c:223:9: note: 	stmt 0 MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = _5;
Dense.c:223:9: note: 	stmt 1 MEM <float *> [(struct PULSE_Layer *)&layer + 96B] = _8;
Dense.c:223:9: note: 	stmt 2 MEM <float *> [(struct PULSE_Layer *)&layer + 104B] = _9;
Dense.c:223:9: note: 	stmt 3 MEM <float *> [(struct PULSE_Layer *)&layer + 112B] = _10;
Dense.c:223:9: note: 	children 0x75de018
Dense.c:223:9: note: node (external) 0x75de018 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Dense.c:223:9: note: 	stmt 0 _5 = aligned_alloc (64, _4);
Dense.c:223:9: note: 	stmt 1 _8 = aligned_alloc (64, _7);
Dense.c:223:9: note: 	stmt 2 _9 = aligned_alloc (64, _7);
Dense.c:223:9: note: 	stmt 3 _10 = aligned_alloc (64, _7);
Dense.c:223:9: note: 	children 0x75de098 0x75de198
Dense.c:223:9: note: node (constant) 0x75de098 (max_nunits=1, refcnt=1)
Dense.c:223:9: note: 	{ 64, 64, 64, 64 }
Dense.c:223:9: note: node (external) 0x75de198 (max_nunits=1, refcnt=1)
Dense.c:223:9: note: 	{ _4, _7, _7, _7 }
Dense.c:223:9: note: ------>vectorizing SLP node starting from: MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = _5;
Dense.c:223:9: note: vect_is_simple_use: operand aligned_alloc (64, _7), type of def: internal
Dense.c:223:9: note: vect_is_simple_use: operand aligned_alloc (64, _7), type of def: internal
Dense.c:223:9: note: vect_is_simple_use: operand aligned_alloc (64, _7), type of def: internal
Dense.c:223:9: note: transform store. ncopies = 1
Dense.c:223:9: note: create vector_type-pointer variable to type: vector(4) long unsigned int  vectorizing a pointer ref: MEM <float *> [(struct PULSE_Layer *)&layer + 88B]
Dense.c:223:9: note: created &MEM <float *> [(struct PULSE_Layer *)&layer + 88B]
Dense.c:223:9: note: add new stmt: MEM <vector(4) long unsigned int> [(struct PULSE_Layer *)&layer + 88B] = _66;
Dense.c:223:9: note: vectorizing stmts using SLP.
Dense.c:223:9: note: ***** The result for vector mode V32QI would be the same
Activations.c:17:19: optimized: loop vectorized using 32 byte vectors
Activations.c:17:19: optimized: loop vectorized using 16 byte vectors
Activations.c:17:19: optimized: loop vectorized using 32 byte vectors
Activations.c:17:19: optimized: loop vectorized using 16 byte vectors
Activations.c:14:13: note: vectorized 2 loops in function.
Activations.c:14:13: note: ***** Analysis failed with vector mode V8SF
Activations.c:14:13: note: ***** The result for vector mode V32QI would be the same
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V16QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V16QI
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V8QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V8QI
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V4QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V4QI
Activations.c:28:19: missed: couldn't vectorize loop
Activations.c:28:19: missed: not vectorized: unsupported control flow in loop.
Activations.c:28:19: optimized: loop vectorized using 32 byte vectors
Activations.c:28:19: optimized: loop vectorized using 16 byte vectors
Activations.c:25:13: note: vectorized 1 loops in function.
Activations.c:25:13: note: ***** Analysis failed with vector mode V8SF
Activations.c:25:13: note: ***** The result for vector mode V32QI would be the same
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V16QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V16QI
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V8QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V8QI
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V4QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V4QI
Activations.c:38:1: note: ***** Analysis failed with vector mode VOID
Activations.c:5:19: missed: couldn't vectorize loop
Activations.c:9:21: missed: statement clobbers memory: _36 = expf (_18);
Activations.c:5:19: missed: couldn't vectorize loop
Activations.c:9:21: missed: statement clobbers memory: _12 = expf (_11);
Activations.c:3:13: note: vectorized 0 loops in function.
Activations.c:9:21: missed: statement clobbers memory: _12 = expf (_11);
Activations.c:9:21: missed: statement clobbers memory: _36 = expf (_18);
Activations.c:11:1: note: ***** Analysis failed with vector mode V8SF
Activations.c:11:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Activations.c:44:2: note: ***** Analysis failed with vector mode VOID
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:4:18: note: vectorized 0 loops in function.
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_4, inputs_15, _3);
PULSE.c:8:2: missed: statement clobbers memory: _5 (layer_17);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_12, pretmp_26, _9);
PULSE.c:13:28: note: ***** Analysis failed with vector mode V8SI
PULSE.c:13:28: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:22:2: missed: statement clobbers memory: _1 (layer_10(D));
PULSE.c:22:2: missed: statement clobbers memory: _14 (_2);
PULSE.c:22:2: missed: statement clobbers memory: _21 (_15);
PULSE.c:22:2: missed: statement clobbers memory: _28 (_22);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_29);
PULSE.c:26:3: missed: statement clobbers memory: memset (_34, 0, _32);
PULSE.c:26:3: missed: statement clobbers memory: memset (_27, 0, _25);
PULSE.c:26:3: missed: statement clobbers memory: memset (_20, 0, _18);
PULSE.c:26:3: missed: statement clobbers memory: memset (_7, 0, _5);
PULSE.c:28:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:28:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:32:6: note: vectorized 1 loops in function.
PULSE.c:34:8: missed: statement clobbers memory: _1 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_2);
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _9 = rand ();
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8SI
PULSE.c:32:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:61:16: missed: couldn't vectorize loop
PULSE.c:61:16: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:64:17: missed: couldn't vectorize loop
PULSE.c:64:17: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:73:19: missed: couldn't vectorize loop
PULSE.c:73:19: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:53:22: missed: couldn't vectorize loop
PULSE.c:53:22: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:47:6: note: vectorized 1 loops in function.
PULSE.c:48:1: missed: statement clobbers memory: saved_stack.7_39 = __builtin_stack_save ();
PULSE.c:49:46: missed: statement clobbers memory: _1 = PULSE_GetLossFunctionPtr (loss_function_40(D));
PULSE.c:60:10: missed: statement clobbers memory: random.4_46 = __builtin_alloca_with_align (_4, 32);
PULSE.c:34:8: missed: statement clobbers memory: _61 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_62);
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _72 = rand ();
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_98, inputs_93, _97);
PULSE.c:8:2: missed: statement clobbers memory: _99 (layer_94);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_105, _104, _103);
PULSE.c:67:11: missed: statement clobbers memory: loss_55 = PULSE_GetLoss_42 (_17, _16, _12, _11);
PULSE.c:22:2: missed: statement clobbers memory: _86 (output_34);
PULSE.c:22:2: missed: statement clobbers memory: _108 (_87);
PULSE.c:22:2: missed: statement clobbers memory: _115 (_109);
PULSE.c:22:2: missed: statement clobbers memory: _122 (_116);
PULSE.c:22:2: missed: statement clobbers memory: _129 (_123);
PULSE.c:22:2: missed: statement clobbers memory: _136 (_130);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_137);
PULSE.c:26:3: missed: statement clobbers memory: memset (_142, 0, _140);
PULSE.c:26:3: missed: statement clobbers memory: memset (_135, 0, _133);
PULSE.c:26:3: missed: statement clobbers memory: memset (_128, 0, _126);
PULSE.c:26:3: missed: statement clobbers memory: memset (_121, 0, _119);
PULSE.c:26:3: missed: statement clobbers memory: memset (_114, 0, _112);
PULSE.c:26:3: missed: statement clobbers memory: memset (_92, 0, _90);
PULSE.c:75:6: missed: statement clobbers memory: _21 (current_191, args);
PULSE.c:81:4: missed: statement clobbers memory: printf ("Epoch: %d | Item: %d | Loss: %.10f | Batch Loss: %.10f\r", i_188, j_189, _25, _24);
PULSE.c:47:6: missed: statement clobbers memory: __builtin_stack_restore (saved_stack.7_39);
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4DI
PULSE.c:47:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:91:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:91:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:99:20: missed: couldn't vectorize loop
PULSE.c:99:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:99:20: missed: couldn't vectorize loop
PULSE.c:99:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:93:15: note: vectorized 0 loops in function.
PULSE.c:97:2: missed: statement clobbers memory: __builtin_va_start (&layers, 0);
PULSE.c:98:44: missed: statement clobbers memory: layers_list_21 = malloc (_3);
PULSE.c:105:67: missed: not vectorized: more than one data ref in stmt: D.6451 = MEM[(struct PULSE_DenseLayerArgs * {ref-all})addr.104_34];
PULSE.c:105:22: missed: statement clobbers memory: *_6 = PULSE_CreateDenseLayer (D.6451); [return slot optimization]
PULSE.c:105:67: missed: not vectorized: more than one data ref in stmt: D.6451 = MEM[(struct PULSE_DenseLayerArgs * {ref-all})addr.104_52];
PULSE.c:105:22: missed: statement clobbers memory: *_37 = PULSE_CreateDenseLayer (D.6451); [return slot optimization]
PULSE.c:111:2: missed: statement clobbers memory: __builtin_va_end (&layers);
PULSE.c:112:9: note: ***** Analysis failed with vector mode V8SI
PULSE.c:112:9: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:118:8: missed: couldn't vectorize loop
PULSE.c:118:8: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:115:6: note: vectorized 0 loops in function.
PULSE.c:120:3: missed: statement clobbers memory: _1 (current_11);
PULSE.c:123:2: missed: statement clobbers memory: free (layer_4(D));
PULSE.c:124:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:124:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Loss.c:15:19: optimized: loop vectorized using 32 byte vectors
Loss.c:15:19: optimized:  loop versioned for vectorization because of possible aliasing
Loss.c:15:19: optimized: loop vectorized using 16 byte vectors
Loss.c:12:23: note: vectorized 1 loops in function.
Loss.c:12:23: note: ***** Analysis failed with vector mode V8SF
Loss.c:12:23: note: ***** The result for vector mode V32QI would be the same
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V16QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V16QI
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V8QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V8QI
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V4QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V4QI
Loss.c:7:19: missed: couldn't vectorize loop
Loss.c:8:38: missed: not vectorized: unsupported use in stmt.
Loss.c:4:23: note: vectorized 0 loops in function.
Loss.c:9:13: note: ***** Analysis failed with vector mode V8SF
Loss.c:9:13: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Loss.c:23:2: note: ***** Analysis failed with vector mode VOID
Dense.c:9:27: missed: couldn't vectorize loop
Dense.c:9:27: missed: not vectorized: unsupported outerloop form.
Dense.c:12:20: missed: couldn't vectorize loop
Dense.c:13:21: missed: not vectorized: complicated access pattern.
Dense.c:6:13: note: vectorized 0 loops in function.
Dense.c:16:2: missed: statement clobbers memory: _28 (pretmp_91, _51, 0);
Dense.c:9:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:9:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:24:27: missed: couldn't vectorize loop
Dense.c:24:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:28:20: optimized: loop vectorized using 32 byte vectors
Dense.c:28:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:28:20: optimized: loop vectorized using 16 byte vectors
Dense.c:28:20: missed: couldn't vectorize loop
Dense.c:30:19: missed: not vectorized: no vectype for stmt: _22 = *_21;
 scalar_type: float
Dense.c:20:13: note: vectorized 1 loops in function.
Dense.c:23:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:24:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:24:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:41:28: missed: couldn't vectorize loop
Dense.c:41:28: missed: not vectorized: unsupported outerloop form.
Dense.c:45:21: optimized: loop vectorized using 32 byte vectors
Dense.c:45:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:45:21: optimized: loop vectorized using 16 byte vectors
Dense.c:37:13: note: vectorized 1 loops in function.
Dense.c:37:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:37:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:41:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:188:1: note: ***** Analysis failed with vector mode VOID
Dense.c:202:19: missed: couldn't vectorize loop
Dense.c:202:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:192:13: note: vectorized 0 loops in function.
Dense.c:196:35: missed: statement clobbers memory: _5 = aligned_alloc (64, _4);
Dense.c:197:37: missed: statement clobbers memory: _6 = aligned_alloc (64, _4);
Dense.c:198:35: missed: statement clobbers memory: _8 = aligned_alloc (64, _7);
Dense.c:199:34: missed: statement clobbers memory: _9 = aligned_alloc (64, _7);
Dense.c:200:35: missed: statement clobbers memory: _10 = aligned_alloc (64, _7);
Dense.c:203:38: missed: statement clobbers memory: _11 = rand ();
Dense.c:203:72: missed: statement clobbers memory: _56 = sqrt (_18);
Dense.c:215:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:216:4: missed: statement clobbers memory: exit (1);
Dense.c:209:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (args$n_inputs_37, args$n_outputs_47, 0, _27, _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:222:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Dense.c:222:9: note: ***** Analysis succeeded with vector mode V8SI
Dense.c:222:9: note: SLPing BB part
Dense.c:222:9: note: Costing subgraph: 
Dense.c:222:9: note: node 0x7c80768 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Dense.c:222:9: note: op template: MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = _5;
Dense.c:222:9: note: 	stmt 0 MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = _5;
Dense.c:222:9: note: 	stmt 1 MEM <float *> [(struct PULSE_Layer *)&layer + 96B] = _8;
Dense.c:222:9: note: 	stmt 2 MEM <float *> [(struct PULSE_Layer *)&layer + 104B] = _9;
Dense.c:222:9: note: 	stmt 3 MEM <float *> [(struct PULSE_Layer *)&layer + 112B] = _10;
Dense.c:222:9: note: 	children 0x7c807e8
Dense.c:222:9: note: node (external) 0x7c807e8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Dense.c:222:9: note: 	stmt 0 _5 = aligned_alloc (64, _4);
Dense.c:222:9: note: 	stmt 1 _8 = aligned_alloc (64, _7);
Dense.c:222:9: note: 	stmt 2 _9 = aligned_alloc (64, _7);
Dense.c:222:9: note: 	stmt 3 _10 = aligned_alloc (64, _7);
Dense.c:222:9: note: 	children 0x7c80868 0x7c80968
Dense.c:222:9: note: node (constant) 0x7c80868 (max_nunits=1, refcnt=1)
Dense.c:222:9: note: 	{ 64, 64, 64, 64 }
Dense.c:222:9: note: node (external) 0x7c80968 (max_nunits=1, refcnt=1)
Dense.c:222:9: note: 	{ _4, _7, _7, _7 }
Dense.c:222:9: note: Cost model analysis: 
Dense.c:222:9: note: Cost model analysis for part in loop 0:
  Vector cost: 64
  Scalar cost: 64
Dense.c:222:9: note: Basic block will be vectorized using SLP
Dense.c:222:9: optimized: basic block part vectorized using 32 byte vectors
Dense.c:222:9: note: Vectorizing SLP tree:
Dense.c:222:9: note: node 0x7c80768 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Dense.c:222:9: note: op template: MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = _5;
Dense.c:222:9: note: 	stmt 0 MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = _5;
Dense.c:222:9: note: 	stmt 1 MEM <float *> [(struct PULSE_Layer *)&layer + 96B] = _8;
Dense.c:222:9: note: 	stmt 2 MEM <float *> [(struct PULSE_Layer *)&layer + 104B] = _9;
Dense.c:222:9: note: 	stmt 3 MEM <float *> [(struct PULSE_Layer *)&layer + 112B] = _10;
Dense.c:222:9: note: 	children 0x7c807e8
Dense.c:222:9: note: node (external) 0x7c807e8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Dense.c:222:9: note: 	stmt 0 _5 = aligned_alloc (64, _4);
Dense.c:222:9: note: 	stmt 1 _8 = aligned_alloc (64, _7);
Dense.c:222:9: note: 	stmt 2 _9 = aligned_alloc (64, _7);
Dense.c:222:9: note: 	stmt 3 _10 = aligned_alloc (64, _7);
Dense.c:222:9: note: 	children 0x7c80868 0x7c80968
Dense.c:222:9: note: node (constant) 0x7c80868 (max_nunits=1, refcnt=1)
Dense.c:222:9: note: 	{ 64, 64, 64, 64 }
Dense.c:222:9: note: node (external) 0x7c80968 (max_nunits=1, refcnt=1)
Dense.c:222:9: note: 	{ _4, _7, _7, _7 }
Dense.c:222:9: note: ------>vectorizing SLP node starting from: MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = _5;
Dense.c:222:9: note: vect_is_simple_use: operand aligned_alloc (64, _7), type of def: internal
Dense.c:222:9: note: vect_is_simple_use: operand aligned_alloc (64, _7), type of def: internal
Dense.c:222:9: note: vect_is_simple_use: operand aligned_alloc (64, _7), type of def: internal
Dense.c:222:9: note: transform store. ncopies = 1
Dense.c:222:9: note: create vector_type-pointer variable to type: vector(4) long unsigned int  vectorizing a pointer ref: MEM <float *> [(struct PULSE_Layer *)&layer + 88B]
Dense.c:222:9: note: created &MEM <float *> [(struct PULSE_Layer *)&layer + 88B]
Dense.c:222:9: note: add new stmt: MEM <vector(4) long unsigned int> [(struct PULSE_Layer *)&layer + 88B] = _66;
Dense.c:222:9: note: vectorizing stmts using SLP.
Dense.c:222:9: note: ***** The result for vector mode V32QI would be the same
Dense.c:9:27: missed: couldn't vectorize loop
Dense.c:9:27: missed: not vectorized: unsupported outerloop form.
Dense.c:12:20: missed: couldn't vectorize loop
Dense.c:13:21: missed: not vectorized: complicated access pattern.
Dense.c:6:13: note: vectorized 0 loops in function.
Dense.c:16:2: missed: statement clobbers memory: _28 (pretmp_91, _51, 0);
Dense.c:9:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:9:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:24:27: missed: couldn't vectorize loop
Dense.c:24:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:28:20: optimized: loop vectorized using 32 byte vectors
Dense.c:28:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:28:20: optimized: loop vectorized using 16 byte vectors
Dense.c:28:20: missed: couldn't vectorize loop
Dense.c:30:19: missed: not vectorized: no vectype for stmt: _22 = *_21;
 scalar_type: float
Dense.c:20:13: note: vectorized 1 loops in function.
Dense.c:23:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:24:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:24:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:41:28: missed: couldn't vectorize loop
Dense.c:41:28: missed: not vectorized: unsupported outerloop form.
Dense.c:45:21: optimized: loop vectorized using 32 byte vectors
Dense.c:45:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:45:21: optimized: loop vectorized using 16 byte vectors
Dense.c:37:13: note: vectorized 1 loops in function.
Dense.c:37:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:37:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:41:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:188:1: note: ***** Analysis failed with vector mode VOID
Dense.c:170:10: optimized: loop vectorized using 32 byte vectors
Dense.c:170:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:170:10: optimized: loop vectorized using 16 byte vectors
Dense.c:161:10: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_27, _64);
Dense.c:154:10: optimized: loop vectorized using 32 byte vectors
Dense.c:154:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:154:10: optimized: loop vectorized using 16 byte vectors
Dense.c:145:10: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_14, _56);
Dense.c:136:13: note: vectorized 2 loops in function.
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_14, _56);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_15, { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 });
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_27, _64);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_28, { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 });
Dense.c:136:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:136:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:105:24: missed: couldn't vectorize loop
Dense.c:105:24: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:108:17: missed: couldn't vectorize loop
Dense.c:108:17: missed: not vectorized: number of iterations cannot be computed.
Dense.c:122:24: missed: couldn't vectorize loop
Dense.c:122:24: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:125:17: missed: couldn't vectorize loop
Dense.c:125:17: missed: not vectorized: number of iterations cannot be computed.
Dense.c:90:15: missed: couldn't vectorize loop
Dense.c:90:15: missed: not vectorized: number of iterations cannot be computed.
Dense.c:83:13: note: vectorized 0 loops in function.
Dense.c:86:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:110:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:110:17: note: SLPing BB part
Dense.c:127:17: note: Costing subgraph: 
Dense.c:127:17: note: node 0x7f40178 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:127:17: note: op template: _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 0 _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 1 _198 = (sizetype) wi_137;
Dense.c:127:17: note: 	children 0x7f40278
Dense.c:127:17: note: node (external) 0x7f40278 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:127:17: note: 	{ j_135, wi_137 }
Dense.c:127:17: note: Cost model analysis: 
Dense.c:127:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:127:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:127:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: Costing subgraph: 
Dense.c:110:17: note: node 0x7f40378 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:110:17: note: op template: _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 0 _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 1 _217 = (sizetype) wi_136;
Dense.c:110:17: note: 	children 0x7f40478
Dense.c:110:17: note: node (external) 0x7f40478 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:110:17: note: 	{ j_134, wi_136 }
Dense.c:110:17: note: Cost model analysis: 
Dense.c:110:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:110:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:110:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:110:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:110:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:110:17: note: SLPing BB part
Dense.c:127:17: note: Costing subgraph: 
Dense.c:127:17: note: node 0x7f40378 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:127:17: note: op template: _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 0 _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 1 _198 = (sizetype) wi_137;
Dense.c:127:17: note: 	children 0x7f40178
Dense.c:127:17: note: node (external) 0x7f40178 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:127:17: note: 	{ j_135, wi_137 }
Dense.c:127:17: note: Cost model analysis: 
Dense.c:127:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:127:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:127:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: Costing subgraph: 
Dense.c:110:17: note: node 0x7f402f8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:110:17: note: op template: _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 0 _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 1 _217 = (sizetype) wi_136;
Dense.c:110:17: note: 	children 0x7f403f8
Dense.c:110:17: note: node (external) 0x7f403f8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:110:17: note: 	{ j_134, wi_136 }
Dense.c:110:17: note: Cost model analysis: 
Dense.c:110:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:110:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:110:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:105:51: note: ***** Analysis failed with vector mode V8QI
Dense.c:105:51: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:105:51: note: ***** Analysis failed with vector mode V4QI
Dense.c:62:15: missed: couldn't vectorize loop
Dense.c:62:15: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:75:11: optimized: loop vectorized using 32 byte vectors
Dense.c:75:11: optimized: loop vectorized using 16 byte vectors
Dense.c:66:11: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:881:10: missed: not vectorized: no vectype for stmt: _53 = MEM[(__m256 * {ref-all})w_ptr_82];
 scalar_type: __m256
Dense.c:54:13: note: vectorized 1 loops in function.
Dense.c:57:2: missed: statement clobbers memory: memcpy (_4, dense$baiases_63, _3);
Dense.c:79:2: missed: statement clobbers memory: _27 (pretmp_163, _68, 0);
Dense.c:54:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:54:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:202:19: missed: couldn't vectorize loop
Dense.c:202:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:192:13: note: vectorized 0 loops in function.
Dense.c:196:35: missed: statement clobbers memory: _5 = aligned_alloc (64, _4);
Dense.c:197:37: missed: statement clobbers memory: _6 = aligned_alloc (64, _4);
Dense.c:198:35: missed: statement clobbers memory: _8 = aligned_alloc (64, _7);
Dense.c:199:34: missed: statement clobbers memory: _9 = aligned_alloc (64, _7);
Dense.c:200:35: missed: statement clobbers memory: _10 = aligned_alloc (64, _7);
Dense.c:203:38: missed: statement clobbers memory: _11 = rand ();
Dense.c:203:72: missed: statement clobbers memory: _57 = sqrt (_18);
Dense.c:215:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:216:4: missed: statement clobbers memory: exit (1);
Dense.c:212:4: missed: statement clobbers memory: layer = PULSE_CreateLayer (args$n_inputs_36, args$n_outputs_47, 0, args$8_48, _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:209:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (args$n_inputs_36, args$n_outputs_47, 0, args$8_48, _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:222:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Dense.c:222:9: note: ***** Analysis succeeded with vector mode V8SI
Dense.c:222:9: note: SLPing BB part
Dense.c:222:9: note: Costing subgraph: 
Dense.c:222:9: note: node 0x7d83438 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Dense.c:222:9: note: op template: MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = _5;
Dense.c:222:9: note: 	stmt 0 MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = _5;
Dense.c:222:9: note: 	stmt 1 MEM <float *> [(struct PULSE_Layer *)&layer + 96B] = _8;
Dense.c:222:9: note: 	stmt 2 MEM <float *> [(struct PULSE_Layer *)&layer + 104B] = _9;
Dense.c:222:9: note: 	stmt 3 MEM <float *> [(struct PULSE_Layer *)&layer + 112B] = _10;
Dense.c:222:9: note: 	children 0x7d834b8
Dense.c:222:9: note: node (external) 0x7d834b8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Dense.c:222:9: note: 	stmt 0 _5 = aligned_alloc (64, _4);
Dense.c:222:9: note: 	stmt 1 _8 = aligned_alloc (64, _7);
Dense.c:222:9: note: 	stmt 2 _9 = aligned_alloc (64, _7);
Dense.c:222:9: note: 	stmt 3 _10 = aligned_alloc (64, _7);
Dense.c:222:9: note: 	children 0x7d83538 0x7d83638
Dense.c:222:9: note: node (constant) 0x7d83538 (max_nunits=1, refcnt=1)
Dense.c:222:9: note: 	{ 64, 64, 64, 64 }
Dense.c:222:9: note: node (external) 0x7d83638 (max_nunits=1, refcnt=1)
Dense.c:222:9: note: 	{ _4, _7, _7, _7 }
Dense.c:222:9: note: Cost model analysis: 
Dense.c:222:9: note: Cost model analysis for part in loop 0:
  Vector cost: 64
  Scalar cost: 64
Dense.c:222:9: note: Basic block will be vectorized using SLP
Dense.c:222:9: optimized: basic block part vectorized using 32 byte vectors
Dense.c:222:9: note: Vectorizing SLP tree:
Dense.c:222:9: note: node 0x7d83438 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Dense.c:222:9: note: op template: MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = _5;
Dense.c:222:9: note: 	stmt 0 MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = _5;
Dense.c:222:9: note: 	stmt 1 MEM <float *> [(struct PULSE_Layer *)&layer + 96B] = _8;
Dense.c:222:9: note: 	stmt 2 MEM <float *> [(struct PULSE_Layer *)&layer + 104B] = _9;
Dense.c:222:9: note: 	stmt 3 MEM <float *> [(struct PULSE_Layer *)&layer + 112B] = _10;
Dense.c:222:9: note: 	children 0x7d834b8
Dense.c:222:9: note: node (external) 0x7d834b8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Dense.c:222:9: note: 	stmt 0 _5 = aligned_alloc (64, _4);
Dense.c:222:9: note: 	stmt 1 _8 = aligned_alloc (64, _7);
Dense.c:222:9: note: 	stmt 2 _9 = aligned_alloc (64, _7);
Dense.c:222:9: note: 	stmt 3 _10 = aligned_alloc (64, _7);
Dense.c:222:9: note: 	children 0x7d83538 0x7d83638
Dense.c:222:9: note: node (constant) 0x7d83538 (max_nunits=1, refcnt=1)
Dense.c:222:9: note: 	{ 64, 64, 64, 64 }
Dense.c:222:9: note: node (external) 0x7d83638 (max_nunits=1, refcnt=1)
Dense.c:222:9: note: 	{ _4, _7, _7, _7 }
Dense.c:222:9: note: ------>vectorizing SLP node starting from: MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = _5;
Dense.c:222:9: note: vect_is_simple_use: operand aligned_alloc (64, _7), type of def: internal
Dense.c:222:9: note: vect_is_simple_use: operand aligned_alloc (64, _7), type of def: internal
Dense.c:222:9: note: vect_is_simple_use: operand aligned_alloc (64, _7), type of def: internal
Dense.c:222:9: note: transform store. ncopies = 1
Dense.c:222:9: note: create vector_type-pointer variable to type: vector(4) long unsigned int  vectorizing a pointer ref: MEM <float *> [(struct PULSE_Layer *)&layer + 88B]
Dense.c:222:9: note: created &MEM <float *> [(struct PULSE_Layer *)&layer + 88B]
Dense.c:222:9: note: add new stmt: MEM <vector(4) long unsigned int> [(struct PULSE_Layer *)&layer + 88B] = _55;
Dense.c:222:9: note: vectorizing stmts using SLP.
Dense.c:222:9: note: ***** The result for vector mode V32QI would be the same
Layer.c:7:34: missed: statement clobbers memory: _3 = aligned_alloc (64, _2);
Layer.c:8:35: missed: statement clobbers memory: _6 = aligned_alloc (64, _5);
Layer.c:9:34: missed: statement clobbers memory: _7 = aligned_alloc (64, _5);
Layer.c:14:19: missed: statement clobbers memory: _8 = PULSE_GetActivationFunctionPtr (activation_function_18(D));
Layer.c:19:9: note: ***** Analysis succeeded with vector mode V8SI
Layer.c:19:9: note: SLPing BB part
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x39423c8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 0 MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 1 MEM <unsigned int> [(struct PULSE_Layer *)&<retval> + 4B] = optimization_type_17(D);
Layer.c:19:9: note: 	children 0x3942448
Layer.c:19:9: note: node (external) 0x3942448 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ type_16(D), optimization_type_17(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x39424c8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 0 <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 1 <retval>.n_outputs = n_outputs_12(D);
Layer.c:19:9: note: 	children 0x3942548
Layer.c:19:9: note: node (external) 0x3942548 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x3942648 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 0 <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 1 <retval>.outputs = _6;
Layer.c:19:9: note: 	children 0x39426c8
Layer.c:19:9: note: node (external) 0x39426c8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	stmt 0 _3 = aligned_alloc (64, _2);
Layer.c:19:9: note: 	stmt 1 _6 = aligned_alloc (64, _5);
Layer.c:19:9: note: 	children 0x3942748 0x39427c8
Layer.c:19:9: note: node (constant) 0x3942748 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 64, 64 }
Layer.c:19:9: note: node 0x39427c8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: patt_38 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 0 patt_38 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 1 patt_39 = n_outputs_12(D) w* 4;
Layer.c:19:9: note: 	children 0x3942848 0x39428c8
Layer.c:19:9: note: node (external) 0x3942848 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: node (constant) 0x39428c8 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ 4, 4 }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x39429c8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: op template: <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 0 <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 1 <retval>.back = back_21(D);
Layer.c:19:9: note: 	stmt 2 <retval>.fix = fix_22(D);
Layer.c:19:9: note: 	stmt 3 <retval>.destroy = destroy_23(D);
Layer.c:19:9: note: 	children 0x3942a48
Layer.c:19:9: note: node (external) 0x3942a48 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: 	{ feed_20(D), back_21(D), fix_22(D), destroy_23(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 64
  Scalar cost: 64
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x3942ac8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 0 <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 1 <retval>.child = 0B;
Layer.c:19:9: note: 	children 0x3942b48
Layer.c:19:9: note: node (constant) 0x3942b48 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ 0B, 0B }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Basic block will be vectorized using SLP
Layer.c:19:9: optimized: basic block part vectorized using 8 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x39423c8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 0 MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 1 MEM <unsigned int> [(struct PULSE_Layer *)&<retval> + 4B] = optimization_type_17(D);
Layer.c:19:9: note: 	children 0x3942448
Layer.c:19:9: note: node (external) 0x3942448 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ type_16(D), optimization_type_17(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: vect_is_simple_use: operand optimization_type_17(D), type of def: external
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>]
Layer.c:19:9: note: created &MEM <unsigned int> [(struct PULSE_Layer *)&<retval>]
Layer.c:19:9: note: add new stmt: MEM <vector(2) unsigned int> [(struct PULSE_Layer *)&<retval>] = _40;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 8 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x39424c8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 0 <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 1 <retval>.n_outputs = n_outputs_12(D);
Layer.c:19:9: note: 	children 0x3942548
Layer.c:19:9: note: node (external) 0x3942548 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: vect_is_simple_use: operand n_outputs_12(D), type of def: external
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: <retval>.n_inputs
Layer.c:19:9: note: created &<retval>.n_inputs
Layer.c:19:9: note: add new stmt: MEM <vector(2) unsigned int> [(unsigned int *)&<retval> + 128B] = _42;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 16 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x3942648 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 0 <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 1 <retval>.outputs = _6;
Layer.c:19:9: note: 	children 0x39426c8
Layer.c:19:9: note: node (external) 0x39426c8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	stmt 0 _3 = aligned_alloc (64, _2);
Layer.c:19:9: note: 	stmt 1 _6 = aligned_alloc (64, _5);
Layer.c:19:9: note: 	children 0x3942748 0x39427c8
Layer.c:19:9: note: node (constant) 0x3942748 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 64, 64 }
Layer.c:19:9: note: node 0x39427c8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: patt_38 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 0 patt_38 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 1 patt_39 = n_outputs_12(D) w* 4;
Layer.c:19:9: note: 	children 0x3942848 0x39428c8
Layer.c:19:9: note: node (external) 0x3942848 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: node (constant) 0x39428c8 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ 4, 4 }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.inputs = _3;
Layer.c:19:9: note: vect_is_simple_use: operand aligned_alloc (64, _5), type of def: internal
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.inputs
Layer.c:19:9: note: created &<retval>.inputs
Layer.c:19:9: note: add new stmt: MEM <vector(2) long unsigned int> [(float * *)&<retval> + 8B] = _46;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 32 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x39429c8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: op template: <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 0 <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 1 <retval>.back = back_21(D);
Layer.c:19:9: note: 	stmt 2 <retval>.fix = fix_22(D);
Layer.c:19:9: note: 	stmt 3 <retval>.destroy = destroy_23(D);
Layer.c:19:9: note: 	children 0x3942a48
Layer.c:19:9: note: node (external) 0x3942a48 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: 	{ feed_20(D), back_21(D), fix_22(D), destroy_23(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.feed = feed_20(D);
Layer.c:19:9: note: vect_is_simple_use: operand back_21(D), type of def: external
Layer.c:19:9: note: vect_is_simple_use: operand fix_22(D), type of def: external
Layer.c:19:9: note: vect_is_simple_use: operand destroy_23(D), type of def: external
Layer.c:19:9: note: conflicting alias set types.
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(4) long unsigned int  vectorizing a pointer ref: <retval>.feed
Layer.c:19:9: note: created &<retval>.feed
Layer.c:19:9: note: add new stmt: MEM <vector(4) long unsigned int> [(void *)&<retval> + 32B] = _52;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 16 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x3942ac8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 0 <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 1 <retval>.child = 0B;
Layer.c:19:9: note: 	children 0x3942b48
Layer.c:19:9: note: node (constant) 0x3942b48 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ 0B, 0B }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.parent = 0B;
Layer.c:19:9: note: vect_is_simple_use: operand 0B, type of def: constant
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.parent
Layer.c:19:9: note: created &<retval>.parent
Layer.c:19:9: note: add new stmt: MEM <vector(2) long unsigned int> [(struct PULSE_Layer * *)&<retval> + 72B] = { 0, 0 };
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: note: ***** The result for vector mode V32QI would be the same
Layer.c:24:2: missed: statement clobbers memory: free (_1);
Layer.c:25:2: missed: statement clobbers memory: free (_2);
Layer.c:26:2: missed: statement clobbers memory: free (_3);
Layer.c:27:1: note: ***** Analysis failed with vector mode V4DI
Layer.c:27:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:9:27: missed: couldn't vectorize loop
Dense.c:9:27: missed: not vectorized: unsupported outerloop form.
Dense.c:12:20: missed: couldn't vectorize loop
Dense.c:13:21: missed: not vectorized: complicated access pattern.
Dense.c:6:13: note: vectorized 0 loops in function.
Dense.c:16:2: missed: statement clobbers memory: _28 (pretmp_91, _51, 0);
Dense.c:9:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:9:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:24:27: missed: couldn't vectorize loop
Dense.c:24:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:28:20: optimized: loop vectorized using 32 byte vectors
Dense.c:28:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:28:20: optimized: loop vectorized using 16 byte vectors
Dense.c:28:20: missed: couldn't vectorize loop
Dense.c:30:19: missed: not vectorized: no vectype for stmt: _22 = *_21;
 scalar_type: float
Dense.c:20:13: note: vectorized 1 loops in function.
Dense.c:23:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:24:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:24:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:41:28: missed: couldn't vectorize loop
Dense.c:41:28: missed: not vectorized: unsupported outerloop form.
Dense.c:45:21: optimized: loop vectorized using 32 byte vectors
Dense.c:45:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:45:21: optimized: loop vectorized using 16 byte vectors
Dense.c:37:13: note: vectorized 1 loops in function.
Dense.c:37:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:37:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:41:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:188:1: note: ***** Analysis failed with vector mode VOID
Dense.c:170:10: optimized: loop vectorized using 32 byte vectors
Dense.c:170:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:170:10: optimized: loop vectorized using 16 byte vectors
Dense.c:161:10: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_27, _64);
Dense.c:154:10: optimized: loop vectorized using 32 byte vectors
Dense.c:154:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:154:10: optimized: loop vectorized using 16 byte vectors
Dense.c:145:10: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_14, _56);
Dense.c:136:13: note: vectorized 2 loops in function.
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_14, _56);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_15, { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 });
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_27, _64);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_28, { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 });
Dense.c:136:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:136:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:105:24: missed: couldn't vectorize loop
Dense.c:105:24: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:108:17: missed: couldn't vectorize loop
Dense.c:108:17: missed: not vectorized: number of iterations cannot be computed.
Dense.c:122:24: missed: couldn't vectorize loop
Dense.c:122:24: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:125:17: missed: couldn't vectorize loop
Dense.c:125:17: missed: not vectorized: number of iterations cannot be computed.
Dense.c:90:15: missed: couldn't vectorize loop
Dense.c:90:15: missed: not vectorized: number of iterations cannot be computed.
Dense.c:83:13: note: vectorized 0 loops in function.
Dense.c:86:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:110:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:110:17: note: SLPing BB part
Dense.c:127:17: note: Costing subgraph: 
Dense.c:127:17: note: node 0x87fe178 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:127:17: note: op template: _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 0 _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 1 _198 = (sizetype) wi_137;
Dense.c:127:17: note: 	children 0x87fe278
Dense.c:127:17: note: node (external) 0x87fe278 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:127:17: note: 	{ j_135, wi_137 }
Dense.c:127:17: note: Cost model analysis: 
Dense.c:127:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:127:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:127:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: Costing subgraph: 
Dense.c:110:17: note: node 0x87fe378 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:110:17: note: op template: _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 0 _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 1 _217 = (sizetype) wi_136;
Dense.c:110:17: note: 	children 0x87fe478
Dense.c:110:17: note: node (external) 0x87fe478 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:110:17: note: 	{ j_134, wi_136 }
Dense.c:110:17: note: Cost model analysis: 
Dense.c:110:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:110:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:110:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:110:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:110:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:110:17: note: SLPing BB part
Dense.c:127:17: note: Costing subgraph: 
Dense.c:127:17: note: node 0x87fe378 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:127:17: note: op template: _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 0 _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 1 _198 = (sizetype) wi_137;
Dense.c:127:17: note: 	children 0x87fe178
Dense.c:127:17: note: node (external) 0x87fe178 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:127:17: note: 	{ j_135, wi_137 }
Dense.c:127:17: note: Cost model analysis: 
Dense.c:127:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:127:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:127:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: Costing subgraph: 
Dense.c:110:17: note: node 0x87fe2f8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:110:17: note: op template: _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 0 _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 1 _217 = (sizetype) wi_136;
Dense.c:110:17: note: 	children 0x87fe3f8
Dense.c:110:17: note: node (external) 0x87fe3f8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:110:17: note: 	{ j_134, wi_136 }
Dense.c:110:17: note: Cost model analysis: 
Dense.c:110:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:110:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:110:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:105:51: note: ***** Analysis failed with vector mode V8QI
Dense.c:105:51: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:105:51: note: ***** Analysis failed with vector mode V4QI
Dense.c:62:15: missed: couldn't vectorize loop
Dense.c:62:15: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:75:11: optimized: loop vectorized using 32 byte vectors
Dense.c:75:11: optimized: loop vectorized using 16 byte vectors
Dense.c:66:11: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:881:10: missed: not vectorized: no vectype for stmt: _53 = MEM[(__m256 * {ref-all})w_ptr_82];
 scalar_type: __m256
Dense.c:54:13: note: vectorized 1 loops in function.
Dense.c:57:2: missed: statement clobbers memory: memcpy (_4, dense$baiases_63, _3);
Dense.c:79:2: missed: statement clobbers memory: _27 (pretmp_163, _68, 0);
Dense.c:54:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:54:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:202:19: missed: couldn't vectorize loop
Dense.c:202:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:192:13: note: vectorized 0 loops in function.
Dense.c:196:35: missed: statement clobbers memory: _5 = aligned_alloc (64, _4);
Dense.c:197:37: missed: statement clobbers memory: _6 = aligned_alloc (64, _4);
Dense.c:198:35: missed: statement clobbers memory: _8 = aligned_alloc (64, _7);
Dense.c:199:34: missed: statement clobbers memory: _9 = aligned_alloc (64, _7);
Dense.c:200:35: missed: statement clobbers memory: _10 = aligned_alloc (64, _7);
Dense.c:203:38: missed: statement clobbers memory: _11 = rand ();
Dense.c:203:72: missed: statement clobbers memory: _57 = sqrt (_18);
Dense.c:215:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:216:4: missed: statement clobbers memory: exit (1);
Dense.c:212:4: missed: statement clobbers memory: layer = PULSE_CreateLayer (args$n_inputs_36, args$n_outputs_47, 0, args$8_48, _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:209:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (args$n_inputs_36, args$n_outputs_47, 0, args$8_48, _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:222:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Dense.c:222:9: note: ***** Analysis succeeded with vector mode V8SI
Dense.c:222:9: note: SLPing BB part
Dense.c:222:9: note: Costing subgraph: 
Dense.c:222:9: note: node 0x86978a8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Dense.c:222:9: note: op template: MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = _5;
Dense.c:222:9: note: 	stmt 0 MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = _5;
Dense.c:222:9: note: 	stmt 1 MEM <float *> [(struct PULSE_Layer *)&layer + 96B] = _8;
Dense.c:222:9: note: 	stmt 2 MEM <float *> [(struct PULSE_Layer *)&layer + 104B] = _9;
Dense.c:222:9: note: 	stmt 3 MEM <float *> [(struct PULSE_Layer *)&layer + 112B] = _10;
Dense.c:222:9: note: 	children 0x8697928
Dense.c:222:9: note: node (external) 0x8697928 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Dense.c:222:9: note: 	stmt 0 _5 = aligned_alloc (64, _4);
Dense.c:222:9: note: 	stmt 1 _8 = aligned_alloc (64, _7);
Dense.c:222:9: note: 	stmt 2 _9 = aligned_alloc (64, _7);
Dense.c:222:9: note: 	stmt 3 _10 = aligned_alloc (64, _7);
Dense.c:222:9: note: 	children 0x86979a8 0x8697aa8
Dense.c:222:9: note: node (constant) 0x86979a8 (max_nunits=1, refcnt=1)
Dense.c:222:9: note: 	{ 64, 64, 64, 64 }
Dense.c:222:9: note: node (external) 0x8697aa8 (max_nunits=1, refcnt=1)
Dense.c:222:9: note: 	{ _4, _7, _7, _7 }
Dense.c:222:9: note: Cost model analysis: 
Dense.c:222:9: note: Cost model analysis for part in loop 0:
  Vector cost: 64
  Scalar cost: 64
Dense.c:222:9: note: Basic block will be vectorized using SLP
Dense.c:222:9: optimized: basic block part vectorized using 32 byte vectors
Dense.c:222:9: note: Vectorizing SLP tree:
Dense.c:222:9: note: node 0x86978a8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Dense.c:222:9: note: op template: MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = _5;
Dense.c:222:9: note: 	stmt 0 MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = _5;
Dense.c:222:9: note: 	stmt 1 MEM <float *> [(struct PULSE_Layer *)&layer + 96B] = _8;
Dense.c:222:9: note: 	stmt 2 MEM <float *> [(struct PULSE_Layer *)&layer + 104B] = _9;
Dense.c:222:9: note: 	stmt 3 MEM <float *> [(struct PULSE_Layer *)&layer + 112B] = _10;
Dense.c:222:9: note: 	children 0x8697928
Dense.c:222:9: note: node (external) 0x8697928 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Dense.c:222:9: note: 	stmt 0 _5 = aligned_alloc (64, _4);
Dense.c:222:9: note: 	stmt 1 _8 = aligned_alloc (64, _7);
Dense.c:222:9: note: 	stmt 2 _9 = aligned_alloc (64, _7);
Dense.c:222:9: note: 	stmt 3 _10 = aligned_alloc (64, _7);
Dense.c:222:9: note: 	children 0x86979a8 0x8697aa8
Dense.c:222:9: note: node (constant) 0x86979a8 (max_nunits=1, refcnt=1)
Dense.c:222:9: note: 	{ 64, 64, 64, 64 }
Dense.c:222:9: note: node (external) 0x8697aa8 (max_nunits=1, refcnt=1)
Dense.c:222:9: note: 	{ _4, _7, _7, _7 }
Dense.c:222:9: note: ------>vectorizing SLP node starting from: MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = _5;
Dense.c:222:9: note: vect_is_simple_use: operand aligned_alloc (64, _7), type of def: internal
Dense.c:222:9: note: vect_is_simple_use: operand aligned_alloc (64, _7), type of def: internal
Dense.c:222:9: note: vect_is_simple_use: operand aligned_alloc (64, _7), type of def: internal
Dense.c:222:9: note: transform store. ncopies = 1
Dense.c:222:9: note: create vector_type-pointer variable to type: vector(4) long unsigned int  vectorizing a pointer ref: MEM <float *> [(struct PULSE_Layer *)&layer + 88B]
Dense.c:222:9: note: created &MEM <float *> [(struct PULSE_Layer *)&layer + 88B]
Dense.c:222:9: note: add new stmt: MEM <vector(4) long unsigned int> [(struct PULSE_Layer *)&layer + 88B] = _55;
Dense.c:222:9: note: vectorizing stmts using SLP.
Dense.c:222:9: note: ***** The result for vector mode V32QI would be the same
Activations.c:17:19: optimized: loop vectorized using 32 byte vectors
Activations.c:17:19: optimized: loop vectorized using 16 byte vectors
Activations.c:17:19: optimized: loop vectorized using 32 byte vectors
Activations.c:17:19: optimized: loop vectorized using 16 byte vectors
Activations.c:14:13: note: vectorized 2 loops in function.
Activations.c:14:13: note: ***** Analysis failed with vector mode V8SF
Activations.c:14:13: note: ***** The result for vector mode V32QI would be the same
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V16QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V16QI
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V8QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V8QI
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V4QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V4QI
Activations.c:28:19: missed: couldn't vectorize loop
Activations.c:28:19: missed: not vectorized: unsupported control flow in loop.
Activations.c:28:19: optimized: loop vectorized using 32 byte vectors
Activations.c:28:19: optimized: loop vectorized using 16 byte vectors
Activations.c:25:13: note: vectorized 1 loops in function.
Activations.c:25:13: note: ***** Analysis failed with vector mode V8SF
Activations.c:25:13: note: ***** The result for vector mode V32QI would be the same
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V16QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V16QI
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V8QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V8QI
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V4QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V4QI
Activations.c:38:1: note: ***** Analysis failed with vector mode VOID
Activations.c:5:19: missed: couldn't vectorize loop
Activations.c:9:21: missed: statement clobbers memory: _36 = expf (_18);
Activations.c:5:19: missed: couldn't vectorize loop
Activations.c:9:21: missed: statement clobbers memory: _12 = expf (_11);
Activations.c:3:13: note: vectorized 0 loops in function.
Activations.c:9:21: missed: statement clobbers memory: _12 = expf (_11);
Activations.c:9:21: missed: statement clobbers memory: _36 = expf (_18);
Activations.c:11:1: note: ***** Analysis failed with vector mode V8SF
Activations.c:11:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Activations.c:44:2: note: ***** Analysis failed with vector mode VOID
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:4:18: note: vectorized 0 loops in function.
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_4, inputs_15, _3);
PULSE.c:8:2: missed: statement clobbers memory: _5 (layer_17);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_12, pretmp_26, _9);
PULSE.c:13:28: note: ***** Analysis failed with vector mode V8SI
PULSE.c:13:28: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:22:2: missed: statement clobbers memory: _1 (layer_10(D));
PULSE.c:22:2: missed: statement clobbers memory: _14 (_2);
PULSE.c:22:2: missed: statement clobbers memory: _21 (_15);
PULSE.c:22:2: missed: statement clobbers memory: _28 (_22);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_29);
PULSE.c:26:3: missed: statement clobbers memory: memset (_34, 0, _32);
PULSE.c:26:3: missed: statement clobbers memory: memset (_27, 0, _25);
PULSE.c:26:3: missed: statement clobbers memory: memset (_20, 0, _18);
PULSE.c:26:3: missed: statement clobbers memory: memset (_7, 0, _5);
PULSE.c:28:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:28:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:32:6: note: vectorized 1 loops in function.
PULSE.c:34:8: missed: statement clobbers memory: _1 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_2);
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _9 = rand ();
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8SI
PULSE.c:32:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:61:16: missed: couldn't vectorize loop
PULSE.c:61:16: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:64:17: missed: couldn't vectorize loop
PULSE.c:64:17: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:73:19: missed: couldn't vectorize loop
PULSE.c:73:19: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:53:22: missed: couldn't vectorize loop
PULSE.c:53:22: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:47:6: note: vectorized 1 loops in function.
PULSE.c:48:1: missed: statement clobbers memory: saved_stack.7_39 = __builtin_stack_save ();
PULSE.c:49:46: missed: statement clobbers memory: _1 = PULSE_GetLossFunctionPtr (loss_function_40(D));
PULSE.c:60:10: missed: statement clobbers memory: random.4_46 = __builtin_alloca_with_align (_4, 32);
PULSE.c:34:8: missed: statement clobbers memory: _61 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_62);
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _72 = rand ();
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_98, inputs_93, _97);
PULSE.c:8:2: missed: statement clobbers memory: _99 (layer_94);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_105, _104, _103);
PULSE.c:67:11: missed: statement clobbers memory: loss_55 = PULSE_GetLoss_42 (_17, _16, _12, _11);
PULSE.c:22:2: missed: statement clobbers memory: _86 (output_34);
PULSE.c:22:2: missed: statement clobbers memory: _108 (_87);
PULSE.c:22:2: missed: statement clobbers memory: _115 (_109);
PULSE.c:22:2: missed: statement clobbers memory: _122 (_116);
PULSE.c:22:2: missed: statement clobbers memory: _129 (_123);
PULSE.c:22:2: missed: statement clobbers memory: _136 (_130);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_137);
PULSE.c:26:3: missed: statement clobbers memory: memset (_142, 0, _140);
PULSE.c:26:3: missed: statement clobbers memory: memset (_135, 0, _133);
PULSE.c:26:3: missed: statement clobbers memory: memset (_128, 0, _126);
PULSE.c:26:3: missed: statement clobbers memory: memset (_121, 0, _119);
PULSE.c:26:3: missed: statement clobbers memory: memset (_114, 0, _112);
PULSE.c:26:3: missed: statement clobbers memory: memset (_92, 0, _90);
PULSE.c:75:6: missed: statement clobbers memory: _21 (current_191, args);
PULSE.c:81:4: missed: statement clobbers memory: printf ("Epoch: %d | Item: %d | Loss: %.10f | Batch Loss: %.10f\r", i_188, j_189, _25, _24);
PULSE.c:47:6: missed: statement clobbers memory: __builtin_stack_restore (saved_stack.7_39);
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4DI
PULSE.c:47:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:91:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:91:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:98:20: missed: couldn't vectorize loop
PULSE.c:98:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:98:20: missed: couldn't vectorize loop
PULSE.c:98:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:93:6: note: vectorized 0 loops in function.
PULSE.c:97:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:104:62: missed: not vectorized: more than one data ref in stmt: D.6452 = MEM[(struct PULSE_DenseLayerArgs * {ref-all})addr.104_29];
PULSE.c:104:17: missed: statement clobbers memory: *_3 = PULSE_CreateDenseLayer (D.6452);
PULSE.c:104:62: missed: not vectorized: more than one data ref in stmt: D.6452 = MEM[(struct PULSE_DenseLayerArgs * {ref-all})addr.104_47];
PULSE.c:104:17: missed: statement clobbers memory: *_32 = PULSE_CreateDenseLayer (D.6452);
PULSE.c:110:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:111:1: note: ***** Analysis failed with vector mode V8SI
PULSE.c:111:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:116:8: missed: couldn't vectorize loop
PULSE.c:116:8: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:113:6: note: vectorized 0 loops in function.
PULSE.c:118:3: missed: statement clobbers memory: _1 (current_11);
PULSE.c:121:2: missed: statement clobbers memory: free (layer_4(D));
PULSE.c:122:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:122:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Loss.c:15:19: optimized: loop vectorized using 32 byte vectors
Loss.c:15:19: optimized:  loop versioned for vectorization because of possible aliasing
Loss.c:15:19: optimized: loop vectorized using 16 byte vectors
Loss.c:12:23: note: vectorized 1 loops in function.
Loss.c:12:23: note: ***** Analysis failed with vector mode V8SF
Loss.c:12:23: note: ***** The result for vector mode V32QI would be the same
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V16QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V16QI
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V8QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V8QI
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V4QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V4QI
Loss.c:7:19: missed: couldn't vectorize loop
Loss.c:8:38: missed: not vectorized: unsupported use in stmt.
Loss.c:4:23: note: vectorized 0 loops in function.
Loss.c:9:13: note: ***** Analysis failed with vector mode V8SF
Loss.c:9:13: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Loss.c:23:2: note: ***** Analysis failed with vector mode VOID
Layer.c:7:34: missed: statement clobbers memory: _3 = aligned_alloc (64, _2);
Layer.c:8:35: missed: statement clobbers memory: _6 = aligned_alloc (64, _5);
Layer.c:9:34: missed: statement clobbers memory: _7 = aligned_alloc (64, _5);
Layer.c:14:19: missed: statement clobbers memory: _8 = PULSE_GetActivationFunctionPtr (activation_function_18(D));
Layer.c:19:9: note: ***** Analysis succeeded with vector mode V8SI
Layer.c:19:9: note: SLPing BB part
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x3c228b8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 0 MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 1 MEM <unsigned int> [(struct PULSE_Layer *)&<retval> + 4B] = optimization_type_17(D);
Layer.c:19:9: note: 	children 0x3c22938
Layer.c:19:9: note: node (external) 0x3c22938 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ type_16(D), optimization_type_17(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x3c229b8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 0 <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 1 <retval>.n_outputs = n_outputs_12(D);
Layer.c:19:9: note: 	children 0x3c22a38
Layer.c:19:9: note: node (external) 0x3c22a38 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x3c22b38 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 0 <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 1 <retval>.outputs = _6;
Layer.c:19:9: note: 	children 0x3c22bb8
Layer.c:19:9: note: node (external) 0x3c22bb8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	stmt 0 _3 = aligned_alloc (64, _2);
Layer.c:19:9: note: 	stmt 1 _6 = aligned_alloc (64, _5);
Layer.c:19:9: note: 	children 0x3c22c38 0x3c22cb8
Layer.c:19:9: note: node (constant) 0x3c22c38 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 64, 64 }
Layer.c:19:9: note: node 0x3c22cb8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: patt_38 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 0 patt_38 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 1 patt_39 = n_outputs_12(D) w* 4;
Layer.c:19:9: note: 	children 0x3c22d38 0x3c22db8
Layer.c:19:9: note: node (external) 0x3c22d38 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: node (constant) 0x3c22db8 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ 4, 4 }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x3c22eb8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: op template: <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 0 <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 1 <retval>.back = back_21(D);
Layer.c:19:9: note: 	stmt 2 <retval>.fix = fix_22(D);
Layer.c:19:9: note: 	stmt 3 <retval>.destroy = destroy_23(D);
Layer.c:19:9: note: 	children 0x3c22f38
Layer.c:19:9: note: node (external) 0x3c22f38 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: 	{ feed_20(D), back_21(D), fix_22(D), destroy_23(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 64
  Scalar cost: 64
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x3c22fb8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 0 <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 1 <retval>.child = 0B;
Layer.c:19:9: note: 	children 0x3c23038
Layer.c:19:9: note: node (constant) 0x3c23038 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ 0B, 0B }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Basic block will be vectorized using SLP
Layer.c:19:9: optimized: basic block part vectorized using 8 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x3c228b8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 0 MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 1 MEM <unsigned int> [(struct PULSE_Layer *)&<retval> + 4B] = optimization_type_17(D);
Layer.c:19:9: note: 	children 0x3c22938
Layer.c:19:9: note: node (external) 0x3c22938 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ type_16(D), optimization_type_17(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: vect_is_simple_use: operand optimization_type_17(D), type of def: external
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>]
Layer.c:19:9: note: created &MEM <unsigned int> [(struct PULSE_Layer *)&<retval>]
Layer.c:19:9: note: add new stmt: MEM <vector(2) unsigned int> [(struct PULSE_Layer *)&<retval>] = _40;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 8 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x3c229b8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 0 <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 1 <retval>.n_outputs = n_outputs_12(D);
Layer.c:19:9: note: 	children 0x3c22a38
Layer.c:19:9: note: node (external) 0x3c22a38 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: vect_is_simple_use: operand n_outputs_12(D), type of def: external
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: <retval>.n_inputs
Layer.c:19:9: note: created &<retval>.n_inputs
Layer.c:19:9: note: add new stmt: MEM <vector(2) unsigned int> [(unsigned int *)&<retval> + 128B] = _42;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 16 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x3c22b38 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 0 <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 1 <retval>.outputs = _6;
Layer.c:19:9: note: 	children 0x3c22bb8
Layer.c:19:9: note: node (external) 0x3c22bb8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	stmt 0 _3 = aligned_alloc (64, _2);
Layer.c:19:9: note: 	stmt 1 _6 = aligned_alloc (64, _5);
Layer.c:19:9: note: 	children 0x3c22c38 0x3c22cb8
Layer.c:19:9: note: node (constant) 0x3c22c38 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 64, 64 }
Layer.c:19:9: note: node 0x3c22cb8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: patt_38 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 0 patt_38 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 1 patt_39 = n_outputs_12(D) w* 4;
Layer.c:19:9: note: 	children 0x3c22d38 0x3c22db8
Layer.c:19:9: note: node (external) 0x3c22d38 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: node (constant) 0x3c22db8 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ 4, 4 }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.inputs = _3;
Layer.c:19:9: note: vect_is_simple_use: operand aligned_alloc (64, _5), type of def: internal
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.inputs
Layer.c:19:9: note: created &<retval>.inputs
Layer.c:19:9: note: add new stmt: MEM <vector(2) long unsigned int> [(float * *)&<retval> + 8B] = _46;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 32 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x3c22eb8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: op template: <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 0 <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 1 <retval>.back = back_21(D);
Layer.c:19:9: note: 	stmt 2 <retval>.fix = fix_22(D);
Layer.c:19:9: note: 	stmt 3 <retval>.destroy = destroy_23(D);
Layer.c:19:9: note: 	children 0x3c22f38
Layer.c:19:9: note: node (external) 0x3c22f38 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: 	{ feed_20(D), back_21(D), fix_22(D), destroy_23(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.feed = feed_20(D);
Layer.c:19:9: note: vect_is_simple_use: operand back_21(D), type of def: external
Layer.c:19:9: note: vect_is_simple_use: operand fix_22(D), type of def: external
Layer.c:19:9: note: vect_is_simple_use: operand destroy_23(D), type of def: external
Layer.c:19:9: note: conflicting alias set types.
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(4) long unsigned int  vectorizing a pointer ref: <retval>.feed
Layer.c:19:9: note: created &<retval>.feed
Layer.c:19:9: note: add new stmt: MEM <vector(4) long unsigned int> [(void *)&<retval> + 32B] = _52;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 16 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x3c22fb8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 0 <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 1 <retval>.child = 0B;
Layer.c:19:9: note: 	children 0x3c23038
Layer.c:19:9: note: node (constant) 0x3c23038 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ 0B, 0B }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.parent = 0B;
Layer.c:19:9: note: vect_is_simple_use: operand 0B, type of def: constant
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.parent
Layer.c:19:9: note: created &<retval>.parent
Layer.c:19:9: note: add new stmt: MEM <vector(2) long unsigned int> [(struct PULSE_Layer * *)&<retval> + 72B] = { 0, 0 };
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: note: ***** The result for vector mode V32QI would be the same
Layer.c:24:2: missed: statement clobbers memory: free (_1);
Layer.c:25:2: missed: statement clobbers memory: free (_2);
Layer.c:26:2: missed: statement clobbers memory: free (_3);
Layer.c:27:1: note: ***** Analysis failed with vector mode V4DI
Layer.c:27:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:9:27: missed: couldn't vectorize loop
Dense.c:9:27: missed: not vectorized: unsupported outerloop form.
Dense.c:12:20: missed: couldn't vectorize loop
Dense.c:13:21: missed: not vectorized: complicated access pattern.
Dense.c:6:13: note: vectorized 0 loops in function.
Dense.c:16:2: missed: statement clobbers memory: _28 (pretmp_91, _51, 0);
Dense.c:9:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:9:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:24:27: missed: couldn't vectorize loop
Dense.c:24:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:28:20: optimized: loop vectorized using 32 byte vectors
Dense.c:28:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:28:20: optimized: loop vectorized using 16 byte vectors
Dense.c:28:20: missed: couldn't vectorize loop
Dense.c:30:19: missed: not vectorized: no vectype for stmt: _22 = *_21;
 scalar_type: float
Dense.c:20:13: note: vectorized 1 loops in function.
Dense.c:23:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:24:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:24:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:41:28: missed: couldn't vectorize loop
Dense.c:41:28: missed: not vectorized: unsupported outerloop form.
Dense.c:45:21: optimized: loop vectorized using 32 byte vectors
Dense.c:45:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:45:21: optimized: loop vectorized using 16 byte vectors
Dense.c:37:13: note: vectorized 1 loops in function.
Dense.c:37:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:37:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:41:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:188:1: note: ***** Analysis failed with vector mode VOID
Dense.c:170:10: optimized: loop vectorized using 32 byte vectors
Dense.c:170:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:170:10: optimized: loop vectorized using 16 byte vectors
Dense.c:161:10: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_27, _64);
Dense.c:154:10: optimized: loop vectorized using 32 byte vectors
Dense.c:154:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:154:10: optimized: loop vectorized using 16 byte vectors
Dense.c:145:10: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_14, _56);
Dense.c:136:13: note: vectorized 2 loops in function.
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_14, _56);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_15, { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 });
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_27, _64);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_28, { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 });
Dense.c:136:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:136:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:105:24: missed: couldn't vectorize loop
Dense.c:105:24: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:108:17: missed: couldn't vectorize loop
Dense.c:108:17: missed: not vectorized: number of iterations cannot be computed.
Dense.c:122:24: missed: couldn't vectorize loop
Dense.c:122:24: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:125:17: missed: couldn't vectorize loop
Dense.c:125:17: missed: not vectorized: number of iterations cannot be computed.
Dense.c:90:15: missed: couldn't vectorize loop
Dense.c:90:15: missed: not vectorized: number of iterations cannot be computed.
Dense.c:83:13: note: vectorized 0 loops in function.
Dense.c:86:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:110:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:110:17: note: SLPing BB part
Dense.c:127:17: note: Costing subgraph: 
Dense.c:127:17: note: node 0x79f7178 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:127:17: note: op template: _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 0 _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 1 _198 = (sizetype) wi_137;
Dense.c:127:17: note: 	children 0x79f7278
Dense.c:127:17: note: node (external) 0x79f7278 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:127:17: note: 	{ j_135, wi_137 }
Dense.c:127:17: note: Cost model analysis: 
Dense.c:127:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:127:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:127:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: Costing subgraph: 
Dense.c:110:17: note: node 0x79f7378 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:110:17: note: op template: _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 0 _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 1 _217 = (sizetype) wi_136;
Dense.c:110:17: note: 	children 0x79f7478
Dense.c:110:17: note: node (external) 0x79f7478 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:110:17: note: 	{ j_134, wi_136 }
Dense.c:110:17: note: Cost model analysis: 
Dense.c:110:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:110:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:110:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:110:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:110:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:110:17: note: SLPing BB part
Dense.c:127:17: note: Costing subgraph: 
Dense.c:127:17: note: node 0x79f7378 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:127:17: note: op template: _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 0 _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 1 _198 = (sizetype) wi_137;
Dense.c:127:17: note: 	children 0x79f7178
Dense.c:127:17: note: node (external) 0x79f7178 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:127:17: note: 	{ j_135, wi_137 }
Dense.c:127:17: note: Cost model analysis: 
Dense.c:127:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:127:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:127:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: Costing subgraph: 
Dense.c:110:17: note: node 0x79f72f8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:110:17: note: op template: _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 0 _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 1 _217 = (sizetype) wi_136;
Dense.c:110:17: note: 	children 0x79f73f8
Dense.c:110:17: note: node (external) 0x79f73f8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:110:17: note: 	{ j_134, wi_136 }
Dense.c:110:17: note: Cost model analysis: 
Dense.c:110:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:110:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:110:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:105:51: note: ***** Analysis failed with vector mode V8QI
Dense.c:105:51: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:105:51: note: ***** Analysis failed with vector mode V4QI
Dense.c:62:15: missed: couldn't vectorize loop
Dense.c:62:15: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:75:11: optimized: loop vectorized using 32 byte vectors
Dense.c:75:11: optimized: loop vectorized using 16 byte vectors
Dense.c:66:11: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:881:10: missed: not vectorized: no vectype for stmt: _53 = MEM[(__m256 * {ref-all})w_ptr_82];
 scalar_type: __m256
Dense.c:54:13: note: vectorized 1 loops in function.
Dense.c:57:2: missed: statement clobbers memory: memcpy (_4, dense$baiases_63, _3);
Dense.c:79:2: missed: statement clobbers memory: _27 (pretmp_163, _68, 0);
Dense.c:54:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:54:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:202:19: missed: couldn't vectorize loop
Dense.c:202:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:192:13: note: vectorized 0 loops in function.
Dense.c:196:35: missed: statement clobbers memory: _5 = aligned_alloc (64, _4);
Dense.c:197:37: missed: statement clobbers memory: _6 = aligned_alloc (64, _4);
Dense.c:198:35: missed: statement clobbers memory: _8 = aligned_alloc (64, _7);
Dense.c:199:34: missed: statement clobbers memory: _9 = aligned_alloc (64, _7);
Dense.c:200:35: missed: statement clobbers memory: _10 = aligned_alloc (64, _7);
Dense.c:203:38: missed: statement clobbers memory: _11 = rand ();
Dense.c:203:72: missed: statement clobbers memory: _57 = sqrt (_18);
Dense.c:215:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:216:4: missed: statement clobbers memory: exit (1);
Dense.c:212:4: missed: statement clobbers memory: layer = PULSE_CreateLayer (args$n_inputs_36, args$n_outputs_47, 0, args$8_48, _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:209:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (args$n_inputs_36, args$n_outputs_47, 0, args$8_48, _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:222:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Dense.c:222:9: note: ***** Analysis succeeded with vector mode V8SI
Dense.c:222:9: note: SLPing BB part
Dense.c:222:9: note: Costing subgraph: 
Dense.c:222:9: note: node 0x783a438 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Dense.c:222:9: note: op template: MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = _5;
Dense.c:222:9: note: 	stmt 0 MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = _5;
Dense.c:222:9: note: 	stmt 1 MEM <float *> [(struct PULSE_Layer *)&layer + 96B] = _8;
Dense.c:222:9: note: 	stmt 2 MEM <float *> [(struct PULSE_Layer *)&layer + 104B] = _9;
Dense.c:222:9: note: 	stmt 3 MEM <float *> [(struct PULSE_Layer *)&layer + 112B] = _10;
Dense.c:222:9: note: 	children 0x783a4b8
Dense.c:222:9: note: node (external) 0x783a4b8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Dense.c:222:9: note: 	stmt 0 _5 = aligned_alloc (64, _4);
Dense.c:222:9: note: 	stmt 1 _8 = aligned_alloc (64, _7);
Dense.c:222:9: note: 	stmt 2 _9 = aligned_alloc (64, _7);
Dense.c:222:9: note: 	stmt 3 _10 = aligned_alloc (64, _7);
Dense.c:222:9: note: 	children 0x783a538 0x783a638
Dense.c:222:9: note: node (constant) 0x783a538 (max_nunits=1, refcnt=1)
Dense.c:222:9: note: 	{ 64, 64, 64, 64 }
Dense.c:222:9: note: node (external) 0x783a638 (max_nunits=1, refcnt=1)
Dense.c:222:9: note: 	{ _4, _7, _7, _7 }
Dense.c:222:9: note: Cost model analysis: 
Dense.c:222:9: note: Cost model analysis for part in loop 0:
  Vector cost: 64
  Scalar cost: 64
Dense.c:222:9: note: Basic block will be vectorized using SLP
Dense.c:222:9: optimized: basic block part vectorized using 32 byte vectors
Dense.c:222:9: note: Vectorizing SLP tree:
Dense.c:222:9: note: node 0x783a438 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Dense.c:222:9: note: op template: MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = _5;
Dense.c:222:9: note: 	stmt 0 MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = _5;
Dense.c:222:9: note: 	stmt 1 MEM <float *> [(struct PULSE_Layer *)&layer + 96B] = _8;
Dense.c:222:9: note: 	stmt 2 MEM <float *> [(struct PULSE_Layer *)&layer + 104B] = _9;
Dense.c:222:9: note: 	stmt 3 MEM <float *> [(struct PULSE_Layer *)&layer + 112B] = _10;
Dense.c:222:9: note: 	children 0x783a4b8
Dense.c:222:9: note: node (external) 0x783a4b8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Dense.c:222:9: note: 	stmt 0 _5 = aligned_alloc (64, _4);
Dense.c:222:9: note: 	stmt 1 _8 = aligned_alloc (64, _7);
Dense.c:222:9: note: 	stmt 2 _9 = aligned_alloc (64, _7);
Dense.c:222:9: note: 	stmt 3 _10 = aligned_alloc (64, _7);
Dense.c:222:9: note: 	children 0x783a538 0x783a638
Dense.c:222:9: note: node (constant) 0x783a538 (max_nunits=1, refcnt=1)
Dense.c:222:9: note: 	{ 64, 64, 64, 64 }
Dense.c:222:9: note: node (external) 0x783a638 (max_nunits=1, refcnt=1)
Dense.c:222:9: note: 	{ _4, _7, _7, _7 }
Dense.c:222:9: note: ------>vectorizing SLP node starting from: MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = _5;
Dense.c:222:9: note: vect_is_simple_use: operand aligned_alloc (64, _7), type of def: internal
Dense.c:222:9: note: vect_is_simple_use: operand aligned_alloc (64, _7), type of def: internal
Dense.c:222:9: note: vect_is_simple_use: operand aligned_alloc (64, _7), type of def: internal
Dense.c:222:9: note: transform store. ncopies = 1
Dense.c:222:9: note: create vector_type-pointer variable to type: vector(4) long unsigned int  vectorizing a pointer ref: MEM <float *> [(struct PULSE_Layer *)&layer + 88B]
Dense.c:222:9: note: created &MEM <float *> [(struct PULSE_Layer *)&layer + 88B]
Dense.c:222:9: note: add new stmt: MEM <vector(4) long unsigned int> [(struct PULSE_Layer *)&layer + 88B] = _55;
Dense.c:222:9: note: vectorizing stmts using SLP.
Dense.c:222:9: note: ***** The result for vector mode V32QI would be the same
Activations.c:17:19: optimized: loop vectorized using 32 byte vectors
Activations.c:17:19: optimized: loop vectorized using 16 byte vectors
Activations.c:17:19: optimized: loop vectorized using 32 byte vectors
Activations.c:17:19: optimized: loop vectorized using 16 byte vectors
Activations.c:14:13: note: vectorized 2 loops in function.
Activations.c:14:13: note: ***** Analysis failed with vector mode V8SF
Activations.c:14:13: note: ***** The result for vector mode V32QI would be the same
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V16QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V16QI
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V8QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V8QI
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V4QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V4QI
Activations.c:28:19: missed: couldn't vectorize loop
Activations.c:28:19: missed: not vectorized: unsupported control flow in loop.
Activations.c:28:19: optimized: loop vectorized using 32 byte vectors
Activations.c:28:19: optimized: loop vectorized using 16 byte vectors
Activations.c:25:13: note: vectorized 1 loops in function.
Activations.c:25:13: note: ***** Analysis failed with vector mode V8SF
Activations.c:25:13: note: ***** The result for vector mode V32QI would be the same
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V16QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V16QI
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V8QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V8QI
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V4QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V4QI
Activations.c:38:1: note: ***** Analysis failed with vector mode VOID
Activations.c:5:19: missed: couldn't vectorize loop
Activations.c:9:21: missed: statement clobbers memory: _36 = expf (_18);
Activations.c:5:19: missed: couldn't vectorize loop
Activations.c:9:21: missed: statement clobbers memory: _12 = expf (_11);
Activations.c:3:13: note: vectorized 0 loops in function.
Activations.c:9:21: missed: statement clobbers memory: _12 = expf (_11);
Activations.c:9:21: missed: statement clobbers memory: _36 = expf (_18);
Activations.c:11:1: note: ***** Analysis failed with vector mode V8SF
Activations.c:11:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Activations.c:44:2: note: ***** Analysis failed with vector mode VOID
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:4:18: note: vectorized 0 loops in function.
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_4, inputs_15, _3);
PULSE.c:8:2: missed: statement clobbers memory: _5 (layer_17);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_12, pretmp_26, _9);
PULSE.c:13:28: note: ***** Analysis failed with vector mode V8SI
PULSE.c:13:28: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:22:2: missed: statement clobbers memory: _1 (layer_10(D));
PULSE.c:22:2: missed: statement clobbers memory: _14 (_2);
PULSE.c:22:2: missed: statement clobbers memory: _21 (_15);
PULSE.c:22:2: missed: statement clobbers memory: _28 (_22);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_29);
PULSE.c:26:3: missed: statement clobbers memory: memset (_34, 0, _32);
PULSE.c:26:3: missed: statement clobbers memory: memset (_27, 0, _25);
PULSE.c:26:3: missed: statement clobbers memory: memset (_20, 0, _18);
PULSE.c:26:3: missed: statement clobbers memory: memset (_7, 0, _5);
PULSE.c:28:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:28:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:32:6: note: vectorized 1 loops in function.
PULSE.c:34:8: missed: statement clobbers memory: _1 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_2);
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _9 = rand ();
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8SI
PULSE.c:32:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:61:16: missed: couldn't vectorize loop
PULSE.c:61:16: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:64:17: missed: couldn't vectorize loop
PULSE.c:64:17: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:73:19: missed: couldn't vectorize loop
PULSE.c:73:19: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:53:22: missed: couldn't vectorize loop
PULSE.c:53:22: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:47:6: note: vectorized 1 loops in function.
PULSE.c:48:1: missed: statement clobbers memory: saved_stack.7_39 = __builtin_stack_save ();
PULSE.c:49:46: missed: statement clobbers memory: _1 = PULSE_GetLossFunctionPtr (loss_function_40(D));
PULSE.c:60:10: missed: statement clobbers memory: random.4_46 = __builtin_alloca_with_align (_4, 32);
PULSE.c:34:8: missed: statement clobbers memory: _61 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_62);
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _72 = rand ();
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_98, inputs_93, _97);
PULSE.c:8:2: missed: statement clobbers memory: _99 (layer_94);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_105, _104, _103);
PULSE.c:67:11: missed: statement clobbers memory: loss_55 = PULSE_GetLoss_42 (_17, _16, _12, _11);
PULSE.c:22:2: missed: statement clobbers memory: _86 (output_34);
PULSE.c:22:2: missed: statement clobbers memory: _108 (_87);
PULSE.c:22:2: missed: statement clobbers memory: _115 (_109);
PULSE.c:22:2: missed: statement clobbers memory: _122 (_116);
PULSE.c:22:2: missed: statement clobbers memory: _129 (_123);
PULSE.c:22:2: missed: statement clobbers memory: _136 (_130);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_137);
PULSE.c:26:3: missed: statement clobbers memory: memset (_142, 0, _140);
PULSE.c:26:3: missed: statement clobbers memory: memset (_135, 0, _133);
PULSE.c:26:3: missed: statement clobbers memory: memset (_128, 0, _126);
PULSE.c:26:3: missed: statement clobbers memory: memset (_121, 0, _119);
PULSE.c:26:3: missed: statement clobbers memory: memset (_114, 0, _112);
PULSE.c:26:3: missed: statement clobbers memory: memset (_92, 0, _90);
PULSE.c:75:6: missed: statement clobbers memory: _21 (current_191, args);
PULSE.c:81:4: missed: statement clobbers memory: printf ("Epoch: %d | Item: %d | Loss: %.10f | Batch Loss: %.10f\r", i_188, j_189, _25, _24);
PULSE.c:47:6: missed: statement clobbers memory: __builtin_stack_restore (saved_stack.7_39);
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4DI
PULSE.c:47:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:91:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:91:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:98:20: missed: couldn't vectorize loop
PULSE.c:98:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:98:20: missed: couldn't vectorize loop
PULSE.c:98:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:93:6: note: vectorized 0 loops in function.
PULSE.c:97:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:104:62: missed: not vectorized: more than one data ref in stmt: D.6452 = MEM[(struct PULSE_DenseLayerArgs * {ref-all})addr.104_29];
PULSE.c:104:17: missed: statement clobbers memory: *_3 = PULSE_CreateDenseLayer (D.6452);
PULSE.c:104:62: missed: not vectorized: more than one data ref in stmt: D.6452 = MEM[(struct PULSE_DenseLayerArgs * {ref-all})addr.104_47];
PULSE.c:104:17: missed: statement clobbers memory: *_32 = PULSE_CreateDenseLayer (D.6452);
PULSE.c:110:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:111:1: note: ***** Analysis failed with vector mode V8SI
PULSE.c:111:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:116:8: missed: couldn't vectorize loop
PULSE.c:116:8: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:113:6: note: vectorized 0 loops in function.
PULSE.c:118:3: missed: statement clobbers memory: _1 (current_11);
PULSE.c:121:2: missed: statement clobbers memory: free (layer_4(D));
PULSE.c:122:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:122:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Loss.c:15:19: optimized: loop vectorized using 32 byte vectors
Loss.c:15:19: optimized:  loop versioned for vectorization because of possible aliasing
Loss.c:15:19: optimized: loop vectorized using 16 byte vectors
Loss.c:12:23: note: vectorized 1 loops in function.
Loss.c:12:23: note: ***** Analysis failed with vector mode V8SF
Loss.c:12:23: note: ***** The result for vector mode V32QI would be the same
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V16QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V16QI
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V8QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V8QI
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V4QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V4QI
Loss.c:7:19: missed: couldn't vectorize loop
Loss.c:8:38: missed: not vectorized: unsupported use in stmt.
Loss.c:4:23: note: vectorized 0 loops in function.
Loss.c:9:13: note: ***** Analysis failed with vector mode V8SF
Loss.c:9:13: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Loss.c:23:2: note: ***** Analysis failed with vector mode VOID
Layer.c:7:34: missed: statement clobbers memory: _3 = aligned_alloc (64, _2);
Layer.c:8:35: missed: statement clobbers memory: _6 = aligned_alloc (64, _5);
Layer.c:9:34: missed: statement clobbers memory: _7 = aligned_alloc (64, _5);
Layer.c:14:19: missed: statement clobbers memory: _8 = PULSE_GetActivationFunctionPtr (activation_function_18(D));
Layer.c:19:9: note: ***** Analysis succeeded with vector mode V8SI
Layer.c:19:9: note: SLPing BB part
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x3f043c8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 0 MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 1 MEM <unsigned int> [(struct PULSE_Layer *)&<retval> + 4B] = optimization_type_17(D);
Layer.c:19:9: note: 	children 0x3f04448
Layer.c:19:9: note: node (external) 0x3f04448 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ type_16(D), optimization_type_17(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x3f044c8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 0 <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 1 <retval>.n_outputs = n_outputs_12(D);
Layer.c:19:9: note: 	children 0x3f04548
Layer.c:19:9: note: node (external) 0x3f04548 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x3f04648 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 0 <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 1 <retval>.outputs = _6;
Layer.c:19:9: note: 	children 0x3f046c8
Layer.c:19:9: note: node (external) 0x3f046c8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	stmt 0 _3 = aligned_alloc (64, _2);
Layer.c:19:9: note: 	stmt 1 _6 = aligned_alloc (64, _5);
Layer.c:19:9: note: 	children 0x3f04748 0x3f047c8
Layer.c:19:9: note: node (constant) 0x3f04748 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 64, 64 }
Layer.c:19:9: note: node 0x3f047c8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: patt_38 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 0 patt_38 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 1 patt_39 = n_outputs_12(D) w* 4;
Layer.c:19:9: note: 	children 0x3f04848 0x3f048c8
Layer.c:19:9: note: node (external) 0x3f04848 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: node (constant) 0x3f048c8 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ 4, 4 }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x3f049c8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: op template: <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 0 <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 1 <retval>.back = back_21(D);
Layer.c:19:9: note: 	stmt 2 <retval>.fix = fix_22(D);
Layer.c:19:9: note: 	stmt 3 <retval>.destroy = destroy_23(D);
Layer.c:19:9: note: 	children 0x3f04a48
Layer.c:19:9: note: node (external) 0x3f04a48 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: 	{ feed_20(D), back_21(D), fix_22(D), destroy_23(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 64
  Scalar cost: 64
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x3f04ac8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 0 <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 1 <retval>.child = 0B;
Layer.c:19:9: note: 	children 0x3f04b48
Layer.c:19:9: note: node (constant) 0x3f04b48 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ 0B, 0B }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Basic block will be vectorized using SLP
Layer.c:19:9: optimized: basic block part vectorized using 8 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x3f043c8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 0 MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 1 MEM <unsigned int> [(struct PULSE_Layer *)&<retval> + 4B] = optimization_type_17(D);
Layer.c:19:9: note: 	children 0x3f04448
Layer.c:19:9: note: node (external) 0x3f04448 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ type_16(D), optimization_type_17(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: vect_is_simple_use: operand optimization_type_17(D), type of def: external
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>]
Layer.c:19:9: note: created &MEM <unsigned int> [(struct PULSE_Layer *)&<retval>]
Layer.c:19:9: note: add new stmt: MEM <vector(2) unsigned int> [(struct PULSE_Layer *)&<retval>] = _40;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 8 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x3f044c8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 0 <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 1 <retval>.n_outputs = n_outputs_12(D);
Layer.c:19:9: note: 	children 0x3f04548
Layer.c:19:9: note: node (external) 0x3f04548 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: vect_is_simple_use: operand n_outputs_12(D), type of def: external
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: <retval>.n_inputs
Layer.c:19:9: note: created &<retval>.n_inputs
Layer.c:19:9: note: add new stmt: MEM <vector(2) unsigned int> [(unsigned int *)&<retval> + 128B] = _42;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 16 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x3f04648 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 0 <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 1 <retval>.outputs = _6;
Layer.c:19:9: note: 	children 0x3f046c8
Layer.c:19:9: note: node (external) 0x3f046c8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	stmt 0 _3 = aligned_alloc (64, _2);
Layer.c:19:9: note: 	stmt 1 _6 = aligned_alloc (64, _5);
Layer.c:19:9: note: 	children 0x3f04748 0x3f047c8
Layer.c:19:9: note: node (constant) 0x3f04748 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 64, 64 }
Layer.c:19:9: note: node 0x3f047c8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: patt_38 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 0 patt_38 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 1 patt_39 = n_outputs_12(D) w* 4;
Layer.c:19:9: note: 	children 0x3f04848 0x3f048c8
Layer.c:19:9: note: node (external) 0x3f04848 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: node (constant) 0x3f048c8 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ 4, 4 }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.inputs = _3;
Layer.c:19:9: note: vect_is_simple_use: operand aligned_alloc (64, _5), type of def: internal
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.inputs
Layer.c:19:9: note: created &<retval>.inputs
Layer.c:19:9: note: add new stmt: MEM <vector(2) long unsigned int> [(float * *)&<retval> + 8B] = _46;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 32 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x3f049c8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: op template: <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 0 <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 1 <retval>.back = back_21(D);
Layer.c:19:9: note: 	stmt 2 <retval>.fix = fix_22(D);
Layer.c:19:9: note: 	stmt 3 <retval>.destroy = destroy_23(D);
Layer.c:19:9: note: 	children 0x3f04a48
Layer.c:19:9: note: node (external) 0x3f04a48 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: 	{ feed_20(D), back_21(D), fix_22(D), destroy_23(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.feed = feed_20(D);
Layer.c:19:9: note: vect_is_simple_use: operand back_21(D), type of def: external
Layer.c:19:9: note: vect_is_simple_use: operand fix_22(D), type of def: external
Layer.c:19:9: note: vect_is_simple_use: operand destroy_23(D), type of def: external
Layer.c:19:9: note: conflicting alias set types.
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(4) long unsigned int  vectorizing a pointer ref: <retval>.feed
Layer.c:19:9: note: created &<retval>.feed
Layer.c:19:9: note: add new stmt: MEM <vector(4) long unsigned int> [(void *)&<retval> + 32B] = _52;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 16 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x3f04ac8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 0 <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 1 <retval>.child = 0B;
Layer.c:19:9: note: 	children 0x3f04b48
Layer.c:19:9: note: node (constant) 0x3f04b48 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ 0B, 0B }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.parent = 0B;
Layer.c:19:9: note: vect_is_simple_use: operand 0B, type of def: constant
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.parent
Layer.c:19:9: note: created &<retval>.parent
Layer.c:19:9: note: add new stmt: MEM <vector(2) long unsigned int> [(struct PULSE_Layer * *)&<retval> + 72B] = { 0, 0 };
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: note: ***** The result for vector mode V32QI would be the same
Layer.c:24:2: missed: statement clobbers memory: free (_1);
Layer.c:25:2: missed: statement clobbers memory: free (_2);
Layer.c:26:2: missed: statement clobbers memory: free (_3);
Layer.c:27:1: note: ***** Analysis failed with vector mode V4DI
Layer.c:27:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:9:27: missed: couldn't vectorize loop
Dense.c:9:27: missed: not vectorized: unsupported outerloop form.
Dense.c:12:20: missed: couldn't vectorize loop
Dense.c:13:21: missed: not vectorized: complicated access pattern.
Dense.c:6:13: note: vectorized 0 loops in function.
Dense.c:16:2: missed: statement clobbers memory: _28 (pretmp_91, _51, 0);
Dense.c:9:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:9:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:24:27: missed: couldn't vectorize loop
Dense.c:24:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:28:20: optimized: loop vectorized using 32 byte vectors
Dense.c:28:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:28:20: optimized: loop vectorized using 16 byte vectors
Dense.c:28:20: missed: couldn't vectorize loop
Dense.c:30:19: missed: not vectorized: no vectype for stmt: _22 = *_21;
 scalar_type: float
Dense.c:20:13: note: vectorized 1 loops in function.
Dense.c:23:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:24:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:24:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:41:28: missed: couldn't vectorize loop
Dense.c:41:28: missed: not vectorized: unsupported outerloop form.
Dense.c:45:21: optimized: loop vectorized using 32 byte vectors
Dense.c:45:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:45:21: optimized: loop vectorized using 16 byte vectors
Dense.c:37:13: note: vectorized 1 loops in function.
Dense.c:37:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:37:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:41:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:188:1: note: ***** Analysis failed with vector mode VOID
Dense.c:170:10: optimized: loop vectorized using 32 byte vectors
Dense.c:170:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:170:10: optimized: loop vectorized using 16 byte vectors
Dense.c:161:10: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_27, _64);
Dense.c:154:10: optimized: loop vectorized using 32 byte vectors
Dense.c:154:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:154:10: optimized: loop vectorized using 16 byte vectors
Dense.c:145:10: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_14, _56);
Dense.c:136:13: note: vectorized 2 loops in function.
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_14, _56);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_15, { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 });
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_27, _64);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_28, { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 });
Dense.c:136:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:136:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:105:24: missed: couldn't vectorize loop
Dense.c:105:24: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:108:17: missed: couldn't vectorize loop
Dense.c:108:17: missed: not vectorized: number of iterations cannot be computed.
Dense.c:122:24: missed: couldn't vectorize loop
Dense.c:122:24: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:125:17: missed: couldn't vectorize loop
Dense.c:125:17: missed: not vectorized: number of iterations cannot be computed.
Dense.c:90:15: missed: couldn't vectorize loop
Dense.c:90:15: missed: not vectorized: number of iterations cannot be computed.
Dense.c:83:13: note: vectorized 0 loops in function.
Dense.c:86:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:110:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:110:17: note: SLPing BB part
Dense.c:127:17: note: Costing subgraph: 
Dense.c:127:17: note: node 0x758b4d8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:127:17: note: op template: _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 0 _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 1 _198 = (sizetype) wi_137;
Dense.c:127:17: note: 	children 0x758b5d8
Dense.c:127:17: note: node (external) 0x758b5d8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:127:17: note: 	{ j_135, wi_137 }
Dense.c:127:17: note: Cost model analysis: 
Dense.c:127:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:127:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:127:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: Costing subgraph: 
Dense.c:110:17: note: node 0x758b6d8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:110:17: note: op template: _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 0 _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 1 _217 = (sizetype) wi_136;
Dense.c:110:17: note: 	children 0x758b7d8
Dense.c:110:17: note: node (external) 0x758b7d8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:110:17: note: 	{ j_134, wi_136 }
Dense.c:110:17: note: Cost model analysis: 
Dense.c:110:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:110:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:110:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:110:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:110:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:110:17: note: SLPing BB part
Dense.c:127:17: note: Costing subgraph: 
Dense.c:127:17: note: node 0x758b6d8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:127:17: note: op template: _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 0 _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 1 _198 = (sizetype) wi_137;
Dense.c:127:17: note: 	children 0x758b4d8
Dense.c:127:17: note: node (external) 0x758b4d8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:127:17: note: 	{ j_135, wi_137 }
Dense.c:127:17: note: Cost model analysis: 
Dense.c:127:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:127:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:127:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: Costing subgraph: 
Dense.c:110:17: note: node 0x758b658 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:110:17: note: op template: _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 0 _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 1 _217 = (sizetype) wi_136;
Dense.c:110:17: note: 	children 0x758b758
Dense.c:110:17: note: node (external) 0x758b758 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:110:17: note: 	{ j_134, wi_136 }
Dense.c:110:17: note: Cost model analysis: 
Dense.c:110:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:110:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:110:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:105:51: note: ***** Analysis failed with vector mode V8QI
Dense.c:105:51: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:105:51: note: ***** Analysis failed with vector mode V4QI
Dense.c:62:15: missed: couldn't vectorize loop
Dense.c:62:15: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:75:11: optimized: loop vectorized using 32 byte vectors
Dense.c:75:11: optimized: loop vectorized using 16 byte vectors
Dense.c:66:11: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:881:10: missed: not vectorized: no vectype for stmt: _53 = MEM[(__m256 * {ref-all})w_ptr_82];
 scalar_type: __m256
Dense.c:54:13: note: vectorized 1 loops in function.
Dense.c:57:2: missed: statement clobbers memory: memcpy (_4, dense$baiases_63, _3);
Dense.c:79:2: missed: statement clobbers memory: _27 (pretmp_163, _68, 0);
Dense.c:54:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:54:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:202:19: missed: couldn't vectorize loop
Dense.c:202:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:192:13: note: vectorized 0 loops in function.
Dense.c:196:35: missed: statement clobbers memory: _5 = aligned_alloc (64, _4);
Dense.c:197:37: missed: statement clobbers memory: _6 = aligned_alloc (64, _4);
Dense.c:198:35: missed: statement clobbers memory: _8 = aligned_alloc (64, _7);
Dense.c:199:34: missed: statement clobbers memory: _9 = aligned_alloc (64, _7);
Dense.c:200:35: missed: statement clobbers memory: _10 = aligned_alloc (64, _7);
Dense.c:203:38: missed: statement clobbers memory: _11 = rand ();
Dense.c:203:72: missed: statement clobbers memory: _57 = sqrt (_18);
Dense.c:215:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:216:4: missed: statement clobbers memory: exit (1);
Dense.c:212:4: missed: statement clobbers memory: layer = PULSE_CreateLayer (args$n_inputs_36, args$n_outputs_47, 0, args$8_48, _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:209:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (args$n_inputs_36, args$n_outputs_47, 0, args$8_48, _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:222:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Dense.c:222:9: note: ***** Analysis succeeded with vector mode V8SI
Dense.c:222:9: note: SLPing BB part
Dense.c:222:9: note: Costing subgraph: 
Dense.c:222:9: note: node 0x7423bd8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Dense.c:222:9: note: op template: MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = _5;
Dense.c:222:9: note: 	stmt 0 MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = _5;
Dense.c:222:9: note: 	stmt 1 MEM <float *> [(struct PULSE_Layer *)&layer + 96B] = _8;
Dense.c:222:9: note: 	stmt 2 MEM <float *> [(struct PULSE_Layer *)&layer + 104B] = _9;
Dense.c:222:9: note: 	stmt 3 MEM <float *> [(struct PULSE_Layer *)&layer + 112B] = _10;
Dense.c:222:9: note: 	children 0x7423c58
Dense.c:222:9: note: node (external) 0x7423c58 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Dense.c:222:9: note: 	stmt 0 _5 = aligned_alloc (64, _4);
Dense.c:222:9: note: 	stmt 1 _8 = aligned_alloc (64, _7);
Dense.c:222:9: note: 	stmt 2 _9 = aligned_alloc (64, _7);
Dense.c:222:9: note: 	stmt 3 _10 = aligned_alloc (64, _7);
Dense.c:222:9: note: 	children 0x7423cd8 0x7423dd8
Dense.c:222:9: note: node (constant) 0x7423cd8 (max_nunits=1, refcnt=1)
Dense.c:222:9: note: 	{ 64, 64, 64, 64 }
Dense.c:222:9: note: node (external) 0x7423dd8 (max_nunits=1, refcnt=1)
Dense.c:222:9: note: 	{ _4, _7, _7, _7 }
Dense.c:222:9: note: Cost model analysis: 
Dense.c:222:9: note: Cost model analysis for part in loop 0:
  Vector cost: 64
  Scalar cost: 64
Dense.c:222:9: note: Basic block will be vectorized using SLP
Dense.c:222:9: optimized: basic block part vectorized using 32 byte vectors
Dense.c:222:9: note: Vectorizing SLP tree:
Dense.c:222:9: note: node 0x7423bd8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Dense.c:222:9: note: op template: MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = _5;
Dense.c:222:9: note: 	stmt 0 MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = _5;
Dense.c:222:9: note: 	stmt 1 MEM <float *> [(struct PULSE_Layer *)&layer + 96B] = _8;
Dense.c:222:9: note: 	stmt 2 MEM <float *> [(struct PULSE_Layer *)&layer + 104B] = _9;
Dense.c:222:9: note: 	stmt 3 MEM <float *> [(struct PULSE_Layer *)&layer + 112B] = _10;
Dense.c:222:9: note: 	children 0x7423c58
Dense.c:222:9: note: node (external) 0x7423c58 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Dense.c:222:9: note: 	stmt 0 _5 = aligned_alloc (64, _4);
Dense.c:222:9: note: 	stmt 1 _8 = aligned_alloc (64, _7);
Dense.c:222:9: note: 	stmt 2 _9 = aligned_alloc (64, _7);
Dense.c:222:9: note: 	stmt 3 _10 = aligned_alloc (64, _7);
Dense.c:222:9: note: 	children 0x7423cd8 0x7423dd8
Dense.c:222:9: note: node (constant) 0x7423cd8 (max_nunits=1, refcnt=1)
Dense.c:222:9: note: 	{ 64, 64, 64, 64 }
Dense.c:222:9: note: node (external) 0x7423dd8 (max_nunits=1, refcnt=1)
Dense.c:222:9: note: 	{ _4, _7, _7, _7 }
Dense.c:222:9: note: ------>vectorizing SLP node starting from: MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = _5;
Dense.c:222:9: note: vect_is_simple_use: operand aligned_alloc (64, _7), type of def: internal
Dense.c:222:9: note: vect_is_simple_use: operand aligned_alloc (64, _7), type of def: internal
Dense.c:222:9: note: vect_is_simple_use: operand aligned_alloc (64, _7), type of def: internal
Dense.c:222:9: note: transform store. ncopies = 1
Dense.c:222:9: note: create vector_type-pointer variable to type: vector(4) long unsigned int  vectorizing a pointer ref: MEM <float *> [(struct PULSE_Layer *)&layer + 88B]
Dense.c:222:9: note: created &MEM <float *> [(struct PULSE_Layer *)&layer + 88B]
Dense.c:222:9: note: add new stmt: MEM <vector(4) long unsigned int> [(struct PULSE_Layer *)&layer + 88B] = _55;
Dense.c:222:9: note: vectorizing stmts using SLP.
Dense.c:222:9: note: ***** The result for vector mode V32QI would be the same
Activations.c:17:19: optimized: loop vectorized using 32 byte vectors
Activations.c:17:19: optimized: loop vectorized using 16 byte vectors
Activations.c:17:19: optimized: loop vectorized using 32 byte vectors
Activations.c:17:19: optimized: loop vectorized using 16 byte vectors
Activations.c:14:13: note: vectorized 2 loops in function.
Activations.c:14:13: note: ***** Analysis failed with vector mode V8SF
Activations.c:14:13: note: ***** The result for vector mode V32QI would be the same
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V16QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V16QI
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V8QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V8QI
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V4QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V4QI
Activations.c:28:19: missed: couldn't vectorize loop
Activations.c:28:19: missed: not vectorized: unsupported control flow in loop.
Activations.c:28:19: optimized: loop vectorized using 32 byte vectors
Activations.c:28:19: optimized: loop vectorized using 16 byte vectors
Activations.c:25:13: note: vectorized 1 loops in function.
Activations.c:25:13: note: ***** Analysis failed with vector mode V8SF
Activations.c:25:13: note: ***** The result for vector mode V32QI would be the same
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V16QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V16QI
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V8QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V8QI
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V4QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V4QI
Activations.c:38:1: note: ***** Analysis failed with vector mode VOID
Activations.c:5:19: missed: couldn't vectorize loop
Activations.c:9:21: missed: statement clobbers memory: _36 = expf (_18);
Activations.c:5:19: missed: couldn't vectorize loop
Activations.c:9:21: missed: statement clobbers memory: _12 = expf (_11);
Activations.c:3:13: note: vectorized 0 loops in function.
Activations.c:9:21: missed: statement clobbers memory: _12 = expf (_11);
Activations.c:9:21: missed: statement clobbers memory: _36 = expf (_18);
Activations.c:11:1: note: ***** Analysis failed with vector mode V8SF
Activations.c:11:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Activations.c:44:2: note: ***** Analysis failed with vector mode VOID
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:4:18: note: vectorized 0 loops in function.
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_4, inputs_15, _3);
PULSE.c:8:2: missed: statement clobbers memory: _5 (layer_17);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_12, pretmp_26, _9);
PULSE.c:13:28: note: ***** Analysis failed with vector mode V8SI
PULSE.c:13:28: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:22:2: missed: statement clobbers memory: _1 (layer_10(D));
PULSE.c:22:2: missed: statement clobbers memory: _14 (_2);
PULSE.c:22:2: missed: statement clobbers memory: _21 (_15);
PULSE.c:22:2: missed: statement clobbers memory: _28 (_22);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_29);
PULSE.c:26:3: missed: statement clobbers memory: memset (_34, 0, _32);
PULSE.c:26:3: missed: statement clobbers memory: memset (_27, 0, _25);
PULSE.c:26:3: missed: statement clobbers memory: memset (_20, 0, _18);
PULSE.c:26:3: missed: statement clobbers memory: memset (_7, 0, _5);
PULSE.c:28:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:28:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:32:6: note: vectorized 1 loops in function.
PULSE.c:34:8: missed: statement clobbers memory: _1 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_2);
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _9 = rand ();
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8SI
PULSE.c:32:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:61:16: missed: couldn't vectorize loop
PULSE.c:61:16: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:64:17: missed: couldn't vectorize loop
PULSE.c:64:17: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:73:19: missed: couldn't vectorize loop
PULSE.c:73:19: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:53:22: missed: couldn't vectorize loop
PULSE.c:53:22: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:47:6: note: vectorized 1 loops in function.
PULSE.c:48:1: missed: statement clobbers memory: saved_stack.7_39 = __builtin_stack_save ();
PULSE.c:49:46: missed: statement clobbers memory: _1 = PULSE_GetLossFunctionPtr (loss_function_40(D));
PULSE.c:60:10: missed: statement clobbers memory: random.4_46 = __builtin_alloca_with_align (_4, 32);
PULSE.c:34:8: missed: statement clobbers memory: _61 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_62);
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _72 = rand ();
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_98, inputs_93, _97);
PULSE.c:8:2: missed: statement clobbers memory: _99 (layer_94);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_105, _104, _103);
PULSE.c:67:11: missed: statement clobbers memory: loss_55 = PULSE_GetLoss_42 (_17, _16, _12, _11);
PULSE.c:22:2: missed: statement clobbers memory: _86 (output_34);
PULSE.c:22:2: missed: statement clobbers memory: _108 (_87);
PULSE.c:22:2: missed: statement clobbers memory: _115 (_109);
PULSE.c:22:2: missed: statement clobbers memory: _122 (_116);
PULSE.c:22:2: missed: statement clobbers memory: _129 (_123);
PULSE.c:22:2: missed: statement clobbers memory: _136 (_130);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_137);
PULSE.c:26:3: missed: statement clobbers memory: memset (_142, 0, _140);
PULSE.c:26:3: missed: statement clobbers memory: memset (_135, 0, _133);
PULSE.c:26:3: missed: statement clobbers memory: memset (_128, 0, _126);
PULSE.c:26:3: missed: statement clobbers memory: memset (_121, 0, _119);
PULSE.c:26:3: missed: statement clobbers memory: memset (_114, 0, _112);
PULSE.c:26:3: missed: statement clobbers memory: memset (_92, 0, _90);
PULSE.c:75:6: missed: statement clobbers memory: _21 (current_191, args);
PULSE.c:81:4: missed: statement clobbers memory: printf ("Epoch: %d | Item: %d | Loss: %.10f | Batch Loss: %.10f\r", i_188, j_189, _25, _24);
PULSE.c:47:6: missed: statement clobbers memory: __builtin_stack_restore (saved_stack.7_39);
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4DI
PULSE.c:47:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:91:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:91:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:98:20: missed: couldn't vectorize loop
PULSE.c:98:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:98:20: missed: couldn't vectorize loop
PULSE.c:98:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:93:6: note: vectorized 0 loops in function.
PULSE.c:97:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:104:62: missed: not vectorized: more than one data ref in stmt: D.6452 = MEM[(struct PULSE_DenseLayerArgs * {ref-all})addr.104_29];
PULSE.c:104:17: missed: statement clobbers memory: *_3 = PULSE_CreateDenseLayer (D.6452);
PULSE.c:104:62: missed: not vectorized: more than one data ref in stmt: D.6452 = MEM[(struct PULSE_DenseLayerArgs * {ref-all})addr.104_47];
PULSE.c:104:17: missed: statement clobbers memory: *_32 = PULSE_CreateDenseLayer (D.6452);
PULSE.c:110:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:111:1: note: ***** Analysis failed with vector mode V8SI
PULSE.c:111:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:116:8: missed: couldn't vectorize loop
PULSE.c:116:8: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:113:6: note: vectorized 0 loops in function.
PULSE.c:118:3: missed: statement clobbers memory: _1 (current_11);
PULSE.c:121:2: missed: statement clobbers memory: free (layer_4(D));
PULSE.c:122:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:122:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Loss.c:15:19: optimized: loop vectorized using 32 byte vectors
Loss.c:15:19: optimized:  loop versioned for vectorization because of possible aliasing
Loss.c:15:19: optimized: loop vectorized using 16 byte vectors
Loss.c:12:23: note: vectorized 1 loops in function.
Loss.c:12:23: note: ***** Analysis failed with vector mode V8SF
Loss.c:12:23: note: ***** The result for vector mode V32QI would be the same
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V16QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V16QI
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V8QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V8QI
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V4QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V4QI
Loss.c:7:19: missed: couldn't vectorize loop
Loss.c:8:38: missed: not vectorized: unsupported use in stmt.
Loss.c:4:23: note: vectorized 0 loops in function.
Loss.c:9:13: note: ***** Analysis failed with vector mode V8SF
Loss.c:9:13: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Loss.c:23:2: note: ***** Analysis failed with vector mode VOID
Layer.c:7:34: missed: statement clobbers memory: _3 = aligned_alloc (64, _2);
Layer.c:8:35: missed: statement clobbers memory: _6 = aligned_alloc (64, _5);
Layer.c:9:34: missed: statement clobbers memory: _7 = aligned_alloc (64, _5);
Layer.c:14:19: missed: statement clobbers memory: _8 = PULSE_GetActivationFunctionPtr (activation_function_18(D));
Layer.c:19:9: note: ***** Analysis succeeded with vector mode V8SI
Layer.c:19:9: note: SLPing BB part
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x3b943c8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 0 MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 1 MEM <unsigned int> [(struct PULSE_Layer *)&<retval> + 4B] = optimization_type_17(D);
Layer.c:19:9: note: 	children 0x3b94448
Layer.c:19:9: note: node (external) 0x3b94448 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ type_16(D), optimization_type_17(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x3b944c8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 0 <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 1 <retval>.n_outputs = n_outputs_12(D);
Layer.c:19:9: note: 	children 0x3b94548
Layer.c:19:9: note: node (external) 0x3b94548 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x3b94648 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 0 <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 1 <retval>.outputs = _6;
Layer.c:19:9: note: 	children 0x3b946c8
Layer.c:19:9: note: node (external) 0x3b946c8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	stmt 0 _3 = aligned_alloc (64, _2);
Layer.c:19:9: note: 	stmt 1 _6 = aligned_alloc (64, _5);
Layer.c:19:9: note: 	children 0x3b94748 0x3b947c8
Layer.c:19:9: note: node (constant) 0x3b94748 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 64, 64 }
Layer.c:19:9: note: node 0x3b947c8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: patt_38 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 0 patt_38 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 1 patt_39 = n_outputs_12(D) w* 4;
Layer.c:19:9: note: 	children 0x3b94848 0x3b948c8
Layer.c:19:9: note: node (external) 0x3b94848 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: node (constant) 0x3b948c8 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ 4, 4 }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x3b949c8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: op template: <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 0 <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 1 <retval>.back = back_21(D);
Layer.c:19:9: note: 	stmt 2 <retval>.fix = fix_22(D);
Layer.c:19:9: note: 	stmt 3 <retval>.destroy = destroy_23(D);
Layer.c:19:9: note: 	children 0x3b94a48
Layer.c:19:9: note: node (external) 0x3b94a48 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: 	{ feed_20(D), back_21(D), fix_22(D), destroy_23(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 64
  Scalar cost: 64
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x3b94ac8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 0 <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 1 <retval>.child = 0B;
Layer.c:19:9: note: 	children 0x3b94b48
Layer.c:19:9: note: node (constant) 0x3b94b48 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ 0B, 0B }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Basic block will be vectorized using SLP
Layer.c:19:9: optimized: basic block part vectorized using 8 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x3b943c8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 0 MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 1 MEM <unsigned int> [(struct PULSE_Layer *)&<retval> + 4B] = optimization_type_17(D);
Layer.c:19:9: note: 	children 0x3b94448
Layer.c:19:9: note: node (external) 0x3b94448 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ type_16(D), optimization_type_17(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: vect_is_simple_use: operand optimization_type_17(D), type of def: external
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>]
Layer.c:19:9: note: created &MEM <unsigned int> [(struct PULSE_Layer *)&<retval>]
Layer.c:19:9: note: add new stmt: MEM <vector(2) unsigned int> [(struct PULSE_Layer *)&<retval>] = _40;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 8 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x3b944c8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 0 <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 1 <retval>.n_outputs = n_outputs_12(D);
Layer.c:19:9: note: 	children 0x3b94548
Layer.c:19:9: note: node (external) 0x3b94548 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: vect_is_simple_use: operand n_outputs_12(D), type of def: external
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: <retval>.n_inputs
Layer.c:19:9: note: created &<retval>.n_inputs
Layer.c:19:9: note: add new stmt: MEM <vector(2) unsigned int> [(unsigned int *)&<retval> + 128B] = _42;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 16 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x3b94648 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 0 <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 1 <retval>.outputs = _6;
Layer.c:19:9: note: 	children 0x3b946c8
Layer.c:19:9: note: node (external) 0x3b946c8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	stmt 0 _3 = aligned_alloc (64, _2);
Layer.c:19:9: note: 	stmt 1 _6 = aligned_alloc (64, _5);
Layer.c:19:9: note: 	children 0x3b94748 0x3b947c8
Layer.c:19:9: note: node (constant) 0x3b94748 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 64, 64 }
Layer.c:19:9: note: node 0x3b947c8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: patt_38 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 0 patt_38 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 1 patt_39 = n_outputs_12(D) w* 4;
Layer.c:19:9: note: 	children 0x3b94848 0x3b948c8
Layer.c:19:9: note: node (external) 0x3b94848 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: node (constant) 0x3b948c8 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ 4, 4 }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.inputs = _3;
Layer.c:19:9: note: vect_is_simple_use: operand aligned_alloc (64, _5), type of def: internal
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.inputs
Layer.c:19:9: note: created &<retval>.inputs
Layer.c:19:9: note: add new stmt: MEM <vector(2) long unsigned int> [(float * *)&<retval> + 8B] = _46;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 32 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x3b949c8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: op template: <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 0 <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 1 <retval>.back = back_21(D);
Layer.c:19:9: note: 	stmt 2 <retval>.fix = fix_22(D);
Layer.c:19:9: note: 	stmt 3 <retval>.destroy = destroy_23(D);
Layer.c:19:9: note: 	children 0x3b94a48
Layer.c:19:9: note: node (external) 0x3b94a48 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: 	{ feed_20(D), back_21(D), fix_22(D), destroy_23(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.feed = feed_20(D);
Layer.c:19:9: note: vect_is_simple_use: operand back_21(D), type of def: external
Layer.c:19:9: note: vect_is_simple_use: operand fix_22(D), type of def: external
Layer.c:19:9: note: vect_is_simple_use: operand destroy_23(D), type of def: external
Layer.c:19:9: note: conflicting alias set types.
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(4) long unsigned int  vectorizing a pointer ref: <retval>.feed
Layer.c:19:9: note: created &<retval>.feed
Layer.c:19:9: note: add new stmt: MEM <vector(4) long unsigned int> [(void *)&<retval> + 32B] = _52;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 16 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x3b94ac8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 0 <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 1 <retval>.child = 0B;
Layer.c:19:9: note: 	children 0x3b94b48
Layer.c:19:9: note: node (constant) 0x3b94b48 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ 0B, 0B }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.parent = 0B;
Layer.c:19:9: note: vect_is_simple_use: operand 0B, type of def: constant
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.parent
Layer.c:19:9: note: created &<retval>.parent
Layer.c:19:9: note: add new stmt: MEM <vector(2) long unsigned int> [(struct PULSE_Layer * *)&<retval> + 72B] = { 0, 0 };
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: note: ***** The result for vector mode V32QI would be the same
Layer.c:24:2: missed: statement clobbers memory: free (_1);
Layer.c:25:2: missed: statement clobbers memory: free (_2);
Layer.c:26:2: missed: statement clobbers memory: free (_3);
Layer.c:27:1: note: ***** Analysis failed with vector mode V4DI
Layer.c:27:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:9:27: missed: couldn't vectorize loop
Dense.c:9:27: missed: not vectorized: unsupported outerloop form.
Dense.c:12:20: missed: couldn't vectorize loop
Dense.c:13:21: missed: not vectorized: complicated access pattern.
Dense.c:6:13: note: vectorized 0 loops in function.
Dense.c:16:2: missed: statement clobbers memory: _28 (pretmp_91, _51, 0);
Dense.c:9:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:9:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:24:27: missed: couldn't vectorize loop
Dense.c:24:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:28:20: optimized: loop vectorized using 32 byte vectors
Dense.c:28:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:28:20: optimized: loop vectorized using 16 byte vectors
Dense.c:28:20: missed: couldn't vectorize loop
Dense.c:30:19: missed: not vectorized: no vectype for stmt: _22 = *_21;
 scalar_type: float
Dense.c:20:13: note: vectorized 1 loops in function.
Dense.c:23:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:24:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:24:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:41:28: missed: couldn't vectorize loop
Dense.c:41:28: missed: not vectorized: unsupported outerloop form.
Dense.c:45:21: optimized: loop vectorized using 32 byte vectors
Dense.c:45:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:45:21: optimized: loop vectorized using 16 byte vectors
Dense.c:37:13: note: vectorized 1 loops in function.
Dense.c:37:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:37:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:41:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:170:10: optimized: loop vectorized using 32 byte vectors
Dense.c:170:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:170:10: optimized: loop vectorized using 16 byte vectors
Dense.c:161:10: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_27, _64);
Dense.c:154:10: optimized: loop vectorized using 32 byte vectors
Dense.c:154:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:154:10: optimized: loop vectorized using 16 byte vectors
Dense.c:145:10: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_14, _56);
Dense.c:136:13: note: vectorized 2 loops in function.
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_14, _56);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_15, { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 });
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_27, _64);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_28, { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 });
Dense.c:136:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:136:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:105:24: missed: couldn't vectorize loop
Dense.c:105:24: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:108:17: missed: couldn't vectorize loop
Dense.c:108:17: missed: not vectorized: number of iterations cannot be computed.
Dense.c:122:24: missed: couldn't vectorize loop
Dense.c:122:24: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:125:17: missed: couldn't vectorize loop
Dense.c:125:17: missed: not vectorized: number of iterations cannot be computed.
Dense.c:90:15: missed: couldn't vectorize loop
Dense.c:90:15: missed: not vectorized: number of iterations cannot be computed.
Dense.c:83:13: note: vectorized 0 loops in function.
Dense.c:86:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:110:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:110:17: note: SLPing BB part
Dense.c:127:17: note: Costing subgraph: 
Dense.c:127:17: note: node 0x86cc3e8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:127:17: note: op template: _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 0 _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 1 _198 = (sizetype) wi_137;
Dense.c:127:17: note: 	children 0x86cc4e8
Dense.c:127:17: note: node (external) 0x86cc4e8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:127:17: note: 	{ j_135, wi_137 }
Dense.c:127:17: note: Cost model analysis: 
Dense.c:127:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:127:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:127:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: Costing subgraph: 
Dense.c:110:17: note: node 0x86cc5e8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:110:17: note: op template: _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 0 _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 1 _217 = (sizetype) wi_136;
Dense.c:110:17: note: 	children 0x86cc6e8
Dense.c:110:17: note: node (external) 0x86cc6e8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:110:17: note: 	{ j_134, wi_136 }
Dense.c:110:17: note: Cost model analysis: 
Dense.c:110:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:110:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:110:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:110:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:110:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:110:17: note: SLPing BB part
Dense.c:127:17: note: Costing subgraph: 
Dense.c:127:17: note: node 0x86cc5e8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:127:17: note: op template: _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 0 _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 1 _198 = (sizetype) wi_137;
Dense.c:127:17: note: 	children 0x86cc3e8
Dense.c:127:17: note: node (external) 0x86cc3e8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:127:17: note: 	{ j_135, wi_137 }
Dense.c:127:17: note: Cost model analysis: 
Dense.c:127:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:127:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:127:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: Costing subgraph: 
Dense.c:110:17: note: node 0x86cc568 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:110:17: note: op template: _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 0 _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 1 _217 = (sizetype) wi_136;
Dense.c:110:17: note: 	children 0x86cc668
Dense.c:110:17: note: node (external) 0x86cc668 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:110:17: note: 	{ j_134, wi_136 }
Dense.c:110:17: note: Cost model analysis: 
Dense.c:110:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:110:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:110:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:105:51: note: ***** Analysis failed with vector mode V8QI
Dense.c:105:51: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:105:51: note: ***** Analysis failed with vector mode V4QI
Dense.c:62:15: missed: couldn't vectorize loop
Dense.c:62:15: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:75:11: optimized: loop vectorized using 32 byte vectors
Dense.c:75:11: optimized: loop vectorized using 16 byte vectors
Dense.c:66:11: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:881:10: missed: not vectorized: no vectype for stmt: _53 = MEM[(__m256 * {ref-all})w_ptr_82];
 scalar_type: __m256
Dense.c:54:13: note: vectorized 1 loops in function.
Dense.c:57:2: missed: statement clobbers memory: memcpy (_4, dense$baiases_63, _3);
Dense.c:79:2: missed: statement clobbers memory: _27 (pretmp_163, _68, 0);
Dense.c:54:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:54:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:182:2: missed: statement clobbers memory: free (dense$weights_7);
Dense.c:183:2: missed: statement clobbers memory: free (dense$baiases_8);
Dense.c:184:2: missed: statement clobbers memory: free (dense$gradients_10);
Dense.c:185:2: missed: statement clobbers memory: free (dense$deltas_9);
Dense.c:186:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:186:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:200:19: missed: couldn't vectorize loop
Dense.c:200:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:190:13: note: vectorized 0 loops in function.
Dense.c:194:35: missed: statement clobbers memory: _5 = aligned_alloc (64, _4);
Dense.c:195:37: missed: statement clobbers memory: _6 = aligned_alloc (64, _4);
Dense.c:196:35: missed: statement clobbers memory: _8 = aligned_alloc (64, _7);
Dense.c:197:34: missed: statement clobbers memory: _9 = aligned_alloc (64, _7);
Dense.c:198:35: missed: statement clobbers memory: _10 = aligned_alloc (64, _7);
Dense.c:201:38: missed: statement clobbers memory: _11 = rand ();
Dense.c:201:72: missed: statement clobbers memory: _57 = sqrt (_18);
Dense.c:213:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:214:4: missed: statement clobbers memory: exit (1);
Dense.c:210:4: missed: statement clobbers memory: layer = PULSE_CreateLayer (args$n_inputs_36, args$n_outputs_47, 0, args$8_48, _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:207:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (args$n_inputs_36, args$n_outputs_47, 0, args$8_48, _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:220:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Dense.c:220:9: note: ***** Analysis succeeded with vector mode V8SI
Dense.c:220:9: note: SLPing BB part
Dense.c:220:9: note: Costing subgraph: 
Dense.c:220:9: note: node 0x85832c8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Dense.c:220:9: note: op template: MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = _5;
Dense.c:220:9: note: 	stmt 0 MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = _5;
Dense.c:220:9: note: 	stmt 1 MEM <float *> [(struct PULSE_Layer *)&layer + 96B] = _8;
Dense.c:220:9: note: 	stmt 2 MEM <float *> [(struct PULSE_Layer *)&layer + 104B] = _9;
Dense.c:220:9: note: 	stmt 3 MEM <float *> [(struct PULSE_Layer *)&layer + 112B] = _10;
Dense.c:220:9: note: 	children 0x8583348
Dense.c:220:9: note: node (external) 0x8583348 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Dense.c:220:9: note: 	stmt 0 _5 = aligned_alloc (64, _4);
Dense.c:220:9: note: 	stmt 1 _8 = aligned_alloc (64, _7);
Dense.c:220:9: note: 	stmt 2 _9 = aligned_alloc (64, _7);
Dense.c:220:9: note: 	stmt 3 _10 = aligned_alloc (64, _7);
Dense.c:220:9: note: 	children 0x85833c8 0x85834c8
Dense.c:220:9: note: node (constant) 0x85833c8 (max_nunits=1, refcnt=1)
Dense.c:220:9: note: 	{ 64, 64, 64, 64 }
Dense.c:220:9: note: node (external) 0x85834c8 (max_nunits=1, refcnt=1)
Dense.c:220:9: note: 	{ _4, _7, _7, _7 }
Dense.c:220:9: note: Cost model analysis: 
Dense.c:220:9: note: Cost model analysis for part in loop 0:
  Vector cost: 64
  Scalar cost: 64
Dense.c:220:9: note: Basic block will be vectorized using SLP
Dense.c:220:9: optimized: basic block part vectorized using 32 byte vectors
Dense.c:220:9: note: Vectorizing SLP tree:
Dense.c:220:9: note: node 0x85832c8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Dense.c:220:9: note: op template: MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = _5;
Dense.c:220:9: note: 	stmt 0 MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = _5;
Dense.c:220:9: note: 	stmt 1 MEM <float *> [(struct PULSE_Layer *)&layer + 96B] = _8;
Dense.c:220:9: note: 	stmt 2 MEM <float *> [(struct PULSE_Layer *)&layer + 104B] = _9;
Dense.c:220:9: note: 	stmt 3 MEM <float *> [(struct PULSE_Layer *)&layer + 112B] = _10;
Dense.c:220:9: note: 	children 0x8583348
Dense.c:220:9: note: node (external) 0x8583348 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Dense.c:220:9: note: 	stmt 0 _5 = aligned_alloc (64, _4);
Dense.c:220:9: note: 	stmt 1 _8 = aligned_alloc (64, _7);
Dense.c:220:9: note: 	stmt 2 _9 = aligned_alloc (64, _7);
Dense.c:220:9: note: 	stmt 3 _10 = aligned_alloc (64, _7);
Dense.c:220:9: note: 	children 0x85833c8 0x85834c8
Dense.c:220:9: note: node (constant) 0x85833c8 (max_nunits=1, refcnt=1)
Dense.c:220:9: note: 	{ 64, 64, 64, 64 }
Dense.c:220:9: note: node (external) 0x85834c8 (max_nunits=1, refcnt=1)
Dense.c:220:9: note: 	{ _4, _7, _7, _7 }
Dense.c:220:9: note: ------>vectorizing SLP node starting from: MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = _5;
Dense.c:220:9: note: vect_is_simple_use: operand aligned_alloc (64, _7), type of def: internal
Dense.c:220:9: note: vect_is_simple_use: operand aligned_alloc (64, _7), type of def: internal
Dense.c:220:9: note: vect_is_simple_use: operand aligned_alloc (64, _7), type of def: internal
Dense.c:220:9: note: transform store. ncopies = 1
Dense.c:220:9: note: create vector_type-pointer variable to type: vector(4) long unsigned int  vectorizing a pointer ref: MEM <float *> [(struct PULSE_Layer *)&layer + 88B]
Dense.c:220:9: note: created &MEM <float *> [(struct PULSE_Layer *)&layer + 88B]
Dense.c:220:9: note: add new stmt: MEM <vector(4) long unsigned int> [(struct PULSE_Layer *)&layer + 88B] = _55;
Dense.c:220:9: note: vectorizing stmts using SLP.
Dense.c:220:9: note: ***** The result for vector mode V32QI would be the same
Activations.c:17:19: optimized: loop vectorized using 32 byte vectors
Activations.c:17:19: optimized: loop vectorized using 16 byte vectors
Activations.c:17:19: optimized: loop vectorized using 32 byte vectors
Activations.c:17:19: optimized: loop vectorized using 16 byte vectors
Activations.c:14:13: note: vectorized 2 loops in function.
Activations.c:14:13: note: ***** Analysis failed with vector mode V8SF
Activations.c:14:13: note: ***** The result for vector mode V32QI would be the same
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V16QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V16QI
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V8QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V8QI
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V4QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V4QI
Activations.c:28:19: missed: couldn't vectorize loop
Activations.c:28:19: missed: not vectorized: unsupported control flow in loop.
Activations.c:28:19: optimized: loop vectorized using 32 byte vectors
Activations.c:28:19: optimized: loop vectorized using 16 byte vectors
Activations.c:25:13: note: vectorized 1 loops in function.
Activations.c:25:13: note: ***** Analysis failed with vector mode V8SF
Activations.c:25:13: note: ***** The result for vector mode V32QI would be the same
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V16QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V16QI
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V8QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V8QI
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V4QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V4QI
Activations.c:38:1: note: ***** Analysis failed with vector mode VOID
Activations.c:5:19: missed: couldn't vectorize loop
Activations.c:9:21: missed: statement clobbers memory: _36 = expf (_18);
Activations.c:5:19: missed: couldn't vectorize loop
Activations.c:9:21: missed: statement clobbers memory: _12 = expf (_11);
Activations.c:3:13: note: vectorized 0 loops in function.
Activations.c:9:21: missed: statement clobbers memory: _12 = expf (_11);
Activations.c:9:21: missed: statement clobbers memory: _36 = expf (_18);
Activations.c:11:1: note: ***** Analysis failed with vector mode V8SF
Activations.c:11:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Activations.c:44:2: note: ***** Analysis failed with vector mode VOID
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:4:18: note: vectorized 0 loops in function.
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_4, inputs_15, _3);
PULSE.c:8:2: missed: statement clobbers memory: _5 (layer_17);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_12, pretmp_26, _9);
PULSE.c:13:28: note: ***** Analysis failed with vector mode V8SI
PULSE.c:13:28: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:22:2: missed: statement clobbers memory: _1 (layer_10(D));
PULSE.c:22:2: missed: statement clobbers memory: _14 (_2);
PULSE.c:22:2: missed: statement clobbers memory: _21 (_15);
PULSE.c:22:2: missed: statement clobbers memory: _28 (_22);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_29);
PULSE.c:26:3: missed: statement clobbers memory: memset (_34, 0, _32);
PULSE.c:26:3: missed: statement clobbers memory: memset (_27, 0, _25);
PULSE.c:26:3: missed: statement clobbers memory: memset (_20, 0, _18);
PULSE.c:26:3: missed: statement clobbers memory: memset (_7, 0, _5);
PULSE.c:28:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:28:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:32:6: note: vectorized 1 loops in function.
PULSE.c:34:8: missed: statement clobbers memory: _1 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_2);
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _9 = rand ();
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8SI
PULSE.c:32:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:61:16: missed: couldn't vectorize loop
PULSE.c:61:16: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:64:17: missed: couldn't vectorize loop
PULSE.c:64:17: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:73:19: missed: couldn't vectorize loop
PULSE.c:73:19: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:53:22: missed: couldn't vectorize loop
PULSE.c:53:22: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:47:6: note: vectorized 1 loops in function.
PULSE.c:48:1: missed: statement clobbers memory: saved_stack.7_39 = __builtin_stack_save ();
PULSE.c:49:46: missed: statement clobbers memory: _1 = PULSE_GetLossFunctionPtr (loss_function_40(D));
PULSE.c:60:10: missed: statement clobbers memory: random.4_46 = __builtin_alloca_with_align (_4, 32);
PULSE.c:34:8: missed: statement clobbers memory: _61 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_62);
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _72 = rand ();
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_98, inputs_93, _97);
PULSE.c:8:2: missed: statement clobbers memory: _99 (layer_94);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_105, _104, _103);
PULSE.c:67:11: missed: statement clobbers memory: loss_55 = PULSE_GetLoss_42 (_17, _16, _12, _11);
PULSE.c:22:2: missed: statement clobbers memory: _86 (output_34);
PULSE.c:22:2: missed: statement clobbers memory: _108 (_87);
PULSE.c:22:2: missed: statement clobbers memory: _115 (_109);
PULSE.c:22:2: missed: statement clobbers memory: _122 (_116);
PULSE.c:22:2: missed: statement clobbers memory: _129 (_123);
PULSE.c:22:2: missed: statement clobbers memory: _136 (_130);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_137);
PULSE.c:26:3: missed: statement clobbers memory: memset (_142, 0, _140);
PULSE.c:26:3: missed: statement clobbers memory: memset (_135, 0, _133);
PULSE.c:26:3: missed: statement clobbers memory: memset (_128, 0, _126);
PULSE.c:26:3: missed: statement clobbers memory: memset (_121, 0, _119);
PULSE.c:26:3: missed: statement clobbers memory: memset (_114, 0, _112);
PULSE.c:26:3: missed: statement clobbers memory: memset (_92, 0, _90);
PULSE.c:75:6: missed: statement clobbers memory: _21 (current_191, args);
PULSE.c:81:4: missed: statement clobbers memory: printf ("Epoch: %d | Item: %d | Loss: %.10f | Batch Loss: %.10f\r", i_188, j_189, _25, _24);
PULSE.c:47:6: missed: statement clobbers memory: __builtin_stack_restore (saved_stack.7_39);
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4DI
PULSE.c:47:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:91:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:91:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:98:20: missed: couldn't vectorize loop
PULSE.c:98:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:98:20: missed: couldn't vectorize loop
PULSE.c:98:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:93:6: note: vectorized 0 loops in function.
PULSE.c:97:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:104:62: missed: not vectorized: more than one data ref in stmt: D.6452 = MEM[(struct PULSE_DenseLayerArgs * {ref-all})addr.104_29];
PULSE.c:104:17: missed: statement clobbers memory: *_3 = PULSE_CreateDenseLayer (D.6452);
PULSE.c:104:62: missed: not vectorized: more than one data ref in stmt: D.6452 = MEM[(struct PULSE_DenseLayerArgs * {ref-all})addr.104_47];
PULSE.c:104:17: missed: statement clobbers memory: *_32 = PULSE_CreateDenseLayer (D.6452);
PULSE.c:110:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:111:1: note: ***** Analysis failed with vector mode V8SI
PULSE.c:111:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:116:8: missed: couldn't vectorize loop
PULSE.c:116:8: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:113:6: note: vectorized 0 loops in function.
PULSE.c:118:3: missed: statement clobbers memory: _1 (current_11);
PULSE.c:121:2: missed: statement clobbers memory: free (layer_4(D));
PULSE.c:122:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:122:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Loss.c:15:19: optimized: loop vectorized using 32 byte vectors
Loss.c:15:19: optimized:  loop versioned for vectorization because of possible aliasing
Loss.c:15:19: optimized: loop vectorized using 16 byte vectors
Loss.c:12:23: note: vectorized 1 loops in function.
Loss.c:12:23: note: ***** Analysis failed with vector mode V8SF
Loss.c:12:23: note: ***** The result for vector mode V32QI would be the same
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V16QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V16QI
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V8QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V8QI
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V4QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V4QI
Loss.c:7:19: missed: couldn't vectorize loop
Loss.c:8:38: missed: not vectorized: unsupported use in stmt.
Loss.c:4:23: note: vectorized 0 loops in function.
Loss.c:9:13: note: ***** Analysis failed with vector mode V8SF
Loss.c:9:13: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Loss.c:23:2: note: ***** Analysis failed with vector mode VOID
Layer.c:7:34: missed: statement clobbers memory: _3 = aligned_alloc (64, _2);
Layer.c:8:35: missed: statement clobbers memory: _6 = aligned_alloc (64, _5);
Layer.c:9:34: missed: statement clobbers memory: _7 = aligned_alloc (64, _5);
Layer.c:14:19: missed: statement clobbers memory: _8 = PULSE_GetActivationFunctionPtr (activation_function_18(D));
Layer.c:19:9: note: ***** Analysis succeeded with vector mode V8SI
Layer.c:19:9: note: SLPing BB part
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x442c3c8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 0 MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 1 MEM <unsigned int> [(struct PULSE_Layer *)&<retval> + 4B] = optimization_type_17(D);
Layer.c:19:9: note: 	children 0x442c448
Layer.c:19:9: note: node (external) 0x442c448 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ type_16(D), optimization_type_17(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x442c4c8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 0 <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 1 <retval>.n_outputs = n_outputs_12(D);
Layer.c:19:9: note: 	children 0x442c548
Layer.c:19:9: note: node (external) 0x442c548 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x442c648 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 0 <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 1 <retval>.outputs = _6;
Layer.c:19:9: note: 	children 0x442c6c8
Layer.c:19:9: note: node (external) 0x442c6c8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	stmt 0 _3 = aligned_alloc (64, _2);
Layer.c:19:9: note: 	stmt 1 _6 = aligned_alloc (64, _5);
Layer.c:19:9: note: 	children 0x442c748 0x442c7c8
Layer.c:19:9: note: node (constant) 0x442c748 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 64, 64 }
Layer.c:19:9: note: node 0x442c7c8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: patt_38 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 0 patt_38 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 1 patt_39 = n_outputs_12(D) w* 4;
Layer.c:19:9: note: 	children 0x442c848 0x442c8c8
Layer.c:19:9: note: node (external) 0x442c848 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: node (constant) 0x442c8c8 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ 4, 4 }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x442c9c8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: op template: <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 0 <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 1 <retval>.back = back_21(D);
Layer.c:19:9: note: 	stmt 2 <retval>.fix = fix_22(D);
Layer.c:19:9: note: 	stmt 3 <retval>.destroy = destroy_23(D);
Layer.c:19:9: note: 	children 0x442ca48
Layer.c:19:9: note: node (external) 0x442ca48 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: 	{ feed_20(D), back_21(D), fix_22(D), destroy_23(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 64
  Scalar cost: 64
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x442cac8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 0 <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 1 <retval>.child = 0B;
Layer.c:19:9: note: 	children 0x442cb48
Layer.c:19:9: note: node (constant) 0x442cb48 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ 0B, 0B }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Basic block will be vectorized using SLP
Layer.c:19:9: optimized: basic block part vectorized using 8 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x442c3c8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 0 MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 1 MEM <unsigned int> [(struct PULSE_Layer *)&<retval> + 4B] = optimization_type_17(D);
Layer.c:19:9: note: 	children 0x442c448
Layer.c:19:9: note: node (external) 0x442c448 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ type_16(D), optimization_type_17(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: vect_is_simple_use: operand optimization_type_17(D), type of def: external
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>]
Layer.c:19:9: note: created &MEM <unsigned int> [(struct PULSE_Layer *)&<retval>]
Layer.c:19:9: note: add new stmt: MEM <vector(2) unsigned int> [(struct PULSE_Layer *)&<retval>] = _40;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 8 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x442c4c8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 0 <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 1 <retval>.n_outputs = n_outputs_12(D);
Layer.c:19:9: note: 	children 0x442c548
Layer.c:19:9: note: node (external) 0x442c548 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: vect_is_simple_use: operand n_outputs_12(D), type of def: external
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: <retval>.n_inputs
Layer.c:19:9: note: created &<retval>.n_inputs
Layer.c:19:9: note: add new stmt: MEM <vector(2) unsigned int> [(unsigned int *)&<retval> + 128B] = _42;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 16 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x442c648 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 0 <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 1 <retval>.outputs = _6;
Layer.c:19:9: note: 	children 0x442c6c8
Layer.c:19:9: note: node (external) 0x442c6c8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	stmt 0 _3 = aligned_alloc (64, _2);
Layer.c:19:9: note: 	stmt 1 _6 = aligned_alloc (64, _5);
Layer.c:19:9: note: 	children 0x442c748 0x442c7c8
Layer.c:19:9: note: node (constant) 0x442c748 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 64, 64 }
Layer.c:19:9: note: node 0x442c7c8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: patt_38 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 0 patt_38 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 1 patt_39 = n_outputs_12(D) w* 4;
Layer.c:19:9: note: 	children 0x442c848 0x442c8c8
Layer.c:19:9: note: node (external) 0x442c848 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: node (constant) 0x442c8c8 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ 4, 4 }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.inputs = _3;
Layer.c:19:9: note: vect_is_simple_use: operand aligned_alloc (64, _5), type of def: internal
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.inputs
Layer.c:19:9: note: created &<retval>.inputs
Layer.c:19:9: note: add new stmt: MEM <vector(2) long unsigned int> [(float * *)&<retval> + 8B] = _46;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 32 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x442c9c8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: op template: <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 0 <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 1 <retval>.back = back_21(D);
Layer.c:19:9: note: 	stmt 2 <retval>.fix = fix_22(D);
Layer.c:19:9: note: 	stmt 3 <retval>.destroy = destroy_23(D);
Layer.c:19:9: note: 	children 0x442ca48
Layer.c:19:9: note: node (external) 0x442ca48 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: 	{ feed_20(D), back_21(D), fix_22(D), destroy_23(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.feed = feed_20(D);
Layer.c:19:9: note: vect_is_simple_use: operand back_21(D), type of def: external
Layer.c:19:9: note: vect_is_simple_use: operand fix_22(D), type of def: external
Layer.c:19:9: note: vect_is_simple_use: operand destroy_23(D), type of def: external
Layer.c:19:9: note: conflicting alias set types.
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(4) long unsigned int  vectorizing a pointer ref: <retval>.feed
Layer.c:19:9: note: created &<retval>.feed
Layer.c:19:9: note: add new stmt: MEM <vector(4) long unsigned int> [(void *)&<retval> + 32B] = _52;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 16 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x442cac8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 0 <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 1 <retval>.child = 0B;
Layer.c:19:9: note: 	children 0x442cb48
Layer.c:19:9: note: node (constant) 0x442cb48 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ 0B, 0B }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.parent = 0B;
Layer.c:19:9: note: vect_is_simple_use: operand 0B, type of def: constant
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.parent
Layer.c:19:9: note: created &<retval>.parent
Layer.c:19:9: note: add new stmt: MEM <vector(2) long unsigned int> [(struct PULSE_Layer * *)&<retval> + 72B] = { 0, 0 };
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: note: ***** The result for vector mode V32QI would be the same
Layer.c:24:2: missed: statement clobbers memory: free (_1);
Layer.c:25:2: missed: statement clobbers memory: free (_2);
Layer.c:26:2: missed: statement clobbers memory: free (_3);
Layer.c:27:1: note: ***** Analysis failed with vector mode V4DI
Layer.c:27:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:9:27: missed: couldn't vectorize loop
Dense.c:9:27: missed: not vectorized: unsupported outerloop form.
Dense.c:12:20: missed: couldn't vectorize loop
Dense.c:13:21: missed: not vectorized: complicated access pattern.
Dense.c:6:13: note: vectorized 0 loops in function.
Dense.c:16:2: missed: statement clobbers memory: _28 (pretmp_91, _51, 0);
Dense.c:9:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:9:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:24:27: missed: couldn't vectorize loop
Dense.c:24:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:28:20: optimized: loop vectorized using 32 byte vectors
Dense.c:28:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:28:20: optimized: loop vectorized using 16 byte vectors
Dense.c:28:20: missed: couldn't vectorize loop
Dense.c:30:19: missed: not vectorized: no vectype for stmt: _22 = *_21;
 scalar_type: float
Dense.c:20:13: note: vectorized 1 loops in function.
Dense.c:23:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:24:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:24:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:41:28: missed: couldn't vectorize loop
Dense.c:41:28: missed: not vectorized: unsupported outerloop form.
Dense.c:45:21: optimized: loop vectorized using 32 byte vectors
Dense.c:45:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:45:21: optimized: loop vectorized using 16 byte vectors
Dense.c:37:13: note: vectorized 1 loops in function.
Dense.c:37:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:37:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:41:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:170:10: optimized: loop vectorized using 32 byte vectors
Dense.c:170:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:170:10: optimized: loop vectorized using 16 byte vectors
Dense.c:161:10: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_27, _64);
Dense.c:154:10: optimized: loop vectorized using 32 byte vectors
Dense.c:154:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:154:10: optimized: loop vectorized using 16 byte vectors
Dense.c:145:10: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_14, _56);
Dense.c:136:13: note: vectorized 2 loops in function.
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_14, _56);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_15, { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 });
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_27, _64);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_28, { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 });
Dense.c:136:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:136:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:105:24: missed: couldn't vectorize loop
Dense.c:105:24: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:108:17: missed: couldn't vectorize loop
Dense.c:108:17: missed: not vectorized: number of iterations cannot be computed.
Dense.c:122:24: missed: couldn't vectorize loop
Dense.c:122:24: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:125:17: missed: couldn't vectorize loop
Dense.c:125:17: missed: not vectorized: number of iterations cannot be computed.
Dense.c:90:15: missed: couldn't vectorize loop
Dense.c:90:15: missed: not vectorized: number of iterations cannot be computed.
Dense.c:83:13: note: vectorized 0 loops in function.
Dense.c:86:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:110:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:110:17: note: SLPing BB part
Dense.c:127:17: note: Costing subgraph: 
Dense.c:127:17: note: node 0x8390428 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:127:17: note: op template: _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 0 _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 1 _198 = (sizetype) wi_137;
Dense.c:127:17: note: 	children 0x8390528
Dense.c:127:17: note: node (external) 0x8390528 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:127:17: note: 	{ j_135, wi_137 }
Dense.c:127:17: note: Cost model analysis: 
Dense.c:127:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:127:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:127:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: Costing subgraph: 
Dense.c:110:17: note: node 0x8390628 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:110:17: note: op template: _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 0 _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 1 _217 = (sizetype) wi_136;
Dense.c:110:17: note: 	children 0x8390728
Dense.c:110:17: note: node (external) 0x8390728 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:110:17: note: 	{ j_134, wi_136 }
Dense.c:110:17: note: Cost model analysis: 
Dense.c:110:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:110:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:110:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:110:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:110:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:110:17: note: SLPing BB part
Dense.c:127:17: note: Costing subgraph: 
Dense.c:127:17: note: node 0x8390628 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:127:17: note: op template: _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 0 _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 1 _198 = (sizetype) wi_137;
Dense.c:127:17: note: 	children 0x8390428
Dense.c:127:17: note: node (external) 0x8390428 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:127:17: note: 	{ j_135, wi_137 }
Dense.c:127:17: note: Cost model analysis: 
Dense.c:127:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:127:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:127:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: Costing subgraph: 
Dense.c:110:17: note: node 0x83905a8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:110:17: note: op template: _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 0 _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 1 _217 = (sizetype) wi_136;
Dense.c:110:17: note: 	children 0x83906a8
Dense.c:110:17: note: node (external) 0x83906a8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:110:17: note: 	{ j_134, wi_136 }
Dense.c:110:17: note: Cost model analysis: 
Dense.c:110:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:110:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:110:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:105:51: note: ***** Analysis failed with vector mode V8QI
Dense.c:105:51: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:105:51: note: ***** Analysis failed with vector mode V4QI
Dense.c:62:15: missed: couldn't vectorize loop
Dense.c:62:15: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:75:11: optimized: loop vectorized using 32 byte vectors
Dense.c:75:11: optimized: loop vectorized using 16 byte vectors
Dense.c:66:11: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:881:10: missed: not vectorized: no vectype for stmt: _53 = MEM[(__m256 * {ref-all})w_ptr_82];
 scalar_type: __m256
Dense.c:54:13: note: vectorized 1 loops in function.
Dense.c:57:2: missed: statement clobbers memory: memcpy (_4, dense$baiases_63, _3);
Dense.c:79:2: missed: statement clobbers memory: _27 (pretmp_163, _68, 0);
Dense.c:54:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:54:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:182:2: missed: statement clobbers memory: free (dense$weights_7);
Dense.c:183:2: missed: statement clobbers memory: free (dense$baiases_8);
Dense.c:184:2: missed: statement clobbers memory: free (dense$gradients_10);
Dense.c:185:2: missed: statement clobbers memory: free (dense$deltas_9);
Dense.c:186:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:186:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:200:19: missed: couldn't vectorize loop
Dense.c:200:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:190:13: note: vectorized 0 loops in function.
Dense.c:194:35: missed: statement clobbers memory: _5 = aligned_alloc (64, _4);
Dense.c:195:37: missed: statement clobbers memory: _6 = aligned_alloc (64, _4);
Dense.c:196:35: missed: statement clobbers memory: _8 = aligned_alloc (64, _7);
Dense.c:197:34: missed: statement clobbers memory: _9 = aligned_alloc (64, _7);
Dense.c:198:35: missed: statement clobbers memory: _10 = aligned_alloc (64, _7);
Dense.c:201:38: missed: statement clobbers memory: _11 = rand ();
Dense.c:201:72: missed: statement clobbers memory: _57 = sqrt (_18);
Dense.c:213:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:214:4: missed: statement clobbers memory: exit (1);
Dense.c:210:4: missed: statement clobbers memory: layer = PULSE_CreateLayer (args$n_inputs_36, args$n_outputs_47, 0, args$8_48, _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:207:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (args$n_inputs_36, args$n_outputs_47, 0, args$8_48, _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:220:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Dense.c:220:9: note: ***** Analysis succeeded with vector mode V8SI
Dense.c:220:9: note: SLPing BB part
Dense.c:220:9: note: Costing subgraph: 
Dense.c:220:9: note: node 0x8248458 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Dense.c:220:9: note: op template: MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = _5;
Dense.c:220:9: note: 	stmt 0 MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = _5;
Dense.c:220:9: note: 	stmt 1 MEM <float *> [(struct PULSE_Layer *)&layer + 96B] = _8;
Dense.c:220:9: note: 	stmt 2 MEM <float *> [(struct PULSE_Layer *)&layer + 104B] = _9;
Dense.c:220:9: note: 	stmt 3 MEM <float *> [(struct PULSE_Layer *)&layer + 112B] = _10;
Dense.c:220:9: note: 	children 0x82484d8
Dense.c:220:9: note: node (external) 0x82484d8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Dense.c:220:9: note: 	stmt 0 _5 = aligned_alloc (64, _4);
Dense.c:220:9: note: 	stmt 1 _8 = aligned_alloc (64, _7);
Dense.c:220:9: note: 	stmt 2 _9 = aligned_alloc (64, _7);
Dense.c:220:9: note: 	stmt 3 _10 = aligned_alloc (64, _7);
Dense.c:220:9: note: 	children 0x8248558 0x8248658
Dense.c:220:9: note: node (constant) 0x8248558 (max_nunits=1, refcnt=1)
Dense.c:220:9: note: 	{ 64, 64, 64, 64 }
Dense.c:220:9: note: node (external) 0x8248658 (max_nunits=1, refcnt=1)
Dense.c:220:9: note: 	{ _4, _7, _7, _7 }
Dense.c:220:9: note: Cost model analysis: 
Dense.c:220:9: note: Cost model analysis for part in loop 0:
  Vector cost: 64
  Scalar cost: 64
Dense.c:220:9: note: Basic block will be vectorized using SLP
Dense.c:220:9: optimized: basic block part vectorized using 32 byte vectors
Dense.c:220:9: note: Vectorizing SLP tree:
Dense.c:220:9: note: node 0x8248458 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Dense.c:220:9: note: op template: MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = _5;
Dense.c:220:9: note: 	stmt 0 MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = _5;
Dense.c:220:9: note: 	stmt 1 MEM <float *> [(struct PULSE_Layer *)&layer + 96B] = _8;
Dense.c:220:9: note: 	stmt 2 MEM <float *> [(struct PULSE_Layer *)&layer + 104B] = _9;
Dense.c:220:9: note: 	stmt 3 MEM <float *> [(struct PULSE_Layer *)&layer + 112B] = _10;
Dense.c:220:9: note: 	children 0x82484d8
Dense.c:220:9: note: node (external) 0x82484d8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Dense.c:220:9: note: 	stmt 0 _5 = aligned_alloc (64, _4);
Dense.c:220:9: note: 	stmt 1 _8 = aligned_alloc (64, _7);
Dense.c:220:9: note: 	stmt 2 _9 = aligned_alloc (64, _7);
Dense.c:220:9: note: 	stmt 3 _10 = aligned_alloc (64, _7);
Dense.c:220:9: note: 	children 0x8248558 0x8248658
Dense.c:220:9: note: node (constant) 0x8248558 (max_nunits=1, refcnt=1)
Dense.c:220:9: note: 	{ 64, 64, 64, 64 }
Dense.c:220:9: note: node (external) 0x8248658 (max_nunits=1, refcnt=1)
Dense.c:220:9: note: 	{ _4, _7, _7, _7 }
Dense.c:220:9: note: ------>vectorizing SLP node starting from: MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = _5;
Dense.c:220:9: note: vect_is_simple_use: operand aligned_alloc (64, _7), type of def: internal
Dense.c:220:9: note: vect_is_simple_use: operand aligned_alloc (64, _7), type of def: internal
Dense.c:220:9: note: vect_is_simple_use: operand aligned_alloc (64, _7), type of def: internal
Dense.c:220:9: note: transform store. ncopies = 1
Dense.c:220:9: note: create vector_type-pointer variable to type: vector(4) long unsigned int  vectorizing a pointer ref: MEM <float *> [(struct PULSE_Layer *)&layer + 88B]
Dense.c:220:9: note: created &MEM <float *> [(struct PULSE_Layer *)&layer + 88B]
Dense.c:220:9: note: add new stmt: MEM <vector(4) long unsigned int> [(struct PULSE_Layer *)&layer + 88B] = _55;
Dense.c:220:9: note: vectorizing stmts using SLP.
Dense.c:220:9: note: ***** The result for vector mode V32QI would be the same
Activations.c:17:19: optimized: loop vectorized using 32 byte vectors
Activations.c:17:19: optimized: loop vectorized using 16 byte vectors
Activations.c:17:19: optimized: loop vectorized using 32 byte vectors
Activations.c:17:19: optimized: loop vectorized using 16 byte vectors
Activations.c:14:13: note: vectorized 2 loops in function.
Activations.c:14:13: note: ***** Analysis failed with vector mode V8SF
Activations.c:14:13: note: ***** The result for vector mode V32QI would be the same
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V16QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V16QI
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V8QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V8QI
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V4QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V4QI
Activations.c:28:19: missed: couldn't vectorize loop
Activations.c:28:19: missed: not vectorized: unsupported control flow in loop.
Activations.c:28:19: optimized: loop vectorized using 32 byte vectors
Activations.c:28:19: optimized: loop vectorized using 16 byte vectors
Activations.c:25:13: note: vectorized 1 loops in function.
Activations.c:25:13: note: ***** Analysis failed with vector mode V8SF
Activations.c:25:13: note: ***** The result for vector mode V32QI would be the same
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V16QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V16QI
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V8QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V8QI
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V4QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V4QI
Activations.c:38:1: note: ***** Analysis failed with vector mode VOID
Activations.c:5:19: missed: couldn't vectorize loop
Activations.c:9:21: missed: statement clobbers memory: _36 = expf (_18);
Activations.c:5:19: missed: couldn't vectorize loop
Activations.c:9:21: missed: statement clobbers memory: _12 = expf (_11);
Activations.c:3:13: note: vectorized 0 loops in function.
Activations.c:9:21: missed: statement clobbers memory: _12 = expf (_11);
Activations.c:9:21: missed: statement clobbers memory: _36 = expf (_18);
Activations.c:11:1: note: ***** Analysis failed with vector mode V8SF
Activations.c:11:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Activations.c:44:2: note: ***** Analysis failed with vector mode VOID
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:4:18: note: vectorized 0 loops in function.
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_4, inputs_15, _3);
PULSE.c:8:2: missed: statement clobbers memory: _5 (layer_17);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_12, pretmp_26, _9);
PULSE.c:13:28: note: ***** Analysis failed with vector mode V8SI
PULSE.c:13:28: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:22:2: missed: statement clobbers memory: _1 (layer_10(D));
PULSE.c:22:2: missed: statement clobbers memory: _14 (_2);
PULSE.c:22:2: missed: statement clobbers memory: _21 (_15);
PULSE.c:22:2: missed: statement clobbers memory: _28 (_22);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_29);
PULSE.c:26:3: missed: statement clobbers memory: memset (_34, 0, _32);
PULSE.c:26:3: missed: statement clobbers memory: memset (_27, 0, _25);
PULSE.c:26:3: missed: statement clobbers memory: memset (_20, 0, _18);
PULSE.c:26:3: missed: statement clobbers memory: memset (_7, 0, _5);
PULSE.c:28:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:28:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:32:6: note: vectorized 1 loops in function.
PULSE.c:34:8: missed: statement clobbers memory: _1 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_2);
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _9 = rand ();
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8SI
PULSE.c:32:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:61:16: missed: couldn't vectorize loop
PULSE.c:61:16: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:64:17: missed: couldn't vectorize loop
PULSE.c:64:17: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:73:19: missed: couldn't vectorize loop
PULSE.c:73:19: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:53:22: missed: couldn't vectorize loop
PULSE.c:53:22: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:47:6: note: vectorized 1 loops in function.
PULSE.c:48:1: missed: statement clobbers memory: saved_stack.7_39 = __builtin_stack_save ();
PULSE.c:49:46: missed: statement clobbers memory: _1 = PULSE_GetLossFunctionPtr (loss_function_40(D));
PULSE.c:60:10: missed: statement clobbers memory: random.4_46 = __builtin_alloca_with_align (_4, 32);
PULSE.c:34:8: missed: statement clobbers memory: _61 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_62);
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _72 = rand ();
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_98, inputs_93, _97);
PULSE.c:8:2: missed: statement clobbers memory: _99 (layer_94);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_105, _104, _103);
PULSE.c:67:11: missed: statement clobbers memory: loss_55 = PULSE_GetLoss_42 (_17, _16, _12, _11);
PULSE.c:22:2: missed: statement clobbers memory: _86 (output_34);
PULSE.c:22:2: missed: statement clobbers memory: _108 (_87);
PULSE.c:22:2: missed: statement clobbers memory: _115 (_109);
PULSE.c:22:2: missed: statement clobbers memory: _122 (_116);
PULSE.c:22:2: missed: statement clobbers memory: _129 (_123);
PULSE.c:22:2: missed: statement clobbers memory: _136 (_130);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_137);
PULSE.c:26:3: missed: statement clobbers memory: memset (_142, 0, _140);
PULSE.c:26:3: missed: statement clobbers memory: memset (_135, 0, _133);
PULSE.c:26:3: missed: statement clobbers memory: memset (_128, 0, _126);
PULSE.c:26:3: missed: statement clobbers memory: memset (_121, 0, _119);
PULSE.c:26:3: missed: statement clobbers memory: memset (_114, 0, _112);
PULSE.c:26:3: missed: statement clobbers memory: memset (_92, 0, _90);
PULSE.c:75:6: missed: statement clobbers memory: _21 (current_191, args);
PULSE.c:81:4: missed: statement clobbers memory: printf ("Epoch: %d | Item: %d | Loss: %.10f | Batch Loss: %.10f\r", i_188, j_189, _25, _24);
PULSE.c:47:6: missed: statement clobbers memory: __builtin_stack_restore (saved_stack.7_39);
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4DI
PULSE.c:47:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:91:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:91:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:98:20: missed: couldn't vectorize loop
PULSE.c:98:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:98:20: missed: couldn't vectorize loop
PULSE.c:98:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:93:6: note: vectorized 0 loops in function.
PULSE.c:97:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:104:62: missed: not vectorized: more than one data ref in stmt: D.6452 = MEM[(struct PULSE_DenseLayerArgs * {ref-all})addr.104_29];
PULSE.c:104:17: missed: statement clobbers memory: *_3 = PULSE_CreateDenseLayer (D.6452);
PULSE.c:104:62: missed: not vectorized: more than one data ref in stmt: D.6452 = MEM[(struct PULSE_DenseLayerArgs * {ref-all})addr.104_47];
PULSE.c:104:17: missed: statement clobbers memory: *_32 = PULSE_CreateDenseLayer (D.6452);
PULSE.c:110:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:111:1: note: ***** Analysis failed with vector mode V8SI
PULSE.c:111:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:116:8: missed: couldn't vectorize loop
PULSE.c:116:8: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:113:6: note: vectorized 0 loops in function.
PULSE.c:118:3: missed: statement clobbers memory: _1 (current_10);
PULSE.c:121:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:121:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Loss.c:15:19: optimized: loop vectorized using 32 byte vectors
Loss.c:15:19: optimized:  loop versioned for vectorization because of possible aliasing
Loss.c:15:19: optimized: loop vectorized using 16 byte vectors
Loss.c:12:23: note: vectorized 1 loops in function.
Loss.c:12:23: note: ***** Analysis failed with vector mode V8SF
Loss.c:12:23: note: ***** The result for vector mode V32QI would be the same
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V16QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V16QI
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V8QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V8QI
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V4QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V4QI
Loss.c:7:19: missed: couldn't vectorize loop
Loss.c:8:38: missed: not vectorized: unsupported use in stmt.
Loss.c:4:23: note: vectorized 0 loops in function.
Loss.c:9:13: note: ***** Analysis failed with vector mode V8SF
Loss.c:9:13: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Loss.c:23:2: note: ***** Analysis failed with vector mode VOID
Dense.c:9:27: missed: couldn't vectorize loop
Dense.c:9:27: missed: not vectorized: unsupported outerloop form.
Dense.c:12:20: missed: couldn't vectorize loop
Dense.c:13:21: missed: not vectorized: complicated access pattern.
Dense.c:6:13: note: vectorized 0 loops in function.
Dense.c:16:2: missed: statement clobbers memory: _28 (pretmp_91, _51, 0);
Dense.c:9:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:9:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:24:27: missed: couldn't vectorize loop
Dense.c:24:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:28:20: optimized: loop vectorized using 32 byte vectors
Dense.c:28:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:28:20: optimized: loop vectorized using 16 byte vectors
Dense.c:28:20: missed: couldn't vectorize loop
Dense.c:30:19: missed: not vectorized: no vectype for stmt: _22 = *_21;
 scalar_type: float
Dense.c:20:13: note: vectorized 1 loops in function.
Dense.c:23:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:24:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:24:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:41:28: missed: couldn't vectorize loop
Dense.c:41:28: missed: not vectorized: unsupported outerloop form.
Dense.c:45:21: optimized: loop vectorized using 32 byte vectors
Dense.c:45:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:45:21: optimized: loop vectorized using 16 byte vectors
Dense.c:37:13: note: vectorized 1 loops in function.
Dense.c:37:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:37:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:41:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:170:10: optimized: loop vectorized using 32 byte vectors
Dense.c:170:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:170:10: optimized: loop vectorized using 16 byte vectors
Dense.c:161:10: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_27, _64);
Dense.c:154:10: optimized: loop vectorized using 32 byte vectors
Dense.c:154:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:154:10: optimized: loop vectorized using 16 byte vectors
Dense.c:145:10: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_14, _56);
Dense.c:136:13: note: vectorized 2 loops in function.
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_14, _56);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_15, { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 });
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_27, _64);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_28, { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 });
Dense.c:136:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:136:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:105:24: missed: couldn't vectorize loop
Dense.c:105:24: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:108:17: missed: couldn't vectorize loop
Dense.c:108:17: missed: not vectorized: number of iterations cannot be computed.
Dense.c:122:24: missed: couldn't vectorize loop
Dense.c:122:24: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:125:17: missed: couldn't vectorize loop
Dense.c:125:17: missed: not vectorized: number of iterations cannot be computed.
Dense.c:90:15: missed: couldn't vectorize loop
Dense.c:90:15: missed: not vectorized: number of iterations cannot be computed.
Dense.c:83:13: note: vectorized 0 loops in function.
Dense.c:86:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:110:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:110:17: note: SLPing BB part
Dense.c:127:17: note: Costing subgraph: 
Dense.c:127:17: note: node 0x8c9e3e8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:127:17: note: op template: _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 0 _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 1 _198 = (sizetype) wi_137;
Dense.c:127:17: note: 	children 0x8c9e4e8
Dense.c:127:17: note: node (external) 0x8c9e4e8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:127:17: note: 	{ j_135, wi_137 }
Dense.c:127:17: note: Cost model analysis: 
Dense.c:127:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:127:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:127:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: Costing subgraph: 
Dense.c:110:17: note: node 0x8c9e5e8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:110:17: note: op template: _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 0 _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 1 _217 = (sizetype) wi_136;
Dense.c:110:17: note: 	children 0x8c9e6e8
Dense.c:110:17: note: node (external) 0x8c9e6e8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:110:17: note: 	{ j_134, wi_136 }
Dense.c:110:17: note: Cost model analysis: 
Dense.c:110:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:110:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:110:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:110:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:110:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:110:17: note: SLPing BB part
Dense.c:127:17: note: Costing subgraph: 
Dense.c:127:17: note: node 0x8c9e5e8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:127:17: note: op template: _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 0 _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 1 _198 = (sizetype) wi_137;
Dense.c:127:17: note: 	children 0x8c9e3e8
Dense.c:127:17: note: node (external) 0x8c9e3e8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:127:17: note: 	{ j_135, wi_137 }
Dense.c:127:17: note: Cost model analysis: 
Dense.c:127:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:127:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:127:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: Costing subgraph: 
Dense.c:110:17: note: node 0x8c9e568 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:110:17: note: op template: _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 0 _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 1 _217 = (sizetype) wi_136;
Dense.c:110:17: note: 	children 0x8c9e668
Dense.c:110:17: note: node (external) 0x8c9e668 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:110:17: note: 	{ j_134, wi_136 }
Dense.c:110:17: note: Cost model analysis: 
Dense.c:110:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:110:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:110:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:105:51: note: ***** Analysis failed with vector mode V8QI
Dense.c:105:51: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:105:51: note: ***** Analysis failed with vector mode V4QI
Dense.c:62:15: missed: couldn't vectorize loop
Dense.c:62:15: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:75:11: optimized: loop vectorized using 32 byte vectors
Dense.c:75:11: optimized: loop vectorized using 16 byte vectors
Dense.c:66:11: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:881:10: missed: not vectorized: no vectype for stmt: _53 = MEM[(__m256 * {ref-all})w_ptr_82];
 scalar_type: __m256
Dense.c:54:13: note: vectorized 1 loops in function.
Dense.c:57:2: missed: statement clobbers memory: memcpy (_4, dense$baiases_63, _3);
Dense.c:79:2: missed: statement clobbers memory: _27 (pretmp_163, _68, 0);
Dense.c:54:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:54:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:182:2: missed: statement clobbers memory: free (dense$weights_7);
Dense.c:183:2: missed: statement clobbers memory: free (dense$baiases_8);
Dense.c:184:2: missed: statement clobbers memory: free (dense$gradients_10);
Dense.c:185:2: missed: statement clobbers memory: free (dense$deltas_9);
Dense.c:186:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:186:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:200:19: missed: couldn't vectorize loop
Dense.c:200:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:190:13: note: vectorized 0 loops in function.
Dense.c:194:35: missed: statement clobbers memory: _5 = aligned_alloc (64, _4);
Dense.c:195:37: missed: statement clobbers memory: _6 = aligned_alloc (64, _4);
Dense.c:196:35: missed: statement clobbers memory: _8 = aligned_alloc (64, _7);
Dense.c:197:34: missed: statement clobbers memory: _9 = aligned_alloc (64, _7);
Dense.c:198:35: missed: statement clobbers memory: _10 = aligned_alloc (64, _7);
Dense.c:201:38: missed: statement clobbers memory: _11 = rand ();
Dense.c:201:72: missed: statement clobbers memory: _57 = sqrt (_18);
Dense.c:213:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:214:4: missed: statement clobbers memory: exit (1);
Dense.c:210:4: missed: statement clobbers memory: layer = PULSE_CreateLayer (args$n_inputs_36, args$n_outputs_47, 0, args$8_48, _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:207:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (args$n_inputs_36, args$n_outputs_47, 0, args$8_48, _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:219:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Dense.c:219:9: note: ***** Analysis succeeded with vector mode V8SI
Dense.c:219:9: note: SLPing BB part
Dense.c:219:9: note: Costing subgraph: 
Dense.c:219:9: note: node 0x8b552c8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Dense.c:219:9: note: op template: MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = _5;
Dense.c:219:9: note: 	stmt 0 MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = _5;
Dense.c:219:9: note: 	stmt 1 MEM <float *> [(struct PULSE_Layer *)&layer + 96B] = _8;
Dense.c:219:9: note: 	stmt 2 MEM <float *> [(struct PULSE_Layer *)&layer + 104B] = _9;
Dense.c:219:9: note: 	stmt 3 MEM <float *> [(struct PULSE_Layer *)&layer + 112B] = _10;
Dense.c:219:9: note: 	children 0x8b55348
Dense.c:219:9: note: node (external) 0x8b55348 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Dense.c:219:9: note: 	stmt 0 _5 = aligned_alloc (64, _4);
Dense.c:219:9: note: 	stmt 1 _8 = aligned_alloc (64, _7);
Dense.c:219:9: note: 	stmt 2 _9 = aligned_alloc (64, _7);
Dense.c:219:9: note: 	stmt 3 _10 = aligned_alloc (64, _7);
Dense.c:219:9: note: 	children 0x8b553c8 0x8b554c8
Dense.c:219:9: note: node (constant) 0x8b553c8 (max_nunits=1, refcnt=1)
Dense.c:219:9: note: 	{ 64, 64, 64, 64 }
Dense.c:219:9: note: node (external) 0x8b554c8 (max_nunits=1, refcnt=1)
Dense.c:219:9: note: 	{ _4, _7, _7, _7 }
Dense.c:219:9: note: Cost model analysis: 
Dense.c:219:9: note: Cost model analysis for part in loop 0:
  Vector cost: 64
  Scalar cost: 64
Dense.c:219:9: note: Basic block will be vectorized using SLP
Dense.c:219:9: optimized: basic block part vectorized using 32 byte vectors
Dense.c:219:9: note: Vectorizing SLP tree:
Dense.c:219:9: note: node 0x8b552c8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Dense.c:219:9: note: op template: MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = _5;
Dense.c:219:9: note: 	stmt 0 MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = _5;
Dense.c:219:9: note: 	stmt 1 MEM <float *> [(struct PULSE_Layer *)&layer + 96B] = _8;
Dense.c:219:9: note: 	stmt 2 MEM <float *> [(struct PULSE_Layer *)&layer + 104B] = _9;
Dense.c:219:9: note: 	stmt 3 MEM <float *> [(struct PULSE_Layer *)&layer + 112B] = _10;
Dense.c:219:9: note: 	children 0x8b55348
Dense.c:219:9: note: node (external) 0x8b55348 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Dense.c:219:9: note: 	stmt 0 _5 = aligned_alloc (64, _4);
Dense.c:219:9: note: 	stmt 1 _8 = aligned_alloc (64, _7);
Dense.c:219:9: note: 	stmt 2 _9 = aligned_alloc (64, _7);
Dense.c:219:9: note: 	stmt 3 _10 = aligned_alloc (64, _7);
Dense.c:219:9: note: 	children 0x8b553c8 0x8b554c8
Dense.c:219:9: note: node (constant) 0x8b553c8 (max_nunits=1, refcnt=1)
Dense.c:219:9: note: 	{ 64, 64, 64, 64 }
Dense.c:219:9: note: node (external) 0x8b554c8 (max_nunits=1, refcnt=1)
Dense.c:219:9: note: 	{ _4, _7, _7, _7 }
Dense.c:219:9: note: ------>vectorizing SLP node starting from: MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = _5;
Dense.c:219:9: note: vect_is_simple_use: operand aligned_alloc (64, _7), type of def: internal
Dense.c:219:9: note: vect_is_simple_use: operand aligned_alloc (64, _7), type of def: internal
Dense.c:219:9: note: vect_is_simple_use: operand aligned_alloc (64, _7), type of def: internal
Dense.c:219:9: note: transform store. ncopies = 1
Dense.c:219:9: note: create vector_type-pointer variable to type: vector(4) long unsigned int  vectorizing a pointer ref: MEM <float *> [(struct PULSE_Layer *)&layer + 88B]
Dense.c:219:9: note: created &MEM <float *> [(struct PULSE_Layer *)&layer + 88B]
Dense.c:219:9: note: add new stmt: MEM <vector(4) long unsigned int> [(struct PULSE_Layer *)&layer + 88B] = _55;
Dense.c:219:9: note: vectorizing stmts using SLP.
Dense.c:219:9: note: ***** The result for vector mode V32QI would be the same
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:4:18: note: vectorized 0 loops in function.
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_4, inputs_15, _3);
PULSE.c:8:2: missed: statement clobbers memory: _5 (layer_17);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_12, pretmp_26, _9);
PULSE.c:13:28: note: ***** Analysis failed with vector mode V8SI
PULSE.c:13:28: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:22:2: missed: statement clobbers memory: _1 (layer_10(D));
PULSE.c:22:2: missed: statement clobbers memory: _14 (_2);
PULSE.c:22:2: missed: statement clobbers memory: _21 (_15);
PULSE.c:22:2: missed: statement clobbers memory: _28 (_22);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_29);
PULSE.c:26:3: missed: statement clobbers memory: memset (_34, 0, _32);
PULSE.c:26:3: missed: statement clobbers memory: memset (_27, 0, _25);
PULSE.c:26:3: missed: statement clobbers memory: memset (_20, 0, _18);
PULSE.c:26:3: missed: statement clobbers memory: memset (_7, 0, _5);
PULSE.c:28:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:28:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:32:6: note: vectorized 1 loops in function.
PULSE.c:34:8: missed: statement clobbers memory: _1 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_2);
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _9 = rand ();
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8SI
PULSE.c:32:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:61:16: missed: couldn't vectorize loop
PULSE.c:61:16: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:64:17: missed: couldn't vectorize loop
PULSE.c:64:17: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:73:19: missed: couldn't vectorize loop
PULSE.c:73:19: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:53:22: missed: couldn't vectorize loop
PULSE.c:53:22: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:47:6: note: vectorized 1 loops in function.
PULSE.c:48:1: missed: statement clobbers memory: saved_stack.7_39 = __builtin_stack_save ();
PULSE.c:49:46: missed: statement clobbers memory: _1 = PULSE_GetLossFunctionPtr (loss_function_40(D));
PULSE.c:60:10: missed: statement clobbers memory: random.4_46 = __builtin_alloca_with_align (_4, 32);
PULSE.c:34:8: missed: statement clobbers memory: _61 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_62);
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _72 = rand ();
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_98, inputs_93, _97);
PULSE.c:8:2: missed: statement clobbers memory: _99 (layer_94);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_105, _104, _103);
PULSE.c:67:11: missed: statement clobbers memory: loss_55 = PULSE_GetLoss_42 (_17, _16, _12, _11);
PULSE.c:22:2: missed: statement clobbers memory: _86 (output_34);
PULSE.c:22:2: missed: statement clobbers memory: _108 (_87);
PULSE.c:22:2: missed: statement clobbers memory: _115 (_109);
PULSE.c:22:2: missed: statement clobbers memory: _122 (_116);
PULSE.c:22:2: missed: statement clobbers memory: _129 (_123);
PULSE.c:22:2: missed: statement clobbers memory: _136 (_130);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_137);
PULSE.c:26:3: missed: statement clobbers memory: memset (_142, 0, _140);
PULSE.c:26:3: missed: statement clobbers memory: memset (_135, 0, _133);
PULSE.c:26:3: missed: statement clobbers memory: memset (_128, 0, _126);
PULSE.c:26:3: missed: statement clobbers memory: memset (_121, 0, _119);
PULSE.c:26:3: missed: statement clobbers memory: memset (_114, 0, _112);
PULSE.c:26:3: missed: statement clobbers memory: memset (_92, 0, _90);
PULSE.c:75:6: missed: statement clobbers memory: _21 (current_191, args);
PULSE.c:81:4: missed: statement clobbers memory: printf ("Epoch: %d | Item: %d | Loss: %.10f | Batch Loss: %.10f\r", i_188, j_189, _25, _24);
PULSE.c:47:6: missed: statement clobbers memory: __builtin_stack_restore (saved_stack.7_39);
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4DI
PULSE.c:47:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:91:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:91:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:119:20: missed: couldn't vectorize loop
PULSE.c:119:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:119:20: missed: couldn't vectorize loop
PULSE.c:119:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:102:20: missed: couldn't vectorize loop
PULSE.c:102:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:102:20: missed: couldn't vectorize loop
PULSE.c:102:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:93:13: note: vectorized 0 loops in function.
PULSE.c:96:39: missed: statement clobbers memory: layers_33 = malloc (_3);
PULSE.c:99:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:114:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:115:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:116:56: missed: statement clobbers memory: MODEL_PARAMETHERS_122 = malloc (0);
PULSE.c:114:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:115:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:116:56: missed: statement clobbers memory: MODEL_PARAMETHERS_38 = malloc (_11);
PULSE.c:125:62: missed: not vectorized: more than one data ref in stmt: D.6472 = MEM[(struct PULSE_DenseLayerArgs * {ref-all})addr.106_66];
PULSE.c:125:17: missed: statement clobbers memory: *_14 = PULSE_CreateDenseLayer (D.6472); [return slot optimization]
PULSE.c:125:62: missed: not vectorized: more than one data ref in stmt: D.6472 = MEM[(struct PULSE_DenseLayerArgs * {ref-all})addr.106_181];
PULSE.c:125:17: missed: statement clobbers memory: *_175 = PULSE_CreateDenseLayer (D.6472); [return slot optimization]
PULSE.c:131:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:132:9: note: ***** Analysis succeeded with vector mode V4DI
PULSE.c:132:9: note: SLPing BB part
PULSE.c:132:9: note: Costing subgraph: 
PULSE.c:132:9: note: node 0x4c0faf8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:132:9: note: op template: <retval>.layers = layers_33;
PULSE.c:132:9: note: 	stmt 0 <retval>.layers = layers_33;
PULSE.c:132:9: note: 	stmt 1 <retval>.paramethers = MODEL_PARAMETHERS_123;
PULSE.c:132:9: note: 	children 0x4c0fbf8
PULSE.c:132:9: note: node (external) 0x4c0fbf8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:132:9: note: 	{ layers_33, MODEL_PARAMETHERS_123 }
PULSE.c:132:9: note: Cost model analysis: 
PULSE.c:132:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
PULSE.c:132:9: note: Costing subgraph: 
PULSE.c:132:9: note: node 0x4c0fc78 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:132:9: note: op template: <retval>.io = 0B;
PULSE.c:132:9: note: 	stmt 0 <retval>.io = 0B;
PULSE.c:132:9: note: 	stmt 1 <retval>.fixes = 0B;
PULSE.c:132:9: note: 	children 0x4c0fcf8
PULSE.c:132:9: note: node (constant) 0x4c0fcf8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:132:9: note: 	{ 0B, 0B }
PULSE.c:132:9: note: Cost model analysis: 
PULSE.c:132:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
PULSE.c:132:9: note: Basic block will be vectorized using SLP
PULSE.c:132:9: optimized: basic block part vectorized using 16 byte vectors
PULSE.c:132:9: note: Vectorizing SLP tree:
PULSE.c:132:9: note: node 0x4c0faf8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:132:9: note: op template: <retval>.layers = layers_33;
PULSE.c:132:9: note: 	stmt 0 <retval>.layers = layers_33;
PULSE.c:132:9: note: 	stmt 1 <retval>.paramethers = MODEL_PARAMETHERS_123;
PULSE.c:132:9: note: 	children 0x4c0fbf8
PULSE.c:132:9: note: node (external) 0x4c0fbf8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:132:9: note: 	{ layers_33, MODEL_PARAMETHERS_123 }
PULSE.c:132:9: note: ------>vectorizing SLP node starting from: <retval>.layers = layers_33;
PULSE.c:132:9: note: vect_is_simple_use: operand MODEL_PARAMETHERS_123 = PHI <MODEL_PARAMETHERS_38(37), MODEL_PARAMETHERS_122(13)>, type of def: internal
PULSE.c:132:9: note: conflicting alias set types.
PULSE.c:132:9: note: transform store. ncopies = 1
PULSE.c:132:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.layers
PULSE.c:132:9: note: created &<retval>
PULSE.c:132:9: note: add new stmt: MEM <vector(2) long unsigned int> [(void *)&<retval>] = _196;
PULSE.c:132:9: note: vectorizing stmts using SLP.
PULSE.c:132:9: optimized: basic block part vectorized using 16 byte vectors
PULSE.c:132:9: note: Vectorizing SLP tree:
PULSE.c:132:9: note: node 0x4c0fc78 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:132:9: note: op template: <retval>.io = 0B;
PULSE.c:132:9: note: 	stmt 0 <retval>.io = 0B;
PULSE.c:132:9: note: 	stmt 1 <retval>.fixes = 0B;
PULSE.c:132:9: note: 	children 0x4c0fcf8
PULSE.c:132:9: note: node (constant) 0x4c0fcf8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:132:9: note: 	{ 0B, 0B }
PULSE.c:132:9: note: ------>vectorizing SLP node starting from: <retval>.io = 0B;
PULSE.c:132:9: note: vect_is_simple_use: operand 0B, type of def: constant
PULSE.c:132:9: note: transform store. ncopies = 1
PULSE.c:132:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.io
PULSE.c:132:9: note: created &<retval>.io
PULSE.c:132:9: note: add new stmt: MEM <vector(2) long unsigned int> [(float * *)&<retval> + 16B] = { 0, 0 };
PULSE.c:132:9: note: vectorizing stmts using SLP.
PULSE.c:132:9: note: ***** The result for vector mode V32QI would be the same
PULSE.c:138:8: missed: couldn't vectorize loop
PULSE.c:138:8: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:135:6: note: vectorized 0 loops in function.
PULSE.c:140:3: missed: statement clobbers memory: _1 (current_10);
PULSE.c:143:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:143:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:4:18: note: vectorized 0 loops in function.
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_4, inputs_15, _3);
PULSE.c:8:2: missed: statement clobbers memory: _5 (layer_17);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_12, pretmp_26, _9);
PULSE.c:13:28: note: ***** Analysis failed with vector mode V8SI
PULSE.c:13:28: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:22:2: missed: statement clobbers memory: _1 (layer_10(D));
PULSE.c:22:2: missed: statement clobbers memory: _14 (_2);
PULSE.c:22:2: missed: statement clobbers memory: _21 (_15);
PULSE.c:22:2: missed: statement clobbers memory: _28 (_22);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_29);
PULSE.c:26:3: missed: statement clobbers memory: memset (_34, 0, _32);
PULSE.c:26:3: missed: statement clobbers memory: memset (_27, 0, _25);
PULSE.c:26:3: missed: statement clobbers memory: memset (_20, 0, _18);
PULSE.c:26:3: missed: statement clobbers memory: memset (_7, 0, _5);
PULSE.c:28:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:28:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:32:6: note: vectorized 1 loops in function.
PULSE.c:34:8: missed: statement clobbers memory: _1 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_2);
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _9 = rand ();
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8SI
PULSE.c:32:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:61:16: missed: couldn't vectorize loop
PULSE.c:61:16: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:64:17: missed: couldn't vectorize loop
PULSE.c:64:17: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:73:19: missed: couldn't vectorize loop
PULSE.c:73:19: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:53:22: missed: couldn't vectorize loop
PULSE.c:53:22: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:47:6: note: vectorized 1 loops in function.
PULSE.c:48:1: missed: statement clobbers memory: saved_stack.7_39 = __builtin_stack_save ();
PULSE.c:49:46: missed: statement clobbers memory: _1 = PULSE_GetLossFunctionPtr (loss_function_40(D));
PULSE.c:60:10: missed: statement clobbers memory: random.4_46 = __builtin_alloca_with_align (_4, 32);
PULSE.c:34:8: missed: statement clobbers memory: _61 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_62);
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _72 = rand ();
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_98, inputs_93, _97);
PULSE.c:8:2: missed: statement clobbers memory: _99 (layer_94);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_105, _104, _103);
PULSE.c:67:11: missed: statement clobbers memory: loss_55 = PULSE_GetLoss_42 (_17, _16, _12, _11);
PULSE.c:22:2: missed: statement clobbers memory: _86 (output_34);
PULSE.c:22:2: missed: statement clobbers memory: _108 (_87);
PULSE.c:22:2: missed: statement clobbers memory: _115 (_109);
PULSE.c:22:2: missed: statement clobbers memory: _122 (_116);
PULSE.c:22:2: missed: statement clobbers memory: _129 (_123);
PULSE.c:22:2: missed: statement clobbers memory: _136 (_130);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_137);
PULSE.c:26:3: missed: statement clobbers memory: memset (_142, 0, _140);
PULSE.c:26:3: missed: statement clobbers memory: memset (_135, 0, _133);
PULSE.c:26:3: missed: statement clobbers memory: memset (_128, 0, _126);
PULSE.c:26:3: missed: statement clobbers memory: memset (_121, 0, _119);
PULSE.c:26:3: missed: statement clobbers memory: memset (_114, 0, _112);
PULSE.c:26:3: missed: statement clobbers memory: memset (_92, 0, _90);
PULSE.c:75:6: missed: statement clobbers memory: _21 (current_191, args);
PULSE.c:81:4: missed: statement clobbers memory: printf ("Epoch: %d | Item: %d | Loss: %.10f | Batch Loss: %.10f\r", i_188, j_189, _25, _24);
PULSE.c:47:6: missed: statement clobbers memory: __builtin_stack_restore (saved_stack.7_39);
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4DI
PULSE.c:47:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:91:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:91:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:119:20: missed: couldn't vectorize loop
PULSE.c:119:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:119:20: missed: couldn't vectorize loop
PULSE.c:119:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:102:20: missed: couldn't vectorize loop
PULSE.c:102:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:102:20: missed: couldn't vectorize loop
PULSE.c:102:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:93:13: note: vectorized 0 loops in function.
PULSE.c:96:39: missed: statement clobbers memory: layers_33 = malloc (_3);
PULSE.c:99:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:114:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:115:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:116:56: missed: statement clobbers memory: MODEL_PARAMETHERS_122 = malloc (0);
PULSE.c:114:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:115:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:116:56: missed: statement clobbers memory: MODEL_PARAMETHERS_38 = malloc (_11);
PULSE.c:125:62: missed: not vectorized: more than one data ref in stmt: D.6468 = MEM[(struct PULSE_DenseLayerArgs * {ref-all})addr.106_66];
PULSE.c:125:17: missed: statement clobbers memory: *_14 = PULSE_CreateDenseLayer (D.6468); [return slot optimization]
PULSE.c:125:62: missed: not vectorized: more than one data ref in stmt: D.6468 = MEM[(struct PULSE_DenseLayerArgs * {ref-all})addr.106_181];
PULSE.c:125:17: missed: statement clobbers memory: *_175 = PULSE_CreateDenseLayer (D.6468); [return slot optimization]
PULSE.c:131:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:132:9: note: ***** Analysis succeeded with vector mode V4DI
PULSE.c:132:9: note: SLPing BB part
PULSE.c:132:9: note: Costing subgraph: 
PULSE.c:132:9: note: node 0x4fd8b08 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:132:9: note: op template: <retval>.layers = layers_33;
PULSE.c:132:9: note: 	stmt 0 <retval>.layers = layers_33;
PULSE.c:132:9: note: 	stmt 1 <retval>.paramethers = MODEL_PARAMETHERS_123;
PULSE.c:132:9: note: 	children 0x4fd8c08
PULSE.c:132:9: note: node (external) 0x4fd8c08 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:132:9: note: 	{ layers_33, MODEL_PARAMETHERS_123 }
PULSE.c:132:9: note: Cost model analysis: 
PULSE.c:132:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
PULSE.c:132:9: note: Costing subgraph: 
PULSE.c:132:9: note: node 0x4fd8c88 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:132:9: note: op template: <retval>.io = 0B;
PULSE.c:132:9: note: 	stmt 0 <retval>.io = 0B;
PULSE.c:132:9: note: 	stmt 1 <retval>.fixes = 0B;
PULSE.c:132:9: note: 	children 0x4fd8d08
PULSE.c:132:9: note: node (constant) 0x4fd8d08 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:132:9: note: 	{ 0B, 0B }
PULSE.c:132:9: note: Cost model analysis: 
PULSE.c:132:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
PULSE.c:132:9: note: Basic block will be vectorized using SLP
PULSE.c:132:9: optimized: basic block part vectorized using 16 byte vectors
PULSE.c:132:9: note: Vectorizing SLP tree:
PULSE.c:132:9: note: node 0x4fd8b08 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:132:9: note: op template: <retval>.layers = layers_33;
PULSE.c:132:9: note: 	stmt 0 <retval>.layers = layers_33;
PULSE.c:132:9: note: 	stmt 1 <retval>.paramethers = MODEL_PARAMETHERS_123;
PULSE.c:132:9: note: 	children 0x4fd8c08
PULSE.c:132:9: note: node (external) 0x4fd8c08 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:132:9: note: 	{ layers_33, MODEL_PARAMETHERS_123 }
PULSE.c:132:9: note: ------>vectorizing SLP node starting from: <retval>.layers = layers_33;
PULSE.c:132:9: note: vect_is_simple_use: operand MODEL_PARAMETHERS_123 = PHI <MODEL_PARAMETHERS_38(37), MODEL_PARAMETHERS_122(13)>, type of def: internal
PULSE.c:132:9: note: conflicting alias set types.
PULSE.c:132:9: note: transform store. ncopies = 1
PULSE.c:132:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.layers
PULSE.c:132:9: note: created &<retval>
PULSE.c:132:9: note: add new stmt: MEM <vector(2) long unsigned int> [(void *)&<retval>] = _196;
PULSE.c:132:9: note: vectorizing stmts using SLP.
PULSE.c:132:9: optimized: basic block part vectorized using 16 byte vectors
PULSE.c:132:9: note: Vectorizing SLP tree:
PULSE.c:132:9: note: node 0x4fd8c88 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:132:9: note: op template: <retval>.io = 0B;
PULSE.c:132:9: note: 	stmt 0 <retval>.io = 0B;
PULSE.c:132:9: note: 	stmt 1 <retval>.fixes = 0B;
PULSE.c:132:9: note: 	children 0x4fd8d08
PULSE.c:132:9: note: node (constant) 0x4fd8d08 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:132:9: note: 	{ 0B, 0B }
PULSE.c:132:9: note: ------>vectorizing SLP node starting from: <retval>.io = 0B;
PULSE.c:132:9: note: vect_is_simple_use: operand 0B, type of def: constant
PULSE.c:132:9: note: transform store. ncopies = 1
PULSE.c:132:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.io
PULSE.c:132:9: note: created &<retval>.io
PULSE.c:132:9: note: add new stmt: MEM <vector(2) long unsigned int> [(float * *)&<retval> + 16B] = { 0, 0 };
PULSE.c:132:9: note: vectorizing stmts using SLP.
PULSE.c:132:9: note: ***** The result for vector mode V32QI would be the same
PULSE.c:144:1: note: ***** Analysis failed with vector mode VOID
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:4:18: note: vectorized 0 loops in function.
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_4, inputs_15, _3);
PULSE.c:8:2: missed: statement clobbers memory: _5 (layer_17);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_12, pretmp_26, _9);
PULSE.c:13:28: note: ***** Analysis failed with vector mode V8SI
PULSE.c:13:28: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:22:2: missed: statement clobbers memory: _1 (layer_10(D));
PULSE.c:22:2: missed: statement clobbers memory: _14 (_2);
PULSE.c:22:2: missed: statement clobbers memory: _21 (_15);
PULSE.c:22:2: missed: statement clobbers memory: _28 (_22);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_29);
PULSE.c:26:3: missed: statement clobbers memory: memset (_34, 0, _32);
PULSE.c:26:3: missed: statement clobbers memory: memset (_27, 0, _25);
PULSE.c:26:3: missed: statement clobbers memory: memset (_20, 0, _18);
PULSE.c:26:3: missed: statement clobbers memory: memset (_7, 0, _5);
PULSE.c:28:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:28:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:32:6: note: vectorized 1 loops in function.
PULSE.c:34:8: missed: statement clobbers memory: _1 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_2);
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _9 = rand ();
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8SI
PULSE.c:32:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:61:16: missed: couldn't vectorize loop
PULSE.c:61:16: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:64:17: missed: couldn't vectorize loop
PULSE.c:64:17: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:73:19: missed: couldn't vectorize loop
PULSE.c:73:19: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:53:22: missed: couldn't vectorize loop
PULSE.c:53:22: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:47:6: note: vectorized 1 loops in function.
PULSE.c:48:1: missed: statement clobbers memory: saved_stack.7_39 = __builtin_stack_save ();
PULSE.c:49:46: missed: statement clobbers memory: _1 = PULSE_GetLossFunctionPtr (loss_function_40(D));
PULSE.c:60:10: missed: statement clobbers memory: random.4_46 = __builtin_alloca_with_align (_4, 32);
PULSE.c:34:8: missed: statement clobbers memory: _61 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_62);
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _72 = rand ();
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_98, inputs_93, _97);
PULSE.c:8:2: missed: statement clobbers memory: _99 (layer_94);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_105, _104, _103);
PULSE.c:67:11: missed: statement clobbers memory: loss_55 = PULSE_GetLoss_42 (_17, _16, _12, _11);
PULSE.c:22:2: missed: statement clobbers memory: _86 (output_34);
PULSE.c:22:2: missed: statement clobbers memory: _108 (_87);
PULSE.c:22:2: missed: statement clobbers memory: _115 (_109);
PULSE.c:22:2: missed: statement clobbers memory: _122 (_116);
PULSE.c:22:2: missed: statement clobbers memory: _129 (_123);
PULSE.c:22:2: missed: statement clobbers memory: _136 (_130);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_137);
PULSE.c:26:3: missed: statement clobbers memory: memset (_142, 0, _140);
PULSE.c:26:3: missed: statement clobbers memory: memset (_135, 0, _133);
PULSE.c:26:3: missed: statement clobbers memory: memset (_128, 0, _126);
PULSE.c:26:3: missed: statement clobbers memory: memset (_121, 0, _119);
PULSE.c:26:3: missed: statement clobbers memory: memset (_114, 0, _112);
PULSE.c:26:3: missed: statement clobbers memory: memset (_92, 0, _90);
PULSE.c:75:6: missed: statement clobbers memory: _21 (current_191, args);
PULSE.c:81:4: missed: statement clobbers memory: printf ("Epoch: %d | Item: %d | Loss: %.10f | Batch Loss: %.10f\r", i_188, j_189, _25, _24);
PULSE.c:47:6: missed: statement clobbers memory: __builtin_stack_restore (saved_stack.7_39);
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4DI
PULSE.c:47:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:91:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:91:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:119:20: missed: couldn't vectorize loop
PULSE.c:119:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:119:20: missed: couldn't vectorize loop
PULSE.c:119:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:102:20: missed: couldn't vectorize loop
PULSE.c:102:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:102:20: missed: couldn't vectorize loop
PULSE.c:102:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:93:13: note: vectorized 0 loops in function.
PULSE.c:96:39: missed: statement clobbers memory: layers_33 = malloc (_3);
PULSE.c:99:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:114:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:115:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:116:44: missed: statement clobbers memory: MODEL_122 = malloc (0);
PULSE.c:114:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:115:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:116:44: missed: statement clobbers memory: MODEL_38 = malloc (_11);
PULSE.c:125:62: missed: not vectorized: more than one data ref in stmt: D.6468 = MEM[(struct PULSE_DenseLayerArgs * {ref-all})addr.106_66];
PULSE.c:125:17: missed: statement clobbers memory: *_14 = PULSE_CreateDenseLayer (D.6468); [return slot optimization]
PULSE.c:125:62: missed: not vectorized: more than one data ref in stmt: D.6468 = MEM[(struct PULSE_DenseLayerArgs * {ref-all})addr.106_181];
PULSE.c:125:17: missed: statement clobbers memory: *_175 = PULSE_CreateDenseLayer (D.6468); [return slot optimization]
PULSE.c:131:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:132:9: note: ***** Analysis succeeded with vector mode V4DI
PULSE.c:132:9: note: SLPing BB part
PULSE.c:132:9: note: Costing subgraph: 
PULSE.c:132:9: note: node 0x31adae8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:132:9: note: op template: <retval>.layers = layers_33;
PULSE.c:132:9: note: 	stmt 0 <retval>.layers = layers_33;
PULSE.c:132:9: note: 	stmt 1 <retval>.paramethers = MODEL_123;
PULSE.c:132:9: note: 	children 0x31adbe8
PULSE.c:132:9: note: node (external) 0x31adbe8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:132:9: note: 	{ layers_33, MODEL_123 }
PULSE.c:132:9: note: Cost model analysis: 
PULSE.c:132:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
PULSE.c:132:9: note: Costing subgraph: 
PULSE.c:132:9: note: node 0x31adc68 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:132:9: note: op template: <retval>.io = 0B;
PULSE.c:132:9: note: 	stmt 0 <retval>.io = 0B;
PULSE.c:132:9: note: 	stmt 1 <retval>.fixes = 0B;
PULSE.c:132:9: note: 	children 0x31adce8
PULSE.c:132:9: note: node (constant) 0x31adce8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:132:9: note: 	{ 0B, 0B }
PULSE.c:132:9: note: Cost model analysis: 
PULSE.c:132:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
PULSE.c:132:9: note: Basic block will be vectorized using SLP
PULSE.c:132:9: optimized: basic block part vectorized using 16 byte vectors
PULSE.c:132:9: note: Vectorizing SLP tree:
PULSE.c:132:9: note: node 0x31adae8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:132:9: note: op template: <retval>.layers = layers_33;
PULSE.c:132:9: note: 	stmt 0 <retval>.layers = layers_33;
PULSE.c:132:9: note: 	stmt 1 <retval>.paramethers = MODEL_123;
PULSE.c:132:9: note: 	children 0x31adbe8
PULSE.c:132:9: note: node (external) 0x31adbe8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:132:9: note: 	{ layers_33, MODEL_123 }
PULSE.c:132:9: note: ------>vectorizing SLP node starting from: <retval>.layers = layers_33;
PULSE.c:132:9: note: vect_is_simple_use: operand MODEL_123 = PHI <MODEL_38(37), MODEL_122(13)>, type of def: internal
PULSE.c:132:9: note: conflicting alias set types.
PULSE.c:132:9: note: transform store. ncopies = 1
PULSE.c:132:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.layers
PULSE.c:132:9: note: created &<retval>
PULSE.c:132:9: note: add new stmt: MEM <vector(2) long unsigned int> [(void *)&<retval>] = _196;
PULSE.c:132:9: note: vectorizing stmts using SLP.
PULSE.c:132:9: optimized: basic block part vectorized using 16 byte vectors
PULSE.c:132:9: note: Vectorizing SLP tree:
PULSE.c:132:9: note: node 0x31adc68 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:132:9: note: op template: <retval>.io = 0B;
PULSE.c:132:9: note: 	stmt 0 <retval>.io = 0B;
PULSE.c:132:9: note: 	stmt 1 <retval>.fixes = 0B;
PULSE.c:132:9: note: 	children 0x31adce8
PULSE.c:132:9: note: node (constant) 0x31adce8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:132:9: note: 	{ 0B, 0B }
PULSE.c:132:9: note: ------>vectorizing SLP node starting from: <retval>.io = 0B;
PULSE.c:132:9: note: vect_is_simple_use: operand 0B, type of def: constant
PULSE.c:132:9: note: transform store. ncopies = 1
PULSE.c:132:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.io
PULSE.c:132:9: note: created &<retval>.io
PULSE.c:132:9: note: add new stmt: MEM <vector(2) long unsigned int> [(float * *)&<retval> + 16B] = { 0, 0 };
PULSE.c:132:9: note: vectorizing stmts using SLP.
PULSE.c:132:9: note: ***** The result for vector mode V32QI would be the same
PULSE.c:144:1: note: ***** Analysis failed with vector mode VOID
Dense.c:9:27: missed: couldn't vectorize loop
Dense.c:9:27: missed: not vectorized: unsupported outerloop form.
Dense.c:12:20: missed: couldn't vectorize loop
Dense.c:13:21: missed: not vectorized: complicated access pattern.
Dense.c:6:13: note: vectorized 0 loops in function.
Dense.c:16:2: missed: statement clobbers memory: _28 (pretmp_91, _51, 0);
Dense.c:9:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:9:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:24:27: missed: couldn't vectorize loop
Dense.c:24:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:28:20: optimized: loop vectorized using 32 byte vectors
Dense.c:28:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:28:20: optimized: loop vectorized using 16 byte vectors
Dense.c:28:20: missed: couldn't vectorize loop
Dense.c:30:19: missed: not vectorized: no vectype for stmt: _22 = *_21;
 scalar_type: float
Dense.c:20:13: note: vectorized 1 loops in function.
Dense.c:23:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:24:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:24:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:41:28: missed: couldn't vectorize loop
Dense.c:41:28: missed: not vectorized: unsupported outerloop form.
Dense.c:45:21: optimized: loop vectorized using 32 byte vectors
Dense.c:45:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:45:21: optimized: loop vectorized using 16 byte vectors
Dense.c:37:13: note: vectorized 1 loops in function.
Dense.c:37:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:37:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:41:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:170:10: optimized: loop vectorized using 32 byte vectors
Dense.c:170:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:170:10: optimized: loop vectorized using 16 byte vectors
Dense.c:161:10: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_27, _64);
Dense.c:154:10: optimized: loop vectorized using 32 byte vectors
Dense.c:154:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:154:10: optimized: loop vectorized using 16 byte vectors
Dense.c:145:10: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_14, _56);
Dense.c:136:13: note: vectorized 2 loops in function.
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_14, _56);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_15, { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 });
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_27, _64);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_28, { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 });
Dense.c:136:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:136:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:105:24: missed: couldn't vectorize loop
Dense.c:105:24: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:108:17: missed: couldn't vectorize loop
Dense.c:108:17: missed: not vectorized: number of iterations cannot be computed.
Dense.c:122:24: missed: couldn't vectorize loop
Dense.c:122:24: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:125:17: missed: couldn't vectorize loop
Dense.c:125:17: missed: not vectorized: number of iterations cannot be computed.
Dense.c:90:15: missed: couldn't vectorize loop
Dense.c:90:15: missed: not vectorized: number of iterations cannot be computed.
Dense.c:83:13: note: vectorized 0 loops in function.
Dense.c:86:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:110:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:110:17: note: SLPing BB part
Dense.c:127:17: note: Costing subgraph: 
Dense.c:127:17: note: node 0x8be9d08 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:127:17: note: op template: _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 0 _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 1 _198 = (sizetype) wi_137;
Dense.c:127:17: note: 	children 0x8be9e08
Dense.c:127:17: note: node (external) 0x8be9e08 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:127:17: note: 	{ j_135, wi_137 }
Dense.c:127:17: note: Cost model analysis: 
Dense.c:127:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:127:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:127:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: Costing subgraph: 
Dense.c:110:17: note: node 0x8be9f08 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:110:17: note: op template: _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 0 _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 1 _217 = (sizetype) wi_136;
Dense.c:110:17: note: 	children 0x8bea008
Dense.c:110:17: note: node (external) 0x8bea008 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:110:17: note: 	{ j_134, wi_136 }
Dense.c:110:17: note: Cost model analysis: 
Dense.c:110:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:110:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:110:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:110:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:110:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:110:17: note: SLPing BB part
Dense.c:127:17: note: Costing subgraph: 
Dense.c:127:17: note: node 0x8be9f08 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:127:17: note: op template: _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 0 _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 1 _198 = (sizetype) wi_137;
Dense.c:127:17: note: 	children 0x8be9d08
Dense.c:127:17: note: node (external) 0x8be9d08 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:127:17: note: 	{ j_135, wi_137 }
Dense.c:127:17: note: Cost model analysis: 
Dense.c:127:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:127:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:127:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: Costing subgraph: 
Dense.c:110:17: note: node 0x8be9e88 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:110:17: note: op template: _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 0 _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 1 _217 = (sizetype) wi_136;
Dense.c:110:17: note: 	children 0x8be9f88
Dense.c:110:17: note: node (external) 0x8be9f88 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:110:17: note: 	{ j_134, wi_136 }
Dense.c:110:17: note: Cost model analysis: 
Dense.c:110:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:110:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:110:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:105:51: note: ***** Analysis failed with vector mode V8QI
Dense.c:105:51: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:105:51: note: ***** Analysis failed with vector mode V4QI
Dense.c:62:15: missed: couldn't vectorize loop
Dense.c:62:15: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:75:11: optimized: loop vectorized using 32 byte vectors
Dense.c:75:11: optimized: loop vectorized using 16 byte vectors
Dense.c:66:11: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:881:10: missed: not vectorized: no vectype for stmt: _53 = MEM[(__m256 * {ref-all})w_ptr_82];
 scalar_type: __m256
Dense.c:54:13: note: vectorized 1 loops in function.
Dense.c:57:2: missed: statement clobbers memory: memcpy (_4, dense$baiases_63, _3);
Dense.c:79:2: missed: statement clobbers memory: _27 (pretmp_163, _68, 0);
Dense.c:54:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:54:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:182:2: missed: statement clobbers memory: free (dense$weights_7);
Dense.c:183:2: missed: statement clobbers memory: free (dense$baiases_8);
Dense.c:184:2: missed: statement clobbers memory: free (dense$gradients_10);
Dense.c:185:2: missed: statement clobbers memory: free (dense$deltas_9);
Dense.c:186:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:186:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:202:19: missed: couldn't vectorize loop
Dense.c:202:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:190:13: note: vectorized 0 loops in function.
Dense.c:198:37: missed: statement clobbers memory: _9 = aligned_alloc (64, _8);
Dense.c:199:34: missed: statement clobbers memory: _10 = aligned_alloc (64, _5);
Dense.c:200:35: missed: statement clobbers memory: _11 = aligned_alloc (64, _5);
Dense.c:203:38: missed: statement clobbers memory: _12 = rand ();
Dense.c:203:72: missed: statement clobbers memory: _57 = sqrt (_19);
Dense.c:215:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:216:4: missed: statement clobbers memory: exit (1);
Dense.c:212:4: missed: statement clobbers memory: layer = PULSE_CreateLayer (args$n_inputs_36, args$n_outputs_47, 0, args$8_48, _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:209:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (args$n_inputs_36, args$n_outputs_47, 0, args$8_48, _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:221:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Dense.c:221:9: note: ***** Analysis succeeded with vector mode V8SI
Dense.c:221:9: note: SLPing BB part
Dense.c:221:9: note: Costing subgraph: 
Dense.c:221:9: note: node 0x8aeee68 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Dense.c:221:9: note: op template: MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = MODEL_31(D);
Dense.c:221:9: note: 	stmt 0 MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = MODEL_31(D);
Dense.c:221:9: note: 	stmt 1 MEM <float *> [(struct PULSE_Layer *)&layer + 96B] = MODEL_32;
Dense.c:221:9: note: 	stmt 2 MEM <float *> [(struct PULSE_Layer *)&layer + 104B] = _10;
Dense.c:221:9: note: 	stmt 3 MEM <float *> [(struct PULSE_Layer *)&layer + 112B] = _11;
Dense.c:221:9: note: 	children 0x8aeeee8
Dense.c:221:9: note: node (external) 0x8aeeee8 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Dense.c:221:9: note: 	{ MODEL_31(D), MODEL_32, _10, _11 }
Dense.c:221:9: note: Cost model analysis: 
Dense.c:221:9: note: Cost model analysis for part in loop 0:
  Vector cost: 64
  Scalar cost: 64
Dense.c:221:9: note: Basic block will be vectorized using SLP
Dense.c:221:9: optimized: basic block part vectorized using 32 byte vectors
Dense.c:221:9: note: Vectorizing SLP tree:
Dense.c:221:9: note: node 0x8aeee68 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Dense.c:221:9: note: op template: MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = MODEL_31(D);
Dense.c:221:9: note: 	stmt 0 MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = MODEL_31(D);
Dense.c:221:9: note: 	stmt 1 MEM <float *> [(struct PULSE_Layer *)&layer + 96B] = MODEL_32;
Dense.c:221:9: note: 	stmt 2 MEM <float *> [(struct PULSE_Layer *)&layer + 104B] = _10;
Dense.c:221:9: note: 	stmt 3 MEM <float *> [(struct PULSE_Layer *)&layer + 112B] = _11;
Dense.c:221:9: note: 	children 0x8aeeee8
Dense.c:221:9: note: node (external) 0x8aeeee8 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Dense.c:221:9: note: 	{ MODEL_31(D), MODEL_32, _10, _11 }
Dense.c:221:9: note: ------>vectorizing SLP node starting from: MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = MODEL_31(D);
Dense.c:221:9: note: vect_is_simple_use: operand MODEL_31(D) + _3, type of def: internal
Dense.c:221:9: note: vect_is_simple_use: operand aligned_alloc (64, _5), type of def: internal
Dense.c:221:9: note: vect_is_simple_use: operand aligned_alloc (64, _5), type of def: internal
Dense.c:221:9: note: transform store. ncopies = 1
Dense.c:221:9: note: create vector_type-pointer variable to type: vector(4) long unsigned int  vectorizing a pointer ref: MEM <float *> [(struct PULSE_Layer *)&layer + 88B]
Dense.c:221:9: note: created &MEM <float *> [(struct PULSE_Layer *)&layer + 88B]
Dense.c:221:9: note: add new stmt: MEM <vector(4) long unsigned int> [(struct PULSE_Layer *)&layer + 88B] = _61;
Dense.c:221:9: note: vectorizing stmts using SLP.
Dense.c:221:9: note: ***** The result for vector mode V32QI would be the same
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:4:18: note: vectorized 0 loops in function.
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_4, inputs_15, _3);
PULSE.c:8:2: missed: statement clobbers memory: _5 (layer_17);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_12, pretmp_26, _9);
PULSE.c:13:28: note: ***** Analysis failed with vector mode V8SI
PULSE.c:13:28: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:22:2: missed: statement clobbers memory: _1 (layer_10(D));
PULSE.c:22:2: missed: statement clobbers memory: _14 (_2);
PULSE.c:22:2: missed: statement clobbers memory: _21 (_15);
PULSE.c:22:2: missed: statement clobbers memory: _28 (_22);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_29);
PULSE.c:26:3: missed: statement clobbers memory: memset (_34, 0, _32);
PULSE.c:26:3: missed: statement clobbers memory: memset (_27, 0, _25);
PULSE.c:26:3: missed: statement clobbers memory: memset (_20, 0, _18);
PULSE.c:26:3: missed: statement clobbers memory: memset (_7, 0, _5);
PULSE.c:28:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:28:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:32:6: note: vectorized 1 loops in function.
PULSE.c:34:8: missed: statement clobbers memory: _1 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_2);
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _9 = rand ();
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8SI
PULSE.c:32:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:61:16: missed: couldn't vectorize loop
PULSE.c:61:16: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:64:17: missed: couldn't vectorize loop
PULSE.c:64:17: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:73:19: missed: couldn't vectorize loop
PULSE.c:73:19: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:53:22: missed: couldn't vectorize loop
PULSE.c:53:22: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:47:6: note: vectorized 1 loops in function.
PULSE.c:48:1: missed: statement clobbers memory: saved_stack.7_39 = __builtin_stack_save ();
PULSE.c:49:46: missed: statement clobbers memory: _1 = PULSE_GetLossFunctionPtr (loss_function_40(D));
PULSE.c:60:10: missed: statement clobbers memory: random.4_46 = __builtin_alloca_with_align (_4, 32);
PULSE.c:34:8: missed: statement clobbers memory: _61 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_62);
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _72 = rand ();
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_98, inputs_93, _97);
PULSE.c:8:2: missed: statement clobbers memory: _99 (layer_94);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_105, _104, _103);
PULSE.c:67:11: missed: statement clobbers memory: loss_55 = PULSE_GetLoss_42 (_17, _16, _12, _11);
PULSE.c:22:2: missed: statement clobbers memory: _86 (output_34);
PULSE.c:22:2: missed: statement clobbers memory: _108 (_87);
PULSE.c:22:2: missed: statement clobbers memory: _115 (_109);
PULSE.c:22:2: missed: statement clobbers memory: _122 (_116);
PULSE.c:22:2: missed: statement clobbers memory: _129 (_123);
PULSE.c:22:2: missed: statement clobbers memory: _136 (_130);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_137);
PULSE.c:26:3: missed: statement clobbers memory: memset (_142, 0, _140);
PULSE.c:26:3: missed: statement clobbers memory: memset (_135, 0, _133);
PULSE.c:26:3: missed: statement clobbers memory: memset (_128, 0, _126);
PULSE.c:26:3: missed: statement clobbers memory: memset (_121, 0, _119);
PULSE.c:26:3: missed: statement clobbers memory: memset (_114, 0, _112);
PULSE.c:26:3: missed: statement clobbers memory: memset (_92, 0, _90);
PULSE.c:75:6: missed: statement clobbers memory: _21 (current_191, args);
PULSE.c:81:4: missed: statement clobbers memory: printf ("Epoch: %d | Item: %d | Loss: %.10f | Batch Loss: %.10f\r", i_188, j_189, _25, _24);
PULSE.c:47:6: missed: statement clobbers memory: __builtin_stack_restore (saved_stack.7_39);
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4DI
PULSE.c:47:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:91:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:91:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:119:20: missed: couldn't vectorize loop
PULSE.c:119:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:119:20: missed: couldn't vectorize loop
PULSE.c:119:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:102:20: missed: couldn't vectorize loop
PULSE.c:102:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:102:20: missed: couldn't vectorize loop
PULSE.c:102:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:93:13: note: vectorized 0 loops in function.
PULSE.c:96:39: missed: statement clobbers memory: layers_33 = malloc (_3);
PULSE.c:99:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:114:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:115:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:116:44: missed: statement clobbers memory: MODEL_122 = malloc (0);
PULSE.c:114:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:115:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:116:44: missed: statement clobbers memory: MODEL_38 = malloc (_11);
PULSE.c:125:62: missed: not vectorized: more than one data ref in stmt: D.6469 = MEM[(struct PULSE_DenseLayerArgs * {ref-all})addr.106_66];
PULSE.c:125:17: missed: statement clobbers memory: *_14 = PULSE_CreateDenseLayer (D.6469, MODEL_38); [return slot optimization]
PULSE.c:125:62: missed: not vectorized: more than one data ref in stmt: D.6469 = MEM[(struct PULSE_DenseLayerArgs * {ref-all})addr.106_181];
PULSE.c:125:17: missed: statement clobbers memory: *_175 = PULSE_CreateDenseLayer (D.6469, MODEL_38); [return slot optimization]
PULSE.c:131:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:132:9: note: ***** Analysis succeeded with vector mode V4DI
PULSE.c:132:9: note: SLPing BB part
PULSE.c:132:9: note: Costing subgraph: 
PULSE.c:132:9: note: node 0x4fd0b08 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:132:9: note: op template: <retval>.layers = layers_33;
PULSE.c:132:9: note: 	stmt 0 <retval>.layers = layers_33;
PULSE.c:132:9: note: 	stmt 1 <retval>.paramethers = MODEL_123;
PULSE.c:132:9: note: 	children 0x4fd0c08
PULSE.c:132:9: note: node (external) 0x4fd0c08 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:132:9: note: 	{ layers_33, MODEL_123 }
PULSE.c:132:9: note: Cost model analysis: 
PULSE.c:132:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
PULSE.c:132:9: note: Costing subgraph: 
PULSE.c:132:9: note: node 0x4fd0c88 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:132:9: note: op template: <retval>.io = 0B;
PULSE.c:132:9: note: 	stmt 0 <retval>.io = 0B;
PULSE.c:132:9: note: 	stmt 1 <retval>.fixes = 0B;
PULSE.c:132:9: note: 	children 0x4fd0d08
PULSE.c:132:9: note: node (constant) 0x4fd0d08 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:132:9: note: 	{ 0B, 0B }
PULSE.c:132:9: note: Cost model analysis: 
PULSE.c:132:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
PULSE.c:132:9: note: Basic block will be vectorized using SLP
PULSE.c:132:9: optimized: basic block part vectorized using 16 byte vectors
PULSE.c:132:9: note: Vectorizing SLP tree:
PULSE.c:132:9: note: node 0x4fd0b08 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:132:9: note: op template: <retval>.layers = layers_33;
PULSE.c:132:9: note: 	stmt 0 <retval>.layers = layers_33;
PULSE.c:132:9: note: 	stmt 1 <retval>.paramethers = MODEL_123;
PULSE.c:132:9: note: 	children 0x4fd0c08
PULSE.c:132:9: note: node (external) 0x4fd0c08 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:132:9: note: 	{ layers_33, MODEL_123 }
PULSE.c:132:9: note: ------>vectorizing SLP node starting from: <retval>.layers = layers_33;
PULSE.c:132:9: note: vect_is_simple_use: operand MODEL_123 = PHI <MODEL_38(37), MODEL_122(13)>, type of def: internal
PULSE.c:132:9: note: conflicting alias set types.
PULSE.c:132:9: note: transform store. ncopies = 1
PULSE.c:132:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.layers
PULSE.c:132:9: note: created &<retval>
PULSE.c:132:9: note: add new stmt: MEM <vector(2) long unsigned int> [(void *)&<retval>] = _196;
PULSE.c:132:9: note: vectorizing stmts using SLP.
PULSE.c:132:9: optimized: basic block part vectorized using 16 byte vectors
PULSE.c:132:9: note: Vectorizing SLP tree:
PULSE.c:132:9: note: node 0x4fd0c88 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:132:9: note: op template: <retval>.io = 0B;
PULSE.c:132:9: note: 	stmt 0 <retval>.io = 0B;
PULSE.c:132:9: note: 	stmt 1 <retval>.fixes = 0B;
PULSE.c:132:9: note: 	children 0x4fd0d08
PULSE.c:132:9: note: node (constant) 0x4fd0d08 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:132:9: note: 	{ 0B, 0B }
PULSE.c:132:9: note: ------>vectorizing SLP node starting from: <retval>.io = 0B;
PULSE.c:132:9: note: vect_is_simple_use: operand 0B, type of def: constant
PULSE.c:132:9: note: transform store. ncopies = 1
PULSE.c:132:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.io
PULSE.c:132:9: note: created &<retval>.io
PULSE.c:132:9: note: add new stmt: MEM <vector(2) long unsigned int> [(float * *)&<retval> + 16B] = { 0, 0 };
PULSE.c:132:9: note: vectorizing stmts using SLP.
PULSE.c:132:9: note: ***** The result for vector mode V32QI would be the same
PULSE.c:144:1: note: ***** Analysis failed with vector mode VOID
Dense.c:9:27: missed: couldn't vectorize loop
Dense.c:9:27: missed: not vectorized: unsupported outerloop form.
Dense.c:12:20: missed: couldn't vectorize loop
Dense.c:13:21: missed: not vectorized: complicated access pattern.
Dense.c:6:13: note: vectorized 0 loops in function.
Dense.c:16:2: missed: statement clobbers memory: _28 (pretmp_91, _51, 0);
Dense.c:9:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:9:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:24:27: missed: couldn't vectorize loop
Dense.c:24:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:28:20: optimized: loop vectorized using 32 byte vectors
Dense.c:28:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:28:20: optimized: loop vectorized using 16 byte vectors
Dense.c:28:20: missed: couldn't vectorize loop
Dense.c:30:19: missed: not vectorized: no vectype for stmt: _22 = *_21;
 scalar_type: float
Dense.c:20:13: note: vectorized 1 loops in function.
Dense.c:23:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:24:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:24:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:41:28: missed: couldn't vectorize loop
Dense.c:41:28: missed: not vectorized: unsupported outerloop form.
Dense.c:45:21: optimized: loop vectorized using 32 byte vectors
Dense.c:45:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:45:21: optimized: loop vectorized using 16 byte vectors
Dense.c:37:13: note: vectorized 1 loops in function.
Dense.c:37:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:37:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:41:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:170:10: optimized: loop vectorized using 32 byte vectors
Dense.c:170:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:170:10: optimized: loop vectorized using 16 byte vectors
Dense.c:161:10: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_27, _64);
Dense.c:154:10: optimized: loop vectorized using 32 byte vectors
Dense.c:154:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:154:10: optimized: loop vectorized using 16 byte vectors
Dense.c:145:10: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_14, _56);
Dense.c:136:13: note: vectorized 2 loops in function.
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_14, _56);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_15, { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 });
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_27, _64);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_28, { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 });
Dense.c:136:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:136:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:105:24: missed: couldn't vectorize loop
Dense.c:105:24: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:108:17: missed: couldn't vectorize loop
Dense.c:108:17: missed: not vectorized: number of iterations cannot be computed.
Dense.c:122:24: missed: couldn't vectorize loop
Dense.c:122:24: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:125:17: missed: couldn't vectorize loop
Dense.c:125:17: missed: not vectorized: number of iterations cannot be computed.
Dense.c:90:15: missed: couldn't vectorize loop
Dense.c:90:15: missed: not vectorized: number of iterations cannot be computed.
Dense.c:83:13: note: vectorized 0 loops in function.
Dense.c:86:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:110:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:110:17: note: SLPing BB part
Dense.c:127:17: note: Costing subgraph: 
Dense.c:127:17: note: node 0x767c138 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:127:17: note: op template: _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 0 _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 1 _198 = (sizetype) wi_137;
Dense.c:127:17: note: 	children 0x767c238
Dense.c:127:17: note: node (external) 0x767c238 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:127:17: note: 	{ j_135, wi_137 }
Dense.c:127:17: note: Cost model analysis: 
Dense.c:127:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:127:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:127:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: Costing subgraph: 
Dense.c:110:17: note: node 0x767c338 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:110:17: note: op template: _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 0 _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 1 _217 = (sizetype) wi_136;
Dense.c:110:17: note: 	children 0x767c438
Dense.c:110:17: note: node (external) 0x767c438 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:110:17: note: 	{ j_134, wi_136 }
Dense.c:110:17: note: Cost model analysis: 
Dense.c:110:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:110:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:110:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:110:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:110:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:110:17: note: SLPing BB part
Dense.c:127:17: note: Costing subgraph: 
Dense.c:127:17: note: node 0x767c338 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:127:17: note: op template: _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 0 _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 1 _198 = (sizetype) wi_137;
Dense.c:127:17: note: 	children 0x767c138
Dense.c:127:17: note: node (external) 0x767c138 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:127:17: note: 	{ j_135, wi_137 }
Dense.c:127:17: note: Cost model analysis: 
Dense.c:127:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:127:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:127:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: Costing subgraph: 
Dense.c:110:17: note: node 0x767c2b8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:110:17: note: op template: _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 0 _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 1 _217 = (sizetype) wi_136;
Dense.c:110:17: note: 	children 0x767c3b8
Dense.c:110:17: note: node (external) 0x767c3b8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:110:17: note: 	{ j_134, wi_136 }
Dense.c:110:17: note: Cost model analysis: 
Dense.c:110:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:110:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:110:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:105:51: note: ***** Analysis failed with vector mode V8QI
Dense.c:105:51: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:105:51: note: ***** Analysis failed with vector mode V4QI
Dense.c:62:15: missed: couldn't vectorize loop
Dense.c:62:15: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:75:11: optimized: loop vectorized using 32 byte vectors
Dense.c:75:11: optimized: loop vectorized using 16 byte vectors
Dense.c:66:11: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:881:10: missed: not vectorized: no vectype for stmt: _53 = MEM[(__m256 * {ref-all})w_ptr_82];
 scalar_type: __m256
Dense.c:54:13: note: vectorized 1 loops in function.
Dense.c:57:2: missed: statement clobbers memory: memcpy (_4, dense$baiases_63, _3);
Dense.c:79:2: missed: statement clobbers memory: _27 (pretmp_163, _68, 0);
Dense.c:54:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:54:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:182:2: missed: statement clobbers memory: free (dense$weights_7);
Dense.c:183:2: missed: statement clobbers memory: free (dense$baiases_8);
Dense.c:184:2: missed: statement clobbers memory: free (dense$gradients_10);
Dense.c:185:2: missed: statement clobbers memory: free (dense$deltas_9);
Dense.c:186:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:186:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:202:19: missed: couldn't vectorize loop
Dense.c:202:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:190:13: note: vectorized 0 loops in function.
Dense.c:198:37: missed: statement clobbers memory: _12 = aligned_alloc (64, _11);
Dense.c:199:34: missed: statement clobbers memory: _13 = aligned_alloc (64, _7);
Dense.c:200:35: missed: statement clobbers memory: _14 = aligned_alloc (64, _7);
Dense.c:203:38: missed: statement clobbers memory: _15 = rand ();
Dense.c:203:72: missed: statement clobbers memory: _60 = sqrt (_22);
Dense.c:215:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:216:4: missed: statement clobbers memory: exit (1);
Dense.c:212:4: missed: statement clobbers memory: layer = PULSE_CreateLayer (args$n_inputs_39, args$n_outputs_50, 0, args$8_51, _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:209:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (args$n_inputs_39, args$n_outputs_50, 0, args$8_51, _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:221:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Dense.c:221:9: note: ***** Analysis succeeded with vector mode V8SI
Dense.c:221:9: note: SLPing BB part
Dense.c:221:9: note: Costing subgraph: 
Dense.c:221:9: note: node 0x7584c48 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Dense.c:221:9: note: op template: MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = _1;
Dense.c:221:9: note: 	stmt 0 MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = _1;
Dense.c:221:9: note: 	stmt 1 MEM <float *> [(struct PULSE_Layer *)&layer + 96B] = _5;
Dense.c:221:9: note: 	stmt 2 MEM <float *> [(struct PULSE_Layer *)&layer + 104B] = _13;
Dense.c:221:9: note: 	stmt 3 MEM <float *> [(struct PULSE_Layer *)&layer + 112B] = _14;
Dense.c:221:9: note: 	children 0x7584d48
Dense.c:221:9: note: node (external) 0x7584d48 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Dense.c:221:9: note: 	{ _1, _5, _13, _14 }
Dense.c:221:9: note: Cost model analysis: 
Dense.c:221:9: note: Cost model analysis for part in loop 0:
  Vector cost: 58
  Scalar cost: 64
Dense.c:221:9: note: Basic block will be vectorized using SLP
Dense.c:221:9: optimized: basic block part vectorized using 32 byte vectors
Dense.c:221:9: note: Vectorizing SLP tree:
Dense.c:221:9: note: node 0x7584c48 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Dense.c:221:9: note: op template: MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = _1;
Dense.c:221:9: note: 	stmt 0 MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = _1;
Dense.c:221:9: note: 	stmt 1 MEM <float *> [(struct PULSE_Layer *)&layer + 96B] = _5;
Dense.c:221:9: note: 	stmt 2 MEM <float *> [(struct PULSE_Layer *)&layer + 104B] = _13;
Dense.c:221:9: note: 	stmt 3 MEM <float *> [(struct PULSE_Layer *)&layer + 112B] = _14;
Dense.c:221:9: note: 	children 0x7584d48
Dense.c:221:9: note: node (external) 0x7584d48 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Dense.c:221:9: note: 	{ _1, _5, _13, _14 }
Dense.c:221:9: note: ------>vectorizing SLP node starting from: MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = _1;
Dense.c:221:9: note: vect_is_simple_use: operand _1 + _4, type of def: internal
Dense.c:221:9: note: vect_is_simple_use: operand aligned_alloc (64, _7), type of def: internal
Dense.c:221:9: note: vect_is_simple_use: operand aligned_alloc (64, _7), type of def: internal
Dense.c:221:9: note: transform store. ncopies = 1
Dense.c:221:9: note: create vector_type-pointer variable to type: vector(4) long unsigned int  vectorizing a pointer ref: MEM <float *> [(struct PULSE_Layer *)&layer + 88B]
Dense.c:221:9: note: created &MEM <float *> [(struct PULSE_Layer *)&layer + 88B]
Dense.c:221:9: note: add new stmt: MEM <vector(4) long unsigned int> [(struct PULSE_Layer *)&layer + 88B] = _64;
Dense.c:221:9: note: vectorizing stmts using SLP.
Dense.c:221:9: note: ***** The result for vector mode V32QI would be the same
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:4:18: note: vectorized 0 loops in function.
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_4, inputs_15, _3);
PULSE.c:8:2: missed: statement clobbers memory: _5 (layer_17);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_12, pretmp_26, _9);
PULSE.c:13:28: note: ***** Analysis failed with vector mode V8SI
PULSE.c:13:28: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:22:2: missed: statement clobbers memory: _1 (layer_10(D));
PULSE.c:22:2: missed: statement clobbers memory: _14 (_2);
PULSE.c:22:2: missed: statement clobbers memory: _21 (_15);
PULSE.c:22:2: missed: statement clobbers memory: _28 (_22);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_29);
PULSE.c:26:3: missed: statement clobbers memory: memset (_34, 0, _32);
PULSE.c:26:3: missed: statement clobbers memory: memset (_27, 0, _25);
PULSE.c:26:3: missed: statement clobbers memory: memset (_20, 0, _18);
PULSE.c:26:3: missed: statement clobbers memory: memset (_7, 0, _5);
PULSE.c:28:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:28:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:32:6: note: vectorized 1 loops in function.
PULSE.c:34:8: missed: statement clobbers memory: _1 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_2);
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _9 = rand ();
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8SI
PULSE.c:32:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:61:16: missed: couldn't vectorize loop
PULSE.c:61:16: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:64:17: missed: couldn't vectorize loop
PULSE.c:64:17: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:73:19: missed: couldn't vectorize loop
PULSE.c:73:19: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:53:22: missed: couldn't vectorize loop
PULSE.c:53:22: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:47:6: note: vectorized 1 loops in function.
PULSE.c:48:1: missed: statement clobbers memory: saved_stack.7_39 = __builtin_stack_save ();
PULSE.c:49:46: missed: statement clobbers memory: _1 = PULSE_GetLossFunctionPtr (loss_function_40(D));
PULSE.c:60:10: missed: statement clobbers memory: random.4_46 = __builtin_alloca_with_align (_4, 32);
PULSE.c:34:8: missed: statement clobbers memory: _61 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_62);
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _72 = rand ();
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_98, inputs_93, _97);
PULSE.c:8:2: missed: statement clobbers memory: _99 (layer_94);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_105, _104, _103);
PULSE.c:67:11: missed: statement clobbers memory: loss_55 = PULSE_GetLoss_42 (_17, _16, _12, _11);
PULSE.c:22:2: missed: statement clobbers memory: _86 (output_34);
PULSE.c:22:2: missed: statement clobbers memory: _108 (_87);
PULSE.c:22:2: missed: statement clobbers memory: _115 (_109);
PULSE.c:22:2: missed: statement clobbers memory: _122 (_116);
PULSE.c:22:2: missed: statement clobbers memory: _129 (_123);
PULSE.c:22:2: missed: statement clobbers memory: _136 (_130);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_137);
PULSE.c:26:3: missed: statement clobbers memory: memset (_142, 0, _140);
PULSE.c:26:3: missed: statement clobbers memory: memset (_135, 0, _133);
PULSE.c:26:3: missed: statement clobbers memory: memset (_128, 0, _126);
PULSE.c:26:3: missed: statement clobbers memory: memset (_121, 0, _119);
PULSE.c:26:3: missed: statement clobbers memory: memset (_114, 0, _112);
PULSE.c:26:3: missed: statement clobbers memory: memset (_92, 0, _90);
PULSE.c:75:6: missed: statement clobbers memory: _21 (current_191, args);
PULSE.c:81:4: missed: statement clobbers memory: printf ("Epoch: %d | Item: %d | Loss: %.10f | Batch Loss: %.10f\r", i_188, j_189, _25, _24);
PULSE.c:47:6: missed: statement clobbers memory: __builtin_stack_restore (saved_stack.7_39);
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4DI
PULSE.c:47:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:91:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:91:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:119:20: missed: couldn't vectorize loop
PULSE.c:119:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:119:20: missed: couldn't vectorize loop
PULSE.c:119:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:102:20: missed: couldn't vectorize loop
PULSE.c:102:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:102:20: missed: couldn't vectorize loop
PULSE.c:102:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:93:13: note: vectorized 0 loops in function.
PULSE.c:96:39: missed: statement clobbers memory: layers_33 = malloc (_3);
PULSE.c:99:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:114:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:115:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:116:44: missed: statement clobbers memory: MODEL_128 = malloc (0);
PULSE.c:114:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:115:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:116:44: missed: statement clobbers memory: MODEL_38 = malloc (_11);
PULSE.c:125:62: missed: not vectorized: more than one data ref in stmt: D.6469 = MEM[(struct PULSE_DenseLayerArgs * {ref-all})addr.106_68];
PULSE.c:125:17: missed: statement clobbers memory: *_14 = PULSE_CreateDenseLayer (D.6469, &MODEL_PTR); [return slot optimization]
PULSE.c:125:62: missed: not vectorized: more than one data ref in stmt: D.6469 = MEM[(struct PULSE_DenseLayerArgs * {ref-all})addr.106_183];
PULSE.c:125:17: missed: statement clobbers memory: *_177 = PULSE_CreateDenseLayer (D.6469, &MODEL_PTR); [return slot optimization]
PULSE.c:131:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:132:9: note: ***** Analysis succeeded with vector mode V4DI
PULSE.c:132:9: note: SLPing BB part
PULSE.c:132:9: note: Costing subgraph: 
PULSE.c:132:9: note: node 0x46b8af8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:132:9: note: op template: <retval>.layers = layers_33;
PULSE.c:132:9: note: 	stmt 0 <retval>.layers = layers_33;
PULSE.c:132:9: note: 	stmt 1 <retval>.paramethers = MODEL_134;
PULSE.c:132:9: note: 	children 0x46b8bf8
PULSE.c:132:9: note: node (external) 0x46b8bf8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:132:9: note: 	{ layers_33, MODEL_134 }
PULSE.c:132:9: note: Cost model analysis: 
PULSE.c:132:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
PULSE.c:132:9: note: Costing subgraph: 
PULSE.c:132:9: note: node 0x46b8c78 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:132:9: note: op template: <retval>.io = 0B;
PULSE.c:132:9: note: 	stmt 0 <retval>.io = 0B;
PULSE.c:132:9: note: 	stmt 1 <retval>.fixes = 0B;
PULSE.c:132:9: note: 	children 0x46b8cf8
PULSE.c:132:9: note: node (constant) 0x46b8cf8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:132:9: note: 	{ 0B, 0B }
PULSE.c:132:9: note: Cost model analysis: 
PULSE.c:132:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
PULSE.c:132:9: note: Basic block will be vectorized using SLP
PULSE.c:132:9: optimized: basic block part vectorized using 16 byte vectors
PULSE.c:132:9: note: Vectorizing SLP tree:
PULSE.c:132:9: note: node 0x46b8af8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:132:9: note: op template: <retval>.layers = layers_33;
PULSE.c:132:9: note: 	stmt 0 <retval>.layers = layers_33;
PULSE.c:132:9: note: 	stmt 1 <retval>.paramethers = MODEL_134;
PULSE.c:132:9: note: 	children 0x46b8bf8
PULSE.c:132:9: note: node (external) 0x46b8bf8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:132:9: note: 	{ layers_33, MODEL_134 }
PULSE.c:132:9: note: ------>vectorizing SLP node starting from: <retval>.layers = layers_33;
PULSE.c:132:9: note: vect_is_simple_use: operand MODEL_134 = PHI <MODEL_38(37), MODEL_128(27)>, type of def: internal
PULSE.c:132:9: note: conflicting alias set types.
PULSE.c:132:9: note: transform store. ncopies = 1
PULSE.c:132:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.layers
PULSE.c:132:9: note: created &<retval>
PULSE.c:132:9: note: add new stmt: MEM <vector(2) long unsigned int> [(void *)&<retval>] = _198;
PULSE.c:132:9: note: vectorizing stmts using SLP.
PULSE.c:132:9: optimized: basic block part vectorized using 16 byte vectors
PULSE.c:132:9: note: Vectorizing SLP tree:
PULSE.c:132:9: note: node 0x46b8c78 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:132:9: note: op template: <retval>.io = 0B;
PULSE.c:132:9: note: 	stmt 0 <retval>.io = 0B;
PULSE.c:132:9: note: 	stmt 1 <retval>.fixes = 0B;
PULSE.c:132:9: note: 	children 0x46b8cf8
PULSE.c:132:9: note: node (constant) 0x46b8cf8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:132:9: note: 	{ 0B, 0B }
PULSE.c:132:9: note: ------>vectorizing SLP node starting from: <retval>.io = 0B;
PULSE.c:132:9: note: vect_is_simple_use: operand 0B, type of def: constant
PULSE.c:132:9: note: transform store. ncopies = 1
PULSE.c:132:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.io
PULSE.c:132:9: note: created &<retval>.io
PULSE.c:132:9: note: add new stmt: MEM <vector(2) long unsigned int> [(float * *)&<retval> + 16B] = { 0, 0 };
PULSE.c:132:9: note: vectorizing stmts using SLP.
PULSE.c:132:9: note: ***** The result for vector mode V32QI would be the same
PULSE.c:144:1: note: ***** Analysis failed with vector mode VOID
Dense.c:9:27: missed: couldn't vectorize loop
Dense.c:9:27: missed: not vectorized: unsupported outerloop form.
Dense.c:12:20: missed: couldn't vectorize loop
Dense.c:13:21: missed: not vectorized: complicated access pattern.
Dense.c:6:13: note: vectorized 0 loops in function.
Dense.c:16:2: missed: statement clobbers memory: _28 (pretmp_91, _51, 0);
Dense.c:9:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:9:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:24:27: missed: couldn't vectorize loop
Dense.c:24:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:28:20: optimized: loop vectorized using 32 byte vectors
Dense.c:28:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:28:20: optimized: loop vectorized using 16 byte vectors
Dense.c:28:20: missed: couldn't vectorize loop
Dense.c:30:19: missed: not vectorized: no vectype for stmt: _22 = *_21;
 scalar_type: float
Dense.c:20:13: note: vectorized 1 loops in function.
Dense.c:23:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:24:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:24:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:41:28: missed: couldn't vectorize loop
Dense.c:41:28: missed: not vectorized: unsupported outerloop form.
Dense.c:45:21: optimized: loop vectorized using 32 byte vectors
Dense.c:45:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:45:21: optimized: loop vectorized using 16 byte vectors
Dense.c:37:13: note: vectorized 1 loops in function.
Dense.c:37:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:37:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:41:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:170:10: optimized: loop vectorized using 32 byte vectors
Dense.c:170:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:170:10: optimized: loop vectorized using 16 byte vectors
Dense.c:161:10: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_27, _64);
Dense.c:154:10: optimized: loop vectorized using 32 byte vectors
Dense.c:154:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:154:10: optimized: loop vectorized using 16 byte vectors
Dense.c:145:10: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_14, _56);
Dense.c:136:13: note: vectorized 2 loops in function.
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_14, _56);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_15, { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 });
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_27, _64);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_28, { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 });
Dense.c:136:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:136:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:105:24: missed: couldn't vectorize loop
Dense.c:105:24: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:108:17: missed: couldn't vectorize loop
Dense.c:108:17: missed: not vectorized: number of iterations cannot be computed.
Dense.c:122:24: missed: couldn't vectorize loop
Dense.c:122:24: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:125:17: missed: couldn't vectorize loop
Dense.c:125:17: missed: not vectorized: number of iterations cannot be computed.
Dense.c:90:15: missed: couldn't vectorize loop
Dense.c:90:15: missed: not vectorized: number of iterations cannot be computed.
Dense.c:83:13: note: vectorized 0 loops in function.
Dense.c:86:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:110:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:110:17: note: SLPing BB part
Dense.c:127:17: note: Costing subgraph: 
Dense.c:127:17: note: node 0x7d781d8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:127:17: note: op template: _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 0 _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 1 _198 = (sizetype) wi_137;
Dense.c:127:17: note: 	children 0x7d782d8
Dense.c:127:17: note: node (external) 0x7d782d8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:127:17: note: 	{ j_135, wi_137 }
Dense.c:127:17: note: Cost model analysis: 
Dense.c:127:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:127:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:127:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: Costing subgraph: 
Dense.c:110:17: note: node 0x7d783d8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:110:17: note: op template: _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 0 _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 1 _217 = (sizetype) wi_136;
Dense.c:110:17: note: 	children 0x7d784d8
Dense.c:110:17: note: node (external) 0x7d784d8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:110:17: note: 	{ j_134, wi_136 }
Dense.c:110:17: note: Cost model analysis: 
Dense.c:110:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:110:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:110:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:110:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:110:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:110:17: note: SLPing BB part
Dense.c:127:17: note: Costing subgraph: 
Dense.c:127:17: note: node 0x7d783d8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:127:17: note: op template: _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 0 _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 1 _198 = (sizetype) wi_137;
Dense.c:127:17: note: 	children 0x7d781d8
Dense.c:127:17: note: node (external) 0x7d781d8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:127:17: note: 	{ j_135, wi_137 }
Dense.c:127:17: note: Cost model analysis: 
Dense.c:127:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:127:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:127:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: Costing subgraph: 
Dense.c:110:17: note: node 0x7d78358 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:110:17: note: op template: _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 0 _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 1 _217 = (sizetype) wi_136;
Dense.c:110:17: note: 	children 0x7d78458
Dense.c:110:17: note: node (external) 0x7d78458 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:110:17: note: 	{ j_134, wi_136 }
Dense.c:110:17: note: Cost model analysis: 
Dense.c:110:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:110:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:110:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:105:51: note: ***** Analysis failed with vector mode V8QI
Dense.c:105:51: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:105:51: note: ***** Analysis failed with vector mode V4QI
Dense.c:62:15: missed: couldn't vectorize loop
Dense.c:62:15: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:75:11: optimized: loop vectorized using 32 byte vectors
Dense.c:75:11: optimized: loop vectorized using 16 byte vectors
Dense.c:66:11: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:881:10: missed: not vectorized: no vectype for stmt: _53 = MEM[(__m256 * {ref-all})w_ptr_82];
 scalar_type: __m256
Dense.c:54:13: note: vectorized 1 loops in function.
Dense.c:57:2: missed: statement clobbers memory: memcpy (_4, dense$baiases_63, _3);
Dense.c:79:2: missed: statement clobbers memory: _27 (pretmp_163, _68, 0);
Dense.c:54:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:54:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:182:2: missed: statement clobbers memory: free (dense$weights_7);
Dense.c:183:2: missed: statement clobbers memory: free (dense$baiases_8);
Dense.c:184:2: missed: statement clobbers memory: free (dense$gradients_10);
Dense.c:185:2: missed: statement clobbers memory: free (dense$deltas_9);
Dense.c:186:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:186:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:202:19: missed: couldn't vectorize loop
Dense.c:202:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:190:13: note: vectorized 0 loops in function.
Dense.c:198:37: missed: statement clobbers memory: _9 = aligned_alloc (64, _8);
Dense.c:199:34: missed: statement clobbers memory: _10 = aligned_alloc (64, _5);
Dense.c:200:35: missed: statement clobbers memory: _11 = aligned_alloc (64, _5);
Dense.c:203:38: missed: statement clobbers memory: _12 = rand ();
Dense.c:203:72: missed: statement clobbers memory: _57 = sqrt (_19);
Dense.c:215:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:216:4: missed: statement clobbers memory: exit (1);
Dense.c:212:4: missed: statement clobbers memory: layer = PULSE_CreateLayer (args$n_inputs_36, args$n_outputs_47, 0, args$8_48, _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:209:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (args$n_inputs_36, args$n_outputs_47, 0, args$8_48, _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:221:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Dense.c:221:9: note: ***** Analysis succeeded with vector mode V8SI
Dense.c:221:9: note: SLPing BB part
Dense.c:221:9: note: Costing subgraph: 
Dense.c:221:9: note: node 0x7c54fa8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Dense.c:221:9: note: op template: MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = MODEL_31(D);
Dense.c:221:9: note: 	stmt 0 MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = MODEL_31(D);
Dense.c:221:9: note: 	stmt 1 MEM <float *> [(struct PULSE_Layer *)&layer + 96B] = MODEL_32;
Dense.c:221:9: note: 	stmt 2 MEM <float *> [(struct PULSE_Layer *)&layer + 104B] = _10;
Dense.c:221:9: note: 	stmt 3 MEM <float *> [(struct PULSE_Layer *)&layer + 112B] = _11;
Dense.c:221:9: note: 	children 0x7c55028
Dense.c:221:9: note: node (external) 0x7c55028 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Dense.c:221:9: note: 	{ MODEL_31(D), MODEL_32, _10, _11 }
Dense.c:221:9: note: Cost model analysis: 
Dense.c:221:9: note: Cost model analysis for part in loop 0:
  Vector cost: 64
  Scalar cost: 64
Dense.c:221:9: note: Basic block will be vectorized using SLP
Dense.c:221:9: optimized: basic block part vectorized using 32 byte vectors
Dense.c:221:9: note: Vectorizing SLP tree:
Dense.c:221:9: note: node 0x7c54fa8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Dense.c:221:9: note: op template: MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = MODEL_31(D);
Dense.c:221:9: note: 	stmt 0 MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = MODEL_31(D);
Dense.c:221:9: note: 	stmt 1 MEM <float *> [(struct PULSE_Layer *)&layer + 96B] = MODEL_32;
Dense.c:221:9: note: 	stmt 2 MEM <float *> [(struct PULSE_Layer *)&layer + 104B] = _10;
Dense.c:221:9: note: 	stmt 3 MEM <float *> [(struct PULSE_Layer *)&layer + 112B] = _11;
Dense.c:221:9: note: 	children 0x7c55028
Dense.c:221:9: note: node (external) 0x7c55028 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Dense.c:221:9: note: 	{ MODEL_31(D), MODEL_32, _10, _11 }
Dense.c:221:9: note: ------>vectorizing SLP node starting from: MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = MODEL_31(D);
Dense.c:221:9: note: vect_is_simple_use: operand MODEL_31(D) + _3, type of def: internal
Dense.c:221:9: note: vect_is_simple_use: operand aligned_alloc (64, _5), type of def: internal
Dense.c:221:9: note: vect_is_simple_use: operand aligned_alloc (64, _5), type of def: internal
Dense.c:221:9: note: transform store. ncopies = 1
Dense.c:221:9: note: create vector_type-pointer variable to type: vector(4) long unsigned int  vectorizing a pointer ref: MEM <float *> [(struct PULSE_Layer *)&layer + 88B]
Dense.c:221:9: note: created &MEM <float *> [(struct PULSE_Layer *)&layer + 88B]
Dense.c:221:9: note: add new stmt: MEM <vector(4) long unsigned int> [(struct PULSE_Layer *)&layer + 88B] = _61;
Dense.c:221:9: note: vectorizing stmts using SLP.
Dense.c:221:9: note: ***** The result for vector mode V32QI would be the same
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:4:18: note: vectorized 0 loops in function.
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_4, inputs_15, _3);
PULSE.c:8:2: missed: statement clobbers memory: _5 (layer_17);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_12, pretmp_26, _9);
PULSE.c:13:28: note: ***** Analysis failed with vector mode V8SI
PULSE.c:13:28: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:22:2: missed: statement clobbers memory: _1 (layer_10(D));
PULSE.c:22:2: missed: statement clobbers memory: _14 (_2);
PULSE.c:22:2: missed: statement clobbers memory: _21 (_15);
PULSE.c:22:2: missed: statement clobbers memory: _28 (_22);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_29);
PULSE.c:26:3: missed: statement clobbers memory: memset (_34, 0, _32);
PULSE.c:26:3: missed: statement clobbers memory: memset (_27, 0, _25);
PULSE.c:26:3: missed: statement clobbers memory: memset (_20, 0, _18);
PULSE.c:26:3: missed: statement clobbers memory: memset (_7, 0, _5);
PULSE.c:28:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:28:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:32:6: note: vectorized 1 loops in function.
PULSE.c:34:8: missed: statement clobbers memory: _1 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_2);
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _9 = rand ();
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8SI
PULSE.c:32:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:61:16: missed: couldn't vectorize loop
PULSE.c:61:16: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:64:17: missed: couldn't vectorize loop
PULSE.c:64:17: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:73:19: missed: couldn't vectorize loop
PULSE.c:73:19: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:53:22: missed: couldn't vectorize loop
PULSE.c:53:22: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:47:6: note: vectorized 1 loops in function.
PULSE.c:48:1: missed: statement clobbers memory: saved_stack.7_39 = __builtin_stack_save ();
PULSE.c:49:46: missed: statement clobbers memory: _1 = PULSE_GetLossFunctionPtr (loss_function_40(D));
PULSE.c:60:10: missed: statement clobbers memory: random.4_46 = __builtin_alloca_with_align (_4, 32);
PULSE.c:34:8: missed: statement clobbers memory: _61 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_62);
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _72 = rand ();
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_98, inputs_93, _97);
PULSE.c:8:2: missed: statement clobbers memory: _99 (layer_94);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_105, _104, _103);
PULSE.c:67:11: missed: statement clobbers memory: loss_55 = PULSE_GetLoss_42 (_17, _16, _12, _11);
PULSE.c:22:2: missed: statement clobbers memory: _86 (output_34);
PULSE.c:22:2: missed: statement clobbers memory: _108 (_87);
PULSE.c:22:2: missed: statement clobbers memory: _115 (_109);
PULSE.c:22:2: missed: statement clobbers memory: _122 (_116);
PULSE.c:22:2: missed: statement clobbers memory: _129 (_123);
PULSE.c:22:2: missed: statement clobbers memory: _136 (_130);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_137);
PULSE.c:26:3: missed: statement clobbers memory: memset (_142, 0, _140);
PULSE.c:26:3: missed: statement clobbers memory: memset (_135, 0, _133);
PULSE.c:26:3: missed: statement clobbers memory: memset (_128, 0, _126);
PULSE.c:26:3: missed: statement clobbers memory: memset (_121, 0, _119);
PULSE.c:26:3: missed: statement clobbers memory: memset (_114, 0, _112);
PULSE.c:26:3: missed: statement clobbers memory: memset (_92, 0, _90);
PULSE.c:75:6: missed: statement clobbers memory: _21 (current_191, args);
PULSE.c:81:4: missed: statement clobbers memory: printf ("Epoch: %d | Item: %d | Loss: %.10f | Batch Loss: %.10f\r", i_188, j_189, _25, _24);
PULSE.c:47:6: missed: statement clobbers memory: __builtin_stack_restore (saved_stack.7_39);
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4DI
PULSE.c:47:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:91:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:91:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:119:20: missed: couldn't vectorize loop
PULSE.c:119:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:119:20: missed: couldn't vectorize loop
PULSE.c:119:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:102:20: missed: couldn't vectorize loop
PULSE.c:102:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:102:20: missed: couldn't vectorize loop
PULSE.c:102:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:93:13: note: vectorized 0 loops in function.
PULSE.c:96:39: missed: statement clobbers memory: layers_41 = malloc (_3);
PULSE.c:99:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:114:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:115:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:116:44: missed: statement clobbers memory: MODEL_110 = malloc (0);
PULSE.c:114:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:115:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:116:44: missed: statement clobbers memory: MODEL_46 = malloc (_11);
PULSE.c:125:62: missed: not vectorized: more than one data ref in stmt: D.6469 = MEM[(struct PULSE_DenseLayerArgs * {ref-all})addr.106_75];
PULSE.c:125:17: missed: statement clobbers memory: *_14 = PULSE_CreateDenseLayer (D.6469, MODEL_PTR_126); [return slot optimization]
PULSE.c:125:62: missed: not vectorized: more than one data ref in stmt: D.6469 = MEM[(struct PULSE_DenseLayerArgs * {ref-all})addr.106_189];
PULSE.c:125:17: missed: statement clobbers memory: *_183 = PULSE_CreateDenseLayer (D.6469, MODEL_PTR_194); [return slot optimization]
PULSE.c:132:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:133:9: note: ***** Analysis succeeded with vector mode V4DI
PULSE.c:133:9: note: SLPing BB part
PULSE.c:133:9: note: Costing subgraph: 
PULSE.c:133:9: note: node 0x47adb48 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:133:9: note: op template: <retval>.layers = layers_41;
PULSE.c:133:9: note: 	stmt 0 <retval>.layers = layers_41;
PULSE.c:133:9: note: 	stmt 1 <retval>.paramethers = MODEL_132;
PULSE.c:133:9: note: 	children 0x47adc48
PULSE.c:133:9: note: node (external) 0x47adc48 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:133:9: note: 	{ layers_41, MODEL_132 }
PULSE.c:133:9: note: Cost model analysis: 
PULSE.c:133:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
PULSE.c:133:9: note: Costing subgraph: 
PULSE.c:133:9: note: node 0x47adcc8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:133:9: note: op template: <retval>.io = 0B;
PULSE.c:133:9: note: 	stmt 0 <retval>.io = 0B;
PULSE.c:133:9: note: 	stmt 1 <retval>.fixes = 0B;
PULSE.c:133:9: note: 	children 0x47add48
PULSE.c:133:9: note: node (constant) 0x47add48 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:133:9: note: 	{ 0B, 0B }
PULSE.c:133:9: note: Cost model analysis: 
PULSE.c:133:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
PULSE.c:133:9: note: Basic block will be vectorized using SLP
PULSE.c:133:9: optimized: basic block part vectorized using 16 byte vectors
PULSE.c:133:9: note: Vectorizing SLP tree:
PULSE.c:133:9: note: node 0x47adb48 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:133:9: note: op template: <retval>.layers = layers_41;
PULSE.c:133:9: note: 	stmt 0 <retval>.layers = layers_41;
PULSE.c:133:9: note: 	stmt 1 <retval>.paramethers = MODEL_132;
PULSE.c:133:9: note: 	children 0x47adc48
PULSE.c:133:9: note: node (external) 0x47adc48 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:133:9: note: 	{ layers_41, MODEL_132 }
PULSE.c:133:9: note: ------>vectorizing SLP node starting from: <retval>.layers = layers_41;
PULSE.c:133:9: note: vect_is_simple_use: operand MODEL_132 = PHI <MODEL_46(36), MODEL_110(13)>, type of def: internal
PULSE.c:133:9: note: conflicting alias set types.
PULSE.c:133:9: note: transform store. ncopies = 1
PULSE.c:133:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.layers
PULSE.c:133:9: note: created &<retval>
PULSE.c:133:9: note: add new stmt: MEM <vector(2) long unsigned int> [(void *)&<retval>] = _217;
PULSE.c:133:9: note: vectorizing stmts using SLP.
PULSE.c:133:9: optimized: basic block part vectorized using 16 byte vectors
PULSE.c:133:9: note: Vectorizing SLP tree:
PULSE.c:133:9: note: node 0x47adcc8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:133:9: note: op template: <retval>.io = 0B;
PULSE.c:133:9: note: 	stmt 0 <retval>.io = 0B;
PULSE.c:133:9: note: 	stmt 1 <retval>.fixes = 0B;
PULSE.c:133:9: note: 	children 0x47add48
PULSE.c:133:9: note: node (constant) 0x47add48 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:133:9: note: 	{ 0B, 0B }
PULSE.c:133:9: note: ------>vectorizing SLP node starting from: <retval>.io = 0B;
PULSE.c:133:9: note: vect_is_simple_use: operand 0B, type of def: constant
PULSE.c:133:9: note: transform store. ncopies = 1
PULSE.c:133:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.io
PULSE.c:133:9: note: created &<retval>.io
PULSE.c:133:9: note: add new stmt: MEM <vector(2) long unsigned int> [(float * *)&<retval> + 16B] = { 0, 0 };
PULSE.c:133:9: note: vectorizing stmts using SLP.
PULSE.c:133:9: note: ***** The result for vector mode V32QI would be the same
PULSE.c:145:1: note: ***** Analysis failed with vector mode VOID
Dense.c:9:27: missed: couldn't vectorize loop
Dense.c:9:27: missed: not vectorized: unsupported outerloop form.
Dense.c:12:20: missed: couldn't vectorize loop
Dense.c:13:21: missed: not vectorized: complicated access pattern.
Dense.c:6:13: note: vectorized 0 loops in function.
Dense.c:16:2: missed: statement clobbers memory: _28 (pretmp_91, _51, 0);
Dense.c:9:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:9:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:24:27: missed: couldn't vectorize loop
Dense.c:24:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:28:20: optimized: loop vectorized using 32 byte vectors
Dense.c:28:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:28:20: optimized: loop vectorized using 16 byte vectors
Dense.c:28:20: missed: couldn't vectorize loop
Dense.c:30:19: missed: not vectorized: no vectype for stmt: _22 = *_21;
 scalar_type: float
Dense.c:20:13: note: vectorized 1 loops in function.
Dense.c:23:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:24:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:24:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:41:28: missed: couldn't vectorize loop
Dense.c:41:28: missed: not vectorized: unsupported outerloop form.
Dense.c:45:21: optimized: loop vectorized using 32 byte vectors
Dense.c:45:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:45:21: optimized: loop vectorized using 16 byte vectors
Dense.c:37:13: note: vectorized 1 loops in function.
Dense.c:37:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:37:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:41:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:170:10: optimized: loop vectorized using 32 byte vectors
Dense.c:170:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:170:10: optimized: loop vectorized using 16 byte vectors
Dense.c:161:10: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_27, _64);
Dense.c:154:10: optimized: loop vectorized using 32 byte vectors
Dense.c:154:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:154:10: optimized: loop vectorized using 16 byte vectors
Dense.c:145:10: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_14, _56);
Dense.c:136:13: note: vectorized 2 loops in function.
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_14, _56);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_15, { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 });
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_27, _64);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_28, { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 });
Dense.c:136:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:136:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:105:24: missed: couldn't vectorize loop
Dense.c:105:24: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:108:17: missed: couldn't vectorize loop
Dense.c:108:17: missed: not vectorized: number of iterations cannot be computed.
Dense.c:122:24: missed: couldn't vectorize loop
Dense.c:122:24: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:125:17: missed: couldn't vectorize loop
Dense.c:125:17: missed: not vectorized: number of iterations cannot be computed.
Dense.c:90:15: missed: couldn't vectorize loop
Dense.c:90:15: missed: not vectorized: number of iterations cannot be computed.
Dense.c:83:13: note: vectorized 0 loops in function.
Dense.c:86:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:110:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:110:17: note: SLPing BB part
Dense.c:127:17: note: Costing subgraph: 
Dense.c:127:17: note: node 0x8668888 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:127:17: note: op template: _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 0 _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 1 _198 = (sizetype) wi_137;
Dense.c:127:17: note: 	children 0x8668988
Dense.c:127:17: note: node (external) 0x8668988 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:127:17: note: 	{ j_135, wi_137 }
Dense.c:127:17: note: Cost model analysis: 
Dense.c:127:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:127:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:127:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: Costing subgraph: 
Dense.c:110:17: note: node 0x8668a88 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:110:17: note: op template: _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 0 _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 1 _217 = (sizetype) wi_136;
Dense.c:110:17: note: 	children 0x8668b88
Dense.c:110:17: note: node (external) 0x8668b88 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:110:17: note: 	{ j_134, wi_136 }
Dense.c:110:17: note: Cost model analysis: 
Dense.c:110:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:110:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:110:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:110:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:110:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:110:17: note: SLPing BB part
Dense.c:127:17: note: Costing subgraph: 
Dense.c:127:17: note: node 0x8668a88 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:127:17: note: op template: _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 0 _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 1 _198 = (sizetype) wi_137;
Dense.c:127:17: note: 	children 0x8668888
Dense.c:127:17: note: node (external) 0x8668888 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:127:17: note: 	{ j_135, wi_137 }
Dense.c:127:17: note: Cost model analysis: 
Dense.c:127:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:127:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:127:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: Costing subgraph: 
Dense.c:110:17: note: node 0x8668a08 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:110:17: note: op template: _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 0 _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 1 _217 = (sizetype) wi_136;
Dense.c:110:17: note: 	children 0x8668b08
Dense.c:110:17: note: node (external) 0x8668b08 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:110:17: note: 	{ j_134, wi_136 }
Dense.c:110:17: note: Cost model analysis: 
Dense.c:110:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:110:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:110:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:105:51: note: ***** Analysis failed with vector mode V8QI
Dense.c:105:51: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:105:51: note: ***** Analysis failed with vector mode V4QI
Dense.c:62:15: missed: couldn't vectorize loop
Dense.c:62:15: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:75:11: optimized: loop vectorized using 32 byte vectors
Dense.c:75:11: optimized: loop vectorized using 16 byte vectors
Dense.c:66:11: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:881:10: missed: not vectorized: no vectype for stmt: _53 = MEM[(__m256 * {ref-all})w_ptr_82];
 scalar_type: __m256
Dense.c:54:13: note: vectorized 1 loops in function.
Dense.c:57:2: missed: statement clobbers memory: memcpy (_4, dense$baiases_63, _3);
Dense.c:79:2: missed: statement clobbers memory: _27 (pretmp_163, _68, 0);
Dense.c:54:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:54:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:182:2: missed: statement clobbers memory: free (dense$weights_7);
Dense.c:183:2: missed: statement clobbers memory: free (dense$baiases_8);
Dense.c:184:2: missed: statement clobbers memory: free (dense$gradients_10);
Dense.c:185:2: missed: statement clobbers memory: free (dense$deltas_9);
Dense.c:186:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:186:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:200:19: missed: couldn't vectorize loop
Dense.c:200:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:190:13: note: vectorized 0 loops in function.
Dense.c:196:37: missed: statement clobbers memory: _9 = aligned_alloc (64, _8);
Dense.c:197:34: missed: statement clobbers memory: _11 = aligned_alloc (64, _10);
Dense.c:198:35: missed: statement clobbers memory: _12 = aligned_alloc (64, _10);
Dense.c:201:38: missed: statement clobbers memory: _13 = rand ();
Dense.c:201:72: missed: statement clobbers memory: _57 = sqrt (_20);
Dense.c:213:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:214:4: missed: statement clobbers memory: exit (1);
Dense.c:210:4: missed: statement clobbers memory: layer = PULSE_CreateLayer (args$n_inputs_36, args$n_outputs_47, 0, args$8_48, _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:207:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (args$n_inputs_36, args$n_outputs_47, 0, args$8_48, _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:219:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Dense.c:219:9: note: ***** Analysis succeeded with vector mode V8SI
Dense.c:219:9: note: SLPing BB part
Dense.c:219:9: note: Costing subgraph: 
Dense.c:219:9: note: node 0x86488e8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Dense.c:219:9: note: op template: MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = MODEL_32(D);
Dense.c:219:9: note: 	stmt 0 MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = MODEL_32(D);
Dense.c:219:9: note: 	stmt 1 MEM <float *> [(struct PULSE_Layer *)&layer + 96B] = _4;
Dense.c:219:9: note: 	stmt 2 MEM <float *> [(struct PULSE_Layer *)&layer + 104B] = _11;
Dense.c:219:9: note: 	stmt 3 MEM <float *> [(struct PULSE_Layer *)&layer + 112B] = _12;
Dense.c:219:9: note: 	children 0x8648968
Dense.c:219:9: note: node (external) 0x8648968 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Dense.c:219:9: note: 	{ MODEL_32(D), _4, _11, _12 }
Dense.c:219:9: note: Cost model analysis: 
Dense.c:219:9: note: Cost model analysis for part in loop 0:
  Vector cost: 64
  Scalar cost: 64
Dense.c:219:9: note: Basic block will be vectorized using SLP
Dense.c:219:9: optimized: basic block part vectorized using 32 byte vectors
Dense.c:219:9: note: Vectorizing SLP tree:
Dense.c:219:9: note: node 0x86488e8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Dense.c:219:9: note: op template: MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = MODEL_32(D);
Dense.c:219:9: note: 	stmt 0 MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = MODEL_32(D);
Dense.c:219:9: note: 	stmt 1 MEM <float *> [(struct PULSE_Layer *)&layer + 96B] = _4;
Dense.c:219:9: note: 	stmt 2 MEM <float *> [(struct PULSE_Layer *)&layer + 104B] = _11;
Dense.c:219:9: note: 	stmt 3 MEM <float *> [(struct PULSE_Layer *)&layer + 112B] = _12;
Dense.c:219:9: note: 	children 0x8648968
Dense.c:219:9: note: node (external) 0x8648968 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Dense.c:219:9: note: 	{ MODEL_32(D), _4, _11, _12 }
Dense.c:219:9: note: ------>vectorizing SLP node starting from: MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = MODEL_32(D);
Dense.c:219:9: note: vect_is_simple_use: operand MODEL_32(D) + _3, type of def: internal
Dense.c:219:9: note: vect_is_simple_use: operand aligned_alloc (64, _10), type of def: internal
Dense.c:219:9: note: vect_is_simple_use: operand aligned_alloc (64, _10), type of def: internal
Dense.c:219:9: note: transform store. ncopies = 1
Dense.c:219:9: note: create vector_type-pointer variable to type: vector(4) long unsigned int  vectorizing a pointer ref: MEM <float *> [(struct PULSE_Layer *)&layer + 88B]
Dense.c:219:9: note: created &MEM <float *> [(struct PULSE_Layer *)&layer + 88B]
Dense.c:219:9: note: add new stmt: MEM <vector(4) long unsigned int> [(struct PULSE_Layer *)&layer + 88B] = _61;
Dense.c:219:9: note: vectorizing stmts using SLP.
Dense.c:219:9: note: ***** The result for vector mode V32QI would be the same
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:4:18: note: vectorized 0 loops in function.
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_4, inputs_15, _3);
PULSE.c:8:2: missed: statement clobbers memory: _5 (layer_17);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_12, pretmp_26, _9);
PULSE.c:13:28: note: ***** Analysis failed with vector mode V8SI
PULSE.c:13:28: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:22:2: missed: statement clobbers memory: _1 (layer_10(D));
PULSE.c:22:2: missed: statement clobbers memory: _14 (_2);
PULSE.c:22:2: missed: statement clobbers memory: _21 (_15);
PULSE.c:22:2: missed: statement clobbers memory: _28 (_22);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_29);
PULSE.c:26:3: missed: statement clobbers memory: memset (_34, 0, _32);
PULSE.c:26:3: missed: statement clobbers memory: memset (_27, 0, _25);
PULSE.c:26:3: missed: statement clobbers memory: memset (_20, 0, _18);
PULSE.c:26:3: missed: statement clobbers memory: memset (_7, 0, _5);
PULSE.c:28:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:28:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:32:6: note: vectorized 1 loops in function.
PULSE.c:34:8: missed: statement clobbers memory: _1 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_2);
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _9 = rand ();
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8SI
PULSE.c:32:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:61:16: missed: couldn't vectorize loop
PULSE.c:61:16: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:64:17: missed: couldn't vectorize loop
PULSE.c:64:17: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:73:19: missed: couldn't vectorize loop
PULSE.c:73:19: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:53:22: missed: couldn't vectorize loop
PULSE.c:53:22: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:47:6: note: vectorized 1 loops in function.
PULSE.c:48:1: missed: statement clobbers memory: saved_stack.7_39 = __builtin_stack_save ();
PULSE.c:49:46: missed: statement clobbers memory: _1 = PULSE_GetLossFunctionPtr (loss_function_40(D));
PULSE.c:60:10: missed: statement clobbers memory: random.4_46 = __builtin_alloca_with_align (_4, 32);
PULSE.c:34:8: missed: statement clobbers memory: _61 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_62);
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _72 = rand ();
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_98, inputs_93, _97);
PULSE.c:8:2: missed: statement clobbers memory: _99 (layer_94);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_105, _104, _103);
PULSE.c:67:11: missed: statement clobbers memory: loss_55 = PULSE_GetLoss_42 (_17, _16, _12, _11);
PULSE.c:22:2: missed: statement clobbers memory: _86 (output_34);
PULSE.c:22:2: missed: statement clobbers memory: _108 (_87);
PULSE.c:22:2: missed: statement clobbers memory: _115 (_109);
PULSE.c:22:2: missed: statement clobbers memory: _122 (_116);
PULSE.c:22:2: missed: statement clobbers memory: _129 (_123);
PULSE.c:22:2: missed: statement clobbers memory: _136 (_130);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_137);
PULSE.c:26:3: missed: statement clobbers memory: memset (_142, 0, _140);
PULSE.c:26:3: missed: statement clobbers memory: memset (_135, 0, _133);
PULSE.c:26:3: missed: statement clobbers memory: memset (_128, 0, _126);
PULSE.c:26:3: missed: statement clobbers memory: memset (_121, 0, _119);
PULSE.c:26:3: missed: statement clobbers memory: memset (_114, 0, _112);
PULSE.c:26:3: missed: statement clobbers memory: memset (_92, 0, _90);
PULSE.c:75:6: missed: statement clobbers memory: _21 (current_191, args);
PULSE.c:81:4: missed: statement clobbers memory: printf ("Epoch: %d | Item: %d | Loss: %.10f | Batch Loss: %.10f\r", i_188, j_189, _25, _24);
PULSE.c:47:6: missed: statement clobbers memory: __builtin_stack_restore (saved_stack.7_39);
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4DI
PULSE.c:47:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:91:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:91:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:119:20: missed: couldn't vectorize loop
PULSE.c:119:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:119:20: missed: couldn't vectorize loop
PULSE.c:119:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:102:20: missed: couldn't vectorize loop
PULSE.c:102:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:102:20: missed: couldn't vectorize loop
PULSE.c:102:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:93:13: note: vectorized 0 loops in function.
PULSE.c:96:39: missed: statement clobbers memory: layers_44 = malloc (_3);
PULSE.c:99:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:114:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:115:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:116:44: missed: statement clobbers memory: MODEL_113 = malloc (0);
PULSE.c:114:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:115:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:116:44: missed: statement clobbers memory: MODEL_49 = malloc (_11);
PULSE.c:125:62: missed: not vectorized: more than one data ref in stmt: D.6469 = MEM[(struct PULSE_DenseLayerArgs * {ref-all})addr.106_78];
PULSE.c:125:17: missed: statement clobbers memory: *_17 = PULSE_CreateDenseLayer (D.6469, _148); [return slot optimization]
PULSE.c:125:62: missed: not vectorized: more than one data ref in stmt: D.6469 = MEM[(struct PULSE_DenseLayerArgs * {ref-all})addr.106_199];
PULSE.c:125:17: missed: statement clobbers memory: *_192 = PULSE_CreateDenseLayer (D.6469, _198); [return slot optimization]
PULSE.c:132:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:133:9: note: ***** Analysis succeeded with vector mode V4DI
PULSE.c:133:9: note: SLPing BB part
PULSE.c:133:9: note: Costing subgraph: 
PULSE.c:133:9: note: node 0x474bb48 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:133:9: note: op template: <retval>.layers = layers_44;
PULSE.c:133:9: note: 	stmt 0 <retval>.layers = layers_44;
PULSE.c:133:9: note: 	stmt 1 <retval>.paramethers = MODEL_135;
PULSE.c:133:9: note: 	children 0x474bc48
PULSE.c:133:9: note: node (external) 0x474bc48 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:133:9: note: 	{ layers_44, MODEL_135 }
PULSE.c:133:9: note: Cost model analysis: 
PULSE.c:133:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
PULSE.c:133:9: note: Costing subgraph: 
PULSE.c:133:9: note: node 0x474bcc8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:133:9: note: op template: <retval>.io = 0B;
PULSE.c:133:9: note: 	stmt 0 <retval>.io = 0B;
PULSE.c:133:9: note: 	stmt 1 <retval>.fixes = 0B;
PULSE.c:133:9: note: 	children 0x474bd48
PULSE.c:133:9: note: node (constant) 0x474bd48 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:133:9: note: 	{ 0B, 0B }
PULSE.c:133:9: note: Cost model analysis: 
PULSE.c:133:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
PULSE.c:133:9: note: Basic block will be vectorized using SLP
PULSE.c:133:9: optimized: basic block part vectorized using 16 byte vectors
PULSE.c:133:9: note: Vectorizing SLP tree:
PULSE.c:133:9: note: node 0x474bb48 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:133:9: note: op template: <retval>.layers = layers_44;
PULSE.c:133:9: note: 	stmt 0 <retval>.layers = layers_44;
PULSE.c:133:9: note: 	stmt 1 <retval>.paramethers = MODEL_135;
PULSE.c:133:9: note: 	children 0x474bc48
PULSE.c:133:9: note: node (external) 0x474bc48 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:133:9: note: 	{ layers_44, MODEL_135 }
PULSE.c:133:9: note: ------>vectorizing SLP node starting from: <retval>.layers = layers_44;
PULSE.c:133:9: note: vect_is_simple_use: operand MODEL_135 = PHI <MODEL_49(36), MODEL_113(13)>, type of def: internal
PULSE.c:133:9: note: conflicting alias set types.
PULSE.c:133:9: note: transform store. ncopies = 1
PULSE.c:133:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.layers
PULSE.c:133:9: note: created &<retval>
PULSE.c:133:9: note: add new stmt: MEM <vector(2) long unsigned int> [(void *)&<retval>] = _247;
PULSE.c:133:9: note: vectorizing stmts using SLP.
PULSE.c:133:9: optimized: basic block part vectorized using 16 byte vectors
PULSE.c:133:9: note: Vectorizing SLP tree:
PULSE.c:133:9: note: node 0x474bcc8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:133:9: note: op template: <retval>.io = 0B;
PULSE.c:133:9: note: 	stmt 0 <retval>.io = 0B;
PULSE.c:133:9: note: 	stmt 1 <retval>.fixes = 0B;
PULSE.c:133:9: note: 	children 0x474bd48
PULSE.c:133:9: note: node (constant) 0x474bd48 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:133:9: note: 	{ 0B, 0B }
PULSE.c:133:9: note: ------>vectorizing SLP node starting from: <retval>.io = 0B;
PULSE.c:133:9: note: vect_is_simple_use: operand 0B, type of def: constant
PULSE.c:133:9: note: transform store. ncopies = 1
PULSE.c:133:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.io
PULSE.c:133:9: note: created &<retval>.io
PULSE.c:133:9: note: add new stmt: MEM <vector(2) long unsigned int> [(float * *)&<retval> + 16B] = { 0, 0 };
PULSE.c:133:9: note: vectorizing stmts using SLP.
PULSE.c:133:9: note: ***** The result for vector mode V32QI would be the same
PULSE.c:145:1: note: ***** Analysis failed with vector mode VOID
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:4:18: note: vectorized 0 loops in function.
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_4, inputs_15, _3);
PULSE.c:8:2: missed: statement clobbers memory: _5 (layer_17);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_12, pretmp_26, _9);
PULSE.c:13:28: note: ***** Analysis failed with vector mode V8SI
PULSE.c:13:28: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:22:2: missed: statement clobbers memory: _1 (layer_10(D));
PULSE.c:22:2: missed: statement clobbers memory: _14 (_2);
PULSE.c:22:2: missed: statement clobbers memory: _21 (_15);
PULSE.c:22:2: missed: statement clobbers memory: _28 (_22);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_29);
PULSE.c:26:3: missed: statement clobbers memory: memset (_34, 0, _32);
PULSE.c:26:3: missed: statement clobbers memory: memset (_27, 0, _25);
PULSE.c:26:3: missed: statement clobbers memory: memset (_20, 0, _18);
PULSE.c:26:3: missed: statement clobbers memory: memset (_7, 0, _5);
PULSE.c:28:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:28:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:32:6: note: vectorized 1 loops in function.
PULSE.c:34:8: missed: statement clobbers memory: _1 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_2);
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _9 = rand ();
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8SI
PULSE.c:32:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:61:16: missed: couldn't vectorize loop
PULSE.c:61:16: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:64:17: missed: couldn't vectorize loop
PULSE.c:64:17: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:73:19: missed: couldn't vectorize loop
PULSE.c:73:19: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:53:22: missed: couldn't vectorize loop
PULSE.c:53:22: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:47:6: note: vectorized 1 loops in function.
PULSE.c:48:1: missed: statement clobbers memory: saved_stack.7_39 = __builtin_stack_save ();
PULSE.c:49:46: missed: statement clobbers memory: _1 = PULSE_GetLossFunctionPtr (loss_function_40(D));
PULSE.c:60:10: missed: statement clobbers memory: random.4_46 = __builtin_alloca_with_align (_4, 32);
PULSE.c:34:8: missed: statement clobbers memory: _61 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_62);
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _72 = rand ();
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_98, inputs_93, _97);
PULSE.c:8:2: missed: statement clobbers memory: _99 (layer_94);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_105, _104, _103);
PULSE.c:67:11: missed: statement clobbers memory: loss_55 = PULSE_GetLoss_42 (_17, _16, _12, _11);
PULSE.c:22:2: missed: statement clobbers memory: _86 (output_34);
PULSE.c:22:2: missed: statement clobbers memory: _108 (_87);
PULSE.c:22:2: missed: statement clobbers memory: _115 (_109);
PULSE.c:22:2: missed: statement clobbers memory: _122 (_116);
PULSE.c:22:2: missed: statement clobbers memory: _129 (_123);
PULSE.c:22:2: missed: statement clobbers memory: _136 (_130);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_137);
PULSE.c:26:3: missed: statement clobbers memory: memset (_142, 0, _140);
PULSE.c:26:3: missed: statement clobbers memory: memset (_135, 0, _133);
PULSE.c:26:3: missed: statement clobbers memory: memset (_128, 0, _126);
PULSE.c:26:3: missed: statement clobbers memory: memset (_121, 0, _119);
PULSE.c:26:3: missed: statement clobbers memory: memset (_114, 0, _112);
PULSE.c:26:3: missed: statement clobbers memory: memset (_92, 0, _90);
PULSE.c:75:6: missed: statement clobbers memory: _21 (current_191, args);
PULSE.c:81:4: missed: statement clobbers memory: printf ("Epoch: %d | Item: %d | Loss: %.10f | Batch Loss: %.10f\r", i_188, j_189, _25, _24);
PULSE.c:47:6: missed: statement clobbers memory: __builtin_stack_restore (saved_stack.7_39);
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4DI
PULSE.c:47:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:91:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:91:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:119:20: missed: couldn't vectorize loop
PULSE.c:119:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:119:20: missed: couldn't vectorize loop
PULSE.c:119:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:102:20: missed: couldn't vectorize loop
PULSE.c:102:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:102:20: missed: couldn't vectorize loop
PULSE.c:102:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:93:13: note: vectorized 0 loops in function.
PULSE.c:96:39: missed: statement clobbers memory: layers_45 = malloc (_3);
PULSE.c:99:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:114:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:115:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:116:44: missed: statement clobbers memory: MODEL_115 = malloc (0);
PULSE.c:114:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:115:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:116:44: missed: statement clobbers memory: MODEL_50 = malloc (_11);
PULSE.c:125:62: missed: not vectorized: more than one data ref in stmt: D.6469 = MEM[(struct PULSE_DenseLayerArgs * {ref-all})addr.106_80];
PULSE.c:125:17: missed: statement clobbers memory: *_17 = PULSE_CreateDenseLayer (D.6469, _150);
PULSE.c:127:5: missed: statement clobbers memory: printf ("%d\n", _24);
PULSE.c:125:62: missed: not vectorized: more than one data ref in stmt: D.6469 = MEM[(struct PULSE_DenseLayerArgs * {ref-all})addr.106_201];
PULSE.c:125:17: missed: statement clobbers memory: *_194 = PULSE_CreateDenseLayer (D.6469, _200);
PULSE.c:127:5: missed: statement clobbers memory: printf ("%d\n", _185);
PULSE.c:133:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:134:9: note: ***** Analysis succeeded with vector mode V4DI
PULSE.c:134:9: note: SLPing BB part
PULSE.c:134:9: note: Costing subgraph: 
PULSE.c:134:9: note: node 0x4e3bb68 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:134:9: note: op template: <retval>.layers = layers_45;
PULSE.c:134:9: note: 	stmt 0 <retval>.layers = layers_45;
PULSE.c:134:9: note: 	stmt 1 <retval>.paramethers = MODEL_137;
PULSE.c:134:9: note: 	children 0x4e3bc68
PULSE.c:134:9: note: node (external) 0x4e3bc68 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:134:9: note: 	{ layers_45, MODEL_137 }
PULSE.c:134:9: note: Cost model analysis: 
PULSE.c:134:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
PULSE.c:134:9: note: Costing subgraph: 
PULSE.c:134:9: note: node 0x4e3bce8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:134:9: note: op template: <retval>.io = 0B;
PULSE.c:134:9: note: 	stmt 0 <retval>.io = 0B;
PULSE.c:134:9: note: 	stmt 1 <retval>.fixes = 0B;
PULSE.c:134:9: note: 	children 0x4e3bd68
PULSE.c:134:9: note: node (constant) 0x4e3bd68 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:134:9: note: 	{ 0B, 0B }
PULSE.c:134:9: note: Cost model analysis: 
PULSE.c:134:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
PULSE.c:134:9: note: Basic block will be vectorized using SLP
PULSE.c:134:9: optimized: basic block part vectorized using 16 byte vectors
PULSE.c:134:9: note: Vectorizing SLP tree:
PULSE.c:134:9: note: node 0x4e3bb68 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:134:9: note: op template: <retval>.layers = layers_45;
PULSE.c:134:9: note: 	stmt 0 <retval>.layers = layers_45;
PULSE.c:134:9: note: 	stmt 1 <retval>.paramethers = MODEL_137;
PULSE.c:134:9: note: 	children 0x4e3bc68
PULSE.c:134:9: note: node (external) 0x4e3bc68 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:134:9: note: 	{ layers_45, MODEL_137 }
PULSE.c:134:9: note: ------>vectorizing SLP node starting from: <retval>.layers = layers_45;
PULSE.c:134:9: note: vect_is_simple_use: operand MODEL_137 = PHI <MODEL_50(36), MODEL_115(13)>, type of def: internal
PULSE.c:134:9: note: conflicting alias set types.
PULSE.c:134:9: note: transform store. ncopies = 1
PULSE.c:134:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.layers
PULSE.c:134:9: note: created &<retval>
PULSE.c:134:9: note: add new stmt: MEM <vector(2) long unsigned int> [(void *)&<retval>] = _251;
PULSE.c:134:9: note: vectorizing stmts using SLP.
PULSE.c:134:9: optimized: basic block part vectorized using 16 byte vectors
PULSE.c:134:9: note: Vectorizing SLP tree:
PULSE.c:134:9: note: node 0x4e3bce8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:134:9: note: op template: <retval>.io = 0B;
PULSE.c:134:9: note: 	stmt 0 <retval>.io = 0B;
PULSE.c:134:9: note: 	stmt 1 <retval>.fixes = 0B;
PULSE.c:134:9: note: 	children 0x4e3bd68
PULSE.c:134:9: note: node (constant) 0x4e3bd68 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:134:9: note: 	{ 0B, 0B }
PULSE.c:134:9: note: ------>vectorizing SLP node starting from: <retval>.io = 0B;
PULSE.c:134:9: note: vect_is_simple_use: operand 0B, type of def: constant
PULSE.c:134:9: note: transform store. ncopies = 1
PULSE.c:134:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.io
PULSE.c:134:9: note: created &<retval>.io
PULSE.c:134:9: note: add new stmt: MEM <vector(2) long unsigned int> [(float * *)&<retval> + 16B] = { 0, 0 };
PULSE.c:134:9: note: vectorizing stmts using SLP.
PULSE.c:134:9: note: ***** The result for vector mode V32QI would be the same
PULSE.c:146:1: note: ***** Analysis failed with vector mode VOID
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:4:18: note: vectorized 0 loops in function.
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_4, inputs_15, _3);
PULSE.c:8:2: missed: statement clobbers memory: _5 (layer_17);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_12, pretmp_26, _9);
PULSE.c:13:28: note: ***** Analysis failed with vector mode V8SI
PULSE.c:13:28: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:22:2: missed: statement clobbers memory: _1 (layer_10(D));
PULSE.c:22:2: missed: statement clobbers memory: _14 (_2);
PULSE.c:22:2: missed: statement clobbers memory: _21 (_15);
PULSE.c:22:2: missed: statement clobbers memory: _28 (_22);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_29);
PULSE.c:26:3: missed: statement clobbers memory: memset (_34, 0, _32);
PULSE.c:26:3: missed: statement clobbers memory: memset (_27, 0, _25);
PULSE.c:26:3: missed: statement clobbers memory: memset (_20, 0, _18);
PULSE.c:26:3: missed: statement clobbers memory: memset (_7, 0, _5);
PULSE.c:28:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:28:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:32:6: note: vectorized 1 loops in function.
PULSE.c:34:8: missed: statement clobbers memory: _1 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_2);
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _9 = rand ();
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8SI
PULSE.c:32:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:61:16: missed: couldn't vectorize loop
PULSE.c:61:16: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:64:17: missed: couldn't vectorize loop
PULSE.c:64:17: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:73:19: missed: couldn't vectorize loop
PULSE.c:73:19: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:53:22: missed: couldn't vectorize loop
PULSE.c:53:22: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:47:6: note: vectorized 1 loops in function.
PULSE.c:48:1: missed: statement clobbers memory: saved_stack.7_39 = __builtin_stack_save ();
PULSE.c:49:46: missed: statement clobbers memory: _1 = PULSE_GetLossFunctionPtr (loss_function_40(D));
PULSE.c:60:10: missed: statement clobbers memory: random.4_46 = __builtin_alloca_with_align (_4, 32);
PULSE.c:34:8: missed: statement clobbers memory: _61 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_62);
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _72 = rand ();
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_98, inputs_93, _97);
PULSE.c:8:2: missed: statement clobbers memory: _99 (layer_94);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_105, _104, _103);
PULSE.c:67:11: missed: statement clobbers memory: loss_55 = PULSE_GetLoss_42 (_17, _16, _12, _11);
PULSE.c:22:2: missed: statement clobbers memory: _86 (output_34);
PULSE.c:22:2: missed: statement clobbers memory: _108 (_87);
PULSE.c:22:2: missed: statement clobbers memory: _115 (_109);
PULSE.c:22:2: missed: statement clobbers memory: _122 (_116);
PULSE.c:22:2: missed: statement clobbers memory: _129 (_123);
PULSE.c:22:2: missed: statement clobbers memory: _136 (_130);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_137);
PULSE.c:26:3: missed: statement clobbers memory: memset (_142, 0, _140);
PULSE.c:26:3: missed: statement clobbers memory: memset (_135, 0, _133);
PULSE.c:26:3: missed: statement clobbers memory: memset (_128, 0, _126);
PULSE.c:26:3: missed: statement clobbers memory: memset (_121, 0, _119);
PULSE.c:26:3: missed: statement clobbers memory: memset (_114, 0, _112);
PULSE.c:26:3: missed: statement clobbers memory: memset (_92, 0, _90);
PULSE.c:75:6: missed: statement clobbers memory: _21 (current_191, args);
PULSE.c:81:4: missed: statement clobbers memory: printf ("Epoch: %d | Item: %d | Loss: %.10f | Batch Loss: %.10f\r", i_188, j_189, _25, _24);
PULSE.c:47:6: missed: statement clobbers memory: __builtin_stack_restore (saved_stack.7_39);
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4DI
PULSE.c:47:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:91:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:91:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:119:20: missed: couldn't vectorize loop
PULSE.c:119:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:119:20: missed: couldn't vectorize loop
PULSE.c:119:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:102:20: missed: couldn't vectorize loop
PULSE.c:102:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:102:20: missed: couldn't vectorize loop
PULSE.c:102:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:93:13: note: vectorized 0 loops in function.
PULSE.c:96:39: missed: statement clobbers memory: layers_45 = malloc (_3);
PULSE.c:99:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:114:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:115:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:116:44: missed: statement clobbers memory: MODEL_115 = malloc (0);
PULSE.c:114:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:115:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:116:44: missed: statement clobbers memory: MODEL_50 = malloc (_11);
PULSE.c:125:62: missed: not vectorized: more than one data ref in stmt: D.6469 = MEM[(struct PULSE_DenseLayerArgs * {ref-all})addr.106_80];
PULSE.c:125:17: missed: statement clobbers memory: *_17 = PULSE_CreateDenseLayer (D.6469, _150);
PULSE.c:127:5: missed: statement clobbers memory: printf ("\nPOS: %d\n", _24);
PULSE.c:125:62: missed: not vectorized: more than one data ref in stmt: D.6469 = MEM[(struct PULSE_DenseLayerArgs * {ref-all})addr.106_201];
PULSE.c:125:17: missed: statement clobbers memory: *_194 = PULSE_CreateDenseLayer (D.6469, _200);
PULSE.c:127:5: missed: statement clobbers memory: printf ("\nPOS: %d\n", _185);
PULSE.c:133:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:134:9: note: ***** Analysis succeeded with vector mode V4DI
PULSE.c:134:9: note: SLPing BB part
PULSE.c:134:9: note: Costing subgraph: 
PULSE.c:134:9: note: node 0x4e47b68 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:134:9: note: op template: <retval>.layers = layers_45;
PULSE.c:134:9: note: 	stmt 0 <retval>.layers = layers_45;
PULSE.c:134:9: note: 	stmt 1 <retval>.paramethers = MODEL_137;
PULSE.c:134:9: note: 	children 0x4e47c68
PULSE.c:134:9: note: node (external) 0x4e47c68 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:134:9: note: 	{ layers_45, MODEL_137 }
PULSE.c:134:9: note: Cost model analysis: 
PULSE.c:134:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
PULSE.c:134:9: note: Costing subgraph: 
PULSE.c:134:9: note: node 0x4e47ce8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:134:9: note: op template: <retval>.io = 0B;
PULSE.c:134:9: note: 	stmt 0 <retval>.io = 0B;
PULSE.c:134:9: note: 	stmt 1 <retval>.fixes = 0B;
PULSE.c:134:9: note: 	children 0x4e47d68
PULSE.c:134:9: note: node (constant) 0x4e47d68 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:134:9: note: 	{ 0B, 0B }
PULSE.c:134:9: note: Cost model analysis: 
PULSE.c:134:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
PULSE.c:134:9: note: Basic block will be vectorized using SLP
PULSE.c:134:9: optimized: basic block part vectorized using 16 byte vectors
PULSE.c:134:9: note: Vectorizing SLP tree:
PULSE.c:134:9: note: node 0x4e47b68 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:134:9: note: op template: <retval>.layers = layers_45;
PULSE.c:134:9: note: 	stmt 0 <retval>.layers = layers_45;
PULSE.c:134:9: note: 	stmt 1 <retval>.paramethers = MODEL_137;
PULSE.c:134:9: note: 	children 0x4e47c68
PULSE.c:134:9: note: node (external) 0x4e47c68 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:134:9: note: 	{ layers_45, MODEL_137 }
PULSE.c:134:9: note: ------>vectorizing SLP node starting from: <retval>.layers = layers_45;
PULSE.c:134:9: note: vect_is_simple_use: operand MODEL_137 = PHI <MODEL_50(36), MODEL_115(13)>, type of def: internal
PULSE.c:134:9: note: conflicting alias set types.
PULSE.c:134:9: note: transform store. ncopies = 1
PULSE.c:134:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.layers
PULSE.c:134:9: note: created &<retval>
PULSE.c:134:9: note: add new stmt: MEM <vector(2) long unsigned int> [(void *)&<retval>] = _251;
PULSE.c:134:9: note: vectorizing stmts using SLP.
PULSE.c:134:9: optimized: basic block part vectorized using 16 byte vectors
PULSE.c:134:9: note: Vectorizing SLP tree:
PULSE.c:134:9: note: node 0x4e47ce8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:134:9: note: op template: <retval>.io = 0B;
PULSE.c:134:9: note: 	stmt 0 <retval>.io = 0B;
PULSE.c:134:9: note: 	stmt 1 <retval>.fixes = 0B;
PULSE.c:134:9: note: 	children 0x4e47d68
PULSE.c:134:9: note: node (constant) 0x4e47d68 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:134:9: note: 	{ 0B, 0B }
PULSE.c:134:9: note: ------>vectorizing SLP node starting from: <retval>.io = 0B;
PULSE.c:134:9: note: vect_is_simple_use: operand 0B, type of def: constant
PULSE.c:134:9: note: transform store. ncopies = 1
PULSE.c:134:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.io
PULSE.c:134:9: note: created &<retval>.io
PULSE.c:134:9: note: add new stmt: MEM <vector(2) long unsigned int> [(float * *)&<retval> + 16B] = { 0, 0 };
PULSE.c:134:9: note: vectorizing stmts using SLP.
PULSE.c:134:9: note: ***** The result for vector mode V32QI would be the same
PULSE.c:146:1: note: ***** Analysis failed with vector mode VOID
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:4:18: note: vectorized 0 loops in function.
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_4, inputs_15, _3);
PULSE.c:8:2: missed: statement clobbers memory: _5 (layer_17);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_12, pretmp_26, _9);
PULSE.c:13:28: note: ***** Analysis failed with vector mode V8SI
PULSE.c:13:28: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:22:2: missed: statement clobbers memory: _1 (layer_10(D));
PULSE.c:22:2: missed: statement clobbers memory: _14 (_2);
PULSE.c:22:2: missed: statement clobbers memory: _21 (_15);
PULSE.c:22:2: missed: statement clobbers memory: _28 (_22);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_29);
PULSE.c:26:3: missed: statement clobbers memory: memset (_34, 0, _32);
PULSE.c:26:3: missed: statement clobbers memory: memset (_27, 0, _25);
PULSE.c:26:3: missed: statement clobbers memory: memset (_20, 0, _18);
PULSE.c:26:3: missed: statement clobbers memory: memset (_7, 0, _5);
PULSE.c:28:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:28:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:32:6: note: vectorized 1 loops in function.
PULSE.c:34:8: missed: statement clobbers memory: _1 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_2);
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _9 = rand ();
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8SI
PULSE.c:32:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:61:16: missed: couldn't vectorize loop
PULSE.c:61:16: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:64:17: missed: couldn't vectorize loop
PULSE.c:64:17: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:73:19: missed: couldn't vectorize loop
PULSE.c:73:19: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:53:22: missed: couldn't vectorize loop
PULSE.c:53:22: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:47:6: note: vectorized 1 loops in function.
PULSE.c:48:1: missed: statement clobbers memory: saved_stack.7_39 = __builtin_stack_save ();
PULSE.c:49:46: missed: statement clobbers memory: _1 = PULSE_GetLossFunctionPtr (loss_function_40(D));
PULSE.c:60:10: missed: statement clobbers memory: random.4_46 = __builtin_alloca_with_align (_4, 32);
PULSE.c:34:8: missed: statement clobbers memory: _61 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_62);
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _72 = rand ();
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_98, inputs_93, _97);
PULSE.c:8:2: missed: statement clobbers memory: _99 (layer_94);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_105, _104, _103);
PULSE.c:67:11: missed: statement clobbers memory: loss_55 = PULSE_GetLoss_42 (_17, _16, _12, _11);
PULSE.c:22:2: missed: statement clobbers memory: _86 (output_34);
PULSE.c:22:2: missed: statement clobbers memory: _108 (_87);
PULSE.c:22:2: missed: statement clobbers memory: _115 (_109);
PULSE.c:22:2: missed: statement clobbers memory: _122 (_116);
PULSE.c:22:2: missed: statement clobbers memory: _129 (_123);
PULSE.c:22:2: missed: statement clobbers memory: _136 (_130);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_137);
PULSE.c:26:3: missed: statement clobbers memory: memset (_142, 0, _140);
PULSE.c:26:3: missed: statement clobbers memory: memset (_135, 0, _133);
PULSE.c:26:3: missed: statement clobbers memory: memset (_128, 0, _126);
PULSE.c:26:3: missed: statement clobbers memory: memset (_121, 0, _119);
PULSE.c:26:3: missed: statement clobbers memory: memset (_114, 0, _112);
PULSE.c:26:3: missed: statement clobbers memory: memset (_92, 0, _90);
PULSE.c:75:6: missed: statement clobbers memory: _21 (current_191, args);
PULSE.c:81:4: missed: statement clobbers memory: printf ("Epoch: %d | Item: %d | Loss: %.10f | Batch Loss: %.10f\r", i_188, j_189, _25, _24);
PULSE.c:47:6: missed: statement clobbers memory: __builtin_stack_restore (saved_stack.7_39);
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4DI
PULSE.c:47:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:91:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:91:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:119:20: missed: couldn't vectorize loop
PULSE.c:119:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:119:20: missed: couldn't vectorize loop
PULSE.c:119:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:102:20: missed: couldn't vectorize loop
PULSE.c:102:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:102:20: missed: couldn't vectorize loop
PULSE.c:102:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:93:13: note: vectorized 0 loops in function.
PULSE.c:96:39: missed: statement clobbers memory: layers_45 = malloc (_3);
PULSE.c:99:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:114:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:115:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:116:44: missed: statement clobbers memory: MODEL_115 = malloc (0);
PULSE.c:114:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:115:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:116:44: missed: statement clobbers memory: MODEL_50 = malloc (_11);
PULSE.c:125:62: missed: not vectorized: more than one data ref in stmt: D.6469 = MEM[(struct PULSE_DenseLayerArgs * {ref-all})addr.106_80];
PULSE.c:125:17: missed: statement clobbers memory: *_17 = PULSE_CreateDenseLayer (D.6469, _150);
PULSE.c:127:5: missed: statement clobbers memory: printf ("\nPOS: %d\n", _24);
PULSE.c:125:62: missed: not vectorized: more than one data ref in stmt: D.6469 = MEM[(struct PULSE_DenseLayerArgs * {ref-all})addr.106_201];
PULSE.c:125:17: missed: statement clobbers memory: *_194 = PULSE_CreateDenseLayer (D.6469, _200);
PULSE.c:127:5: missed: statement clobbers memory: printf ("\nPOS: %d\n", _185);
PULSE.c:133:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:134:9: note: ***** Analysis succeeded with vector mode V4DI
PULSE.c:134:9: note: SLPing BB part
PULSE.c:134:9: note: Costing subgraph: 
PULSE.c:134:9: note: node 0x33f4ba8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:134:9: note: op template: <retval>.layers = layers_45;
PULSE.c:134:9: note: 	stmt 0 <retval>.layers = layers_45;
PULSE.c:134:9: note: 	stmt 1 <retval>.paramethers = MODEL_137;
PULSE.c:134:9: note: 	children 0x33f4ca8
PULSE.c:134:9: note: node (external) 0x33f4ca8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:134:9: note: 	{ layers_45, MODEL_137 }
PULSE.c:134:9: note: Cost model analysis: 
PULSE.c:134:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
PULSE.c:134:9: note: Costing subgraph: 
PULSE.c:134:9: note: node 0x33f4d28 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:134:9: note: op template: <retval>.io = 0B;
PULSE.c:134:9: note: 	stmt 0 <retval>.io = 0B;
PULSE.c:134:9: note: 	stmt 1 <retval>.fixes = 0B;
PULSE.c:134:9: note: 	children 0x33f4da8
PULSE.c:134:9: note: node (constant) 0x33f4da8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:134:9: note: 	{ 0B, 0B }
PULSE.c:134:9: note: Cost model analysis: 
PULSE.c:134:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
PULSE.c:134:9: note: Basic block will be vectorized using SLP
PULSE.c:134:9: optimized: basic block part vectorized using 16 byte vectors
PULSE.c:134:9: note: Vectorizing SLP tree:
PULSE.c:134:9: note: node 0x33f4ba8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:134:9: note: op template: <retval>.layers = layers_45;
PULSE.c:134:9: note: 	stmt 0 <retval>.layers = layers_45;
PULSE.c:134:9: note: 	stmt 1 <retval>.paramethers = MODEL_137;
PULSE.c:134:9: note: 	children 0x33f4ca8
PULSE.c:134:9: note: node (external) 0x33f4ca8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:134:9: note: 	{ layers_45, MODEL_137 }
PULSE.c:134:9: note: ------>vectorizing SLP node starting from: <retval>.layers = layers_45;
PULSE.c:134:9: note: vect_is_simple_use: operand MODEL_137 = PHI <MODEL_50(36), MODEL_115(13)>, type of def: internal
PULSE.c:134:9: note: conflicting alias set types.
PULSE.c:134:9: note: transform store. ncopies = 1
PULSE.c:134:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.layers
PULSE.c:134:9: note: created &<retval>
PULSE.c:134:9: note: add new stmt: MEM <vector(2) long unsigned int> [(void *)&<retval>] = _243;
PULSE.c:134:9: note: vectorizing stmts using SLP.
PULSE.c:134:9: optimized: basic block part vectorized using 16 byte vectors
PULSE.c:134:9: note: Vectorizing SLP tree:
PULSE.c:134:9: note: node 0x33f4d28 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:134:9: note: op template: <retval>.io = 0B;
PULSE.c:134:9: note: 	stmt 0 <retval>.io = 0B;
PULSE.c:134:9: note: 	stmt 1 <retval>.fixes = 0B;
PULSE.c:134:9: note: 	children 0x33f4da8
PULSE.c:134:9: note: node (constant) 0x33f4da8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:134:9: note: 	{ 0B, 0B }
PULSE.c:134:9: note: ------>vectorizing SLP node starting from: <retval>.io = 0B;
PULSE.c:134:9: note: vect_is_simple_use: operand 0B, type of def: constant
PULSE.c:134:9: note: transform store. ncopies = 1
PULSE.c:134:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.io
PULSE.c:134:9: note: created &<retval>.io
PULSE.c:134:9: note: add new stmt: MEM <vector(2) long unsigned int> [(float * *)&<retval> + 16B] = { 0, 0 };
PULSE.c:134:9: note: vectorizing stmts using SLP.
PULSE.c:134:9: note: ***** The result for vector mode V32QI would be the same
PULSE.c:146:1: note: ***** Analysis failed with vector mode VOID
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:4:18: note: vectorized 0 loops in function.
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_4, inputs_15, _3);
PULSE.c:8:2: missed: statement clobbers memory: _5 (layer_17);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_12, pretmp_26, _9);
PULSE.c:13:28: note: ***** Analysis failed with vector mode V8SI
PULSE.c:13:28: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:22:2: missed: statement clobbers memory: _1 (layer_10(D));
PULSE.c:22:2: missed: statement clobbers memory: _14 (_2);
PULSE.c:22:2: missed: statement clobbers memory: _21 (_15);
PULSE.c:22:2: missed: statement clobbers memory: _28 (_22);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_29);
PULSE.c:26:3: missed: statement clobbers memory: memset (_34, 0, _32);
PULSE.c:26:3: missed: statement clobbers memory: memset (_27, 0, _25);
PULSE.c:26:3: missed: statement clobbers memory: memset (_20, 0, _18);
PULSE.c:26:3: missed: statement clobbers memory: memset (_7, 0, _5);
PULSE.c:28:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:28:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:32:6: note: vectorized 1 loops in function.
PULSE.c:34:8: missed: statement clobbers memory: _1 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_2);
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _9 = rand ();
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8SI
PULSE.c:32:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:61:16: missed: couldn't vectorize loop
PULSE.c:61:16: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:64:17: missed: couldn't vectorize loop
PULSE.c:64:17: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:73:19: missed: couldn't vectorize loop
PULSE.c:73:19: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:53:22: missed: couldn't vectorize loop
PULSE.c:53:22: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:47:6: note: vectorized 1 loops in function.
PULSE.c:48:1: missed: statement clobbers memory: saved_stack.7_39 = __builtin_stack_save ();
PULSE.c:49:46: missed: statement clobbers memory: _1 = PULSE_GetLossFunctionPtr (loss_function_40(D));
PULSE.c:60:10: missed: statement clobbers memory: random.4_46 = __builtin_alloca_with_align (_4, 32);
PULSE.c:34:8: missed: statement clobbers memory: _61 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_62);
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _72 = rand ();
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_98, inputs_93, _97);
PULSE.c:8:2: missed: statement clobbers memory: _99 (layer_94);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_105, _104, _103);
PULSE.c:67:11: missed: statement clobbers memory: loss_55 = PULSE_GetLoss_42 (_17, _16, _12, _11);
PULSE.c:22:2: missed: statement clobbers memory: _86 (output_34);
PULSE.c:22:2: missed: statement clobbers memory: _108 (_87);
PULSE.c:22:2: missed: statement clobbers memory: _115 (_109);
PULSE.c:22:2: missed: statement clobbers memory: _122 (_116);
PULSE.c:22:2: missed: statement clobbers memory: _129 (_123);
PULSE.c:22:2: missed: statement clobbers memory: _136 (_130);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_137);
PULSE.c:26:3: missed: statement clobbers memory: memset (_142, 0, _140);
PULSE.c:26:3: missed: statement clobbers memory: memset (_135, 0, _133);
PULSE.c:26:3: missed: statement clobbers memory: memset (_128, 0, _126);
PULSE.c:26:3: missed: statement clobbers memory: memset (_121, 0, _119);
PULSE.c:26:3: missed: statement clobbers memory: memset (_114, 0, _112);
PULSE.c:26:3: missed: statement clobbers memory: memset (_92, 0, _90);
PULSE.c:75:6: missed: statement clobbers memory: _21 (current_191, args);
PULSE.c:81:4: missed: statement clobbers memory: printf ("Epoch: %d | Item: %d | Loss: %.10f | Batch Loss: %.10f\r", i_188, j_189, _25, _24);
PULSE.c:47:6: missed: statement clobbers memory: __builtin_stack_restore (saved_stack.7_39);
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4DI
PULSE.c:47:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:91:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:91:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:119:20: missed: couldn't vectorize loop
PULSE.c:119:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:119:20: missed: couldn't vectorize loop
PULSE.c:119:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:102:20: missed: couldn't vectorize loop
PULSE.c:102:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:102:20: missed: couldn't vectorize loop
PULSE.c:102:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:93:13: note: vectorized 0 loops in function.
PULSE.c:96:39: missed: statement clobbers memory: layers_46 = malloc (_3);
PULSE.c:99:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:114:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:115:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:116:44: missed: statement clobbers memory: MODEL_117 = malloc (0);
PULSE.c:114:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:115:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:116:44: missed: statement clobbers memory: MODEL_51 = malloc (_11);
PULSE.c:125:62: missed: not vectorized: more than one data ref in stmt: D.6469 = MEM[(struct PULSE_DenseLayerArgs * {ref-all})addr.106_82];
PULSE.c:125:17: missed: statement clobbers memory: *_17 = PULSE_CreateDenseLayer (D.6469, _152);
PULSE.c:127:5: missed: statement clobbers memory: printf ("\nPOS: %d\n", _24);
PULSE.c:128:5: missed: statement clobbers memory: printf ("\nPOS: %d\n", _25);
PULSE.c:125:62: missed: not vectorized: more than one data ref in stmt: D.6469 = MEM[(struct PULSE_DenseLayerArgs * {ref-all})addr.106_203];
PULSE.c:125:17: missed: statement clobbers memory: *_196 = PULSE_CreateDenseLayer (D.6469, _202);
PULSE.c:127:5: missed: statement clobbers memory: printf ("\nPOS: %d\n", _187);
PULSE.c:128:5: missed: statement clobbers memory: printf ("\nPOS: %d\n", _185);
PULSE.c:134:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:135:9: note: ***** Analysis succeeded with vector mode V4DI
PULSE.c:135:9: note: SLPing BB part
PULSE.c:135:9: note: Costing subgraph: 
PULSE.c:135:9: note: node 0x462fbc8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:135:9: note: op template: <retval>.layers = layers_46;
PULSE.c:135:9: note: 	stmt 0 <retval>.layers = layers_46;
PULSE.c:135:9: note: 	stmt 1 <retval>.paramethers = MODEL_139;
PULSE.c:135:9: note: 	children 0x462fcc8
PULSE.c:135:9: note: node (external) 0x462fcc8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:135:9: note: 	{ layers_46, MODEL_139 }
PULSE.c:135:9: note: Cost model analysis: 
PULSE.c:135:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
PULSE.c:135:9: note: Costing subgraph: 
PULSE.c:135:9: note: node 0x462fd48 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:135:9: note: op template: <retval>.io = 0B;
PULSE.c:135:9: note: 	stmt 0 <retval>.io = 0B;
PULSE.c:135:9: note: 	stmt 1 <retval>.fixes = 0B;
PULSE.c:135:9: note: 	children 0x462fdc8
PULSE.c:135:9: note: node (constant) 0x462fdc8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:135:9: note: 	{ 0B, 0B }
PULSE.c:135:9: note: Cost model analysis: 
PULSE.c:135:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
PULSE.c:135:9: note: Basic block will be vectorized using SLP
PULSE.c:135:9: optimized: basic block part vectorized using 16 byte vectors
PULSE.c:135:9: note: Vectorizing SLP tree:
PULSE.c:135:9: note: node 0x462fbc8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:135:9: note: op template: <retval>.layers = layers_46;
PULSE.c:135:9: note: 	stmt 0 <retval>.layers = layers_46;
PULSE.c:135:9: note: 	stmt 1 <retval>.paramethers = MODEL_139;
PULSE.c:135:9: note: 	children 0x462fcc8
PULSE.c:135:9: note: node (external) 0x462fcc8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:135:9: note: 	{ layers_46, MODEL_139 }
PULSE.c:135:9: note: ------>vectorizing SLP node starting from: <retval>.layers = layers_46;
PULSE.c:135:9: note: vect_is_simple_use: operand MODEL_139 = PHI <MODEL_51(36), MODEL_117(13)>, type of def: internal
PULSE.c:135:9: note: conflicting alias set types.
PULSE.c:135:9: note: transform store. ncopies = 1
PULSE.c:135:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.layers
PULSE.c:135:9: note: created &<retval>
PULSE.c:135:9: note: add new stmt: MEM <vector(2) long unsigned int> [(void *)&<retval>] = _247;
PULSE.c:135:9: note: vectorizing stmts using SLP.
PULSE.c:135:9: optimized: basic block part vectorized using 16 byte vectors
PULSE.c:135:9: note: Vectorizing SLP tree:
PULSE.c:135:9: note: node 0x462fd48 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:135:9: note: op template: <retval>.io = 0B;
PULSE.c:135:9: note: 	stmt 0 <retval>.io = 0B;
PULSE.c:135:9: note: 	stmt 1 <retval>.fixes = 0B;
PULSE.c:135:9: note: 	children 0x462fdc8
PULSE.c:135:9: note: node (constant) 0x462fdc8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:135:9: note: 	{ 0B, 0B }
PULSE.c:135:9: note: ------>vectorizing SLP node starting from: <retval>.io = 0B;
PULSE.c:135:9: note: vect_is_simple_use: operand 0B, type of def: constant
PULSE.c:135:9: note: transform store. ncopies = 1
PULSE.c:135:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.io
PULSE.c:135:9: note: created &<retval>.io
PULSE.c:135:9: note: add new stmt: MEM <vector(2) long unsigned int> [(float * *)&<retval> + 16B] = { 0, 0 };
PULSE.c:135:9: note: vectorizing stmts using SLP.
PULSE.c:135:9: note: ***** The result for vector mode V32QI would be the same
PULSE.c:147:1: note: ***** Analysis failed with vector mode VOID
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:4:18: note: vectorized 0 loops in function.
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_4, inputs_15, _3);
PULSE.c:8:2: missed: statement clobbers memory: _5 (layer_17);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_12, pretmp_26, _9);
PULSE.c:13:28: note: ***** Analysis failed with vector mode V8SI
PULSE.c:13:28: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:22:2: missed: statement clobbers memory: _1 (layer_10(D));
PULSE.c:22:2: missed: statement clobbers memory: _14 (_2);
PULSE.c:22:2: missed: statement clobbers memory: _21 (_15);
PULSE.c:22:2: missed: statement clobbers memory: _28 (_22);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_29);
PULSE.c:26:3: missed: statement clobbers memory: memset (_34, 0, _32);
PULSE.c:26:3: missed: statement clobbers memory: memset (_27, 0, _25);
PULSE.c:26:3: missed: statement clobbers memory: memset (_20, 0, _18);
PULSE.c:26:3: missed: statement clobbers memory: memset (_7, 0, _5);
PULSE.c:28:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:28:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:32:6: note: vectorized 1 loops in function.
PULSE.c:34:8: missed: statement clobbers memory: _1 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_2);
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _9 = rand ();
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8SI
PULSE.c:32:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:61:16: missed: couldn't vectorize loop
PULSE.c:61:16: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:64:17: missed: couldn't vectorize loop
PULSE.c:64:17: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:73:19: missed: couldn't vectorize loop
PULSE.c:73:19: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:53:22: missed: couldn't vectorize loop
PULSE.c:53:22: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:47:6: note: vectorized 1 loops in function.
PULSE.c:48:1: missed: statement clobbers memory: saved_stack.7_39 = __builtin_stack_save ();
PULSE.c:49:46: missed: statement clobbers memory: _1 = PULSE_GetLossFunctionPtr (loss_function_40(D));
PULSE.c:60:10: missed: statement clobbers memory: random.4_46 = __builtin_alloca_with_align (_4, 32);
PULSE.c:34:8: missed: statement clobbers memory: _61 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_62);
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _72 = rand ();
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_98, inputs_93, _97);
PULSE.c:8:2: missed: statement clobbers memory: _99 (layer_94);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_105, _104, _103);
PULSE.c:67:11: missed: statement clobbers memory: loss_55 = PULSE_GetLoss_42 (_17, _16, _12, _11);
PULSE.c:22:2: missed: statement clobbers memory: _86 (output_34);
PULSE.c:22:2: missed: statement clobbers memory: _108 (_87);
PULSE.c:22:2: missed: statement clobbers memory: _115 (_109);
PULSE.c:22:2: missed: statement clobbers memory: _122 (_116);
PULSE.c:22:2: missed: statement clobbers memory: _129 (_123);
PULSE.c:22:2: missed: statement clobbers memory: _136 (_130);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_137);
PULSE.c:26:3: missed: statement clobbers memory: memset (_142, 0, _140);
PULSE.c:26:3: missed: statement clobbers memory: memset (_135, 0, _133);
PULSE.c:26:3: missed: statement clobbers memory: memset (_128, 0, _126);
PULSE.c:26:3: missed: statement clobbers memory: memset (_121, 0, _119);
PULSE.c:26:3: missed: statement clobbers memory: memset (_114, 0, _112);
PULSE.c:26:3: missed: statement clobbers memory: memset (_92, 0, _90);
PULSE.c:75:6: missed: statement clobbers memory: _21 (current_191, args);
PULSE.c:81:4: missed: statement clobbers memory: printf ("Epoch: %d | Item: %d | Loss: %.10f | Batch Loss: %.10f\r", i_188, j_189, _25, _24);
PULSE.c:47:6: missed: statement clobbers memory: __builtin_stack_restore (saved_stack.7_39);
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4DI
PULSE.c:47:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:91:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:91:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:119:20: missed: couldn't vectorize loop
PULSE.c:119:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:119:20: missed: couldn't vectorize loop
PULSE.c:119:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:102:20: missed: couldn't vectorize loop
PULSE.c:102:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:102:20: missed: couldn't vectorize loop
PULSE.c:102:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:93:13: note: vectorized 0 loops in function.
PULSE.c:96:39: missed: statement clobbers memory: layers_40 = malloc (_3);
PULSE.c:99:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:114:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:115:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:116:44: missed: statement clobbers memory: MODEL_111 = malloc (0);
PULSE.c:114:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:115:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:116:44: missed: statement clobbers memory: MODEL_45 = malloc (_9);
PULSE.c:125:62: missed: not vectorized: more than one data ref in stmt: D.6469 = MEM[(struct PULSE_DenseLayerArgs * {ref-all})addr.106_76];
PULSE.c:125:17: missed: statement clobbers memory: *_15 = PULSE_CreateDenseLayer (D.6469, _146);
PULSE.c:127:5: missed: statement clobbers memory: printf ("\nPOS: %d\n", _19);
PULSE.c:128:5: missed: statement clobbers memory: printf ("\nPOS: %d\n", MODEL_POS_57);
PULSE.c:125:62: missed: not vectorized: more than one data ref in stmt: D.6469 = MEM[(struct PULSE_DenseLayerArgs * {ref-all})addr.106_183];
PULSE.c:125:17: missed: statement clobbers memory: *_176 = PULSE_CreateDenseLayer (D.6469, _182);
PULSE.c:127:5: missed: statement clobbers memory: printf ("\nPOS: %d\n", _171);
PULSE.c:128:5: missed: statement clobbers memory: printf ("\nPOS: %d\n", MODEL_POS_170);
PULSE.c:134:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:135:9: note: ***** Analysis succeeded with vector mode V4DI
PULSE.c:135:9: note: SLPing BB part
PULSE.c:135:9: note: Costing subgraph: 
PULSE.c:135:9: note: node 0x30b4bc8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:135:9: note: op template: <retval>.layers = layers_40;
PULSE.c:135:9: note: 	stmt 0 <retval>.layers = layers_40;
PULSE.c:135:9: note: 	stmt 1 <retval>.paramethers = MODEL_133;
PULSE.c:135:9: note: 	children 0x30b4cc8
PULSE.c:135:9: note: node (external) 0x30b4cc8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:135:9: note: 	{ layers_40, MODEL_133 }
PULSE.c:135:9: note: Cost model analysis: 
PULSE.c:135:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
PULSE.c:135:9: note: Costing subgraph: 
PULSE.c:135:9: note: node 0x30b4d48 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:135:9: note: op template: <retval>.io = 0B;
PULSE.c:135:9: note: 	stmt 0 <retval>.io = 0B;
PULSE.c:135:9: note: 	stmt 1 <retval>.fixes = 0B;
PULSE.c:135:9: note: 	children 0x30b4dc8
PULSE.c:135:9: note: node (constant) 0x30b4dc8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:135:9: note: 	{ 0B, 0B }
PULSE.c:135:9: note: Cost model analysis: 
PULSE.c:135:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
PULSE.c:135:9: note: Basic block will be vectorized using SLP
PULSE.c:135:9: optimized: basic block part vectorized using 16 byte vectors
PULSE.c:135:9: note: Vectorizing SLP tree:
PULSE.c:135:9: note: node 0x30b4bc8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:135:9: note: op template: <retval>.layers = layers_40;
PULSE.c:135:9: note: 	stmt 0 <retval>.layers = layers_40;
PULSE.c:135:9: note: 	stmt 1 <retval>.paramethers = MODEL_133;
PULSE.c:135:9: note: 	children 0x30b4cc8
PULSE.c:135:9: note: node (external) 0x30b4cc8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:135:9: note: 	{ layers_40, MODEL_133 }
PULSE.c:135:9: note: ------>vectorizing SLP node starting from: <retval>.layers = layers_40;
PULSE.c:135:9: note: vect_is_simple_use: operand MODEL_133 = PHI <MODEL_45(36), MODEL_111(13)>, type of def: internal
PULSE.c:135:9: note: conflicting alias set types.
PULSE.c:135:9: note: transform store. ncopies = 1
PULSE.c:135:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.layers
PULSE.c:135:9: note: created &<retval>
PULSE.c:135:9: note: add new stmt: MEM <vector(2) long unsigned int> [(void *)&<retval>] = _23;
PULSE.c:135:9: note: vectorizing stmts using SLP.
PULSE.c:135:9: optimized: basic block part vectorized using 16 byte vectors
PULSE.c:135:9: note: Vectorizing SLP tree:
PULSE.c:135:9: note: node 0x30b4d48 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:135:9: note: op template: <retval>.io = 0B;
PULSE.c:135:9: note: 	stmt 0 <retval>.io = 0B;
PULSE.c:135:9: note: 	stmt 1 <retval>.fixes = 0B;
PULSE.c:135:9: note: 	children 0x30b4dc8
PULSE.c:135:9: note: node (constant) 0x30b4dc8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:135:9: note: 	{ 0B, 0B }
PULSE.c:135:9: note: ------>vectorizing SLP node starting from: <retval>.io = 0B;
PULSE.c:135:9: note: vect_is_simple_use: operand 0B, type of def: constant
PULSE.c:135:9: note: transform store. ncopies = 1
PULSE.c:135:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.io
PULSE.c:135:9: note: created &<retval>.io
PULSE.c:135:9: note: add new stmt: MEM <vector(2) long unsigned int> [(float * *)&<retval> + 16B] = { 0, 0 };
PULSE.c:135:9: note: vectorizing stmts using SLP.
PULSE.c:135:9: note: ***** The result for vector mode V32QI would be the same
PULSE.c:147:1: note: ***** Analysis failed with vector mode VOID
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:4:18: note: vectorized 0 loops in function.
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_4, inputs_15, _3);
PULSE.c:8:2: missed: statement clobbers memory: _5 (layer_17);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_12, pretmp_26, _9);
PULSE.c:13:28: note: ***** Analysis failed with vector mode V8SI
PULSE.c:13:28: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:22:2: missed: statement clobbers memory: _1 (layer_10(D));
PULSE.c:22:2: missed: statement clobbers memory: _14 (_2);
PULSE.c:22:2: missed: statement clobbers memory: _21 (_15);
PULSE.c:22:2: missed: statement clobbers memory: _28 (_22);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_29);
PULSE.c:26:3: missed: statement clobbers memory: memset (_34, 0, _32);
PULSE.c:26:3: missed: statement clobbers memory: memset (_27, 0, _25);
PULSE.c:26:3: missed: statement clobbers memory: memset (_20, 0, _18);
PULSE.c:26:3: missed: statement clobbers memory: memset (_7, 0, _5);
PULSE.c:28:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:28:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:32:6: note: vectorized 1 loops in function.
PULSE.c:34:8: missed: statement clobbers memory: _1 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_2);
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _9 = rand ();
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8SI
PULSE.c:32:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:61:16: missed: couldn't vectorize loop
PULSE.c:61:16: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:64:17: missed: couldn't vectorize loop
PULSE.c:64:17: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:73:19: missed: couldn't vectorize loop
PULSE.c:73:19: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:53:22: missed: couldn't vectorize loop
PULSE.c:53:22: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:47:6: note: vectorized 1 loops in function.
PULSE.c:48:1: missed: statement clobbers memory: saved_stack.7_39 = __builtin_stack_save ();
PULSE.c:49:46: missed: statement clobbers memory: _1 = PULSE_GetLossFunctionPtr (loss_function_40(D));
PULSE.c:60:10: missed: statement clobbers memory: random.4_46 = __builtin_alloca_with_align (_4, 32);
PULSE.c:34:8: missed: statement clobbers memory: _61 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_62);
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _72 = rand ();
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_98, inputs_93, _97);
PULSE.c:8:2: missed: statement clobbers memory: _99 (layer_94);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_105, _104, _103);
PULSE.c:67:11: missed: statement clobbers memory: loss_55 = PULSE_GetLoss_42 (_17, _16, _12, _11);
PULSE.c:22:2: missed: statement clobbers memory: _86 (output_34);
PULSE.c:22:2: missed: statement clobbers memory: _108 (_87);
PULSE.c:22:2: missed: statement clobbers memory: _115 (_109);
PULSE.c:22:2: missed: statement clobbers memory: _122 (_116);
PULSE.c:22:2: missed: statement clobbers memory: _129 (_123);
PULSE.c:22:2: missed: statement clobbers memory: _136 (_130);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_137);
PULSE.c:26:3: missed: statement clobbers memory: memset (_142, 0, _140);
PULSE.c:26:3: missed: statement clobbers memory: memset (_135, 0, _133);
PULSE.c:26:3: missed: statement clobbers memory: memset (_128, 0, _126);
PULSE.c:26:3: missed: statement clobbers memory: memset (_121, 0, _119);
PULSE.c:26:3: missed: statement clobbers memory: memset (_114, 0, _112);
PULSE.c:26:3: missed: statement clobbers memory: memset (_92, 0, _90);
PULSE.c:75:6: missed: statement clobbers memory: _21 (current_191, args);
PULSE.c:81:4: missed: statement clobbers memory: printf ("Epoch: %d | Item: %d | Loss: %.10f | Batch Loss: %.10f\r", i_188, j_189, _25, _24);
PULSE.c:47:6: missed: statement clobbers memory: __builtin_stack_restore (saved_stack.7_39);
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4DI
PULSE.c:47:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:91:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:91:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:119:20: missed: couldn't vectorize loop
PULSE.c:119:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:119:20: missed: couldn't vectorize loop
PULSE.c:119:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:102:20: missed: couldn't vectorize loop
PULSE.c:102:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:102:20: missed: couldn't vectorize loop
PULSE.c:102:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:93:13: note: vectorized 0 loops in function.
PULSE.c:96:39: missed: statement clobbers memory: layers_40 = malloc (_3);
PULSE.c:99:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:114:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:115:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:116:44: missed: statement clobbers memory: MODEL_109 = malloc (0);
PULSE.c:114:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:115:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:116:44: missed: statement clobbers memory: MODEL_45 = malloc (_9);
PULSE.c:125:62: missed: not vectorized: more than one data ref in stmt: D.6469 = MEM[(struct PULSE_DenseLayerArgs * {ref-all})addr.106_74];
PULSE.c:125:17: missed: statement clobbers memory: *_15 = PULSE_CreateDenseLayer (D.6469, _144); [return slot optimization]
PULSE.c:125:62: missed: not vectorized: more than one data ref in stmt: D.6469 = MEM[(struct PULSE_DenseLayerArgs * {ref-all})addr.106_181];
PULSE.c:125:17: missed: statement clobbers memory: *_174 = PULSE_CreateDenseLayer (D.6469, _180); [return slot optimization]
PULSE.c:132:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:133:9: note: ***** Analysis succeeded with vector mode V4DI
PULSE.c:133:9: note: SLPing BB part
PULSE.c:133:9: note: Costing subgraph: 
PULSE.c:133:9: note: node 0x4c0db48 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:133:9: note: op template: <retval>.layers = layers_40;
PULSE.c:133:9: note: 	stmt 0 <retval>.layers = layers_40;
PULSE.c:133:9: note: 	stmt 1 <retval>.paramethers = MODEL_131;
PULSE.c:133:9: note: 	children 0x4c0dc48
PULSE.c:133:9: note: node (external) 0x4c0dc48 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:133:9: note: 	{ layers_40, MODEL_131 }
PULSE.c:133:9: note: Cost model analysis: 
PULSE.c:133:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
PULSE.c:133:9: note: Costing subgraph: 
PULSE.c:133:9: note: node 0x4c0dcc8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:133:9: note: op template: <retval>.io = 0B;
PULSE.c:133:9: note: 	stmt 0 <retval>.io = 0B;
PULSE.c:133:9: note: 	stmt 1 <retval>.fixes = 0B;
PULSE.c:133:9: note: 	children 0x4c0dd48
PULSE.c:133:9: note: node (constant) 0x4c0dd48 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:133:9: note: 	{ 0B, 0B }
PULSE.c:133:9: note: Cost model analysis: 
PULSE.c:133:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
PULSE.c:133:9: note: Basic block will be vectorized using SLP
PULSE.c:133:9: optimized: basic block part vectorized using 16 byte vectors
PULSE.c:133:9: note: Vectorizing SLP tree:
PULSE.c:133:9: note: node 0x4c0db48 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:133:9: note: op template: <retval>.layers = layers_40;
PULSE.c:133:9: note: 	stmt 0 <retval>.layers = layers_40;
PULSE.c:133:9: note: 	stmt 1 <retval>.paramethers = MODEL_131;
PULSE.c:133:9: note: 	children 0x4c0dc48
PULSE.c:133:9: note: node (external) 0x4c0dc48 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:133:9: note: 	{ layers_40, MODEL_131 }
PULSE.c:133:9: note: ------>vectorizing SLP node starting from: <retval>.layers = layers_40;
PULSE.c:133:9: note: vect_is_simple_use: operand MODEL_131 = PHI <MODEL_45(36), MODEL_109(13)>, type of def: internal
PULSE.c:133:9: note: conflicting alias set types.
PULSE.c:133:9: note: transform store. ncopies = 1
PULSE.c:133:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.layers
PULSE.c:133:9: note: created &<retval>
PULSE.c:133:9: note: add new stmt: MEM <vector(2) long unsigned int> [(void *)&<retval>] = _23;
PULSE.c:133:9: note: vectorizing stmts using SLP.
PULSE.c:133:9: optimized: basic block part vectorized using 16 byte vectors
PULSE.c:133:9: note: Vectorizing SLP tree:
PULSE.c:133:9: note: node 0x4c0dcc8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:133:9: note: op template: <retval>.io = 0B;
PULSE.c:133:9: note: 	stmt 0 <retval>.io = 0B;
PULSE.c:133:9: note: 	stmt 1 <retval>.fixes = 0B;
PULSE.c:133:9: note: 	children 0x4c0dd48
PULSE.c:133:9: note: node (constant) 0x4c0dd48 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:133:9: note: 	{ 0B, 0B }
PULSE.c:133:9: note: ------>vectorizing SLP node starting from: <retval>.io = 0B;
PULSE.c:133:9: note: vect_is_simple_use: operand 0B, type of def: constant
PULSE.c:133:9: note: transform store. ncopies = 1
PULSE.c:133:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.io
PULSE.c:133:9: note: created &<retval>.io
PULSE.c:133:9: note: add new stmt: MEM <vector(2) long unsigned int> [(float * *)&<retval> + 16B] = { 0, 0 };
PULSE.c:133:9: note: vectorizing stmts using SLP.
PULSE.c:133:9: note: ***** The result for vector mode V32QI would be the same
PULSE.c:145:1: note: ***** Analysis failed with vector mode VOID
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:4:18: note: vectorized 0 loops in function.
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_4, inputs_15, _3);
PULSE.c:8:2: missed: statement clobbers memory: _5 (layer_17);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_12, pretmp_26, _9);
PULSE.c:13:28: note: ***** Analysis failed with vector mode V8SI
PULSE.c:13:28: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:22:2: missed: statement clobbers memory: _1 (layer_10(D));
PULSE.c:22:2: missed: statement clobbers memory: _14 (_2);
PULSE.c:22:2: missed: statement clobbers memory: _21 (_15);
PULSE.c:22:2: missed: statement clobbers memory: _28 (_22);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_29);
PULSE.c:26:3: missed: statement clobbers memory: memset (_34, 0, _32);
PULSE.c:26:3: missed: statement clobbers memory: memset (_27, 0, _25);
PULSE.c:26:3: missed: statement clobbers memory: memset (_20, 0, _18);
PULSE.c:26:3: missed: statement clobbers memory: memset (_7, 0, _5);
PULSE.c:28:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:28:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:32:6: note: vectorized 1 loops in function.
PULSE.c:34:8: missed: statement clobbers memory: _1 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_2);
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _9 = rand ();
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8SI
PULSE.c:32:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:61:16: missed: couldn't vectorize loop
PULSE.c:61:16: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:64:17: missed: couldn't vectorize loop
PULSE.c:64:17: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:73:19: missed: couldn't vectorize loop
PULSE.c:73:19: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:53:22: missed: couldn't vectorize loop
PULSE.c:53:22: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:47:6: note: vectorized 1 loops in function.
PULSE.c:48:1: missed: statement clobbers memory: saved_stack.7_39 = __builtin_stack_save ();
PULSE.c:49:46: missed: statement clobbers memory: _1 = PULSE_GetLossFunctionPtr (loss_function_40(D));
PULSE.c:60:10: missed: statement clobbers memory: random.4_46 = __builtin_alloca_with_align (_4, 32);
PULSE.c:34:8: missed: statement clobbers memory: _61 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_62);
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _72 = rand ();
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_98, inputs_93, _97);
PULSE.c:8:2: missed: statement clobbers memory: _99 (layer_94);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_105, _104, _103);
PULSE.c:67:11: missed: statement clobbers memory: loss_55 = PULSE_GetLoss_42 (_17, _16, _12, _11);
PULSE.c:22:2: missed: statement clobbers memory: _86 (output_34);
PULSE.c:22:2: missed: statement clobbers memory: _108 (_87);
PULSE.c:22:2: missed: statement clobbers memory: _115 (_109);
PULSE.c:22:2: missed: statement clobbers memory: _122 (_116);
PULSE.c:22:2: missed: statement clobbers memory: _129 (_123);
PULSE.c:22:2: missed: statement clobbers memory: _136 (_130);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_137);
PULSE.c:26:3: missed: statement clobbers memory: memset (_142, 0, _140);
PULSE.c:26:3: missed: statement clobbers memory: memset (_135, 0, _133);
PULSE.c:26:3: missed: statement clobbers memory: memset (_128, 0, _126);
PULSE.c:26:3: missed: statement clobbers memory: memset (_121, 0, _119);
PULSE.c:26:3: missed: statement clobbers memory: memset (_114, 0, _112);
PULSE.c:26:3: missed: statement clobbers memory: memset (_92, 0, _90);
PULSE.c:75:6: missed: statement clobbers memory: _21 (current_191, args);
PULSE.c:81:4: missed: statement clobbers memory: printf ("Epoch: %d | Item: %d | Loss: %.10f | Batch Loss: %.10f\r", i_188, j_189, _25, _24);
PULSE.c:47:6: missed: statement clobbers memory: __builtin_stack_restore (saved_stack.7_39);
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4DI
PULSE.c:47:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:91:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:91:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:119:20: missed: couldn't vectorize loop
PULSE.c:119:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:119:20: missed: couldn't vectorize loop
PULSE.c:119:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:102:20: missed: couldn't vectorize loop
PULSE.c:102:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:102:20: missed: couldn't vectorize loop
PULSE.c:102:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:93:13: note: vectorized 0 loops in function.
PULSE.c:96:39: missed: statement clobbers memory: layers_40 = malloc (_3);
PULSE.c:99:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:114:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:115:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:116:46: missed: statement clobbers memory: WEIGHTS_109 = malloc (0);
PULSE.c:114:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:115:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:116:46: missed: statement clobbers memory: WEIGHTS_45 = malloc (_9);
PULSE.c:125:62: missed: not vectorized: more than one data ref in stmt: D.6471 = MEM[(struct PULSE_DenseLayerArgs * {ref-all})addr.106_74];
PULSE.c:125:17: missed: statement clobbers memory: *_15 = PULSE_CreateDenseLayer (D.6471, _144); [return slot optimization]
PULSE.c:125:62: missed: not vectorized: more than one data ref in stmt: D.6471 = MEM[(struct PULSE_DenseLayerArgs * {ref-all})addr.106_181];
PULSE.c:125:17: missed: statement clobbers memory: *_174 = PULSE_CreateDenseLayer (D.6471, _180); [return slot optimization]
PULSE.c:132:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:133:9: note: ***** Analysis succeeded with vector mode V4DI
PULSE.c:133:9: note: SLPing BB part
PULSE.c:133:9: note: Costing subgraph: 
PULSE.c:133:9: note: node 0x49cab58 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:133:9: note: op template: <retval>.layers = layers_40;
PULSE.c:133:9: note: 	stmt 0 <retval>.layers = layers_40;
PULSE.c:133:9: note: 	stmt 1 <retval>.paramethers = WEIGHTS_131;
PULSE.c:133:9: note: 	children 0x49cac58
PULSE.c:133:9: note: node (external) 0x49cac58 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:133:9: note: 	{ layers_40, WEIGHTS_131 }
PULSE.c:133:9: note: Cost model analysis: 
PULSE.c:133:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
PULSE.c:133:9: note: Costing subgraph: 
PULSE.c:133:9: note: node 0x49cacd8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:133:9: note: op template: <retval>.io = 0B;
PULSE.c:133:9: note: 	stmt 0 <retval>.io = 0B;
PULSE.c:133:9: note: 	stmt 1 <retval>.fixes = 0B;
PULSE.c:133:9: note: 	children 0x49cad58
PULSE.c:133:9: note: node (constant) 0x49cad58 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:133:9: note: 	{ 0B, 0B }
PULSE.c:133:9: note: Cost model analysis: 
PULSE.c:133:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
PULSE.c:133:9: note: Basic block will be vectorized using SLP
PULSE.c:133:9: optimized: basic block part vectorized using 16 byte vectors
PULSE.c:133:9: note: Vectorizing SLP tree:
PULSE.c:133:9: note: node 0x49cab58 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:133:9: note: op template: <retval>.layers = layers_40;
PULSE.c:133:9: note: 	stmt 0 <retval>.layers = layers_40;
PULSE.c:133:9: note: 	stmt 1 <retval>.paramethers = WEIGHTS_131;
PULSE.c:133:9: note: 	children 0x49cac58
PULSE.c:133:9: note: node (external) 0x49cac58 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:133:9: note: 	{ layers_40, WEIGHTS_131 }
PULSE.c:133:9: note: ------>vectorizing SLP node starting from: <retval>.layers = layers_40;
PULSE.c:133:9: note: vect_is_simple_use: operand WEIGHTS_131 = PHI <WEIGHTS_45(36), WEIGHTS_109(13)>, type of def: internal
PULSE.c:133:9: note: conflicting alias set types.
PULSE.c:133:9: note: transform store. ncopies = 1
PULSE.c:133:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.layers
PULSE.c:133:9: note: created &<retval>
PULSE.c:133:9: note: add new stmt: MEM <vector(2) long unsigned int> [(void *)&<retval>] = _23;
PULSE.c:133:9: note: vectorizing stmts using SLP.
PULSE.c:133:9: optimized: basic block part vectorized using 16 byte vectors
PULSE.c:133:9: note: Vectorizing SLP tree:
PULSE.c:133:9: note: node 0x49cacd8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:133:9: note: op template: <retval>.io = 0B;
PULSE.c:133:9: note: 	stmt 0 <retval>.io = 0B;
PULSE.c:133:9: note: 	stmt 1 <retval>.fixes = 0B;
PULSE.c:133:9: note: 	children 0x49cad58
PULSE.c:133:9: note: node (constant) 0x49cad58 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:133:9: note: 	{ 0B, 0B }
PULSE.c:133:9: note: ------>vectorizing SLP node starting from: <retval>.io = 0B;
PULSE.c:133:9: note: vect_is_simple_use: operand 0B, type of def: constant
PULSE.c:133:9: note: transform store. ncopies = 1
PULSE.c:133:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.io
PULSE.c:133:9: note: created &<retval>.io
PULSE.c:133:9: note: add new stmt: MEM <vector(2) long unsigned int> [(float * *)&<retval> + 16B] = { 0, 0 };
PULSE.c:133:9: note: vectorizing stmts using SLP.
PULSE.c:133:9: note: ***** The result for vector mode V32QI would be the same
PULSE.c:145:1: note: ***** Analysis failed with vector mode VOID
Dense.c:9:27: missed: couldn't vectorize loop
Dense.c:9:27: missed: not vectorized: unsupported outerloop form.
Dense.c:12:20: missed: couldn't vectorize loop
Dense.c:13:21: missed: not vectorized: complicated access pattern.
Dense.c:6:13: note: vectorized 0 loops in function.
Dense.c:16:2: missed: statement clobbers memory: _28 (pretmp_91, _51, 0);
Dense.c:9:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:9:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:24:27: missed: couldn't vectorize loop
Dense.c:24:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:28:20: optimized: loop vectorized using 32 byte vectors
Dense.c:28:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:28:20: optimized: loop vectorized using 16 byte vectors
Dense.c:28:20: missed: couldn't vectorize loop
Dense.c:30:19: missed: not vectorized: no vectype for stmt: _22 = *_21;
 scalar_type: float
Dense.c:20:13: note: vectorized 1 loops in function.
Dense.c:23:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:24:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:24:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:41:28: missed: couldn't vectorize loop
Dense.c:41:28: missed: not vectorized: unsupported outerloop form.
Dense.c:45:21: optimized: loop vectorized using 32 byte vectors
Dense.c:45:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:45:21: optimized: loop vectorized using 16 byte vectors
Dense.c:37:13: note: vectorized 1 loops in function.
Dense.c:37:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:37:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:41:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:170:10: optimized: loop vectorized using 32 byte vectors
Dense.c:170:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:170:10: optimized: loop vectorized using 16 byte vectors
Dense.c:161:10: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_27, _64);
Dense.c:154:10: optimized: loop vectorized using 32 byte vectors
Dense.c:154:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:154:10: optimized: loop vectorized using 16 byte vectors
Dense.c:145:10: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_14, _56);
Dense.c:136:13: note: vectorized 2 loops in function.
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_14, _56);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_15, { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 });
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_27, _64);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_28, { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 });
Dense.c:136:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:136:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:105:24: missed: couldn't vectorize loop
Dense.c:105:24: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:108:17: missed: couldn't vectorize loop
Dense.c:108:17: missed: not vectorized: number of iterations cannot be computed.
Dense.c:122:24: missed: couldn't vectorize loop
Dense.c:122:24: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:125:17: missed: couldn't vectorize loop
Dense.c:125:17: missed: not vectorized: number of iterations cannot be computed.
Dense.c:90:15: missed: couldn't vectorize loop
Dense.c:90:15: missed: not vectorized: number of iterations cannot be computed.
Dense.c:83:13: note: vectorized 0 loops in function.
Dense.c:86:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:110:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:110:17: note: SLPing BB part
Dense.c:127:17: note: Costing subgraph: 
Dense.c:127:17: note: node 0x884e2a8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:127:17: note: op template: _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 0 _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 1 _198 = (sizetype) wi_137;
Dense.c:127:17: note: 	children 0x884e3a8
Dense.c:127:17: note: node (external) 0x884e3a8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:127:17: note: 	{ j_135, wi_137 }
Dense.c:127:17: note: Cost model analysis: 
Dense.c:127:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:127:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:127:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: Costing subgraph: 
Dense.c:110:17: note: node 0x884e4a8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:110:17: note: op template: _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 0 _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 1 _217 = (sizetype) wi_136;
Dense.c:110:17: note: 	children 0x884e5a8
Dense.c:110:17: note: node (external) 0x884e5a8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:110:17: note: 	{ j_134, wi_136 }
Dense.c:110:17: note: Cost model analysis: 
Dense.c:110:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:110:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:110:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:110:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:110:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:110:17: note: SLPing BB part
Dense.c:127:17: note: Costing subgraph: 
Dense.c:127:17: note: node 0x884e4a8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:127:17: note: op template: _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 0 _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 1 _198 = (sizetype) wi_137;
Dense.c:127:17: note: 	children 0x884e2a8
Dense.c:127:17: note: node (external) 0x884e2a8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:127:17: note: 	{ j_135, wi_137 }
Dense.c:127:17: note: Cost model analysis: 
Dense.c:127:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:127:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:127:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: Costing subgraph: 
Dense.c:110:17: note: node 0x884e428 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:110:17: note: op template: _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 0 _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 1 _217 = (sizetype) wi_136;
Dense.c:110:17: note: 	children 0x884e528
Dense.c:110:17: note: node (external) 0x884e528 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:110:17: note: 	{ j_134, wi_136 }
Dense.c:110:17: note: Cost model analysis: 
Dense.c:110:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:110:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:110:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:105:51: note: ***** Analysis failed with vector mode V8QI
Dense.c:105:51: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:105:51: note: ***** Analysis failed with vector mode V4QI
Dense.c:62:15: missed: couldn't vectorize loop
Dense.c:62:15: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:75:11: optimized: loop vectorized using 32 byte vectors
Dense.c:75:11: optimized: loop vectorized using 16 byte vectors
Dense.c:66:11: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:881:10: missed: not vectorized: no vectype for stmt: _53 = MEM[(__m256 * {ref-all})w_ptr_82];
 scalar_type: __m256
Dense.c:54:13: note: vectorized 1 loops in function.
Dense.c:57:2: missed: statement clobbers memory: memcpy (_4, dense$baiases_63, _3);
Dense.c:79:2: missed: statement clobbers memory: _27 (pretmp_163, _68, 0);
Dense.c:54:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:54:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:181:2: missed: statement clobbers memory: free (dense$weights_7);
Dense.c:182:2: missed: statement clobbers memory: free (dense$baiases_8);
Dense.c:183:2: missed: statement clobbers memory: free (dense$gradients_10);
Dense.c:184:2: missed: statement clobbers memory: free (dense$deltas_9);
Dense.c:185:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:185:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:200:19: missed: couldn't vectorize loop
Dense.c:200:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:190:13: note: vectorized 0 loops in function.
Dense.c:196:37: missed: statement clobbers memory: _9 = aligned_alloc (64, _8);
Dense.c:197:34: missed: statement clobbers memory: _11 = aligned_alloc (64, _10);
Dense.c:198:35: missed: statement clobbers memory: _12 = aligned_alloc (64, _10);
Dense.c:201:38: missed: statement clobbers memory: _13 = rand ();
Dense.c:201:72: missed: statement clobbers memory: _57 = sqrt (_20);
Dense.c:213:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:214:4: missed: statement clobbers memory: exit (1);
Dense.c:210:4: missed: statement clobbers memory: layer = PULSE_CreateLayer (args$n_inputs_36, args$n_outputs_47, 0, args$8_48, _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:207:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (args$n_inputs_36, args$n_outputs_47, 0, args$8_48, _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:219:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Dense.c:219:9: note: ***** Analysis succeeded with vector mode V8SI
Dense.c:219:9: note: SLPing BB part
Dense.c:219:9: note: Costing subgraph: 
Dense.c:219:9: note: node 0x87342f8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Dense.c:219:9: note: op template: MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = MODEL_32(D);
Dense.c:219:9: note: 	stmt 0 MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = MODEL_32(D);
Dense.c:219:9: note: 	stmt 1 MEM <float *> [(struct PULSE_Layer *)&layer + 96B] = _4;
Dense.c:219:9: note: 	stmt 2 MEM <float *> [(struct PULSE_Layer *)&layer + 104B] = _11;
Dense.c:219:9: note: 	stmt 3 MEM <float *> [(struct PULSE_Layer *)&layer + 112B] = _12;
Dense.c:219:9: note: 	children 0x8734378
Dense.c:219:9: note: node (external) 0x8734378 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Dense.c:219:9: note: 	{ MODEL_32(D), _4, _11, _12 }
Dense.c:219:9: note: Cost model analysis: 
Dense.c:219:9: note: Cost model analysis for part in loop 0:
  Vector cost: 64
  Scalar cost: 64
Dense.c:219:9: note: Basic block will be vectorized using SLP
Dense.c:219:9: optimized: basic block part vectorized using 32 byte vectors
Dense.c:219:9: note: Vectorizing SLP tree:
Dense.c:219:9: note: node 0x87342f8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Dense.c:219:9: note: op template: MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = MODEL_32(D);
Dense.c:219:9: note: 	stmt 0 MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = MODEL_32(D);
Dense.c:219:9: note: 	stmt 1 MEM <float *> [(struct PULSE_Layer *)&layer + 96B] = _4;
Dense.c:219:9: note: 	stmt 2 MEM <float *> [(struct PULSE_Layer *)&layer + 104B] = _11;
Dense.c:219:9: note: 	stmt 3 MEM <float *> [(struct PULSE_Layer *)&layer + 112B] = _12;
Dense.c:219:9: note: 	children 0x8734378
Dense.c:219:9: note: node (external) 0x8734378 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Dense.c:219:9: note: 	{ MODEL_32(D), _4, _11, _12 }
Dense.c:219:9: note: ------>vectorizing SLP node starting from: MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = MODEL_32(D);
Dense.c:219:9: note: vect_is_simple_use: operand MODEL_32(D) + _3, type of def: internal
Dense.c:219:9: note: vect_is_simple_use: operand aligned_alloc (64, _10), type of def: internal
Dense.c:219:9: note: vect_is_simple_use: operand aligned_alloc (64, _10), type of def: internal
Dense.c:219:9: note: transform store. ncopies = 1
Dense.c:219:9: note: create vector_type-pointer variable to type: vector(4) long unsigned int  vectorizing a pointer ref: MEM <float *> [(struct PULSE_Layer *)&layer + 88B]
Dense.c:219:9: note: created &MEM <float *> [(struct PULSE_Layer *)&layer + 88B]
Dense.c:219:9: note: add new stmt: MEM <vector(4) long unsigned int> [(struct PULSE_Layer *)&layer + 88B] = _61;
Dense.c:219:9: note: vectorizing stmts using SLP.
Dense.c:219:9: note: ***** The result for vector mode V32QI would be the same
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:4:18: note: vectorized 0 loops in function.
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_4, inputs_15, _3);
PULSE.c:8:2: missed: statement clobbers memory: _5 (layer_17);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_12, pretmp_26, _9);
PULSE.c:13:28: note: ***** Analysis failed with vector mode V8SI
PULSE.c:13:28: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:22:2: missed: statement clobbers memory: _1 (layer_10(D));
PULSE.c:22:2: missed: statement clobbers memory: _14 (_2);
PULSE.c:22:2: missed: statement clobbers memory: _21 (_15);
PULSE.c:22:2: missed: statement clobbers memory: _28 (_22);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_29);
PULSE.c:26:3: missed: statement clobbers memory: memset (_34, 0, _32);
PULSE.c:26:3: missed: statement clobbers memory: memset (_27, 0, _25);
PULSE.c:26:3: missed: statement clobbers memory: memset (_20, 0, _18);
PULSE.c:26:3: missed: statement clobbers memory: memset (_7, 0, _5);
PULSE.c:28:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:28:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:32:6: note: vectorized 1 loops in function.
PULSE.c:34:8: missed: statement clobbers memory: _1 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_2);
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _9 = rand ();
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8SI
PULSE.c:32:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:61:16: missed: couldn't vectorize loop
PULSE.c:61:16: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:64:17: missed: couldn't vectorize loop
PULSE.c:64:17: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:73:19: missed: couldn't vectorize loop
PULSE.c:73:19: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:53:22: missed: couldn't vectorize loop
PULSE.c:53:22: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:47:6: note: vectorized 1 loops in function.
PULSE.c:48:1: missed: statement clobbers memory: saved_stack.7_39 = __builtin_stack_save ();
PULSE.c:49:46: missed: statement clobbers memory: _1 = PULSE_GetLossFunctionPtr (loss_function_40(D));
PULSE.c:60:10: missed: statement clobbers memory: random.4_46 = __builtin_alloca_with_align (_4, 32);
PULSE.c:34:8: missed: statement clobbers memory: _61 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_62);
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _72 = rand ();
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_98, inputs_93, _97);
PULSE.c:8:2: missed: statement clobbers memory: _99 (layer_94);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_105, _104, _103);
PULSE.c:67:11: missed: statement clobbers memory: loss_55 = PULSE_GetLoss_42 (_17, _16, _12, _11);
PULSE.c:22:2: missed: statement clobbers memory: _86 (output_34);
PULSE.c:22:2: missed: statement clobbers memory: _108 (_87);
PULSE.c:22:2: missed: statement clobbers memory: _115 (_109);
PULSE.c:22:2: missed: statement clobbers memory: _122 (_116);
PULSE.c:22:2: missed: statement clobbers memory: _129 (_123);
PULSE.c:22:2: missed: statement clobbers memory: _136 (_130);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_137);
PULSE.c:26:3: missed: statement clobbers memory: memset (_142, 0, _140);
PULSE.c:26:3: missed: statement clobbers memory: memset (_135, 0, _133);
PULSE.c:26:3: missed: statement clobbers memory: memset (_128, 0, _126);
PULSE.c:26:3: missed: statement clobbers memory: memset (_121, 0, _119);
PULSE.c:26:3: missed: statement clobbers memory: memset (_114, 0, _112);
PULSE.c:26:3: missed: statement clobbers memory: memset (_92, 0, _90);
PULSE.c:75:6: missed: statement clobbers memory: _21 (current_191, args);
PULSE.c:81:4: missed: statement clobbers memory: printf ("Epoch: %d | Item: %d | Loss: %.10f | Batch Loss: %.10f\r", i_188, j_189, _25, _24);
PULSE.c:47:6: missed: statement clobbers memory: __builtin_stack_restore (saved_stack.7_39);
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4DI
PULSE.c:47:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:91:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:91:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:119:20: missed: couldn't vectorize loop
PULSE.c:119:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:119:20: missed: couldn't vectorize loop
PULSE.c:119:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:102:20: missed: couldn't vectorize loop
PULSE.c:102:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:102:20: missed: couldn't vectorize loop
PULSE.c:102:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:93:13: note: vectorized 0 loops in function.
PULSE.c:96:39: missed: statement clobbers memory: layers_32 = malloc (_3);
PULSE.c:99:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:114:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:115:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:116:46: missed: statement clobbers memory: WEIGHTS_47 = malloc (0);
PULSE.c:108:26: missed: not vectorized: more than one data ref in stmt: args = MEM[(struct PULSE_DenseLayerArgs * {ref-all})addr.104_69];
PULSE.c:109:21: missed: statement clobbers memory: _58 = PULSE_GetWeightsLayerSize (args);
PULSE.c:108:26: missed: not vectorized: more than one data ref in stmt: args = MEM[(struct PULSE_DenseLayerArgs * {ref-all})_181];
PULSE.c:109:21: missed: statement clobbers memory: _172 = PULSE_GetWeightsLayerSize (args);
PULSE.c:114:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:115:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:116:46: missed: statement clobbers memory: WEIGHTS_37 = malloc (_6);
PULSE.c:125:26: missed: not vectorized: more than one data ref in stmt: args = MEM[(struct PULSE_DenseLayerArgs * {ref-all})addr.106_71];
PULSE.c:126:17: missed: statement clobbers memory: *_9 = PULSE_CreateDenseLayer (args, WEIGHTS_PTR_122); [return slot optimization]
PULSE.c:127:20: missed: statement clobbers memory: _50 = PULSE_GetWeightsLayerSize (args);
PULSE.c:125:26: missed: not vectorized: more than one data ref in stmt: args = MEM[(struct PULSE_DenseLayerArgs * {ref-all})addr.106_114];
PULSE.c:126:17: missed: statement clobbers memory: *_99 = PULSE_CreateDenseLayer (args, WEIGHTS_PTR_136); [return slot optimization]
PULSE.c:127:20: missed: statement clobbers memory: _77 = PULSE_GetWeightsLayerSize (args);
PULSE.c:133:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:134:9: note: ***** Analysis succeeded with vector mode V8SI
PULSE.c:134:9: note: SLPing BB part
PULSE.c:134:9: note: Costing subgraph: 
PULSE.c:134:9: note: node 0x3b13b38 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:134:9: note: op template: <retval>.layers = layers_32;
PULSE.c:134:9: note: 	stmt 0 <retval>.layers = layers_32;
PULSE.c:134:9: note: 	stmt 1 <retval>.paramethers = WEIGHTS_81;
PULSE.c:134:9: note: 	children 0x3b13c38
PULSE.c:134:9: note: node (external) 0x3b13c38 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:134:9: note: 	{ layers_32, WEIGHTS_81 }
PULSE.c:134:9: note: Cost model analysis: 
PULSE.c:134:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
PULSE.c:134:9: note: Costing subgraph: 
PULSE.c:134:9: note: node 0x3b13cb8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:134:9: note: op template: <retval>.io = 0B;
PULSE.c:134:9: note: 	stmt 0 <retval>.io = 0B;
PULSE.c:134:9: note: 	stmt 1 <retval>.fixes = 0B;
PULSE.c:134:9: note: 	children 0x3b13d38
PULSE.c:134:9: note: node (constant) 0x3b13d38 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:134:9: note: 	{ 0B, 0B }
PULSE.c:134:9: note: Cost model analysis: 
PULSE.c:134:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
PULSE.c:134:9: note: Basic block will be vectorized using SLP
PULSE.c:134:9: optimized: basic block part vectorized using 16 byte vectors
PULSE.c:134:9: note: Vectorizing SLP tree:
PULSE.c:134:9: note: node 0x3b13b38 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:134:9: note: op template: <retval>.layers = layers_32;
PULSE.c:134:9: note: 	stmt 0 <retval>.layers = layers_32;
PULSE.c:134:9: note: 	stmt 1 <retval>.paramethers = WEIGHTS_81;
PULSE.c:134:9: note: 	children 0x3b13c38
PULSE.c:134:9: note: node (external) 0x3b13c38 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:134:9: note: 	{ layers_32, WEIGHTS_81 }
PULSE.c:134:9: note: ------>vectorizing SLP node starting from: <retval>.layers = layers_32;
PULSE.c:134:9: note: vect_is_simple_use: operand WEIGHTS_81 = PHI <WEIGHTS_37(36), WEIGHTS_47(12)>, type of def: internal
PULSE.c:134:9: note: conflicting alias set types.
PULSE.c:134:9: note: transform store. ncopies = 1
PULSE.c:134:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.layers
PULSE.c:134:9: note: created &<retval>
PULSE.c:134:9: note: add new stmt: MEM <vector(2) long unsigned int> [(void *)&<retval>] = _14;
PULSE.c:134:9: note: vectorizing stmts using SLP.
PULSE.c:134:9: optimized: basic block part vectorized using 16 byte vectors
PULSE.c:134:9: note: Vectorizing SLP tree:
PULSE.c:134:9: note: node 0x3b13cb8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:134:9: note: op template: <retval>.io = 0B;
PULSE.c:134:9: note: 	stmt 0 <retval>.io = 0B;
PULSE.c:134:9: note: 	stmt 1 <retval>.fixes = 0B;
PULSE.c:134:9: note: 	children 0x3b13d38
PULSE.c:134:9: note: node (constant) 0x3b13d38 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:134:9: note: 	{ 0B, 0B }
PULSE.c:134:9: note: ------>vectorizing SLP node starting from: <retval>.io = 0B;
PULSE.c:134:9: note: vect_is_simple_use: operand 0B, type of def: constant
PULSE.c:134:9: note: transform store. ncopies = 1
PULSE.c:134:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.io
PULSE.c:134:9: note: created &<retval>.io
PULSE.c:134:9: note: add new stmt: MEM <vector(2) long unsigned int> [(float * *)&<retval> + 16B] = { 0, 0 };
PULSE.c:134:9: note: vectorizing stmts using SLP.
PULSE.c:134:9: note: ***** The result for vector mode V32QI would be the same
PULSE.c:146:1: note: ***** Analysis failed with vector mode VOID
Dense.c:9:27: missed: couldn't vectorize loop
Dense.c:9:27: missed: not vectorized: unsupported outerloop form.
Dense.c:12:20: missed: couldn't vectorize loop
Dense.c:13:21: missed: not vectorized: complicated access pattern.
Dense.c:6:13: note: vectorized 0 loops in function.
Dense.c:16:2: missed: statement clobbers memory: _28 (pretmp_91, _51, 0);
Dense.c:9:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:9:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:24:27: missed: couldn't vectorize loop
Dense.c:24:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:28:20: optimized: loop vectorized using 32 byte vectors
Dense.c:28:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:28:20: optimized: loop vectorized using 16 byte vectors
Dense.c:28:20: missed: couldn't vectorize loop
Dense.c:30:19: missed: not vectorized: no vectype for stmt: _22 = *_21;
 scalar_type: float
Dense.c:20:13: note: vectorized 1 loops in function.
Dense.c:23:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:24:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:24:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:41:28: missed: couldn't vectorize loop
Dense.c:41:28: missed: not vectorized: unsupported outerloop form.
Dense.c:45:21: optimized: loop vectorized using 32 byte vectors
Dense.c:45:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:45:21: optimized: loop vectorized using 16 byte vectors
Dense.c:37:13: note: vectorized 1 loops in function.
Dense.c:37:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:37:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:41:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:170:10: optimized: loop vectorized using 32 byte vectors
Dense.c:170:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:170:10: optimized: loop vectorized using 16 byte vectors
Dense.c:161:10: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_27, _64);
Dense.c:154:10: optimized: loop vectorized using 32 byte vectors
Dense.c:154:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:154:10: optimized: loop vectorized using 16 byte vectors
Dense.c:145:10: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_14, _56);
Dense.c:136:13: note: vectorized 2 loops in function.
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_14, _56);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_15, { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 });
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_27, _64);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_28, { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 });
Dense.c:136:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:136:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:105:24: missed: couldn't vectorize loop
Dense.c:105:24: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:108:17: missed: couldn't vectorize loop
Dense.c:108:17: missed: not vectorized: number of iterations cannot be computed.
Dense.c:122:24: missed: couldn't vectorize loop
Dense.c:122:24: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:125:17: missed: couldn't vectorize loop
Dense.c:125:17: missed: not vectorized: number of iterations cannot be computed.
Dense.c:90:15: missed: couldn't vectorize loop
Dense.c:90:15: missed: not vectorized: number of iterations cannot be computed.
Dense.c:83:13: note: vectorized 0 loops in function.
Dense.c:86:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:110:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:110:17: note: SLPing BB part
Dense.c:127:17: note: Costing subgraph: 
Dense.c:127:17: note: node 0x7382358 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:127:17: note: op template: _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 0 _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 1 _198 = (sizetype) wi_137;
Dense.c:127:17: note: 	children 0x7382458
Dense.c:127:17: note: node (external) 0x7382458 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:127:17: note: 	{ j_135, wi_137 }
Dense.c:127:17: note: Cost model analysis: 
Dense.c:127:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:127:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:127:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: Costing subgraph: 
Dense.c:110:17: note: node 0x7382558 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:110:17: note: op template: _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 0 _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 1 _217 = (sizetype) wi_136;
Dense.c:110:17: note: 	children 0x7382658
Dense.c:110:17: note: node (external) 0x7382658 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:110:17: note: 	{ j_134, wi_136 }
Dense.c:110:17: note: Cost model analysis: 
Dense.c:110:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:110:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:110:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:110:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:110:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:110:17: note: SLPing BB part
Dense.c:127:17: note: Costing subgraph: 
Dense.c:127:17: note: node 0x7382558 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:127:17: note: op template: _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 0 _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 1 _198 = (sizetype) wi_137;
Dense.c:127:17: note: 	children 0x7382358
Dense.c:127:17: note: node (external) 0x7382358 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:127:17: note: 	{ j_135, wi_137 }
Dense.c:127:17: note: Cost model analysis: 
Dense.c:127:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:127:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:127:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: Costing subgraph: 
Dense.c:110:17: note: node 0x73824d8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:110:17: note: op template: _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 0 _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 1 _217 = (sizetype) wi_136;
Dense.c:110:17: note: 	children 0x73825d8
Dense.c:110:17: note: node (external) 0x73825d8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:110:17: note: 	{ j_134, wi_136 }
Dense.c:110:17: note: Cost model analysis: 
Dense.c:110:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:110:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:110:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:105:51: note: ***** Analysis failed with vector mode V8QI
Dense.c:105:51: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:105:51: note: ***** Analysis failed with vector mode V4QI
Dense.c:62:15: missed: couldn't vectorize loop
Dense.c:62:15: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:75:11: optimized: loop vectorized using 32 byte vectors
Dense.c:75:11: optimized: loop vectorized using 16 byte vectors
Dense.c:66:11: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:881:10: missed: not vectorized: no vectype for stmt: _53 = MEM[(__m256 * {ref-all})w_ptr_82];
 scalar_type: __m256
Dense.c:54:13: note: vectorized 1 loops in function.
Dense.c:57:2: missed: statement clobbers memory: memcpy (_4, dense$baiases_63, _3);
Dense.c:79:2: missed: statement clobbers memory: _27 (pretmp_163, _68, 0);
Dense.c:54:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:54:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:181:2: missed: statement clobbers memory: free (dense$weights_7);
Dense.c:182:2: missed: statement clobbers memory: free (dense$baiases_8);
Dense.c:183:2: missed: statement clobbers memory: free (dense$gradients_10);
Dense.c:184:2: missed: statement clobbers memory: free (dense$deltas_9);
Dense.c:185:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:185:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:200:19: missed: couldn't vectorize loop
Dense.c:200:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:190:13: note: vectorized 0 loops in function.
Dense.c:196:37: missed: statement clobbers memory: _9 = aligned_alloc (64, _8);
Dense.c:197:34: missed: statement clobbers memory: _11 = aligned_alloc (64, _10);
Dense.c:198:35: missed: statement clobbers memory: _12 = aligned_alloc (64, _10);
Dense.c:201:38: missed: statement clobbers memory: _13 = rand ();
Dense.c:201:72: missed: statement clobbers memory: _57 = sqrt (_20);
Dense.c:213:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:214:4: missed: statement clobbers memory: exit (1);
Dense.c:210:4: missed: statement clobbers memory: layer = PULSE_CreateLayer (args$n_inputs_36, args$n_outputs_47, 0, args$8_48, _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:207:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (args$n_inputs_36, args$n_outputs_47, 0, args$8_48, _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:219:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Dense.c:219:9: note: ***** Analysis succeeded with vector mode V8SI
Dense.c:219:9: note: SLPing BB part
Dense.c:219:9: note: Costing subgraph: 
Dense.c:219:9: note: node 0x719ed68 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Dense.c:219:9: note: op template: MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = MODEL_32(D);
Dense.c:219:9: note: 	stmt 0 MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = MODEL_32(D);
Dense.c:219:9: note: 	stmt 1 MEM <float *> [(struct PULSE_Layer *)&layer + 96B] = _4;
Dense.c:219:9: note: 	stmt 2 MEM <float *> [(struct PULSE_Layer *)&layer + 104B] = _11;
Dense.c:219:9: note: 	stmt 3 MEM <float *> [(struct PULSE_Layer *)&layer + 112B] = _12;
Dense.c:219:9: note: 	children 0x719ede8
Dense.c:219:9: note: node (external) 0x719ede8 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Dense.c:219:9: note: 	{ MODEL_32(D), _4, _11, _12 }
Dense.c:219:9: note: Cost model analysis: 
Dense.c:219:9: note: Cost model analysis for part in loop 0:
  Vector cost: 64
  Scalar cost: 64
Dense.c:219:9: note: Basic block will be vectorized using SLP
Dense.c:219:9: optimized: basic block part vectorized using 32 byte vectors
Dense.c:219:9: note: Vectorizing SLP tree:
Dense.c:219:9: note: node 0x719ed68 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Dense.c:219:9: note: op template: MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = MODEL_32(D);
Dense.c:219:9: note: 	stmt 0 MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = MODEL_32(D);
Dense.c:219:9: note: 	stmt 1 MEM <float *> [(struct PULSE_Layer *)&layer + 96B] = _4;
Dense.c:219:9: note: 	stmt 2 MEM <float *> [(struct PULSE_Layer *)&layer + 104B] = _11;
Dense.c:219:9: note: 	stmt 3 MEM <float *> [(struct PULSE_Layer *)&layer + 112B] = _12;
Dense.c:219:9: note: 	children 0x719ede8
Dense.c:219:9: note: node (external) 0x719ede8 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Dense.c:219:9: note: 	{ MODEL_32(D), _4, _11, _12 }
Dense.c:219:9: note: ------>vectorizing SLP node starting from: MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = MODEL_32(D);
Dense.c:219:9: note: vect_is_simple_use: operand MODEL_32(D) + _3, type of def: internal
Dense.c:219:9: note: vect_is_simple_use: operand aligned_alloc (64, _10), type of def: internal
Dense.c:219:9: note: vect_is_simple_use: operand aligned_alloc (64, _10), type of def: internal
Dense.c:219:9: note: transform store. ncopies = 1
Dense.c:219:9: note: create vector_type-pointer variable to type: vector(4) long unsigned int  vectorizing a pointer ref: MEM <float *> [(struct PULSE_Layer *)&layer + 88B]
Dense.c:219:9: note: created &MEM <float *> [(struct PULSE_Layer *)&layer + 88B]
Dense.c:219:9: note: add new stmt: MEM <vector(4) long unsigned int> [(struct PULSE_Layer *)&layer + 88B] = _61;
Dense.c:219:9: note: vectorizing stmts using SLP.
Dense.c:219:9: note: ***** The result for vector mode V32QI would be the same
Dense.c:9:27: missed: couldn't vectorize loop
Dense.c:9:27: missed: not vectorized: unsupported outerloop form.
Dense.c:12:20: missed: couldn't vectorize loop
Dense.c:13:21: missed: not vectorized: complicated access pattern.
Dense.c:6:13: note: vectorized 0 loops in function.
Dense.c:16:2: missed: statement clobbers memory: _28 (pretmp_91, _51, 0);
Dense.c:9:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:9:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:24:27: missed: couldn't vectorize loop
Dense.c:24:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:28:20: optimized: loop vectorized using 32 byte vectors
Dense.c:28:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:28:20: optimized: loop vectorized using 16 byte vectors
Dense.c:28:20: missed: couldn't vectorize loop
Dense.c:30:19: missed: not vectorized: no vectype for stmt: _22 = *_21;
 scalar_type: float
Dense.c:20:13: note: vectorized 1 loops in function.
Dense.c:23:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:24:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:24:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:41:28: missed: couldn't vectorize loop
Dense.c:41:28: missed: not vectorized: unsupported outerloop form.
Dense.c:45:21: optimized: loop vectorized using 32 byte vectors
Dense.c:45:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:45:21: optimized: loop vectorized using 16 byte vectors
Dense.c:37:13: note: vectorized 1 loops in function.
Dense.c:37:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:37:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:41:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:170:10: optimized: loop vectorized using 32 byte vectors
Dense.c:170:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:170:10: optimized: loop vectorized using 16 byte vectors
Dense.c:161:10: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_27, _64);
Dense.c:154:10: optimized: loop vectorized using 32 byte vectors
Dense.c:154:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:154:10: optimized: loop vectorized using 16 byte vectors
Dense.c:145:10: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_14, _56);
Dense.c:136:13: note: vectorized 2 loops in function.
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_14, _56);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_15, { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 });
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_27, _64);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_28, { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 });
Dense.c:136:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:136:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:105:24: missed: couldn't vectorize loop
Dense.c:105:24: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:108:17: missed: couldn't vectorize loop
Dense.c:108:17: missed: not vectorized: number of iterations cannot be computed.
Dense.c:122:24: missed: couldn't vectorize loop
Dense.c:122:24: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:125:17: missed: couldn't vectorize loop
Dense.c:125:17: missed: not vectorized: number of iterations cannot be computed.
Dense.c:90:15: missed: couldn't vectorize loop
Dense.c:90:15: missed: not vectorized: number of iterations cannot be computed.
Dense.c:83:13: note: vectorized 0 loops in function.
Dense.c:86:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:110:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:110:17: note: SLPing BB part
Dense.c:127:17: note: Costing subgraph: 
Dense.c:127:17: note: node 0x6f2cc38 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:127:17: note: op template: _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 0 _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 1 _198 = (sizetype) wi_137;
Dense.c:127:17: note: 	children 0x6f2cd38
Dense.c:127:17: note: node (external) 0x6f2cd38 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:127:17: note: 	{ j_135, wi_137 }
Dense.c:127:17: note: Cost model analysis: 
Dense.c:127:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:127:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:127:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: Costing subgraph: 
Dense.c:110:17: note: node 0x6f2ce38 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:110:17: note: op template: _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 0 _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 1 _217 = (sizetype) wi_136;
Dense.c:110:17: note: 	children 0x6f2cf38
Dense.c:110:17: note: node (external) 0x6f2cf38 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:110:17: note: 	{ j_134, wi_136 }
Dense.c:110:17: note: Cost model analysis: 
Dense.c:110:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:110:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:110:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:110:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:110:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:110:17: note: SLPing BB part
Dense.c:127:17: note: Costing subgraph: 
Dense.c:127:17: note: node 0x6f2ce38 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:127:17: note: op template: _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 0 _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 1 _198 = (sizetype) wi_137;
Dense.c:127:17: note: 	children 0x6f2cc38
Dense.c:127:17: note: node (external) 0x6f2cc38 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:127:17: note: 	{ j_135, wi_137 }
Dense.c:127:17: note: Cost model analysis: 
Dense.c:127:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:127:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:127:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: Costing subgraph: 
Dense.c:110:17: note: node 0x6f2cdb8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:110:17: note: op template: _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 0 _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 1 _217 = (sizetype) wi_136;
Dense.c:110:17: note: 	children 0x6f2ceb8
Dense.c:110:17: note: node (external) 0x6f2ceb8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:110:17: note: 	{ j_134, wi_136 }
Dense.c:110:17: note: Cost model analysis: 
Dense.c:110:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:110:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:110:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:105:51: note: ***** Analysis failed with vector mode V8QI
Dense.c:105:51: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:105:51: note: ***** Analysis failed with vector mode V4QI
Dense.c:62:15: missed: couldn't vectorize loop
Dense.c:62:15: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:75:11: optimized: loop vectorized using 32 byte vectors
Dense.c:75:11: optimized: loop vectorized using 16 byte vectors
Dense.c:66:11: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:881:10: missed: not vectorized: no vectype for stmt: _53 = MEM[(__m256 * {ref-all})w_ptr_82];
 scalar_type: __m256
Dense.c:54:13: note: vectorized 1 loops in function.
Dense.c:57:2: missed: statement clobbers memory: memcpy (_4, dense$baiases_63, _3);
Dense.c:79:2: missed: statement clobbers memory: _27 (pretmp_163, _68, 0);
Dense.c:54:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:54:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:181:2: missed: statement clobbers memory: free (dense$weights_7);
Dense.c:182:2: missed: statement clobbers memory: free (dense$baiases_8);
Dense.c:183:2: missed: statement clobbers memory: free (dense$gradients_10);
Dense.c:184:2: missed: statement clobbers memory: free (dense$deltas_9);
Dense.c:185:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:185:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:200:19: missed: couldn't vectorize loop
Dense.c:200:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:190:13: note: vectorized 0 loops in function.
Dense.c:196:37: missed: statement clobbers memory: _9 = aligned_alloc (64, _8);
Dense.c:197:34: missed: statement clobbers memory: _11 = aligned_alloc (64, _10);
Dense.c:198:35: missed: statement clobbers memory: _12 = aligned_alloc (64, _10);
Dense.c:201:38: missed: statement clobbers memory: _13 = rand ();
Dense.c:201:72: missed: statement clobbers memory: _57 = sqrt (_20);
Dense.c:213:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:214:4: missed: statement clobbers memory: exit (1);
Dense.c:210:4: missed: statement clobbers memory: layer = PULSE_CreateLayer (args$n_inputs_36, args$n_outputs_47, 0, args$8_48, _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:207:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (args$n_inputs_36, args$n_outputs_47, 0, args$8_48, _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:219:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Dense.c:219:9: note: ***** Analysis succeeded with vector mode V8SI
Dense.c:219:9: note: SLPing BB part
Dense.c:219:9: note: Costing subgraph: 
Dense.c:219:9: note: node 0x6d51548 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Dense.c:219:9: note: op template: MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = MODEL_32(D);
Dense.c:219:9: note: 	stmt 0 MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = MODEL_32(D);
Dense.c:219:9: note: 	stmt 1 MEM <float *> [(struct PULSE_Layer *)&layer + 96B] = _4;
Dense.c:219:9: note: 	stmt 2 MEM <float *> [(struct PULSE_Layer *)&layer + 104B] = _11;
Dense.c:219:9: note: 	stmt 3 MEM <float *> [(struct PULSE_Layer *)&layer + 112B] = _12;
Dense.c:219:9: note: 	children 0x6d515c8
Dense.c:219:9: note: node (external) 0x6d515c8 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Dense.c:219:9: note: 	{ MODEL_32(D), _4, _11, _12 }
Dense.c:219:9: note: Cost model analysis: 
Dense.c:219:9: note: Cost model analysis for part in loop 0:
  Vector cost: 64
  Scalar cost: 64
Dense.c:219:9: note: Basic block will be vectorized using SLP
Dense.c:219:9: optimized: basic block part vectorized using 32 byte vectors
Dense.c:219:9: note: Vectorizing SLP tree:
Dense.c:219:9: note: node 0x6d51548 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Dense.c:219:9: note: op template: MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = MODEL_32(D);
Dense.c:219:9: note: 	stmt 0 MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = MODEL_32(D);
Dense.c:219:9: note: 	stmt 1 MEM <float *> [(struct PULSE_Layer *)&layer + 96B] = _4;
Dense.c:219:9: note: 	stmt 2 MEM <float *> [(struct PULSE_Layer *)&layer + 104B] = _11;
Dense.c:219:9: note: 	stmt 3 MEM <float *> [(struct PULSE_Layer *)&layer + 112B] = _12;
Dense.c:219:9: note: 	children 0x6d515c8
Dense.c:219:9: note: node (external) 0x6d515c8 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Dense.c:219:9: note: 	{ MODEL_32(D), _4, _11, _12 }
Dense.c:219:9: note: ------>vectorizing SLP node starting from: MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = MODEL_32(D);
Dense.c:219:9: note: vect_is_simple_use: operand MODEL_32(D) + _3, type of def: internal
Dense.c:219:9: note: vect_is_simple_use: operand aligned_alloc (64, _10), type of def: internal
Dense.c:219:9: note: vect_is_simple_use: operand aligned_alloc (64, _10), type of def: internal
Dense.c:219:9: note: transform store. ncopies = 1
Dense.c:219:9: note: create vector_type-pointer variable to type: vector(4) long unsigned int  vectorizing a pointer ref: MEM <float *> [(struct PULSE_Layer *)&layer + 88B]
Dense.c:219:9: note: created &MEM <float *> [(struct PULSE_Layer *)&layer + 88B]
Dense.c:219:9: note: add new stmt: MEM <vector(4) long unsigned int> [(struct PULSE_Layer *)&layer + 88B] = _61;
Dense.c:219:9: note: vectorizing stmts using SLP.
Dense.c:219:9: note: ***** The result for vector mode V32QI would be the same
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:4:18: note: vectorized 0 loops in function.
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_4, inputs_15, _3);
PULSE.c:8:2: missed: statement clobbers memory: _5 (layer_17);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_12, pretmp_26, _9);
PULSE.c:13:28: note: ***** Analysis failed with vector mode V8SI
PULSE.c:13:28: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:22:2: missed: statement clobbers memory: _1 (layer_10(D));
PULSE.c:22:2: missed: statement clobbers memory: _14 (_2);
PULSE.c:22:2: missed: statement clobbers memory: _21 (_15);
PULSE.c:22:2: missed: statement clobbers memory: _28 (_22);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_29);
PULSE.c:26:3: missed: statement clobbers memory: memset (_34, 0, _32);
PULSE.c:26:3: missed: statement clobbers memory: memset (_27, 0, _25);
PULSE.c:26:3: missed: statement clobbers memory: memset (_20, 0, _18);
PULSE.c:26:3: missed: statement clobbers memory: memset (_7, 0, _5);
PULSE.c:28:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:28:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:32:6: note: vectorized 1 loops in function.
PULSE.c:34:8: missed: statement clobbers memory: _1 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_2);
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _9 = rand ();
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8SI
PULSE.c:32:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:61:16: missed: couldn't vectorize loop
PULSE.c:61:16: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:64:17: missed: couldn't vectorize loop
PULSE.c:64:17: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:73:19: missed: couldn't vectorize loop
PULSE.c:73:19: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:53:22: missed: couldn't vectorize loop
PULSE.c:53:22: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:47:6: note: vectorized 1 loops in function.
PULSE.c:48:1: missed: statement clobbers memory: saved_stack.7_39 = __builtin_stack_save ();
PULSE.c:49:46: missed: statement clobbers memory: _1 = PULSE_GetLossFunctionPtr (loss_function_40(D));
PULSE.c:60:10: missed: statement clobbers memory: random.4_46 = __builtin_alloca_with_align (_4, 32);
PULSE.c:34:8: missed: statement clobbers memory: _61 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_62);
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _72 = rand ();
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_98, inputs_93, _97);
PULSE.c:8:2: missed: statement clobbers memory: _99 (layer_94);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_105, _104, _103);
PULSE.c:67:11: missed: statement clobbers memory: loss_55 = PULSE_GetLoss_42 (_17, _16, _12, _11);
PULSE.c:22:2: missed: statement clobbers memory: _86 (output_34);
PULSE.c:22:2: missed: statement clobbers memory: _108 (_87);
PULSE.c:22:2: missed: statement clobbers memory: _115 (_109);
PULSE.c:22:2: missed: statement clobbers memory: _122 (_116);
PULSE.c:22:2: missed: statement clobbers memory: _129 (_123);
PULSE.c:22:2: missed: statement clobbers memory: _136 (_130);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_137);
PULSE.c:26:3: missed: statement clobbers memory: memset (_142, 0, _140);
PULSE.c:26:3: missed: statement clobbers memory: memset (_135, 0, _133);
PULSE.c:26:3: missed: statement clobbers memory: memset (_128, 0, _126);
PULSE.c:26:3: missed: statement clobbers memory: memset (_121, 0, _119);
PULSE.c:26:3: missed: statement clobbers memory: memset (_114, 0, _112);
PULSE.c:26:3: missed: statement clobbers memory: memset (_92, 0, _90);
PULSE.c:75:6: missed: statement clobbers memory: _21 (current_191, args);
PULSE.c:81:4: missed: statement clobbers memory: printf ("Epoch: %d | Item: %d | Loss: %.10f | Batch Loss: %.10f\r", i_188, j_189, _25, _24);
PULSE.c:47:6: missed: statement clobbers memory: __builtin_stack_restore (saved_stack.7_39);
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4DI
PULSE.c:47:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:91:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:91:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:119:20: missed: couldn't vectorize loop
PULSE.c:119:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:119:20: missed: couldn't vectorize loop
PULSE.c:119:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:102:20: missed: couldn't vectorize loop
PULSE.c:102:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:102:20: missed: couldn't vectorize loop
PULSE.c:102:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:93:13: note: vectorized 0 loops in function.
PULSE.c:96:39: missed: statement clobbers memory: layers_31 = malloc (_3);
PULSE.c:99:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:114:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:115:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:116:46: missed: statement clobbers memory: WEIGHTS_46 = malloc (0);
PULSE.c:108:26: missed: not vectorized: more than one data ref in stmt: args = MEM[(struct PULSE_DenseLayerArgs * {ref-all})addr.104_68];
PULSE.c:109:21: missed: statement clobbers memory: _57 = PULSE_GetDenseWeightsSize (args);
PULSE.c:108:26: missed: not vectorized: more than one data ref in stmt: args = MEM[(struct PULSE_DenseLayerArgs * {ref-all})_179];
PULSE.c:109:21: missed: statement clobbers memory: _171 = PULSE_GetDenseWeightsSize (args);
PULSE.c:114:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:115:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:116:46: missed: statement clobbers memory: WEIGHTS_36 = malloc (_5);
PULSE.c:125:26: missed: not vectorized: more than one data ref in stmt: args = MEM[(struct PULSE_DenseLayerArgs * {ref-all})addr.106_70];
PULSE.c:126:17: missed: statement clobbers memory: *_8 = PULSE_CreateDenseLayer (args, WEIGHTS_PTR_121); [return slot optimization]
PULSE.c:127:20: missed: statement clobbers memory: _49 = PULSE_GetDenseWeightsSize (args);
PULSE.c:125:26: missed: not vectorized: more than one data ref in stmt: args = MEM[(struct PULSE_DenseLayerArgs * {ref-all})addr.106_113];
PULSE.c:126:17: missed: statement clobbers memory: *_98 = PULSE_CreateDenseLayer (args, WEIGHTS_PTR_135); [return slot optimization]
PULSE.c:127:20: missed: statement clobbers memory: _76 = PULSE_GetDenseWeightsSize (args);
PULSE.c:133:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:134:9: note: ***** Analysis succeeded with vector mode V8SI
PULSE.c:134:9: note: SLPing BB part
PULSE.c:134:9: note: Costing subgraph: 
PULSE.c:134:9: note: node 0x44e5b38 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:134:9: note: op template: <retval>.layers = layers_31;
PULSE.c:134:9: note: 	stmt 0 <retval>.layers = layers_31;
PULSE.c:134:9: note: 	stmt 1 <retval>.paramethers = WEIGHTS_80;
PULSE.c:134:9: note: 	children 0x44e5c38
PULSE.c:134:9: note: node (external) 0x44e5c38 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:134:9: note: 	{ layers_31, WEIGHTS_80 }
PULSE.c:134:9: note: Cost model analysis: 
PULSE.c:134:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
PULSE.c:134:9: note: Costing subgraph: 
PULSE.c:134:9: note: node 0x44e5cb8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:134:9: note: op template: <retval>.io = 0B;
PULSE.c:134:9: note: 	stmt 0 <retval>.io = 0B;
PULSE.c:134:9: note: 	stmt 1 <retval>.fixes = 0B;
PULSE.c:134:9: note: 	children 0x44e5d38
PULSE.c:134:9: note: node (constant) 0x44e5d38 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:134:9: note: 	{ 0B, 0B }
PULSE.c:134:9: note: Cost model analysis: 
PULSE.c:134:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
PULSE.c:134:9: note: Basic block will be vectorized using SLP
PULSE.c:134:9: optimized: basic block part vectorized using 16 byte vectors
PULSE.c:134:9: note: Vectorizing SLP tree:
PULSE.c:134:9: note: node 0x44e5b38 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:134:9: note: op template: <retval>.layers = layers_31;
PULSE.c:134:9: note: 	stmt 0 <retval>.layers = layers_31;
PULSE.c:134:9: note: 	stmt 1 <retval>.paramethers = WEIGHTS_80;
PULSE.c:134:9: note: 	children 0x44e5c38
PULSE.c:134:9: note: node (external) 0x44e5c38 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:134:9: note: 	{ layers_31, WEIGHTS_80 }
PULSE.c:134:9: note: ------>vectorizing SLP node starting from: <retval>.layers = layers_31;
PULSE.c:134:9: note: vect_is_simple_use: operand WEIGHTS_80 = PHI <WEIGHTS_36(36), WEIGHTS_46(12)>, type of def: internal
PULSE.c:134:9: note: conflicting alias set types.
PULSE.c:134:9: note: transform store. ncopies = 1
PULSE.c:134:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.layers
PULSE.c:134:9: note: created &<retval>
PULSE.c:134:9: note: add new stmt: MEM <vector(2) long unsigned int> [(void *)&<retval>] = _11;
PULSE.c:134:9: note: vectorizing stmts using SLP.
PULSE.c:134:9: optimized: basic block part vectorized using 16 byte vectors
PULSE.c:134:9: note: Vectorizing SLP tree:
PULSE.c:134:9: note: node 0x44e5cb8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:134:9: note: op template: <retval>.io = 0B;
PULSE.c:134:9: note: 	stmt 0 <retval>.io = 0B;
PULSE.c:134:9: note: 	stmt 1 <retval>.fixes = 0B;
PULSE.c:134:9: note: 	children 0x44e5d38
PULSE.c:134:9: note: node (constant) 0x44e5d38 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:134:9: note: 	{ 0B, 0B }
PULSE.c:134:9: note: ------>vectorizing SLP node starting from: <retval>.io = 0B;
PULSE.c:134:9: note: vect_is_simple_use: operand 0B, type of def: constant
PULSE.c:134:9: note: transform store. ncopies = 1
PULSE.c:134:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.io
PULSE.c:134:9: note: created &<retval>.io
PULSE.c:134:9: note: add new stmt: MEM <vector(2) long unsigned int> [(float * *)&<retval> + 16B] = { 0, 0 };
PULSE.c:134:9: note: vectorizing stmts using SLP.
PULSE.c:134:9: note: ***** The result for vector mode V32QI would be the same
PULSE.c:146:1: note: ***** Analysis failed with vector mode VOID
Layer.c:7:34: missed: statement clobbers memory: _3 = aligned_alloc (64, _2);
Layer.c:8:35: missed: statement clobbers memory: _6 = aligned_alloc (64, _5);
Layer.c:9:34: missed: statement clobbers memory: _7 = aligned_alloc (64, _5);
Layer.c:14:19: missed: statement clobbers memory: _8 = PULSE_GetActivationFunctionPtr (activation_function_18(D));
Layer.c:19:9: note: ***** Analysis succeeded with vector mode V8SI
Layer.c:19:9: note: SLPing BB part
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x44cd3c8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 0 MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 1 MEM <unsigned int> [(struct PULSE_Layer *)&<retval> + 4B] = optimization_type_17(D);
Layer.c:19:9: note: 	children 0x44cd448
Layer.c:19:9: note: node (external) 0x44cd448 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ type_16(D), optimization_type_17(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x44cd4c8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 0 <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 1 <retval>.n_outputs = n_outputs_12(D);
Layer.c:19:9: note: 	children 0x44cd548
Layer.c:19:9: note: node (external) 0x44cd548 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x44cd648 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 0 <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 1 <retval>.outputs = _6;
Layer.c:19:9: note: 	children 0x44cd6c8
Layer.c:19:9: note: node (external) 0x44cd6c8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	stmt 0 _3 = aligned_alloc (64, _2);
Layer.c:19:9: note: 	stmt 1 _6 = aligned_alloc (64, _5);
Layer.c:19:9: note: 	children 0x44cd748 0x44cd7c8
Layer.c:19:9: note: node (constant) 0x44cd748 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 64, 64 }
Layer.c:19:9: note: node 0x44cd7c8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: patt_38 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 0 patt_38 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 1 patt_39 = n_outputs_12(D) w* 4;
Layer.c:19:9: note: 	children 0x44cd848 0x44cd8c8
Layer.c:19:9: note: node (external) 0x44cd848 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: node (constant) 0x44cd8c8 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ 4, 4 }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x44cd9c8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: op template: <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 0 <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 1 <retval>.back = back_21(D);
Layer.c:19:9: note: 	stmt 2 <retval>.fix = fix_22(D);
Layer.c:19:9: note: 	stmt 3 <retval>.destroy = destroy_23(D);
Layer.c:19:9: note: 	children 0x44cda48
Layer.c:19:9: note: node (external) 0x44cda48 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: 	{ feed_20(D), back_21(D), fix_22(D), destroy_23(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 64
  Scalar cost: 64
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x44cdac8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 0 <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 1 <retval>.child = 0B;
Layer.c:19:9: note: 	children 0x44cdb48
Layer.c:19:9: note: node (constant) 0x44cdb48 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ 0B, 0B }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Basic block will be vectorized using SLP
Layer.c:19:9: optimized: basic block part vectorized using 8 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x44cd3c8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 0 MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 1 MEM <unsigned int> [(struct PULSE_Layer *)&<retval> + 4B] = optimization_type_17(D);
Layer.c:19:9: note: 	children 0x44cd448
Layer.c:19:9: note: node (external) 0x44cd448 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ type_16(D), optimization_type_17(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: vect_is_simple_use: operand optimization_type_17(D), type of def: external
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>]
Layer.c:19:9: note: created &MEM <unsigned int> [(struct PULSE_Layer *)&<retval>]
Layer.c:19:9: note: add new stmt: MEM <vector(2) unsigned int> [(struct PULSE_Layer *)&<retval>] = _40;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 8 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x44cd4c8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 0 <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 1 <retval>.n_outputs = n_outputs_12(D);
Layer.c:19:9: note: 	children 0x44cd548
Layer.c:19:9: note: node (external) 0x44cd548 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: vect_is_simple_use: operand n_outputs_12(D), type of def: external
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: <retval>.n_inputs
Layer.c:19:9: note: created &<retval>.n_inputs
Layer.c:19:9: note: add new stmt: MEM <vector(2) unsigned int> [(unsigned int *)&<retval> + 128B] = _42;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 16 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x44cd648 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 0 <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 1 <retval>.outputs = _6;
Layer.c:19:9: note: 	children 0x44cd6c8
Layer.c:19:9: note: node (external) 0x44cd6c8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	stmt 0 _3 = aligned_alloc (64, _2);
Layer.c:19:9: note: 	stmt 1 _6 = aligned_alloc (64, _5);
Layer.c:19:9: note: 	children 0x44cd748 0x44cd7c8
Layer.c:19:9: note: node (constant) 0x44cd748 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 64, 64 }
Layer.c:19:9: note: node 0x44cd7c8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: patt_38 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 0 patt_38 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 1 patt_39 = n_outputs_12(D) w* 4;
Layer.c:19:9: note: 	children 0x44cd848 0x44cd8c8
Layer.c:19:9: note: node (external) 0x44cd848 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: node (constant) 0x44cd8c8 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ 4, 4 }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.inputs = _3;
Layer.c:19:9: note: vect_is_simple_use: operand aligned_alloc (64, _5), type of def: internal
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.inputs
Layer.c:19:9: note: created &<retval>.inputs
Layer.c:19:9: note: add new stmt: MEM <vector(2) long unsigned int> [(float * *)&<retval> + 8B] = _46;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 32 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x44cd9c8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: op template: <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 0 <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 1 <retval>.back = back_21(D);
Layer.c:19:9: note: 	stmt 2 <retval>.fix = fix_22(D);
Layer.c:19:9: note: 	stmt 3 <retval>.destroy = destroy_23(D);
Layer.c:19:9: note: 	children 0x44cda48
Layer.c:19:9: note: node (external) 0x44cda48 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: 	{ feed_20(D), back_21(D), fix_22(D), destroy_23(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.feed = feed_20(D);
Layer.c:19:9: note: vect_is_simple_use: operand back_21(D), type of def: external
Layer.c:19:9: note: vect_is_simple_use: operand fix_22(D), type of def: external
Layer.c:19:9: note: vect_is_simple_use: operand destroy_23(D), type of def: external
Layer.c:19:9: note: conflicting alias set types.
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(4) long unsigned int  vectorizing a pointer ref: <retval>.feed
Layer.c:19:9: note: created &<retval>.feed
Layer.c:19:9: note: add new stmt: MEM <vector(4) long unsigned int> [(void *)&<retval> + 32B] = _52;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 16 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x44cdac8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 0 <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 1 <retval>.child = 0B;
Layer.c:19:9: note: 	children 0x44cdb48
Layer.c:19:9: note: node (constant) 0x44cdb48 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ 0B, 0B }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.parent = 0B;
Layer.c:19:9: note: vect_is_simple_use: operand 0B, type of def: constant
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.parent
Layer.c:19:9: note: created &<retval>.parent
Layer.c:19:9: note: add new stmt: MEM <vector(2) long unsigned int> [(struct PULSE_Layer * *)&<retval> + 72B] = { 0, 0 };
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: note: ***** The result for vector mode V32QI would be the same
Layer.c:24:2: missed: statement clobbers memory: free (_1);
Layer.c:25:2: missed: statement clobbers memory: free (_2);
Layer.c:26:2: missed: statement clobbers memory: free (_3);
Layer.c:27:1: note: ***** Analysis failed with vector mode V4DI
Layer.c:27:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:9:27: missed: couldn't vectorize loop
Dense.c:9:27: missed: not vectorized: unsupported outerloop form.
Dense.c:12:20: missed: couldn't vectorize loop
Dense.c:13:21: missed: not vectorized: complicated access pattern.
Dense.c:6:13: note: vectorized 0 loops in function.
Dense.c:16:2: missed: statement clobbers memory: _28 (pretmp_91, _51, 0);
Dense.c:9:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:9:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:24:27: missed: couldn't vectorize loop
Dense.c:24:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:28:20: optimized: loop vectorized using 32 byte vectors
Dense.c:28:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:28:20: optimized: loop vectorized using 16 byte vectors
Dense.c:28:20: missed: couldn't vectorize loop
Dense.c:30:19: missed: not vectorized: no vectype for stmt: _22 = *_21;
 scalar_type: float
Dense.c:20:13: note: vectorized 1 loops in function.
Dense.c:23:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:24:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:24:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:41:28: missed: couldn't vectorize loop
Dense.c:41:28: missed: not vectorized: unsupported outerloop form.
Dense.c:45:21: optimized: loop vectorized using 32 byte vectors
Dense.c:45:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:45:21: optimized: loop vectorized using 16 byte vectors
Dense.c:37:13: note: vectorized 1 loops in function.
Dense.c:37:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:37:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:41:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:170:10: optimized: loop vectorized using 32 byte vectors
Dense.c:170:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:170:10: optimized: loop vectorized using 16 byte vectors
Dense.c:161:10: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_27, _64);
Dense.c:154:10: optimized: loop vectorized using 32 byte vectors
Dense.c:154:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:154:10: optimized: loop vectorized using 16 byte vectors
Dense.c:145:10: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_14, _56);
Dense.c:136:13: note: vectorized 2 loops in function.
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_14, _56);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_15, { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 });
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_27, _64);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_28, { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 });
Dense.c:136:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:136:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:105:24: missed: couldn't vectorize loop
Dense.c:105:24: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:108:17: missed: couldn't vectorize loop
Dense.c:108:17: missed: not vectorized: number of iterations cannot be computed.
Dense.c:122:24: missed: couldn't vectorize loop
Dense.c:122:24: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:125:17: missed: couldn't vectorize loop
Dense.c:125:17: missed: not vectorized: number of iterations cannot be computed.
Dense.c:90:15: missed: couldn't vectorize loop
Dense.c:90:15: missed: not vectorized: number of iterations cannot be computed.
Dense.c:83:13: note: vectorized 0 loops in function.
Dense.c:86:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:110:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:110:17: note: SLPing BB part
Dense.c:127:17: note: Costing subgraph: 
Dense.c:127:17: note: node 0x7a082b8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:127:17: note: op template: _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 0 _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 1 _198 = (sizetype) wi_137;
Dense.c:127:17: note: 	children 0x7a083b8
Dense.c:127:17: note: node (external) 0x7a083b8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:127:17: note: 	{ j_135, wi_137 }
Dense.c:127:17: note: Cost model analysis: 
Dense.c:127:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:127:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:127:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: Costing subgraph: 
Dense.c:110:17: note: node 0x7a084b8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:110:17: note: op template: _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 0 _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 1 _217 = (sizetype) wi_136;
Dense.c:110:17: note: 	children 0x7a085b8
Dense.c:110:17: note: node (external) 0x7a085b8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:110:17: note: 	{ j_134, wi_136 }
Dense.c:110:17: note: Cost model analysis: 
Dense.c:110:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:110:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:110:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:110:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:110:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:110:17: note: SLPing BB part
Dense.c:127:17: note: Costing subgraph: 
Dense.c:127:17: note: node 0x7a084b8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:127:17: note: op template: _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 0 _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 1 _198 = (sizetype) wi_137;
Dense.c:127:17: note: 	children 0x7a082b8
Dense.c:127:17: note: node (external) 0x7a082b8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:127:17: note: 	{ j_135, wi_137 }
Dense.c:127:17: note: Cost model analysis: 
Dense.c:127:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:127:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:127:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: Costing subgraph: 
Dense.c:110:17: note: node 0x7a08438 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:110:17: note: op template: _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 0 _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 1 _217 = (sizetype) wi_136;
Dense.c:110:17: note: 	children 0x7a08538
Dense.c:110:17: note: node (external) 0x7a08538 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:110:17: note: 	{ j_134, wi_136 }
Dense.c:110:17: note: Cost model analysis: 
Dense.c:110:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:110:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:110:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:105:51: note: ***** Analysis failed with vector mode V8QI
Dense.c:105:51: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:105:51: note: ***** Analysis failed with vector mode V4QI
Dense.c:62:15: missed: couldn't vectorize loop
Dense.c:62:15: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:75:11: optimized: loop vectorized using 32 byte vectors
Dense.c:75:11: optimized: loop vectorized using 16 byte vectors
Dense.c:66:11: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:881:10: missed: not vectorized: no vectype for stmt: _53 = MEM[(__m256 * {ref-all})w_ptr_82];
 scalar_type: __m256
Dense.c:54:13: note: vectorized 1 loops in function.
Dense.c:57:2: missed: statement clobbers memory: memcpy (_4, dense$baiases_63, _3);
Dense.c:79:2: missed: statement clobbers memory: _27 (pretmp_163, _68, 0);
Dense.c:54:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:54:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:181:2: missed: statement clobbers memory: free (dense$weights_7);
Dense.c:182:2: missed: statement clobbers memory: free (dense$baiases_8);
Dense.c:183:2: missed: statement clobbers memory: free (dense$gradients_10);
Dense.c:184:2: missed: statement clobbers memory: free (dense$deltas_9);
Dense.c:185:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:185:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:200:19: missed: couldn't vectorize loop
Dense.c:200:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:190:13: note: vectorized 0 loops in function.
Dense.c:196:37: missed: statement clobbers memory: _9 = aligned_alloc (64, _8);
Dense.c:197:34: missed: statement clobbers memory: _11 = aligned_alloc (64, _10);
Dense.c:198:35: missed: statement clobbers memory: _12 = aligned_alloc (64, _10);
Dense.c:201:38: missed: statement clobbers memory: _13 = rand ();
Dense.c:201:72: missed: statement clobbers memory: _57 = sqrt (_20);
Dense.c:213:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:214:4: missed: statement clobbers memory: exit (1);
Dense.c:210:4: missed: statement clobbers memory: layer = PULSE_CreateLayer (args$n_inputs_36, args$n_outputs_47, 0, args$8_48, _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:207:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (args$n_inputs_36, args$n_outputs_47, 0, args$8_48, _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:219:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Dense.c:219:9: note: ***** Analysis succeeded with vector mode V8SI
Dense.c:219:9: note: SLPing BB part
Dense.c:219:9: note: Costing subgraph: 
Dense.c:219:9: note: node 0x7846868 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Dense.c:219:9: note: op template: MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = MODEL_32(D);
Dense.c:219:9: note: 	stmt 0 MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = MODEL_32(D);
Dense.c:219:9: note: 	stmt 1 MEM <float *> [(struct PULSE_Layer *)&layer + 96B] = _4;
Dense.c:219:9: note: 	stmt 2 MEM <float *> [(struct PULSE_Layer *)&layer + 104B] = _11;
Dense.c:219:9: note: 	stmt 3 MEM <float *> [(struct PULSE_Layer *)&layer + 112B] = _12;
Dense.c:219:9: note: 	children 0x78468e8
Dense.c:219:9: note: node (external) 0x78468e8 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Dense.c:219:9: note: 	{ MODEL_32(D), _4, _11, _12 }
Dense.c:219:9: note: Cost model analysis: 
Dense.c:219:9: note: Cost model analysis for part in loop 0:
  Vector cost: 64
  Scalar cost: 64
Dense.c:219:9: note: Basic block will be vectorized using SLP
Dense.c:219:9: optimized: basic block part vectorized using 32 byte vectors
Dense.c:219:9: note: Vectorizing SLP tree:
Dense.c:219:9: note: node 0x7846868 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Dense.c:219:9: note: op template: MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = MODEL_32(D);
Dense.c:219:9: note: 	stmt 0 MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = MODEL_32(D);
Dense.c:219:9: note: 	stmt 1 MEM <float *> [(struct PULSE_Layer *)&layer + 96B] = _4;
Dense.c:219:9: note: 	stmt 2 MEM <float *> [(struct PULSE_Layer *)&layer + 104B] = _11;
Dense.c:219:9: note: 	stmt 3 MEM <float *> [(struct PULSE_Layer *)&layer + 112B] = _12;
Dense.c:219:9: note: 	children 0x78468e8
Dense.c:219:9: note: node (external) 0x78468e8 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Dense.c:219:9: note: 	{ MODEL_32(D), _4, _11, _12 }
Dense.c:219:9: note: ------>vectorizing SLP node starting from: MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = MODEL_32(D);
Dense.c:219:9: note: vect_is_simple_use: operand MODEL_32(D) + _3, type of def: internal
Dense.c:219:9: note: vect_is_simple_use: operand aligned_alloc (64, _10), type of def: internal
Dense.c:219:9: note: vect_is_simple_use: operand aligned_alloc (64, _10), type of def: internal
Dense.c:219:9: note: transform store. ncopies = 1
Dense.c:219:9: note: create vector_type-pointer variable to type: vector(4) long unsigned int  vectorizing a pointer ref: MEM <float *> [(struct PULSE_Layer *)&layer + 88B]
Dense.c:219:9: note: created &MEM <float *> [(struct PULSE_Layer *)&layer + 88B]
Dense.c:219:9: note: add new stmt: MEM <vector(4) long unsigned int> [(struct PULSE_Layer *)&layer + 88B] = _61;
Dense.c:219:9: note: vectorizing stmts using SLP.
Dense.c:219:9: note: ***** The result for vector mode V32QI would be the same
Activations.c:17:19: optimized: loop vectorized using 32 byte vectors
Activations.c:17:19: optimized: loop vectorized using 16 byte vectors
Activations.c:17:19: optimized: loop vectorized using 32 byte vectors
Activations.c:17:19: optimized: loop vectorized using 16 byte vectors
Activations.c:14:13: note: vectorized 2 loops in function.
Activations.c:14:13: note: ***** Analysis failed with vector mode V8SF
Activations.c:14:13: note: ***** The result for vector mode V32QI would be the same
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V16QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V16QI
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V8QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V8QI
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V4QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V4QI
Activations.c:28:19: missed: couldn't vectorize loop
Activations.c:28:19: missed: not vectorized: unsupported control flow in loop.
Activations.c:28:19: optimized: loop vectorized using 32 byte vectors
Activations.c:28:19: optimized: loop vectorized using 16 byte vectors
Activations.c:25:13: note: vectorized 1 loops in function.
Activations.c:25:13: note: ***** Analysis failed with vector mode V8SF
Activations.c:25:13: note: ***** The result for vector mode V32QI would be the same
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V16QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V16QI
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V8QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V8QI
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V4QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V4QI
Activations.c:38:1: note: ***** Analysis failed with vector mode VOID
Activations.c:5:19: missed: couldn't vectorize loop
Activations.c:9:21: missed: statement clobbers memory: _36 = expf (_18);
Activations.c:5:19: missed: couldn't vectorize loop
Activations.c:9:21: missed: statement clobbers memory: _12 = expf (_11);
Activations.c:3:13: note: vectorized 0 loops in function.
Activations.c:9:21: missed: statement clobbers memory: _12 = expf (_11);
Activations.c:9:21: missed: statement clobbers memory: _36 = expf (_18);
Activations.c:11:1: note: ***** Analysis failed with vector mode V8SF
Activations.c:11:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Activations.c:44:2: note: ***** Analysis failed with vector mode VOID
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:4:18: note: vectorized 0 loops in function.
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_4, inputs_15, _3);
PULSE.c:8:2: missed: statement clobbers memory: _5 (layer_17);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_12, pretmp_26, _9);
PULSE.c:13:28: note: ***** Analysis failed with vector mode V8SI
PULSE.c:13:28: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:22:2: missed: statement clobbers memory: _1 (layer_10(D));
PULSE.c:22:2: missed: statement clobbers memory: _14 (_2);
PULSE.c:22:2: missed: statement clobbers memory: _21 (_15);
PULSE.c:22:2: missed: statement clobbers memory: _28 (_22);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_29);
PULSE.c:26:3: missed: statement clobbers memory: memset (_34, 0, _32);
PULSE.c:26:3: missed: statement clobbers memory: memset (_27, 0, _25);
PULSE.c:26:3: missed: statement clobbers memory: memset (_20, 0, _18);
PULSE.c:26:3: missed: statement clobbers memory: memset (_7, 0, _5);
PULSE.c:28:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:28:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:32:6: note: vectorized 1 loops in function.
PULSE.c:34:8: missed: statement clobbers memory: _1 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_2);
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _9 = rand ();
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8SI
PULSE.c:32:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:61:16: missed: couldn't vectorize loop
PULSE.c:61:16: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:64:17: missed: couldn't vectorize loop
PULSE.c:64:17: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:73:19: missed: couldn't vectorize loop
PULSE.c:73:19: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:53:22: missed: couldn't vectorize loop
PULSE.c:53:22: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:47:6: note: vectorized 1 loops in function.
PULSE.c:48:1: missed: statement clobbers memory: saved_stack.7_39 = __builtin_stack_save ();
PULSE.c:49:46: missed: statement clobbers memory: _1 = PULSE_GetLossFunctionPtr (loss_function_40(D));
PULSE.c:60:10: missed: statement clobbers memory: random.4_46 = __builtin_alloca_with_align (_4, 32);
PULSE.c:34:8: missed: statement clobbers memory: _61 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_62);
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _72 = rand ();
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_98, inputs_93, _97);
PULSE.c:8:2: missed: statement clobbers memory: _99 (layer_94);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_105, _104, _103);
PULSE.c:67:11: missed: statement clobbers memory: loss_55 = PULSE_GetLoss_42 (_17, _16, _12, _11);
PULSE.c:22:2: missed: statement clobbers memory: _86 (output_34);
PULSE.c:22:2: missed: statement clobbers memory: _108 (_87);
PULSE.c:22:2: missed: statement clobbers memory: _115 (_109);
PULSE.c:22:2: missed: statement clobbers memory: _122 (_116);
PULSE.c:22:2: missed: statement clobbers memory: _129 (_123);
PULSE.c:22:2: missed: statement clobbers memory: _136 (_130);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_137);
PULSE.c:26:3: missed: statement clobbers memory: memset (_142, 0, _140);
PULSE.c:26:3: missed: statement clobbers memory: memset (_135, 0, _133);
PULSE.c:26:3: missed: statement clobbers memory: memset (_128, 0, _126);
PULSE.c:26:3: missed: statement clobbers memory: memset (_121, 0, _119);
PULSE.c:26:3: missed: statement clobbers memory: memset (_114, 0, _112);
PULSE.c:26:3: missed: statement clobbers memory: memset (_92, 0, _90);
PULSE.c:75:6: missed: statement clobbers memory: _21 (current_191, args);
PULSE.c:81:4: missed: statement clobbers memory: printf ("Epoch: %d | Item: %d | Loss: %.10f | Batch Loss: %.10f\r", i_188, j_189, _25, _24);
PULSE.c:47:6: missed: statement clobbers memory: __builtin_stack_restore (saved_stack.7_39);
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4DI
PULSE.c:47:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:91:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:91:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:119:20: missed: couldn't vectorize loop
PULSE.c:119:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:119:20: missed: couldn't vectorize loop
PULSE.c:119:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:102:20: missed: couldn't vectorize loop
PULSE.c:102:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:102:20: missed: couldn't vectorize loop
PULSE.c:102:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:93:13: note: vectorized 0 loops in function.
PULSE.c:96:39: missed: statement clobbers memory: layers_31 = malloc (_3);
PULSE.c:99:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:114:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:115:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:116:46: missed: statement clobbers memory: WEIGHTS_46 = malloc (0);
PULSE.c:108:26: missed: not vectorized: more than one data ref in stmt: args = MEM[(struct PULSE_DenseLayerArgs * {ref-all})addr.104_68];
PULSE.c:109:21: missed: statement clobbers memory: _57 = PULSE_GetDenseWeightsSize (args);
PULSE.c:108:26: missed: not vectorized: more than one data ref in stmt: args = MEM[(struct PULSE_DenseLayerArgs * {ref-all})_179];
PULSE.c:109:21: missed: statement clobbers memory: _171 = PULSE_GetDenseWeightsSize (args);
PULSE.c:114:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:115:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:116:46: missed: statement clobbers memory: WEIGHTS_36 = malloc (_5);
PULSE.c:125:26: missed: not vectorized: more than one data ref in stmt: args = MEM[(struct PULSE_DenseLayerArgs * {ref-all})addr.106_70];
PULSE.c:126:17: missed: statement clobbers memory: *_8 = PULSE_CreateDenseLayer (args, WEIGHTS_PTR_121); [return slot optimization]
PULSE.c:127:20: missed: statement clobbers memory: _49 = PULSE_GetDenseWeightsSize (args);
PULSE.c:125:26: missed: not vectorized: more than one data ref in stmt: args = MEM[(struct PULSE_DenseLayerArgs * {ref-all})addr.106_113];
PULSE.c:126:17: missed: statement clobbers memory: *_98 = PULSE_CreateDenseLayer (args, WEIGHTS_PTR_135); [return slot optimization]
PULSE.c:127:20: missed: statement clobbers memory: _76 = PULSE_GetDenseWeightsSize (args);
PULSE.c:133:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:134:9: note: ***** Analysis succeeded with vector mode V8SI
PULSE.c:134:9: note: SLPing BB part
PULSE.c:134:9: note: Costing subgraph: 
PULSE.c:134:9: note: node 0x4978808 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:134:9: note: op template: <retval>.layers = layers_31;
PULSE.c:134:9: note: 	stmt 0 <retval>.layers = layers_31;
PULSE.c:134:9: note: 	stmt 1 <retval>.paramethers = WEIGHTS_80;
PULSE.c:134:9: note: 	children 0x4978908
PULSE.c:134:9: note: node (external) 0x4978908 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:134:9: note: 	{ layers_31, WEIGHTS_80 }
PULSE.c:134:9: note: Cost model analysis: 
PULSE.c:134:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
PULSE.c:134:9: note: Costing subgraph: 
PULSE.c:134:9: note: node 0x4978988 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:134:9: note: op template: <retval>.io = 0B;
PULSE.c:134:9: note: 	stmt 0 <retval>.io = 0B;
PULSE.c:134:9: note: 	stmt 1 <retval>.fixes = 0B;
PULSE.c:134:9: note: 	children 0x4978a08
PULSE.c:134:9: note: node (constant) 0x4978a08 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:134:9: note: 	{ 0B, 0B }
PULSE.c:134:9: note: Cost model analysis: 
PULSE.c:134:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
PULSE.c:134:9: note: Basic block will be vectorized using SLP
PULSE.c:134:9: optimized: basic block part vectorized using 16 byte vectors
PULSE.c:134:9: note: Vectorizing SLP tree:
PULSE.c:134:9: note: node 0x4978808 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:134:9: note: op template: <retval>.layers = layers_31;
PULSE.c:134:9: note: 	stmt 0 <retval>.layers = layers_31;
PULSE.c:134:9: note: 	stmt 1 <retval>.paramethers = WEIGHTS_80;
PULSE.c:134:9: note: 	children 0x4978908
PULSE.c:134:9: note: node (external) 0x4978908 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:134:9: note: 	{ layers_31, WEIGHTS_80 }
PULSE.c:134:9: note: ------>vectorizing SLP node starting from: <retval>.layers = layers_31;
PULSE.c:134:9: note: vect_is_simple_use: operand WEIGHTS_80 = PHI <WEIGHTS_36(36), WEIGHTS_46(12)>, type of def: internal
PULSE.c:134:9: note: conflicting alias set types.
PULSE.c:134:9: note: transform store. ncopies = 1
PULSE.c:134:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.layers
PULSE.c:134:9: note: created &<retval>
PULSE.c:134:9: note: add new stmt: MEM <vector(2) long unsigned int> [(void *)&<retval>] = _11;
PULSE.c:134:9: note: vectorizing stmts using SLP.
PULSE.c:134:9: optimized: basic block part vectorized using 16 byte vectors
PULSE.c:134:9: note: Vectorizing SLP tree:
PULSE.c:134:9: note: node 0x4978988 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:134:9: note: op template: <retval>.io = 0B;
PULSE.c:134:9: note: 	stmt 0 <retval>.io = 0B;
PULSE.c:134:9: note: 	stmt 1 <retval>.fixes = 0B;
PULSE.c:134:9: note: 	children 0x4978a08
PULSE.c:134:9: note: node (constant) 0x4978a08 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:134:9: note: 	{ 0B, 0B }
PULSE.c:134:9: note: ------>vectorizing SLP node starting from: <retval>.io = 0B;
PULSE.c:134:9: note: vect_is_simple_use: operand 0B, type of def: constant
PULSE.c:134:9: note: transform store. ncopies = 1
PULSE.c:134:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.io
PULSE.c:134:9: note: created &<retval>.io
PULSE.c:134:9: note: add new stmt: MEM <vector(2) long unsigned int> [(float * *)&<retval> + 16B] = { 0, 0 };
PULSE.c:134:9: note: vectorizing stmts using SLP.
PULSE.c:134:9: note: ***** The result for vector mode V32QI would be the same
PULSE.c:146:1: note: ***** Analysis failed with vector mode VOID
Loss.c:15:19: optimized: loop vectorized using 32 byte vectors
Loss.c:15:19: optimized:  loop versioned for vectorization because of possible aliasing
Loss.c:15:19: optimized: loop vectorized using 16 byte vectors
Loss.c:12:23: note: vectorized 1 loops in function.
Loss.c:12:23: note: ***** Analysis failed with vector mode V8SF
Loss.c:12:23: note: ***** The result for vector mode V32QI would be the same
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V16QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V16QI
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V8QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V8QI
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V4QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V4QI
Loss.c:7:19: missed: couldn't vectorize loop
Loss.c:8:38: missed: not vectorized: unsupported use in stmt.
Loss.c:4:23: note: vectorized 0 loops in function.
Loss.c:9:13: note: ***** Analysis failed with vector mode V8SF
Loss.c:9:13: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Loss.c:23:2: note: ***** Analysis failed with vector mode VOID
Dense.c:9:27: missed: couldn't vectorize loop
Dense.c:9:27: missed: not vectorized: unsupported outerloop form.
Dense.c:12:20: missed: couldn't vectorize loop
Dense.c:13:21: missed: not vectorized: complicated access pattern.
Dense.c:6:13: note: vectorized 0 loops in function.
Dense.c:16:2: missed: statement clobbers memory: _28 (pretmp_91, _51, 0);
Dense.c:9:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:9:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:24:27: missed: couldn't vectorize loop
Dense.c:24:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:28:20: optimized: loop vectorized using 32 byte vectors
Dense.c:28:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:28:20: optimized: loop vectorized using 16 byte vectors
Dense.c:28:20: missed: couldn't vectorize loop
Dense.c:30:19: missed: not vectorized: no vectype for stmt: _22 = *_21;
 scalar_type: float
Dense.c:20:13: note: vectorized 1 loops in function.
Dense.c:23:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:24:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:24:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:41:28: missed: couldn't vectorize loop
Dense.c:41:28: missed: not vectorized: unsupported outerloop form.
Dense.c:45:21: optimized: loop vectorized using 32 byte vectors
Dense.c:45:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:45:21: optimized: loop vectorized using 16 byte vectors
Dense.c:37:13: note: vectorized 1 loops in function.
Dense.c:37:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:37:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:41:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:170:10: optimized: loop vectorized using 32 byte vectors
Dense.c:170:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:170:10: optimized: loop vectorized using 16 byte vectors
Dense.c:161:10: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_27, _64);
Dense.c:154:10: optimized: loop vectorized using 32 byte vectors
Dense.c:154:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:154:10: optimized: loop vectorized using 16 byte vectors
Dense.c:145:10: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_14, _56);
Dense.c:136:13: note: vectorized 2 loops in function.
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_14, _56);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_15, { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 });
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_27, _64);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_28, { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 });
Dense.c:136:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:136:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:105:24: missed: couldn't vectorize loop
Dense.c:105:24: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:108:17: missed: couldn't vectorize loop
Dense.c:108:17: missed: not vectorized: number of iterations cannot be computed.
Dense.c:122:24: missed: couldn't vectorize loop
Dense.c:122:24: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:125:17: missed: couldn't vectorize loop
Dense.c:125:17: missed: not vectorized: number of iterations cannot be computed.
Dense.c:90:15: missed: couldn't vectorize loop
Dense.c:90:15: missed: not vectorized: number of iterations cannot be computed.
Dense.c:83:13: note: vectorized 0 loops in function.
Dense.c:86:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:110:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:110:17: note: SLPing BB part
Dense.c:127:17: note: Costing subgraph: 
Dense.c:127:17: note: node 0x83f4518 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:127:17: note: op template: _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 0 _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 1 _198 = (sizetype) wi_137;
Dense.c:127:17: note: 	children 0x83f4618
Dense.c:127:17: note: node (external) 0x83f4618 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:127:17: note: 	{ j_135, wi_137 }
Dense.c:127:17: note: Cost model analysis: 
Dense.c:127:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:127:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:127:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: Costing subgraph: 
Dense.c:110:17: note: node 0x83f4718 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:110:17: note: op template: _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 0 _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 1 _217 = (sizetype) wi_136;
Dense.c:110:17: note: 	children 0x83f4818
Dense.c:110:17: note: node (external) 0x83f4818 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:110:17: note: 	{ j_134, wi_136 }
Dense.c:110:17: note: Cost model analysis: 
Dense.c:110:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:110:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:110:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:110:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:110:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:110:17: note: SLPing BB part
Dense.c:127:17: note: Costing subgraph: 
Dense.c:127:17: note: node 0x83f4718 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:127:17: note: op template: _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 0 _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 1 _198 = (sizetype) wi_137;
Dense.c:127:17: note: 	children 0x83f4518
Dense.c:127:17: note: node (external) 0x83f4518 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:127:17: note: 	{ j_135, wi_137 }
Dense.c:127:17: note: Cost model analysis: 
Dense.c:127:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:127:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:127:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: Costing subgraph: 
Dense.c:110:17: note: node 0x83f4698 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:110:17: note: op template: _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 0 _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 1 _217 = (sizetype) wi_136;
Dense.c:110:17: note: 	children 0x83f4798
Dense.c:110:17: note: node (external) 0x83f4798 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:110:17: note: 	{ j_134, wi_136 }
Dense.c:110:17: note: Cost model analysis: 
Dense.c:110:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:110:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:110:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:105:51: note: ***** Analysis failed with vector mode V8QI
Dense.c:105:51: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:105:51: note: ***** Analysis failed with vector mode V4QI
Dense.c:62:15: missed: couldn't vectorize loop
Dense.c:62:15: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:75:11: optimized: loop vectorized using 32 byte vectors
Dense.c:75:11: optimized: loop vectorized using 16 byte vectors
Dense.c:66:11: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:881:10: missed: not vectorized: no vectype for stmt: _53 = MEM[(__m256 * {ref-all})w_ptr_82];
 scalar_type: __m256
Dense.c:54:13: note: vectorized 1 loops in function.
Dense.c:57:2: missed: statement clobbers memory: memcpy (_4, dense$baiases_63, _3);
Dense.c:79:2: missed: statement clobbers memory: _27 (pretmp_163, _68, 0);
Dense.c:54:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:54:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:181:2: missed: statement clobbers memory: free (dense$weights_7);
Dense.c:182:2: missed: statement clobbers memory: free (dense$baiases_8);
Dense.c:183:2: missed: statement clobbers memory: free (dense$gradients_10);
Dense.c:184:2: missed: statement clobbers memory: free (dense$deltas_9);
Dense.c:185:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:185:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:188:107: note: ***** Analysis failed with vector mode V8SI
Dense.c:188:107: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
Dense.c:200:19: missed: couldn't vectorize loop
Dense.c:200:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:190:13: note: vectorized 0 loops in function.
Dense.c:196:37: missed: statement clobbers memory: _9 = aligned_alloc (64, _8);
Dense.c:197:34: missed: statement clobbers memory: _11 = aligned_alloc (64, _10);
Dense.c:198:35: missed: statement clobbers memory: _12 = aligned_alloc (64, _10);
Dense.c:201:38: missed: statement clobbers memory: _13 = rand ();
Dense.c:201:72: missed: statement clobbers memory: _57 = sqrt (_20);
Dense.c:213:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:214:4: missed: statement clobbers memory: exit (1);
Dense.c:210:4: missed: statement clobbers memory: layer = PULSE_CreateLayer (args$n_inputs_36, args$n_outputs_47, 0, args$8_48, _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:207:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (args$n_inputs_36, args$n_outputs_47, 0, args$8_48, _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:219:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Dense.c:219:9: note: ***** Analysis succeeded with vector mode V8SI
Dense.c:219:9: note: SLPing BB part
Dense.c:219:9: note: Costing subgraph: 
Dense.c:219:9: note: node 0x822abe8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Dense.c:219:9: note: op template: MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = MODEL_32(D);
Dense.c:219:9: note: 	stmt 0 MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = MODEL_32(D);
Dense.c:219:9: note: 	stmt 1 MEM <float *> [(struct PULSE_Layer *)&layer + 96B] = _4;
Dense.c:219:9: note: 	stmt 2 MEM <float *> [(struct PULSE_Layer *)&layer + 104B] = _11;
Dense.c:219:9: note: 	stmt 3 MEM <float *> [(struct PULSE_Layer *)&layer + 112B] = _12;
Dense.c:219:9: note: 	children 0x822ac68
Dense.c:219:9: note: node (external) 0x822ac68 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Dense.c:219:9: note: 	{ MODEL_32(D), _4, _11, _12 }
Dense.c:219:9: note: Cost model analysis: 
Dense.c:219:9: note: Cost model analysis for part in loop 0:
  Vector cost: 64
  Scalar cost: 64
Dense.c:219:9: note: Basic block will be vectorized using SLP
Dense.c:219:9: optimized: basic block part vectorized using 32 byte vectors
Dense.c:219:9: note: Vectorizing SLP tree:
Dense.c:219:9: note: node 0x822abe8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Dense.c:219:9: note: op template: MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = MODEL_32(D);
Dense.c:219:9: note: 	stmt 0 MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = MODEL_32(D);
Dense.c:219:9: note: 	stmt 1 MEM <float *> [(struct PULSE_Layer *)&layer + 96B] = _4;
Dense.c:219:9: note: 	stmt 2 MEM <float *> [(struct PULSE_Layer *)&layer + 104B] = _11;
Dense.c:219:9: note: 	stmt 3 MEM <float *> [(struct PULSE_Layer *)&layer + 112B] = _12;
Dense.c:219:9: note: 	children 0x822ac68
Dense.c:219:9: note: node (external) 0x822ac68 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Dense.c:219:9: note: 	{ MODEL_32(D), _4, _11, _12 }
Dense.c:219:9: note: ------>vectorizing SLP node starting from: MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = MODEL_32(D);
Dense.c:219:9: note: vect_is_simple_use: operand MODEL_32(D) + _3, type of def: internal
Dense.c:219:9: note: vect_is_simple_use: operand aligned_alloc (64, _10), type of def: internal
Dense.c:219:9: note: vect_is_simple_use: operand aligned_alloc (64, _10), type of def: internal
Dense.c:219:9: note: transform store. ncopies = 1
Dense.c:219:9: note: create vector_type-pointer variable to type: vector(4) long unsigned int  vectorizing a pointer ref: MEM <float *> [(struct PULSE_Layer *)&layer + 88B]
Dense.c:219:9: note: created &MEM <float *> [(struct PULSE_Layer *)&layer + 88B]
Dense.c:219:9: note: add new stmt: MEM <vector(4) long unsigned int> [(struct PULSE_Layer *)&layer + 88B] = _61;
Dense.c:219:9: note: vectorizing stmts using SLP.
Dense.c:219:9: note: ***** The result for vector mode V32QI would be the same
Layer.c:7:34: missed: statement clobbers memory: _3 = aligned_alloc (64, _2);
Layer.c:8:35: missed: statement clobbers memory: _6 = aligned_alloc (64, _5);
Layer.c:9:34: missed: statement clobbers memory: _7 = aligned_alloc (64, _5);
Layer.c:14:19: missed: statement clobbers memory: _8 = PULSE_GetActivationFunctionPtr (activation_function_18(D));
Layer.c:19:9: note: ***** Analysis succeeded with vector mode V8SI
Layer.c:19:9: note: SLPing BB part
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x4ee73c8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 0 MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 1 MEM <unsigned int> [(struct PULSE_Layer *)&<retval> + 4B] = optimization_type_17(D);
Layer.c:19:9: note: 	children 0x4ee7448
Layer.c:19:9: note: node (external) 0x4ee7448 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ type_16(D), optimization_type_17(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x4ee74c8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 0 <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 1 <retval>.n_outputs = n_outputs_12(D);
Layer.c:19:9: note: 	children 0x4ee7548
Layer.c:19:9: note: node (external) 0x4ee7548 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x4ee7648 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 0 <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 1 <retval>.outputs = _6;
Layer.c:19:9: note: 	children 0x4ee76c8
Layer.c:19:9: note: node (external) 0x4ee76c8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	stmt 0 _3 = aligned_alloc (64, _2);
Layer.c:19:9: note: 	stmt 1 _6 = aligned_alloc (64, _5);
Layer.c:19:9: note: 	children 0x4ee7748 0x4ee77c8
Layer.c:19:9: note: node (constant) 0x4ee7748 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 64, 64 }
Layer.c:19:9: note: node 0x4ee77c8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: patt_38 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 0 patt_38 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 1 patt_39 = n_outputs_12(D) w* 4;
Layer.c:19:9: note: 	children 0x4ee7848 0x4ee78c8
Layer.c:19:9: note: node (external) 0x4ee7848 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: node (constant) 0x4ee78c8 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ 4, 4 }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x4ee79c8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: op template: <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 0 <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 1 <retval>.back = back_21(D);
Layer.c:19:9: note: 	stmt 2 <retval>.fix = fix_22(D);
Layer.c:19:9: note: 	stmt 3 <retval>.destroy = destroy_23(D);
Layer.c:19:9: note: 	children 0x4ee7a48
Layer.c:19:9: note: node (external) 0x4ee7a48 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: 	{ feed_20(D), back_21(D), fix_22(D), destroy_23(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 64
  Scalar cost: 64
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x4ee7ac8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 0 <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 1 <retval>.child = 0B;
Layer.c:19:9: note: 	children 0x4ee7b48
Layer.c:19:9: note: node (constant) 0x4ee7b48 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ 0B, 0B }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Basic block will be vectorized using SLP
Layer.c:19:9: optimized: basic block part vectorized using 8 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x4ee73c8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 0 MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 1 MEM <unsigned int> [(struct PULSE_Layer *)&<retval> + 4B] = optimization_type_17(D);
Layer.c:19:9: note: 	children 0x4ee7448
Layer.c:19:9: note: node (external) 0x4ee7448 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ type_16(D), optimization_type_17(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: vect_is_simple_use: operand optimization_type_17(D), type of def: external
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>]
Layer.c:19:9: note: created &MEM <unsigned int> [(struct PULSE_Layer *)&<retval>]
Layer.c:19:9: note: add new stmt: MEM <vector(2) unsigned int> [(struct PULSE_Layer *)&<retval>] = _40;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 8 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x4ee74c8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 0 <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 1 <retval>.n_outputs = n_outputs_12(D);
Layer.c:19:9: note: 	children 0x4ee7548
Layer.c:19:9: note: node (external) 0x4ee7548 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: vect_is_simple_use: operand n_outputs_12(D), type of def: external
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: <retval>.n_inputs
Layer.c:19:9: note: created &<retval>.n_inputs
Layer.c:19:9: note: add new stmt: MEM <vector(2) unsigned int> [(unsigned int *)&<retval> + 128B] = _42;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 16 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x4ee7648 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 0 <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 1 <retval>.outputs = _6;
Layer.c:19:9: note: 	children 0x4ee76c8
Layer.c:19:9: note: node (external) 0x4ee76c8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	stmt 0 _3 = aligned_alloc (64, _2);
Layer.c:19:9: note: 	stmt 1 _6 = aligned_alloc (64, _5);
Layer.c:19:9: note: 	children 0x4ee7748 0x4ee77c8
Layer.c:19:9: note: node (constant) 0x4ee7748 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 64, 64 }
Layer.c:19:9: note: node 0x4ee77c8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: patt_38 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 0 patt_38 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 1 patt_39 = n_outputs_12(D) w* 4;
Layer.c:19:9: note: 	children 0x4ee7848 0x4ee78c8
Layer.c:19:9: note: node (external) 0x4ee7848 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: node (constant) 0x4ee78c8 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ 4, 4 }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.inputs = _3;
Layer.c:19:9: note: vect_is_simple_use: operand aligned_alloc (64, _5), type of def: internal
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.inputs
Layer.c:19:9: note: created &<retval>.inputs
Layer.c:19:9: note: add new stmt: MEM <vector(2) long unsigned int> [(float * *)&<retval> + 8B] = _46;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 32 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x4ee79c8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: op template: <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 0 <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 1 <retval>.back = back_21(D);
Layer.c:19:9: note: 	stmt 2 <retval>.fix = fix_22(D);
Layer.c:19:9: note: 	stmt 3 <retval>.destroy = destroy_23(D);
Layer.c:19:9: note: 	children 0x4ee7a48
Layer.c:19:9: note: node (external) 0x4ee7a48 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: 	{ feed_20(D), back_21(D), fix_22(D), destroy_23(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.feed = feed_20(D);
Layer.c:19:9: note: vect_is_simple_use: operand back_21(D), type of def: external
Layer.c:19:9: note: vect_is_simple_use: operand fix_22(D), type of def: external
Layer.c:19:9: note: vect_is_simple_use: operand destroy_23(D), type of def: external
Layer.c:19:9: note: conflicting alias set types.
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(4) long unsigned int  vectorizing a pointer ref: <retval>.feed
Layer.c:19:9: note: created &<retval>.feed
Layer.c:19:9: note: add new stmt: MEM <vector(4) long unsigned int> [(void *)&<retval> + 32B] = _52;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 16 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x4ee7ac8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 0 <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 1 <retval>.child = 0B;
Layer.c:19:9: note: 	children 0x4ee7b48
Layer.c:19:9: note: node (constant) 0x4ee7b48 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ 0B, 0B }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.parent = 0B;
Layer.c:19:9: note: vect_is_simple_use: operand 0B, type of def: constant
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.parent
Layer.c:19:9: note: created &<retval>.parent
Layer.c:19:9: note: add new stmt: MEM <vector(2) long unsigned int> [(struct PULSE_Layer * *)&<retval> + 72B] = { 0, 0 };
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: note: ***** The result for vector mode V32QI would be the same
Layer.c:24:2: missed: statement clobbers memory: free (_1);
Layer.c:25:2: missed: statement clobbers memory: free (_2);
Layer.c:26:2: missed: statement clobbers memory: free (_3);
Layer.c:27:1: note: ***** Analysis failed with vector mode V4DI
Layer.c:27:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:9:27: missed: couldn't vectorize loop
Dense.c:9:27: missed: not vectorized: unsupported outerloop form.
Dense.c:12:20: missed: couldn't vectorize loop
Dense.c:13:21: missed: not vectorized: complicated access pattern.
Dense.c:6:13: note: vectorized 0 loops in function.
Dense.c:16:2: missed: statement clobbers memory: _28 (pretmp_91, _51, 0);
Dense.c:9:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:9:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:24:27: missed: couldn't vectorize loop
Dense.c:24:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:28:20: optimized: loop vectorized using 32 byte vectors
Dense.c:28:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:28:20: optimized: loop vectorized using 16 byte vectors
Dense.c:28:20: missed: couldn't vectorize loop
Dense.c:30:19: missed: not vectorized: no vectype for stmt: _22 = *_21;
 scalar_type: float
Dense.c:20:13: note: vectorized 1 loops in function.
Dense.c:23:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:24:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:24:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:41:28: missed: couldn't vectorize loop
Dense.c:41:28: missed: not vectorized: unsupported outerloop form.
Dense.c:45:21: optimized: loop vectorized using 32 byte vectors
Dense.c:45:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:45:21: optimized: loop vectorized using 16 byte vectors
Dense.c:37:13: note: vectorized 1 loops in function.
Dense.c:37:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:37:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:41:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:170:10: optimized: loop vectorized using 32 byte vectors
Dense.c:170:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:170:10: optimized: loop vectorized using 16 byte vectors
Dense.c:161:10: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_27, _64);
Dense.c:154:10: optimized: loop vectorized using 32 byte vectors
Dense.c:154:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:154:10: optimized: loop vectorized using 16 byte vectors
Dense.c:145:10: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_14, _56);
Dense.c:136:13: note: vectorized 2 loops in function.
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_14, _56);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_15, { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 });
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_27, _64);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_28, { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 });
Dense.c:136:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:136:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:105:24: missed: couldn't vectorize loop
Dense.c:105:24: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:108:17: missed: couldn't vectorize loop
Dense.c:108:17: missed: not vectorized: number of iterations cannot be computed.
Dense.c:122:24: missed: couldn't vectorize loop
Dense.c:122:24: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:125:17: missed: couldn't vectorize loop
Dense.c:125:17: missed: not vectorized: number of iterations cannot be computed.
Dense.c:90:15: missed: couldn't vectorize loop
Dense.c:90:15: missed: not vectorized: number of iterations cannot be computed.
Dense.c:83:13: note: vectorized 0 loops in function.
Dense.c:86:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:110:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:110:17: note: SLPing BB part
Dense.c:127:17: note: Costing subgraph: 
Dense.c:127:17: note: node 0x877c6c8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:127:17: note: op template: _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 0 _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 1 _198 = (sizetype) wi_137;
Dense.c:127:17: note: 	children 0x877c7c8
Dense.c:127:17: note: node (external) 0x877c7c8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:127:17: note: 	{ j_135, wi_137 }
Dense.c:127:17: note: Cost model analysis: 
Dense.c:127:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:127:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:127:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: Costing subgraph: 
Dense.c:110:17: note: node 0x877c8c8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:110:17: note: op template: _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 0 _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 1 _217 = (sizetype) wi_136;
Dense.c:110:17: note: 	children 0x877c9c8
Dense.c:110:17: note: node (external) 0x877c9c8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:110:17: note: 	{ j_134, wi_136 }
Dense.c:110:17: note: Cost model analysis: 
Dense.c:110:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:110:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:110:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:110:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:110:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:110:17: note: SLPing BB part
Dense.c:127:17: note: Costing subgraph: 
Dense.c:127:17: note: node 0x877c8c8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:127:17: note: op template: _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 0 _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 1 _198 = (sizetype) wi_137;
Dense.c:127:17: note: 	children 0x877c6c8
Dense.c:127:17: note: node (external) 0x877c6c8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:127:17: note: 	{ j_135, wi_137 }
Dense.c:127:17: note: Cost model analysis: 
Dense.c:127:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:127:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:127:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: Costing subgraph: 
Dense.c:110:17: note: node 0x877c848 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:110:17: note: op template: _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 0 _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 1 _217 = (sizetype) wi_136;
Dense.c:110:17: note: 	children 0x877c948
Dense.c:110:17: note: node (external) 0x877c948 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:110:17: note: 	{ j_134, wi_136 }
Dense.c:110:17: note: Cost model analysis: 
Dense.c:110:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:110:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:110:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:105:51: note: ***** Analysis failed with vector mode V8QI
Dense.c:105:51: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:105:51: note: ***** Analysis failed with vector mode V4QI
Dense.c:62:15: missed: couldn't vectorize loop
Dense.c:62:15: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:75:11: optimized: loop vectorized using 32 byte vectors
Dense.c:75:11: optimized: loop vectorized using 16 byte vectors
Dense.c:66:11: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:881:10: missed: not vectorized: no vectype for stmt: _53 = MEM[(__m256 * {ref-all})w_ptr_82];
 scalar_type: __m256
Dense.c:54:13: note: vectorized 1 loops in function.
Dense.c:57:2: missed: statement clobbers memory: memcpy (_4, dense$baiases_63, _3);
Dense.c:79:2: missed: statement clobbers memory: _27 (pretmp_163, _68, 0);
Dense.c:54:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:54:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:181:2: missed: statement clobbers memory: free (dense$weights_7);
Dense.c:182:2: missed: statement clobbers memory: free (dense$baiases_8);
Dense.c:183:2: missed: statement clobbers memory: free (dense$gradients_10);
Dense.c:184:2: missed: statement clobbers memory: free (dense$deltas_9);
Dense.c:185:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:185:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:188:107: note: ***** Analysis failed with vector mode V8SI
Dense.c:188:107: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
Dense.c:200:19: missed: couldn't vectorize loop
Dense.c:200:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:190:13: note: vectorized 0 loops in function.
Dense.c:196:37: missed: statement clobbers memory: _9 = aligned_alloc (64, _8);
Dense.c:197:34: missed: statement clobbers memory: _11 = aligned_alloc (64, _10);
Dense.c:198:35: missed: statement clobbers memory: _12 = aligned_alloc (64, _10);
Dense.c:201:38: missed: statement clobbers memory: _13 = rand ();
Dense.c:201:72: missed: statement clobbers memory: _57 = sqrt (_20);
Dense.c:213:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:214:4: missed: statement clobbers memory: exit (1);
Dense.c:210:4: missed: statement clobbers memory: layer = PULSE_CreateLayer (args$n_inputs_36, args$n_outputs_47, 0, args$8_48, _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:207:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (args$n_inputs_36, args$n_outputs_47, 0, args$8_48, _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:219:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Dense.c:219:9: note: ***** Analysis succeeded with vector mode V8SI
Dense.c:219:9: note: SLPing BB part
Dense.c:219:9: note: Costing subgraph: 
Dense.c:219:9: note: node 0x8664038 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Dense.c:219:9: note: op template: MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = MODEL_32(D);
Dense.c:219:9: note: 	stmt 0 MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = MODEL_32(D);
Dense.c:219:9: note: 	stmt 1 MEM <float *> [(struct PULSE_Layer *)&layer + 96B] = _4;
Dense.c:219:9: note: 	stmt 2 MEM <float *> [(struct PULSE_Layer *)&layer + 104B] = _11;
Dense.c:219:9: note: 	stmt 3 MEM <float *> [(struct PULSE_Layer *)&layer + 112B] = _12;
Dense.c:219:9: note: 	children 0x86640b8
Dense.c:219:9: note: node (external) 0x86640b8 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Dense.c:219:9: note: 	{ MODEL_32(D), _4, _11, _12 }
Dense.c:219:9: note: Cost model analysis: 
Dense.c:219:9: note: Cost model analysis for part in loop 0:
  Vector cost: 64
  Scalar cost: 64
Dense.c:219:9: note: Basic block will be vectorized using SLP
Dense.c:219:9: optimized: basic block part vectorized using 32 byte vectors
Dense.c:219:9: note: Vectorizing SLP tree:
Dense.c:219:9: note: node 0x8664038 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Dense.c:219:9: note: op template: MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = MODEL_32(D);
Dense.c:219:9: note: 	stmt 0 MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = MODEL_32(D);
Dense.c:219:9: note: 	stmt 1 MEM <float *> [(struct PULSE_Layer *)&layer + 96B] = _4;
Dense.c:219:9: note: 	stmt 2 MEM <float *> [(struct PULSE_Layer *)&layer + 104B] = _11;
Dense.c:219:9: note: 	stmt 3 MEM <float *> [(struct PULSE_Layer *)&layer + 112B] = _12;
Dense.c:219:9: note: 	children 0x86640b8
Dense.c:219:9: note: node (external) 0x86640b8 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Dense.c:219:9: note: 	{ MODEL_32(D), _4, _11, _12 }
Dense.c:219:9: note: ------>vectorizing SLP node starting from: MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = MODEL_32(D);
Dense.c:219:9: note: vect_is_simple_use: operand MODEL_32(D) + _3, type of def: internal
Dense.c:219:9: note: vect_is_simple_use: operand aligned_alloc (64, _10), type of def: internal
Dense.c:219:9: note: vect_is_simple_use: operand aligned_alloc (64, _10), type of def: internal
Dense.c:219:9: note: transform store. ncopies = 1
Dense.c:219:9: note: create vector_type-pointer variable to type: vector(4) long unsigned int  vectorizing a pointer ref: MEM <float *> [(struct PULSE_Layer *)&layer + 88B]
Dense.c:219:9: note: created &MEM <float *> [(struct PULSE_Layer *)&layer + 88B]
Dense.c:219:9: note: add new stmt: MEM <vector(4) long unsigned int> [(struct PULSE_Layer *)&layer + 88B] = _61;
Dense.c:219:9: note: vectorizing stmts using SLP.
Dense.c:219:9: note: ***** The result for vector mode V32QI would be the same
Activations.c:17:19: optimized: loop vectorized using 32 byte vectors
Activations.c:17:19: optimized: loop vectorized using 16 byte vectors
Activations.c:17:19: optimized: loop vectorized using 32 byte vectors
Activations.c:17:19: optimized: loop vectorized using 16 byte vectors
Activations.c:14:13: note: vectorized 2 loops in function.
Activations.c:14:13: note: ***** Analysis failed with vector mode V8SF
Activations.c:14:13: note: ***** The result for vector mode V32QI would be the same
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V16QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V16QI
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V8QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V8QI
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V4QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V4QI
Activations.c:28:19: missed: couldn't vectorize loop
Activations.c:28:19: missed: not vectorized: unsupported control flow in loop.
Activations.c:28:19: optimized: loop vectorized using 32 byte vectors
Activations.c:28:19: optimized: loop vectorized using 16 byte vectors
Activations.c:25:13: note: vectorized 1 loops in function.
Activations.c:25:13: note: ***** Analysis failed with vector mode V8SF
Activations.c:25:13: note: ***** The result for vector mode V32QI would be the same
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V16QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V16QI
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V8QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V8QI
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V4QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V4QI
Activations.c:38:1: note: ***** Analysis failed with vector mode VOID
Activations.c:5:19: missed: couldn't vectorize loop
Activations.c:9:21: missed: statement clobbers memory: _36 = expf (_18);
Activations.c:5:19: missed: couldn't vectorize loop
Activations.c:9:21: missed: statement clobbers memory: _12 = expf (_11);
Activations.c:3:13: note: vectorized 0 loops in function.
Activations.c:9:21: missed: statement clobbers memory: _12 = expf (_11);
Activations.c:9:21: missed: statement clobbers memory: _36 = expf (_18);
Activations.c:11:1: note: ***** Analysis failed with vector mode V8SF
Activations.c:11:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Activations.c:44:2: note: ***** Analysis failed with vector mode VOID
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:4:18: note: vectorized 0 loops in function.
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_4, inputs_15, _3);
PULSE.c:8:2: missed: statement clobbers memory: _5 (layer_17);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_12, pretmp_26, _9);
PULSE.c:13:28: note: ***** Analysis failed with vector mode V8SI
PULSE.c:13:28: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:22:2: missed: statement clobbers memory: _1 (layer_10(D));
PULSE.c:22:2: missed: statement clobbers memory: _14 (_2);
PULSE.c:22:2: missed: statement clobbers memory: _21 (_15);
PULSE.c:22:2: missed: statement clobbers memory: _28 (_22);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_29);
PULSE.c:26:3: missed: statement clobbers memory: memset (_34, 0, _32);
PULSE.c:26:3: missed: statement clobbers memory: memset (_27, 0, _25);
PULSE.c:26:3: missed: statement clobbers memory: memset (_20, 0, _18);
PULSE.c:26:3: missed: statement clobbers memory: memset (_7, 0, _5);
PULSE.c:28:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:28:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:32:6: note: vectorized 1 loops in function.
PULSE.c:34:8: missed: statement clobbers memory: _1 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_2);
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _9 = rand ();
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8SI
PULSE.c:32:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:61:16: missed: couldn't vectorize loop
PULSE.c:61:16: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:64:17: missed: couldn't vectorize loop
PULSE.c:64:17: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:73:19: missed: couldn't vectorize loop
PULSE.c:73:19: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:53:22: missed: couldn't vectorize loop
PULSE.c:53:22: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:47:6: note: vectorized 1 loops in function.
PULSE.c:48:1: missed: statement clobbers memory: saved_stack.7_39 = __builtin_stack_save ();
PULSE.c:49:46: missed: statement clobbers memory: _1 = PULSE_GetLossFunctionPtr (loss_function_40(D));
PULSE.c:60:10: missed: statement clobbers memory: random.4_46 = __builtin_alloca_with_align (_4, 32);
PULSE.c:34:8: missed: statement clobbers memory: _61 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_62);
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _72 = rand ();
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_98, inputs_93, _97);
PULSE.c:8:2: missed: statement clobbers memory: _99 (layer_94);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_105, _104, _103);
PULSE.c:67:11: missed: statement clobbers memory: loss_55 = PULSE_GetLoss_42 (_17, _16, _12, _11);
PULSE.c:22:2: missed: statement clobbers memory: _86 (output_34);
PULSE.c:22:2: missed: statement clobbers memory: _108 (_87);
PULSE.c:22:2: missed: statement clobbers memory: _115 (_109);
PULSE.c:22:2: missed: statement clobbers memory: _122 (_116);
PULSE.c:22:2: missed: statement clobbers memory: _129 (_123);
PULSE.c:22:2: missed: statement clobbers memory: _136 (_130);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_137);
PULSE.c:26:3: missed: statement clobbers memory: memset (_142, 0, _140);
PULSE.c:26:3: missed: statement clobbers memory: memset (_135, 0, _133);
PULSE.c:26:3: missed: statement clobbers memory: memset (_128, 0, _126);
PULSE.c:26:3: missed: statement clobbers memory: memset (_121, 0, _119);
PULSE.c:26:3: missed: statement clobbers memory: memset (_114, 0, _112);
PULSE.c:26:3: missed: statement clobbers memory: memset (_92, 0, _90);
PULSE.c:75:6: missed: statement clobbers memory: _21 (current_191, args);
PULSE.c:81:4: missed: statement clobbers memory: printf ("Epoch: %d | Item: %d | Loss: %.10f | Batch Loss: %.10f\r", i_188, j_189, _25, _24);
PULSE.c:47:6: missed: statement clobbers memory: __builtin_stack_restore (saved_stack.7_39);
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4DI
PULSE.c:47:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:91:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:91:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:119:20: missed: couldn't vectorize loop
PULSE.c:119:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:119:20: missed: couldn't vectorize loop
PULSE.c:119:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:102:20: missed: couldn't vectorize loop
PULSE.c:102:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:102:20: missed: couldn't vectorize loop
PULSE.c:102:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:93:13: note: vectorized 0 loops in function.
PULSE.c:96:39: missed: statement clobbers memory: layers_31 = malloc (_3);
PULSE.c:99:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:114:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:115:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:116:46: missed: statement clobbers memory: WEIGHTS_46 = malloc (0);
PULSE.c:108:26: missed: not vectorized: more than one data ref in stmt: args = MEM[(struct PULSE_DenseLayerArgs * {ref-all})addr.104_68];
PULSE.c:109:21: missed: statement clobbers memory: _57 = PULSE_GetDenseWeightsSize (args);
PULSE.c:108:26: missed: not vectorized: more than one data ref in stmt: args = MEM[(struct PULSE_DenseLayerArgs * {ref-all})_179];
PULSE.c:109:21: missed: statement clobbers memory: _171 = PULSE_GetDenseWeightsSize (args);
PULSE.c:114:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:115:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:116:46: missed: statement clobbers memory: WEIGHTS_36 = malloc (_5);
PULSE.c:125:26: missed: not vectorized: more than one data ref in stmt: args = MEM[(struct PULSE_DenseLayerArgs * {ref-all})addr.106_70];
PULSE.c:126:17: missed: statement clobbers memory: *_8 = PULSE_CreateDenseLayer (args, WEIGHTS_PTR_121); [return slot optimization]
PULSE.c:127:20: missed: statement clobbers memory: _49 = PULSE_GetDenseWeightsSize (args);
PULSE.c:125:26: missed: not vectorized: more than one data ref in stmt: args = MEM[(struct PULSE_DenseLayerArgs * {ref-all})addr.106_113];
PULSE.c:126:17: missed: statement clobbers memory: *_98 = PULSE_CreateDenseLayer (args, WEIGHTS_PTR_135); [return slot optimization]
PULSE.c:127:20: missed: statement clobbers memory: _76 = PULSE_GetDenseWeightsSize (args);
PULSE.c:133:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:134:9: note: ***** Analysis succeeded with vector mode V8SI
PULSE.c:134:9: note: SLPing BB part
PULSE.c:134:9: note: Costing subgraph: 
PULSE.c:134:9: note: node 0x49b2b38 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:134:9: note: op template: <retval>.layers = layers_31;
PULSE.c:134:9: note: 	stmt 0 <retval>.layers = layers_31;
PULSE.c:134:9: note: 	stmt 1 <retval>.paramethers = WEIGHTS_80;
PULSE.c:134:9: note: 	children 0x49b2c38
PULSE.c:134:9: note: node (external) 0x49b2c38 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:134:9: note: 	{ layers_31, WEIGHTS_80 }
PULSE.c:134:9: note: Cost model analysis: 
PULSE.c:134:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
PULSE.c:134:9: note: Costing subgraph: 
PULSE.c:134:9: note: node 0x49b2cb8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:134:9: note: op template: <retval>.io = 0B;
PULSE.c:134:9: note: 	stmt 0 <retval>.io = 0B;
PULSE.c:134:9: note: 	stmt 1 <retval>.fixes = 0B;
PULSE.c:134:9: note: 	children 0x49b2d38
PULSE.c:134:9: note: node (constant) 0x49b2d38 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:134:9: note: 	{ 0B, 0B }
PULSE.c:134:9: note: Cost model analysis: 
PULSE.c:134:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
PULSE.c:134:9: note: Basic block will be vectorized using SLP
PULSE.c:134:9: optimized: basic block part vectorized using 16 byte vectors
PULSE.c:134:9: note: Vectorizing SLP tree:
PULSE.c:134:9: note: node 0x49b2b38 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:134:9: note: op template: <retval>.layers = layers_31;
PULSE.c:134:9: note: 	stmt 0 <retval>.layers = layers_31;
PULSE.c:134:9: note: 	stmt 1 <retval>.paramethers = WEIGHTS_80;
PULSE.c:134:9: note: 	children 0x49b2c38
PULSE.c:134:9: note: node (external) 0x49b2c38 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:134:9: note: 	{ layers_31, WEIGHTS_80 }
PULSE.c:134:9: note: ------>vectorizing SLP node starting from: <retval>.layers = layers_31;
PULSE.c:134:9: note: vect_is_simple_use: operand WEIGHTS_80 = PHI <WEIGHTS_36(36), WEIGHTS_46(12)>, type of def: internal
PULSE.c:134:9: note: conflicting alias set types.
PULSE.c:134:9: note: transform store. ncopies = 1
PULSE.c:134:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.layers
PULSE.c:134:9: note: created &<retval>
PULSE.c:134:9: note: add new stmt: MEM <vector(2) long unsigned int> [(void *)&<retval>] = _11;
PULSE.c:134:9: note: vectorizing stmts using SLP.
PULSE.c:134:9: optimized: basic block part vectorized using 16 byte vectors
PULSE.c:134:9: note: Vectorizing SLP tree:
PULSE.c:134:9: note: node 0x49b2cb8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:134:9: note: op template: <retval>.io = 0B;
PULSE.c:134:9: note: 	stmt 0 <retval>.io = 0B;
PULSE.c:134:9: note: 	stmt 1 <retval>.fixes = 0B;
PULSE.c:134:9: note: 	children 0x49b2d38
PULSE.c:134:9: note: node (constant) 0x49b2d38 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:134:9: note: 	{ 0B, 0B }
PULSE.c:134:9: note: ------>vectorizing SLP node starting from: <retval>.io = 0B;
PULSE.c:134:9: note: vect_is_simple_use: operand 0B, type of def: constant
PULSE.c:134:9: note: transform store. ncopies = 1
PULSE.c:134:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.io
PULSE.c:134:9: note: created &<retval>.io
PULSE.c:134:9: note: add new stmt: MEM <vector(2) long unsigned int> [(float * *)&<retval> + 16B] = { 0, 0 };
PULSE.c:134:9: note: vectorizing stmts using SLP.
PULSE.c:134:9: note: ***** The result for vector mode V32QI would be the same
PULSE.c:146:1: note: ***** Analysis failed with vector mode VOID
Loss.c:15:19: optimized: loop vectorized using 32 byte vectors
Loss.c:15:19: optimized:  loop versioned for vectorization because of possible aliasing
Loss.c:15:19: optimized: loop vectorized using 16 byte vectors
Loss.c:12:23: note: vectorized 1 loops in function.
Loss.c:12:23: note: ***** Analysis failed with vector mode V8SF
Loss.c:12:23: note: ***** The result for vector mode V32QI would be the same
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V16QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V16QI
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V8QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V8QI
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V4QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V4QI
Loss.c:7:19: missed: couldn't vectorize loop
Loss.c:8:38: missed: not vectorized: unsupported use in stmt.
Loss.c:4:23: note: vectorized 0 loops in function.
Loss.c:9:13: note: ***** Analysis failed with vector mode V8SF
Loss.c:9:13: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Loss.c:23:2: note: ***** Analysis failed with vector mode VOID
Dense.c:9:27: missed: couldn't vectorize loop
Dense.c:9:27: missed: not vectorized: unsupported outerloop form.
Dense.c:12:20: missed: couldn't vectorize loop
Dense.c:13:21: missed: not vectorized: complicated access pattern.
Dense.c:6:13: note: vectorized 0 loops in function.
Dense.c:16:2: missed: statement clobbers memory: _28 (pretmp_91, _51, 0);
Dense.c:9:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:9:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:24:27: missed: couldn't vectorize loop
Dense.c:24:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:28:20: optimized: loop vectorized using 32 byte vectors
Dense.c:28:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:28:20: optimized: loop vectorized using 16 byte vectors
Dense.c:28:20: missed: couldn't vectorize loop
Dense.c:30:19: missed: not vectorized: no vectype for stmt: _22 = *_21;
 scalar_type: float
Dense.c:20:13: note: vectorized 1 loops in function.
Dense.c:23:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:24:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:24:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:41:28: missed: couldn't vectorize loop
Dense.c:41:28: missed: not vectorized: unsupported outerloop form.
Dense.c:45:21: optimized: loop vectorized using 32 byte vectors
Dense.c:45:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:45:21: optimized: loop vectorized using 16 byte vectors
Dense.c:37:13: note: vectorized 1 loops in function.
Dense.c:37:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:37:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:41:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:170:10: optimized: loop vectorized using 32 byte vectors
Dense.c:170:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:170:10: optimized: loop vectorized using 16 byte vectors
Dense.c:161:10: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_27, _64);
Dense.c:154:10: optimized: loop vectorized using 32 byte vectors
Dense.c:154:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:154:10: optimized: loop vectorized using 16 byte vectors
Dense.c:145:10: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_14, _56);
Dense.c:136:13: note: vectorized 2 loops in function.
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_14, _56);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_15, { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 });
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_27, _64);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_28, { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 });
Dense.c:136:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:136:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:105:24: missed: couldn't vectorize loop
Dense.c:105:24: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:108:17: missed: couldn't vectorize loop
Dense.c:108:17: missed: not vectorized: number of iterations cannot be computed.
Dense.c:122:24: missed: couldn't vectorize loop
Dense.c:122:24: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:125:17: missed: couldn't vectorize loop
Dense.c:125:17: missed: not vectorized: number of iterations cannot be computed.
Dense.c:90:15: missed: couldn't vectorize loop
Dense.c:90:15: missed: not vectorized: number of iterations cannot be computed.
Dense.c:83:13: note: vectorized 0 loops in function.
Dense.c:86:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:110:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:110:17: note: SLPing BB part
Dense.c:127:17: note: Costing subgraph: 
Dense.c:127:17: note: node 0x76fe588 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:127:17: note: op template: _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 0 _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 1 _198 = (sizetype) wi_137;
Dense.c:127:17: note: 	children 0x76fe688
Dense.c:127:17: note: node (external) 0x76fe688 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:127:17: note: 	{ j_135, wi_137 }
Dense.c:127:17: note: Cost model analysis: 
Dense.c:127:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:127:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:127:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: Costing subgraph: 
Dense.c:110:17: note: node 0x76fe788 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:110:17: note: op template: _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 0 _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 1 _217 = (sizetype) wi_136;
Dense.c:110:17: note: 	children 0x76fe888
Dense.c:110:17: note: node (external) 0x76fe888 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:110:17: note: 	{ j_134, wi_136 }
Dense.c:110:17: note: Cost model analysis: 
Dense.c:110:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:110:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:110:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:110:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:110:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:110:17: note: SLPing BB part
Dense.c:127:17: note: Costing subgraph: 
Dense.c:127:17: note: node 0x76fe788 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:127:17: note: op template: _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 0 _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 1 _198 = (sizetype) wi_137;
Dense.c:127:17: note: 	children 0x76fe588
Dense.c:127:17: note: node (external) 0x76fe588 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:127:17: note: 	{ j_135, wi_137 }
Dense.c:127:17: note: Cost model analysis: 
Dense.c:127:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:127:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:127:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: Costing subgraph: 
Dense.c:110:17: note: node 0x76fe708 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:110:17: note: op template: _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 0 _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 1 _217 = (sizetype) wi_136;
Dense.c:110:17: note: 	children 0x76fe808
Dense.c:110:17: note: node (external) 0x76fe808 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:110:17: note: 	{ j_134, wi_136 }
Dense.c:110:17: note: Cost model analysis: 
Dense.c:110:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:110:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:110:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:105:51: note: ***** Analysis failed with vector mode V8QI
Dense.c:105:51: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:105:51: note: ***** Analysis failed with vector mode V4QI
Dense.c:62:15: missed: couldn't vectorize loop
Dense.c:62:15: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:75:11: optimized: loop vectorized using 32 byte vectors
Dense.c:75:11: optimized: loop vectorized using 16 byte vectors
Dense.c:66:11: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:881:10: missed: not vectorized: no vectype for stmt: _53 = MEM[(__m256 * {ref-all})w_ptr_82];
 scalar_type: __m256
Dense.c:54:13: note: vectorized 1 loops in function.
Dense.c:57:2: missed: statement clobbers memory: memcpy (_4, dense$baiases_63, _3);
Dense.c:79:2: missed: statement clobbers memory: _27 (pretmp_163, _68, 0);
Dense.c:54:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:54:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:181:2: missed: statement clobbers memory: free (dense$weights_7);
Dense.c:182:2: missed: statement clobbers memory: free (dense$baiases_8);
Dense.c:183:2: missed: statement clobbers memory: free (dense$gradients_10);
Dense.c:184:2: missed: statement clobbers memory: free (dense$deltas_9);
Dense.c:185:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:185:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:188:107: note: ***** Analysis failed with vector mode V8SI
Dense.c:188:107: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
Dense.c:200:19: missed: couldn't vectorize loop
Dense.c:200:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:190:13: note: vectorized 0 loops in function.
Dense.c:196:37: missed: statement clobbers memory: _9 = aligned_alloc (64, _8);
Dense.c:197:34: missed: statement clobbers memory: _11 = aligned_alloc (64, _10);
Dense.c:198:35: missed: statement clobbers memory: _12 = aligned_alloc (64, _10);
Dense.c:201:38: missed: statement clobbers memory: _13 = rand ();
Dense.c:201:72: missed: statement clobbers memory: _57 = sqrt (_20);
Dense.c:213:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:214:4: missed: statement clobbers memory: exit (1);
Dense.c:210:4: missed: statement clobbers memory: layer = PULSE_CreateLayer (args$n_inputs_36, args$n_outputs_47, 0, args$8_48, _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:207:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (args$n_inputs_36, args$n_outputs_47, 0, args$8_48, _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:219:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Dense.c:219:9: note: ***** Analysis succeeded with vector mode V8SI
Dense.c:219:9: note: SLPing BB part
Dense.c:219:9: note: Costing subgraph: 
Dense.c:219:9: note: node 0x753d248 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Dense.c:219:9: note: op template: MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = MODEL_32(D);
Dense.c:219:9: note: 	stmt 0 MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = MODEL_32(D);
Dense.c:219:9: note: 	stmt 1 MEM <float *> [(struct PULSE_Layer *)&layer + 96B] = _4;
Dense.c:219:9: note: 	stmt 2 MEM <float *> [(struct PULSE_Layer *)&layer + 104B] = _11;
Dense.c:219:9: note: 	stmt 3 MEM <float *> [(struct PULSE_Layer *)&layer + 112B] = _12;
Dense.c:219:9: note: 	children 0x753d2c8
Dense.c:219:9: note: node (external) 0x753d2c8 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Dense.c:219:9: note: 	{ MODEL_32(D), _4, _11, _12 }
Dense.c:219:9: note: Cost model analysis: 
Dense.c:219:9: note: Cost model analysis for part in loop 0:
  Vector cost: 64
  Scalar cost: 64
Dense.c:219:9: note: Basic block will be vectorized using SLP
Dense.c:219:9: optimized: basic block part vectorized using 32 byte vectors
Dense.c:219:9: note: Vectorizing SLP tree:
Dense.c:219:9: note: node 0x753d248 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Dense.c:219:9: note: op template: MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = MODEL_32(D);
Dense.c:219:9: note: 	stmt 0 MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = MODEL_32(D);
Dense.c:219:9: note: 	stmt 1 MEM <float *> [(struct PULSE_Layer *)&layer + 96B] = _4;
Dense.c:219:9: note: 	stmt 2 MEM <float *> [(struct PULSE_Layer *)&layer + 104B] = _11;
Dense.c:219:9: note: 	stmt 3 MEM <float *> [(struct PULSE_Layer *)&layer + 112B] = _12;
Dense.c:219:9: note: 	children 0x753d2c8
Dense.c:219:9: note: node (external) 0x753d2c8 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Dense.c:219:9: note: 	{ MODEL_32(D), _4, _11, _12 }
Dense.c:219:9: note: ------>vectorizing SLP node starting from: MEM <float *> [(struct PULSE_Layer *)&layer + 88B] = MODEL_32(D);
Dense.c:219:9: note: vect_is_simple_use: operand MODEL_32(D) + _3, type of def: internal
Dense.c:219:9: note: vect_is_simple_use: operand aligned_alloc (64, _10), type of def: internal
Dense.c:219:9: note: vect_is_simple_use: operand aligned_alloc (64, _10), type of def: internal
Dense.c:219:9: note: transform store. ncopies = 1
Dense.c:219:9: note: create vector_type-pointer variable to type: vector(4) long unsigned int  vectorizing a pointer ref: MEM <float *> [(struct PULSE_Layer *)&layer + 88B]
Dense.c:219:9: note: created &MEM <float *> [(struct PULSE_Layer *)&layer + 88B]
Dense.c:219:9: note: add new stmt: MEM <vector(4) long unsigned int> [(struct PULSE_Layer *)&layer + 88B] = _61;
Dense.c:219:9: note: vectorizing stmts using SLP.
Dense.c:219:9: note: ***** The result for vector mode V32QI would be the same
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:4:18: note: vectorized 0 loops in function.
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_4, inputs_15, _3);
PULSE.c:8:2: missed: statement clobbers memory: _5 (layer_17);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_12, pretmp_26, _9);
PULSE.c:13:28: note: ***** Analysis failed with vector mode V8SI
PULSE.c:13:28: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:22:2: missed: statement clobbers memory: _1 (layer_10(D));
PULSE.c:22:2: missed: statement clobbers memory: _14 (_2);
PULSE.c:22:2: missed: statement clobbers memory: _21 (_15);
PULSE.c:22:2: missed: statement clobbers memory: _28 (_22);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_29);
PULSE.c:26:3: missed: statement clobbers memory: memset (_34, 0, _32);
PULSE.c:26:3: missed: statement clobbers memory: memset (_27, 0, _25);
PULSE.c:26:3: missed: statement clobbers memory: memset (_20, 0, _18);
PULSE.c:26:3: missed: statement clobbers memory: memset (_7, 0, _5);
PULSE.c:28:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:28:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:32:6: note: vectorized 1 loops in function.
PULSE.c:34:8: missed: statement clobbers memory: _1 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_2);
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _9 = rand ();
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8SI
PULSE.c:32:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:61:16: missed: couldn't vectorize loop
PULSE.c:61:16: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:64:17: missed: couldn't vectorize loop
PULSE.c:64:17: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:73:19: missed: couldn't vectorize loop
PULSE.c:73:19: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:53:22: missed: couldn't vectorize loop
PULSE.c:53:22: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:47:6: note: vectorized 1 loops in function.
PULSE.c:48:1: missed: statement clobbers memory: saved_stack.7_39 = __builtin_stack_save ();
PULSE.c:49:46: missed: statement clobbers memory: _1 = PULSE_GetLossFunctionPtr (loss_function_40(D));
PULSE.c:60:10: missed: statement clobbers memory: random.4_46 = __builtin_alloca_with_align (_4, 32);
PULSE.c:34:8: missed: statement clobbers memory: _61 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_62);
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _72 = rand ();
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_98, inputs_93, _97);
PULSE.c:8:2: missed: statement clobbers memory: _99 (layer_94);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_105, _104, _103);
PULSE.c:67:11: missed: statement clobbers memory: loss_55 = PULSE_GetLoss_42 (_17, _16, _12, _11);
PULSE.c:22:2: missed: statement clobbers memory: _86 (output_34);
PULSE.c:22:2: missed: statement clobbers memory: _108 (_87);
PULSE.c:22:2: missed: statement clobbers memory: _115 (_109);
PULSE.c:22:2: missed: statement clobbers memory: _122 (_116);
PULSE.c:22:2: missed: statement clobbers memory: _129 (_123);
PULSE.c:22:2: missed: statement clobbers memory: _136 (_130);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_137);
PULSE.c:26:3: missed: statement clobbers memory: memset (_142, 0, _140);
PULSE.c:26:3: missed: statement clobbers memory: memset (_135, 0, _133);
PULSE.c:26:3: missed: statement clobbers memory: memset (_128, 0, _126);
PULSE.c:26:3: missed: statement clobbers memory: memset (_121, 0, _119);
PULSE.c:26:3: missed: statement clobbers memory: memset (_114, 0, _112);
PULSE.c:26:3: missed: statement clobbers memory: memset (_92, 0, _90);
PULSE.c:75:6: missed: statement clobbers memory: _21 (current_191, args);
PULSE.c:81:4: missed: statement clobbers memory: printf ("Epoch: %d | Item: %d | Loss: %.10f | Batch Loss: %.10f\r", i_188, j_189, _25, _24);
PULSE.c:47:6: missed: statement clobbers memory: __builtin_stack_restore (saved_stack.7_39);
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4DI
PULSE.c:47:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:91:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:91:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:119:20: missed: couldn't vectorize loop
PULSE.c:119:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:119:20: missed: couldn't vectorize loop
PULSE.c:119:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:102:20: missed: couldn't vectorize loop
PULSE.c:102:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:102:20: missed: couldn't vectorize loop
PULSE.c:102:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:93:13: note: vectorized 0 loops in function.
PULSE.c:96:39: missed: statement clobbers memory: layers_31 = malloc (_3);
PULSE.c:99:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:114:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:115:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:116:46: missed: statement clobbers memory: WEIGHTS_105 = aligned_alloc (64, 0);
PULSE.c:108:26: missed: not vectorized: more than one data ref in stmt: args = MEM[(struct PULSE_DenseLayerArgs * {ref-all})addr.104_68];
PULSE.c:109:21: missed: statement clobbers memory: _57 = PULSE_GetDenseWeightsSize (args);
PULSE.c:108:26: missed: not vectorized: more than one data ref in stmt: args = MEM[(struct PULSE_DenseLayerArgs * {ref-all})_179];
PULSE.c:109:21: missed: statement clobbers memory: _171 = PULSE_GetDenseWeightsSize (args);
PULSE.c:114:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:115:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:116:46: missed: statement clobbers memory: WEIGHTS_36 = aligned_alloc (64, _5);
PULSE.c:125:26: missed: not vectorized: more than one data ref in stmt: args = MEM[(struct PULSE_DenseLayerArgs * {ref-all})addr.106_70];
PULSE.c:126:17: missed: statement clobbers memory: *_8 = PULSE_CreateDenseLayer (args, WEIGHTS_PTR_121); [return slot optimization]
PULSE.c:127:20: missed: statement clobbers memory: _49 = PULSE_GetDenseWeightsSize (args);
PULSE.c:125:26: missed: not vectorized: more than one data ref in stmt: args = MEM[(struct PULSE_DenseLayerArgs * {ref-all})addr.106_124];
PULSE.c:126:17: missed: statement clobbers memory: *_98 = PULSE_CreateDenseLayer (args, WEIGHTS_PTR_135); [return slot optimization]
PULSE.c:127:20: missed: statement clobbers memory: _80 = PULSE_GetDenseWeightsSize (args);
PULSE.c:133:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:134:9: note: ***** Analysis succeeded with vector mode V8SI
PULSE.c:134:9: note: SLPing BB part
PULSE.c:134:9: note: Costing subgraph: 
PULSE.c:134:9: note: node 0x3548258 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:134:9: note: op template: <retval>.layers = layers_31;
PULSE.c:134:9: note: 	stmt 0 <retval>.layers = layers_31;
PULSE.c:134:9: note: 	stmt 1 <retval>.weights = WEIGHTS_131;
PULSE.c:134:9: note: 	children 0x3548358
PULSE.c:134:9: note: node (external) 0x3548358 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:134:9: note: 	{ layers_31, WEIGHTS_131 }
PULSE.c:134:9: note: Cost model analysis: 
PULSE.c:134:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
PULSE.c:134:9: note: Costing subgraph: 
PULSE.c:134:9: note: node 0x35483d8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:134:9: note: op template: <retval>.io = 0B;
PULSE.c:134:9: note: 	stmt 0 <retval>.io = 0B;
PULSE.c:134:9: note: 	stmt 1 <retval>.fixes = 0B;
PULSE.c:134:9: note: 	children 0x3548458
PULSE.c:134:9: note: node (constant) 0x3548458 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:134:9: note: 	{ 0B, 0B }
PULSE.c:134:9: note: Cost model analysis: 
PULSE.c:134:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
PULSE.c:134:9: note: Basic block will be vectorized using SLP
PULSE.c:134:9: optimized: basic block part vectorized using 16 byte vectors
PULSE.c:134:9: note: Vectorizing SLP tree:
PULSE.c:134:9: note: node 0x3548258 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:134:9: note: op template: <retval>.layers = layers_31;
PULSE.c:134:9: note: 	stmt 0 <retval>.layers = layers_31;
PULSE.c:134:9: note: 	stmt 1 <retval>.weights = WEIGHTS_131;
PULSE.c:134:9: note: 	children 0x3548358
PULSE.c:134:9: note: node (external) 0x3548358 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:134:9: note: 	{ layers_31, WEIGHTS_131 }
PULSE.c:134:9: note: ------>vectorizing SLP node starting from: <retval>.layers = layers_31;
PULSE.c:134:9: note: vect_is_simple_use: operand WEIGHTS_131 = PHI <WEIGHTS_36(36), WEIGHTS_105(25)>, type of def: internal
PULSE.c:134:9: note: conflicting alias set types.
PULSE.c:134:9: note: transform store. ncopies = 1
PULSE.c:134:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.layers
PULSE.c:134:9: note: created &<retval>
PULSE.c:134:9: note: add new stmt: MEM <vector(2) long unsigned int> [(void *)&<retval>] = _11;
PULSE.c:134:9: note: vectorizing stmts using SLP.
PULSE.c:134:9: optimized: basic block part vectorized using 16 byte vectors
PULSE.c:134:9: note: Vectorizing SLP tree:
PULSE.c:134:9: note: node 0x35483d8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:134:9: note: op template: <retval>.io = 0B;
PULSE.c:134:9: note: 	stmt 0 <retval>.io = 0B;
PULSE.c:134:9: note: 	stmt 1 <retval>.fixes = 0B;
PULSE.c:134:9: note: 	children 0x3548458
PULSE.c:134:9: note: node (constant) 0x3548458 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:134:9: note: 	{ 0B, 0B }
PULSE.c:134:9: note: ------>vectorizing SLP node starting from: <retval>.io = 0B;
PULSE.c:134:9: note: vect_is_simple_use: operand 0B, type of def: constant
PULSE.c:134:9: note: transform store. ncopies = 1
PULSE.c:134:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.io
PULSE.c:134:9: note: created &<retval>.io
PULSE.c:134:9: note: add new stmt: MEM <vector(2) long unsigned int> [(float * *)&<retval> + 16B] = { 0, 0 };
PULSE.c:134:9: note: vectorizing stmts using SLP.
PULSE.c:134:9: note: ***** The result for vector mode V32QI would be the same
PULSE.c:146:1: note: ***** Analysis failed with vector mode VOID
Dense.c:9:27: missed: couldn't vectorize loop
Dense.c:9:27: missed: not vectorized: unsupported outerloop form.
Dense.c:12:20: missed: couldn't vectorize loop
Dense.c:13:21: missed: not vectorized: complicated access pattern.
Dense.c:6:13: note: vectorized 0 loops in function.
Dense.c:16:2: missed: statement clobbers memory: _28 (pretmp_91, _51, 0);
Dense.c:9:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:9:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:24:27: missed: couldn't vectorize loop
Dense.c:24:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:28:20: optimized: loop vectorized using 32 byte vectors
Dense.c:28:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:28:20: optimized: loop vectorized using 16 byte vectors
Dense.c:28:20: missed: couldn't vectorize loop
Dense.c:30:19: missed: not vectorized: no vectype for stmt: _22 = *_21;
 scalar_type: float
Dense.c:20:13: note: vectorized 1 loops in function.
Dense.c:23:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:24:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:24:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:41:28: missed: couldn't vectorize loop
Dense.c:41:28: missed: not vectorized: unsupported outerloop form.
Dense.c:45:21: optimized: loop vectorized using 32 byte vectors
Dense.c:45:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:45:21: optimized: loop vectorized using 16 byte vectors
Dense.c:37:13: note: vectorized 1 loops in function.
Dense.c:37:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:37:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:41:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:170:10: optimized: loop vectorized using 32 byte vectors
Dense.c:170:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:170:10: optimized: loop vectorized using 16 byte vectors
Dense.c:161:10: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_27, _64);
Dense.c:154:10: optimized: loop vectorized using 32 byte vectors
Dense.c:154:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:154:10: optimized: loop vectorized using 16 byte vectors
Dense.c:145:10: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_14, _56);
Dense.c:136:13: note: vectorized 2 loops in function.
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_14, _56);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_15, { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 });
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_27, _64);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_28, { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 });
Dense.c:136:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:136:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:105:24: missed: couldn't vectorize loop
Dense.c:105:24: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:108:17: missed: couldn't vectorize loop
Dense.c:108:17: missed: not vectorized: number of iterations cannot be computed.
Dense.c:122:24: missed: couldn't vectorize loop
Dense.c:122:24: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:125:17: missed: couldn't vectorize loop
Dense.c:125:17: missed: not vectorized: number of iterations cannot be computed.
Dense.c:90:15: missed: couldn't vectorize loop
Dense.c:90:15: missed: not vectorized: number of iterations cannot be computed.
Dense.c:83:13: note: vectorized 0 loops in function.
Dense.c:86:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:110:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:110:17: note: SLPing BB part
Dense.c:127:17: note: Costing subgraph: 
Dense.c:127:17: note: node 0x7678f08 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:127:17: note: op template: _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 0 _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 1 _198 = (sizetype) wi_137;
Dense.c:127:17: note: 	children 0x7679008
Dense.c:127:17: note: node (external) 0x7679008 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:127:17: note: 	{ j_135, wi_137 }
Dense.c:127:17: note: Cost model analysis: 
Dense.c:127:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:127:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:127:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: Costing subgraph: 
Dense.c:110:17: note: node 0x7679108 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:110:17: note: op template: _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 0 _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 1 _217 = (sizetype) wi_136;
Dense.c:110:17: note: 	children 0x7679208
Dense.c:110:17: note: node (external) 0x7679208 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:110:17: note: 	{ j_134, wi_136 }
Dense.c:110:17: note: Cost model analysis: 
Dense.c:110:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:110:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:110:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:110:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:110:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:110:17: note: SLPing BB part
Dense.c:127:17: note: Costing subgraph: 
Dense.c:127:17: note: node 0x7679108 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:127:17: note: op template: _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 0 _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 1 _198 = (sizetype) wi_137;
Dense.c:127:17: note: 	children 0x7678f08
Dense.c:127:17: note: node (external) 0x7678f08 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:127:17: note: 	{ j_135, wi_137 }
Dense.c:127:17: note: Cost model analysis: 
Dense.c:127:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:127:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:127:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: Costing subgraph: 
Dense.c:110:17: note: node 0x7679088 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:110:17: note: op template: _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 0 _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 1 _217 = (sizetype) wi_136;
Dense.c:110:17: note: 	children 0x7679188
Dense.c:110:17: note: node (external) 0x7679188 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:110:17: note: 	{ j_134, wi_136 }
Dense.c:110:17: note: Cost model analysis: 
Dense.c:110:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:110:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:110:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:105:51: note: ***** Analysis failed with vector mode V8QI
Dense.c:105:51: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:105:51: note: ***** Analysis failed with vector mode V4QI
Dense.c:62:15: missed: couldn't vectorize loop
Dense.c:62:15: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:75:11: optimized: loop vectorized using 32 byte vectors
Dense.c:75:11: optimized: loop vectorized using 16 byte vectors
Dense.c:66:11: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:881:10: missed: not vectorized: no vectype for stmt: _53 = MEM[(__m256 * {ref-all})w_ptr_82];
 scalar_type: __m256
Dense.c:54:13: note: vectorized 1 loops in function.
Dense.c:57:2: missed: statement clobbers memory: memcpy (_4, dense$baiases_63, _3);
Dense.c:79:2: missed: statement clobbers memory: _27 (pretmp_163, _68, 0);
Dense.c:54:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:54:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:188:107: note: ***** Analysis failed with vector mode V8SI
Dense.c:188:107: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
Dense.c:189:85: note: ***** Analysis failed with vector mode V8SI
Dense.c:189:85: note: ***** The result for vector mode V32QI would be the same
Dense.c:189:85: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:189:85: note: ***** Analysis failed with vector mode V16QI
Dense.c:189:85: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:189:85: note: ***** Analysis failed with vector mode V8QI
Dense.c:189:85: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:189:85: note: ***** Analysis failed with vector mode V4QI
Dense.c:201:19: missed: couldn't vectorize loop
Dense.c:201:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:191:13: note: vectorized 0 loops in function.
Dense.c:197:37: missed: statement clobbers memory: _9 = aligned_alloc (64, _8);
Dense.c:198:34: missed: statement clobbers memory: _11 = aligned_alloc (64, _10);
Dense.c:199:35: missed: statement clobbers memory: _12 = aligned_alloc (64, _10);
Dense.c:202:38: missed: statement clobbers memory: _13 = rand ();
Dense.c:202:72: missed: statement clobbers memory: _77 = sqrt (_20);
Dense.c:215:19: missed: statement clobbers memory: _31 = PULSE_GetActivationFunctionPtr (_30);
Dense.c:231:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:232:4: missed: statement clobbers memory: exit (1);
Dense.c:236:9: note: ***** Analysis succeeded with vector mode V8SI
Dense.c:236:9: note: SLPing BB part
Dense.c:236:9: note: Costing subgraph: 
Dense.c:236:9: note: node 0x7581458 (max_nunits=2, refcnt=1) vector(2) unsigned int
Dense.c:236:9: note: op template: <retval>.n_inputs = args$n_inputs_51;
Dense.c:236:9: note: 	stmt 0 <retval>.n_inputs = args$n_inputs_51;
Dense.c:236:9: note: 	stmt 1 <retval>.n_outputs = args$n_outputs_52;
Dense.c:236:9: note: 	children 0x75814d8
Dense.c:236:9: note: node 0x75814d8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Dense.c:236:9: note: op template: args$n_inputs_51 = args.n_inputs;
Dense.c:236:9: note: 	stmt 0 args$n_inputs_51 = args.n_inputs;
Dense.c:236:9: note: 	stmt 1 args$n_outputs_52 = args.n_outputs;
Dense.c:236:9: note: Cost model analysis: 
Dense.c:236:9: note: Cost model analysis for part in loop 0:
  Vector cost: 40
  Scalar cost: 56
Dense.c:236:9: note: Costing subgraph: 
Dense.c:236:9: note: node 0x75815d8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Dense.c:236:9: note: op template: <retval>.inputs = IO_41(D);
Dense.c:236:9: note: 	stmt 0 <retval>.inputs = IO_41(D);
Dense.c:236:9: note: 	stmt 1 <retval>.outputs = _29;
Dense.c:236:9: note: 	children 0x7581658
Dense.c:236:9: note: node (external) 0x7581658 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Dense.c:236:9: note: 	{ IO_41(D), _29 }
Dense.c:236:9: note: Cost model analysis: 
Dense.c:236:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Dense.c:236:9: note: Costing subgraph: 
Dense.c:236:9: note: node 0x7581758 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Dense.c:236:9: note: op template: <retval>.feed = layer$feed_40;
Dense.c:236:9: note: 	stmt 0 <retval>.feed = layer$feed_40;
Dense.c:236:9: note: 	stmt 1 <retval>.back = layer$back_49;
Dense.c:236:9: note: 	children 0x7581958
Dense.c:236:9: note: node (external) 0x7581958 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Dense.c:236:9: note: 	{ layer$feed_40, layer$back_49 }
Dense.c:236:9: note: Cost model analysis: 
Dense.c:236:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Dense.c:236:9: note: Costing subgraph: 
Dense.c:236:9: note: node 0x7581858 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Dense.c:236:9: note: op template: <retval>.parent = 0B;
Dense.c:236:9: note: 	stmt 0 <retval>.parent = 0B;
Dense.c:236:9: note: 	stmt 1 <retval>.child = 0B;
Dense.c:236:9: note: 	children 0x75819d8
Dense.c:236:9: note: node (constant) 0x75819d8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Dense.c:236:9: note: 	{ 0B, 0B }
Dense.c:236:9: note: Cost model analysis: 
Dense.c:236:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Dense.c:236:9: note: Costing subgraph: 
Dense.c:236:9: note: node 0x7581ad8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Dense.c:236:9: note: op template: MEM <float *> [(struct PULSE_Layer *)&<retval> + 88B] = MODEL_36(D);
Dense.c:236:9: note: 	stmt 0 MEM <float *> [(struct PULSE_Layer *)&<retval> + 88B] = MODEL_36(D);
Dense.c:236:9: note: 	stmt 1 MEM <float *> [(struct PULSE_Layer *)&<retval> + 96B] = _4;
Dense.c:236:9: note: 	stmt 2 MEM <float *> [(struct PULSE_Layer *)&<retval> + 104B] = _11;
Dense.c:236:9: note: 	stmt 3 MEM <float *> [(struct PULSE_Layer *)&<retval> + 112B] = _12;
Dense.c:236:9: note: 	children 0x7581b58
Dense.c:236:9: note: node (external) 0x7581b58 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Dense.c:236:9: note: 	{ MODEL_36(D), _4, _11, _12 }
Dense.c:236:9: note: Cost model analysis: 
Dense.c:236:9: note: Cost model analysis for part in loop 0:
  Vector cost: 64
  Scalar cost: 64
Dense.c:236:9: note: Basic block will be vectorized using SLP
Dense.c:236:9: optimized: basic block part vectorized using 8 byte vectors
Dense.c:236:9: note: Vectorizing SLP tree:
Dense.c:236:9: note: node 0x7581458 (max_nunits=2, refcnt=1) vector(2) unsigned int
Dense.c:236:9: note: op template: <retval>.n_inputs = args$n_inputs_51;
Dense.c:236:9: note: 	stmt 0 <retval>.n_inputs = args$n_inputs_51;
Dense.c:236:9: note: 	stmt 1 <retval>.n_outputs = args$n_outputs_52;
Dense.c:236:9: note: 	children 0x75814d8
Dense.c:236:9: note: node 0x75814d8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Dense.c:236:9: note: op template: args$n_inputs_51 = args.n_inputs;
Dense.c:236:9: note: 	stmt 0 args$n_inputs_51 = args.n_inputs;
Dense.c:236:9: note: 	stmt 1 args$n_outputs_52 = args.n_outputs;
Dense.c:236:9: note: ------>vectorizing SLP node starting from: args$n_inputs_51 = args.n_inputs;
Dense.c:236:9: note: transform load. ncopies = 1
Dense.c:236:9: note: conflicting alias set types.
Dense.c:236:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: args.n_inputs
Dense.c:236:9: note: created &args
Dense.c:236:9: note: add new stmt: vect_args_n_inputs_51.504_86 = MEM <vector(2) unsigned int> [(void *)&args];
Dense.c:236:9: note: extracting lane for live stmt args$n_inputs_51 = args.n_inputs;
Dense.c:236:9: note: extracting lane for live stmt args$n_outputs_52 = args.n_outputs;
Dense.c:236:9: note: ------>vectorizing SLP node starting from: <retval>.n_inputs = args$n_inputs_51;
Dense.c:236:9: note: vect_is_simple_use: operand args.n_inputs, type of def: internal
Dense.c:236:9: note: vect_is_simple_use: operand args.n_outputs, type of def: internal
Dense.c:236:9: note: transform store. ncopies = 1
Dense.c:236:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: <retval>.n_inputs
Dense.c:236:9: note: created &<retval>.n_inputs
Dense.c:236:9: note: add new stmt: MEM <vector(2) unsigned int> [(unsigned int *)&<retval> + 128B] = vect_args_n_inputs_51.504_86;
Dense.c:236:9: note: vectorizing stmts using SLP.
Dense.c:236:9: optimized: basic block part vectorized using 16 byte vectors
Dense.c:236:9: note: Vectorizing SLP tree:
Dense.c:236:9: note: node 0x75815d8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Dense.c:236:9: note: op template: <retval>.inputs = IO_41(D);
Dense.c:236:9: note: 	stmt 0 <retval>.inputs = IO_41(D);
Dense.c:236:9: note: 	stmt 1 <retval>.outputs = _29;
Dense.c:236:9: note: 	children 0x7581658
Dense.c:236:9: note: node (external) 0x7581658 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Dense.c:236:9: note: 	{ IO_41(D), _29 }
Dense.c:236:9: note: ------>vectorizing SLP node starting from: <retval>.inputs = IO_41(D);
Dense.c:236:9: note: vect_is_simple_use: operand IO_41(D) + _28, type of def: internal
Dense.c:236:9: note: transform store. ncopies = 1
Dense.c:236:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.inputs
Dense.c:236:9: note: created &<retval>
Dense.c:236:9: note: add new stmt: MEM <vector(2) long unsigned int> [(float * *)&<retval>] = _92;
Dense.c:236:9: note: vectorizing stmts using SLP.
Dense.c:236:9: optimized: basic block part vectorized using 16 byte vectors
Dense.c:236:9: note: Vectorizing SLP tree:
Dense.c:236:9: note: node 0x7581758 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Dense.c:236:9: note: op template: <retval>.feed = layer$feed_40;
Dense.c:236:9: note: 	stmt 0 <retval>.feed = layer$feed_40;
Dense.c:236:9: note: 	stmt 1 <retval>.back = layer$back_49;
Dense.c:236:9: note: 	children 0x7581958
Dense.c:236:9: note: node (external) 0x7581958 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Dense.c:236:9: note: 	{ layer$feed_40, layer$back_49 }
Dense.c:236:9: note: ------>vectorizing SLP node starting from: <retval>.feed = layer$feed_40;
Dense.c:236:9: note: vect_is_simple_use: operand layer$back_49 = PHI <layer$back_55(D)(11), _BackDense(9), _SIMD_BackDense(15)>, type of def: internal
Dense.c:236:9: note: transform store. ncopies = 1
Dense.c:236:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.feed
Dense.c:236:9: note: created &<retval>.feed
Dense.c:236:9: note: add new stmt: MEM <vector(2) long unsigned int> [(void (*<T921>) (struct PULSE_Layer *) *)&<retval> + 32B] = _96;
Dense.c:236:9: note: vectorizing stmts using SLP.
Dense.c:236:9: optimized: basic block part vectorized using 16 byte vectors
Dense.c:236:9: note: Vectorizing SLP tree:
Dense.c:236:9: note: node 0x7581858 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Dense.c:236:9: note: op template: <retval>.parent = 0B;
Dense.c:236:9: note: 	stmt 0 <retval>.parent = 0B;
Dense.c:236:9: note: 	stmt 1 <retval>.child = 0B;
Dense.c:236:9: note: 	children 0x75819d8
Dense.c:236:9: note: node (constant) 0x75819d8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Dense.c:236:9: note: 	{ 0B, 0B }
Dense.c:236:9: note: ------>vectorizing SLP node starting from: <retval>.parent = 0B;
Dense.c:236:9: note: vect_is_simple_use: operand 0B, type of def: constant
Dense.c:236:9: note: transform store. ncopies = 1
Dense.c:236:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.parent
Dense.c:236:9: note: created &<retval>.parent
Dense.c:236:9: note: add new stmt: MEM <vector(2) long unsigned int> [(struct PULSE_Layer * *)&<retval> + 72B] = { 0, 0 };
Dense.c:236:9: note: vectorizing stmts using SLP.
Dense.c:236:9: optimized: basic block part vectorized using 32 byte vectors
Dense.c:236:9: note: Vectorizing SLP tree:
Dense.c:236:9: note: node 0x7581ad8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Dense.c:236:9: note: op template: MEM <float *> [(struct PULSE_Layer *)&<retval> + 88B] = MODEL_36(D);
Dense.c:236:9: note: 	stmt 0 MEM <float *> [(struct PULSE_Layer *)&<retval> + 88B] = MODEL_36(D);
Dense.c:236:9: note: 	stmt 1 MEM <float *> [(struct PULSE_Layer *)&<retval> + 96B] = _4;
Dense.c:236:9: note: 	stmt 2 MEM <float *> [(struct PULSE_Layer *)&<retval> + 104B] = _11;
Dense.c:236:9: note: 	stmt 3 MEM <float *> [(struct PULSE_Layer *)&<retval> + 112B] = _12;
Dense.c:236:9: note: 	children 0x7581b58
Dense.c:236:9: note: node (external) 0x7581b58 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Dense.c:236:9: note: 	{ MODEL_36(D), _4, _11, _12 }
Dense.c:236:9: note: ------>vectorizing SLP node starting from: MEM <float *> [(struct PULSE_Layer *)&<retval> + 88B] = MODEL_36(D);
Dense.c:236:9: note: vect_is_simple_use: operand MODEL_36(D) + _3, type of def: internal
Dense.c:236:9: note: vect_is_simple_use: operand aligned_alloc (64, _10), type of def: internal
Dense.c:236:9: note: vect_is_simple_use: operand aligned_alloc (64, _10), type of def: internal
Dense.c:236:9: note: transform store. ncopies = 1
Dense.c:236:9: note: create vector_type-pointer variable to type: vector(4) long unsigned int  vectorizing a pointer ref: MEM <float *> [(struct PULSE_Layer *)&<retval> + 88B]
Dense.c:236:9: note: created &MEM <float *> [(struct PULSE_Layer *)&<retval> + 88B]
Dense.c:236:9: note: add new stmt: MEM <vector(4) long unsigned int> [(struct PULSE_Layer *)&<retval> + 88B] = _103;
Dense.c:236:9: note: vectorizing stmts using SLP.
Dense.c:236:9: note: ***** The result for vector mode V32QI would be the same
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:4:18: note: vectorized 0 loops in function.
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_4, inputs_15, _3);
PULSE.c:8:2: missed: statement clobbers memory: _5 (layer_17);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_12, pretmp_26, _9);
PULSE.c:13:28: note: ***** Analysis failed with vector mode V8SI
PULSE.c:13:28: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:22:2: missed: statement clobbers memory: _1 (layer_10(D));
PULSE.c:22:2: missed: statement clobbers memory: _14 (_2);
PULSE.c:22:2: missed: statement clobbers memory: _21 (_15);
PULSE.c:22:2: missed: statement clobbers memory: _28 (_22);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_29);
PULSE.c:26:3: missed: statement clobbers memory: memset (_34, 0, _32);
PULSE.c:26:3: missed: statement clobbers memory: memset (_27, 0, _25);
PULSE.c:26:3: missed: statement clobbers memory: memset (_20, 0, _18);
PULSE.c:26:3: missed: statement clobbers memory: memset (_7, 0, _5);
PULSE.c:28:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:28:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:32:6: note: vectorized 1 loops in function.
PULSE.c:34:8: missed: statement clobbers memory: _1 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_2);
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _9 = rand ();
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8SI
PULSE.c:32:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:61:16: missed: couldn't vectorize loop
PULSE.c:61:16: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:64:17: missed: couldn't vectorize loop
PULSE.c:64:17: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:73:19: missed: couldn't vectorize loop
PULSE.c:73:19: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:53:22: missed: couldn't vectorize loop
PULSE.c:53:22: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:47:6: note: vectorized 1 loops in function.
PULSE.c:48:1: missed: statement clobbers memory: saved_stack.7_39 = __builtin_stack_save ();
PULSE.c:49:46: missed: statement clobbers memory: _1 = PULSE_GetLossFunctionPtr (loss_function_40(D));
PULSE.c:60:10: missed: statement clobbers memory: random.4_46 = __builtin_alloca_with_align (_4, 32);
PULSE.c:34:8: missed: statement clobbers memory: _61 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_62);
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _72 = rand ();
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_98, inputs_93, _97);
PULSE.c:8:2: missed: statement clobbers memory: _99 (layer_94);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_105, _104, _103);
PULSE.c:67:11: missed: statement clobbers memory: loss_55 = PULSE_GetLoss_42 (_17, _16, _12, _11);
PULSE.c:22:2: missed: statement clobbers memory: _86 (output_34);
PULSE.c:22:2: missed: statement clobbers memory: _108 (_87);
PULSE.c:22:2: missed: statement clobbers memory: _115 (_109);
PULSE.c:22:2: missed: statement clobbers memory: _122 (_116);
PULSE.c:22:2: missed: statement clobbers memory: _129 (_123);
PULSE.c:22:2: missed: statement clobbers memory: _136 (_130);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_137);
PULSE.c:26:3: missed: statement clobbers memory: memset (_142, 0, _140);
PULSE.c:26:3: missed: statement clobbers memory: memset (_135, 0, _133);
PULSE.c:26:3: missed: statement clobbers memory: memset (_128, 0, _126);
PULSE.c:26:3: missed: statement clobbers memory: memset (_121, 0, _119);
PULSE.c:26:3: missed: statement clobbers memory: memset (_114, 0, _112);
PULSE.c:26:3: missed: statement clobbers memory: memset (_92, 0, _90);
PULSE.c:75:6: missed: statement clobbers memory: _21 (current_191, args);
PULSE.c:81:4: missed: statement clobbers memory: printf ("Epoch: %d | Item: %d | Loss: %.10f | Batch Loss: %.10f\r", i_188, j_189, _25, _24);
PULSE.c:47:6: missed: statement clobbers memory: __builtin_stack_restore (saved_stack.7_39);
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4DI
PULSE.c:47:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:91:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:91:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:123:20: missed: couldn't vectorize loop
PULSE.c:123:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:123:20: missed: couldn't vectorize loop
PULSE.c:123:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:103:20: missed: couldn't vectorize loop
PULSE.c:103:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:103:20: missed: couldn't vectorize loop
PULSE.c:103:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:93:13: note: vectorized 0 loops in function.
PULSE.c:96:39: missed: statement clobbers memory: layers_35 = malloc (_3);
PULSE.c:99:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:116:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:117:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:118:46: missed: statement clobbers memory: WEIGHTS_128 = aligned_alloc (64, 0);
PULSE.c:109:26: missed: not vectorized: more than one data ref in stmt: args = MEM[(struct PULSE_DenseLayerArgs * {ref-all})addr.104_79];
PULSE.c:110:21: missed: statement clobbers memory: _64 = PULSE_GetDenseWeightsSize (args);
PULSE.c:111:16: missed: statement clobbers memory: _67 = PULSE_GetDenseIOSize (args);
PULSE.c:109:26: missed: not vectorized: more than one data ref in stmt: args = MEM[(struct PULSE_DenseLayerArgs * {ref-all})_195];
PULSE.c:110:21: missed: statement clobbers memory: _184 = PULSE_GetDenseWeightsSize (args);
PULSE.c:111:16: missed: statement clobbers memory: _187 = PULSE_GetDenseIOSize (args);
PULSE.c:116:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:117:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:118:46: missed: statement clobbers memory: WEIGHTS_40 = aligned_alloc (64, _5);
PULSE.c:119:41: missed: statement clobbers memory: IO_42 = aligned_alloc (64, _7);
PULSE.c:129:26: missed: not vectorized: more than one data ref in stmt: args = MEM[(struct PULSE_DenseLayerArgs * {ref-all})addr.106_81];
PULSE.c:130:17: missed: statement clobbers memory: *_10 = PULSE_CreateDenseLayer (args, WEIGHTS_PTR_134, IO_42); [return slot optimization]
PULSE.c:131:20: missed: statement clobbers memory: _55 = PULSE_GetDenseWeightsSize (args);
PULSE.c:132:15: missed: statement clobbers memory: PULSE_GetDenseIOSize (args);
PULSE.c:129:26: missed: not vectorized: more than one data ref in stmt: args = MEM[(struct PULSE_DenseLayerArgs * {ref-all})addr.106_132];
PULSE.c:130:17: missed: statement clobbers memory: *_112 = PULSE_CreateDenseLayer (args, WEIGHTS_PTR_143, IO_42); [return slot optimization]
PULSE.c:131:20: missed: statement clobbers memory: _96 = PULSE_GetDenseWeightsSize (args);
PULSE.c:132:15: missed: statement clobbers memory: PULSE_GetDenseIOSize (args);
PULSE.c:138:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:139:9: note: ***** Analysis succeeded with vector mode V8SI
PULSE.c:139:9: note: SLPing BB part
PULSE.c:139:9: note: Costing subgraph: 
PULSE.c:139:9: note: node 0x4280368 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:139:9: note: op template: <retval>.layers = layers_35;
PULSE.c:139:9: note: 	stmt 0 <retval>.layers = layers_35;
PULSE.c:139:9: note: 	stmt 1 <retval>.weights = WEIGHTS_147;
PULSE.c:139:9: note: 	children 0x4280468
PULSE.c:139:9: note: node (external) 0x4280468 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:139:9: note: 	{ layers_35, WEIGHTS_147 }
PULSE.c:139:9: note: Cost model analysis: 
PULSE.c:139:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
PULSE.c:139:9: note: Costing subgraph: 
PULSE.c:139:9: note: node 0x42804e8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:139:9: note: op template: <retval>.io = 0B;
PULSE.c:139:9: note: 	stmt 0 <retval>.io = 0B;
PULSE.c:139:9: note: 	stmt 1 <retval>.fixes = 0B;
PULSE.c:139:9: note: 	children 0x4280568
PULSE.c:139:9: note: node (constant) 0x4280568 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:139:9: note: 	{ 0B, 0B }
PULSE.c:139:9: note: Cost model analysis: 
PULSE.c:139:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
PULSE.c:139:9: note: Basic block will be vectorized using SLP
PULSE.c:139:9: optimized: basic block part vectorized using 16 byte vectors
PULSE.c:139:9: note: Vectorizing SLP tree:
PULSE.c:139:9: note: node 0x4280368 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:139:9: note: op template: <retval>.layers = layers_35;
PULSE.c:139:9: note: 	stmt 0 <retval>.layers = layers_35;
PULSE.c:139:9: note: 	stmt 1 <retval>.weights = WEIGHTS_147;
PULSE.c:139:9: note: 	children 0x4280468
PULSE.c:139:9: note: node (external) 0x4280468 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:139:9: note: 	{ layers_35, WEIGHTS_147 }
PULSE.c:139:9: note: ------>vectorizing SLP node starting from: <retval>.layers = layers_35;
PULSE.c:139:9: note: vect_is_simple_use: operand WEIGHTS_147 = PHI <WEIGHTS_40(36), WEIGHTS_128(25)>, type of def: internal
PULSE.c:139:9: note: conflicting alias set types.
PULSE.c:139:9: note: transform store. ncopies = 1
PULSE.c:139:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.layers
PULSE.c:139:9: note: created &<retval>
PULSE.c:139:9: note: add new stmt: MEM <vector(2) long unsigned int> [(void *)&<retval>] = _15;
PULSE.c:139:9: note: vectorizing stmts using SLP.
PULSE.c:139:9: optimized: basic block part vectorized using 16 byte vectors
PULSE.c:139:9: note: Vectorizing SLP tree:
PULSE.c:139:9: note: node 0x42804e8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:139:9: note: op template: <retval>.io = 0B;
PULSE.c:139:9: note: 	stmt 0 <retval>.io = 0B;
PULSE.c:139:9: note: 	stmt 1 <retval>.fixes = 0B;
PULSE.c:139:9: note: 	children 0x4280568
PULSE.c:139:9: note: node (constant) 0x4280568 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:139:9: note: 	{ 0B, 0B }
PULSE.c:139:9: note: ------>vectorizing SLP node starting from: <retval>.io = 0B;
PULSE.c:139:9: note: vect_is_simple_use: operand 0B, type of def: constant
PULSE.c:139:9: note: transform store. ncopies = 1
PULSE.c:139:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.io
PULSE.c:139:9: note: created &<retval>.io
PULSE.c:139:9: note: add new stmt: MEM <vector(2) long unsigned int> [(float * *)&<retval> + 16B] = { 0, 0 };
PULSE.c:139:9: note: vectorizing stmts using SLP.
PULSE.c:139:9: note: ***** The result for vector mode V32QI would be the same
PULSE.c:151:1: note: ***** Analysis failed with vector mode VOID
Dense.c:9:27: missed: couldn't vectorize loop
Dense.c:9:27: missed: not vectorized: unsupported outerloop form.
Dense.c:12:20: missed: couldn't vectorize loop
Dense.c:13:21: missed: not vectorized: complicated access pattern.
Dense.c:6:13: note: vectorized 0 loops in function.
Dense.c:16:2: missed: statement clobbers memory: _28 (pretmp_91, _51, 0);
Dense.c:9:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:9:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:24:27: missed: couldn't vectorize loop
Dense.c:24:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:28:20: optimized: loop vectorized using 32 byte vectors
Dense.c:28:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:28:20: optimized: loop vectorized using 16 byte vectors
Dense.c:28:20: missed: couldn't vectorize loop
Dense.c:30:19: missed: not vectorized: no vectype for stmt: _22 = *_21;
 scalar_type: float
Dense.c:20:13: note: vectorized 1 loops in function.
Dense.c:23:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:24:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:24:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:41:28: missed: couldn't vectorize loop
Dense.c:41:28: missed: not vectorized: unsupported outerloop form.
Dense.c:45:21: optimized: loop vectorized using 32 byte vectors
Dense.c:45:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:45:21: optimized: loop vectorized using 16 byte vectors
Dense.c:37:13: note: vectorized 1 loops in function.
Dense.c:37:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:37:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:41:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:170:10: optimized: loop vectorized using 32 byte vectors
Dense.c:170:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:170:10: optimized: loop vectorized using 16 byte vectors
Dense.c:161:10: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_27, _64);
Dense.c:154:10: optimized: loop vectorized using 32 byte vectors
Dense.c:154:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:154:10: optimized: loop vectorized using 16 byte vectors
Dense.c:145:10: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_14, _56);
Dense.c:136:13: note: vectorized 2 loops in function.
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_14, _56);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_15, { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 });
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_27, _64);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_28, { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 });
Dense.c:136:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:136:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:105:24: missed: couldn't vectorize loop
Dense.c:105:24: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:108:17: missed: couldn't vectorize loop
Dense.c:108:17: missed: not vectorized: number of iterations cannot be computed.
Dense.c:122:24: missed: couldn't vectorize loop
Dense.c:122:24: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:125:17: missed: couldn't vectorize loop
Dense.c:125:17: missed: not vectorized: number of iterations cannot be computed.
Dense.c:90:15: missed: couldn't vectorize loop
Dense.c:90:15: missed: not vectorized: number of iterations cannot be computed.
Dense.c:83:13: note: vectorized 0 loops in function.
Dense.c:86:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:110:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:110:17: note: SLPing BB part
Dense.c:127:17: note: Costing subgraph: 
Dense.c:127:17: note: node 0x83a34b8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:127:17: note: op template: _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 0 _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 1 _198 = (sizetype) wi_137;
Dense.c:127:17: note: 	children 0x83a35b8
Dense.c:127:17: note: node (external) 0x83a35b8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:127:17: note: 	{ j_135, wi_137 }
Dense.c:127:17: note: Cost model analysis: 
Dense.c:127:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:127:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:127:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: Costing subgraph: 
Dense.c:110:17: note: node 0x83a36b8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:110:17: note: op template: _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 0 _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 1 _217 = (sizetype) wi_136;
Dense.c:110:17: note: 	children 0x83a37b8
Dense.c:110:17: note: node (external) 0x83a37b8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:110:17: note: 	{ j_134, wi_136 }
Dense.c:110:17: note: Cost model analysis: 
Dense.c:110:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:110:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:110:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:110:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:110:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:110:17: note: SLPing BB part
Dense.c:127:17: note: Costing subgraph: 
Dense.c:127:17: note: node 0x83a36b8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:127:17: note: op template: _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 0 _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 1 _198 = (sizetype) wi_137;
Dense.c:127:17: note: 	children 0x83a34b8
Dense.c:127:17: note: node (external) 0x83a34b8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:127:17: note: 	{ j_135, wi_137 }
Dense.c:127:17: note: Cost model analysis: 
Dense.c:127:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:127:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:127:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: Costing subgraph: 
Dense.c:110:17: note: node 0x83a3638 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:110:17: note: op template: _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 0 _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 1 _217 = (sizetype) wi_136;
Dense.c:110:17: note: 	children 0x83a3738
Dense.c:110:17: note: node (external) 0x83a3738 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:110:17: note: 	{ j_134, wi_136 }
Dense.c:110:17: note: Cost model analysis: 
Dense.c:110:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:110:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:110:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:105:51: note: ***** Analysis failed with vector mode V8QI
Dense.c:105:51: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:105:51: note: ***** Analysis failed with vector mode V4QI
Dense.c:62:15: missed: couldn't vectorize loop
Dense.c:62:15: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:75:11: optimized: loop vectorized using 32 byte vectors
Dense.c:75:11: optimized: loop vectorized using 16 byte vectors
Dense.c:66:11: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:881:10: missed: not vectorized: no vectype for stmt: _53 = MEM[(__m256 * {ref-all})w_ptr_82];
 scalar_type: __m256
Dense.c:54:13: note: vectorized 1 loops in function.
Dense.c:57:2: missed: statement clobbers memory: memcpy (_4, dense$baiases_63, _3);
Dense.c:79:2: missed: statement clobbers memory: _27 (pretmp_163, _68, 0);
Dense.c:54:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:54:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:179:107: note: ***** Analysis failed with vector mode V8SI
Dense.c:179:107: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
Dense.c:180:85: note: ***** Analysis failed with vector mode V8SI
Dense.c:180:85: note: ***** The result for vector mode V32QI would be the same
Dense.c:180:85: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:180:85: note: ***** Analysis failed with vector mode V16QI
Dense.c:180:85: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:180:85: note: ***** Analysis failed with vector mode V8QI
Dense.c:180:85: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:180:85: note: ***** Analysis failed with vector mode V4QI
Dense.c:192:19: missed: couldn't vectorize loop
Dense.c:192:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:182:13: note: vectorized 0 loops in function.
Dense.c:188:37: missed: statement clobbers memory: _9 = aligned_alloc (64, _8);
Dense.c:189:34: missed: statement clobbers memory: _11 = aligned_alloc (64, _10);
Dense.c:190:35: missed: statement clobbers memory: _12 = aligned_alloc (64, _10);
Dense.c:193:38: missed: statement clobbers memory: _13 = rand ();
Dense.c:193:72: missed: statement clobbers memory: _77 = sqrt (_20);
Dense.c:206:19: missed: statement clobbers memory: _31 = PULSE_GetActivationFunctionPtr (_30);
Dense.c:222:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:223:4: missed: statement clobbers memory: exit (1);
Dense.c:227:9: note: ***** Analysis succeeded with vector mode V8SI
Dense.c:227:9: note: SLPing BB part
Dense.c:227:9: note: Costing subgraph: 
Dense.c:227:9: note: node 0x8229468 (max_nunits=2, refcnt=1) vector(2) unsigned int
Dense.c:227:9: note: op template: <retval>.n_inputs = args$n_inputs_51;
Dense.c:227:9: note: 	stmt 0 <retval>.n_inputs = args$n_inputs_51;
Dense.c:227:9: note: 	stmt 1 <retval>.n_outputs = args$n_outputs_52;
Dense.c:227:9: note: 	children 0x82294e8
Dense.c:227:9: note: node 0x82294e8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Dense.c:227:9: note: op template: args$n_inputs_51 = args.n_inputs;
Dense.c:227:9: note: 	stmt 0 args$n_inputs_51 = args.n_inputs;
Dense.c:227:9: note: 	stmt 1 args$n_outputs_52 = args.n_outputs;
Dense.c:227:9: note: Cost model analysis: 
Dense.c:227:9: note: Cost model analysis for part in loop 0:
  Vector cost: 40
  Scalar cost: 56
Dense.c:227:9: note: Costing subgraph: 
Dense.c:227:9: note: node 0x82295e8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Dense.c:227:9: note: op template: <retval>.inputs = IO_41(D);
Dense.c:227:9: note: 	stmt 0 <retval>.inputs = IO_41(D);
Dense.c:227:9: note: 	stmt 1 <retval>.outputs = _29;
Dense.c:227:9: note: 	children 0x8229668
Dense.c:227:9: note: node (external) 0x8229668 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Dense.c:227:9: note: 	{ IO_41(D), _29 }
Dense.c:227:9: note: Cost model analysis: 
Dense.c:227:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Dense.c:227:9: note: Costing subgraph: 
Dense.c:227:9: note: node 0x8229768 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Dense.c:227:9: note: op template: <retval>.feed = layer$feed_40;
Dense.c:227:9: note: 	stmt 0 <retval>.feed = layer$feed_40;
Dense.c:227:9: note: 	stmt 1 <retval>.back = layer$back_49;
Dense.c:227:9: note: 	children 0x8229968
Dense.c:227:9: note: node (external) 0x8229968 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Dense.c:227:9: note: 	{ layer$feed_40, layer$back_49 }
Dense.c:227:9: note: Cost model analysis: 
Dense.c:227:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Dense.c:227:9: note: Costing subgraph: 
Dense.c:227:9: note: node 0x8229868 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Dense.c:227:9: note: op template: <retval>.parent = 0B;
Dense.c:227:9: note: 	stmt 0 <retval>.parent = 0B;
Dense.c:227:9: note: 	stmt 1 <retval>.child = 0B;
Dense.c:227:9: note: 	children 0x82299e8
Dense.c:227:9: note: node (constant) 0x82299e8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Dense.c:227:9: note: 	{ 0B, 0B }
Dense.c:227:9: note: Cost model analysis: 
Dense.c:227:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Dense.c:227:9: note: Costing subgraph: 
Dense.c:227:9: note: node 0x8229ae8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Dense.c:227:9: note: op template: MEM <float *> [(struct PULSE_Layer *)&<retval> + 88B] = MODEL_36(D);
Dense.c:227:9: note: 	stmt 0 MEM <float *> [(struct PULSE_Layer *)&<retval> + 88B] = MODEL_36(D);
Dense.c:227:9: note: 	stmt 1 MEM <float *> [(struct PULSE_Layer *)&<retval> + 96B] = _4;
Dense.c:227:9: note: 	stmt 2 MEM <float *> [(struct PULSE_Layer *)&<retval> + 104B] = _11;
Dense.c:227:9: note: 	stmt 3 MEM <float *> [(struct PULSE_Layer *)&<retval> + 112B] = _12;
Dense.c:227:9: note: 	children 0x8229b68
Dense.c:227:9: note: node (external) 0x8229b68 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Dense.c:227:9: note: 	{ MODEL_36(D), _4, _11, _12 }
Dense.c:227:9: note: Cost model analysis: 
Dense.c:227:9: note: Cost model analysis for part in loop 0:
  Vector cost: 64
  Scalar cost: 64
Dense.c:227:9: note: Basic block will be vectorized using SLP
Dense.c:227:9: optimized: basic block part vectorized using 8 byte vectors
Dense.c:227:9: note: Vectorizing SLP tree:
Dense.c:227:9: note: node 0x8229468 (max_nunits=2, refcnt=1) vector(2) unsigned int
Dense.c:227:9: note: op template: <retval>.n_inputs = args$n_inputs_51;
Dense.c:227:9: note: 	stmt 0 <retval>.n_inputs = args$n_inputs_51;
Dense.c:227:9: note: 	stmt 1 <retval>.n_outputs = args$n_outputs_52;
Dense.c:227:9: note: 	children 0x82294e8
Dense.c:227:9: note: node 0x82294e8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Dense.c:227:9: note: op template: args$n_inputs_51 = args.n_inputs;
Dense.c:227:9: note: 	stmt 0 args$n_inputs_51 = args.n_inputs;
Dense.c:227:9: note: 	stmt 1 args$n_outputs_52 = args.n_outputs;
Dense.c:227:9: note: ------>vectorizing SLP node starting from: args$n_inputs_51 = args.n_inputs;
Dense.c:227:9: note: transform load. ncopies = 1
Dense.c:227:9: note: conflicting alias set types.
Dense.c:227:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: args.n_inputs
Dense.c:227:9: note: created &args
Dense.c:227:9: note: add new stmt: vect_args_n_inputs_51.504_86 = MEM <vector(2) unsigned int> [(void *)&args];
Dense.c:227:9: note: extracting lane for live stmt args$n_inputs_51 = args.n_inputs;
Dense.c:227:9: note: extracting lane for live stmt args$n_outputs_52 = args.n_outputs;
Dense.c:227:9: note: ------>vectorizing SLP node starting from: <retval>.n_inputs = args$n_inputs_51;
Dense.c:227:9: note: vect_is_simple_use: operand args.n_inputs, type of def: internal
Dense.c:227:9: note: vect_is_simple_use: operand args.n_outputs, type of def: internal
Dense.c:227:9: note: transform store. ncopies = 1
Dense.c:227:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: <retval>.n_inputs
Dense.c:227:9: note: created &<retval>.n_inputs
Dense.c:227:9: note: add new stmt: MEM <vector(2) unsigned int> [(unsigned int *)&<retval> + 128B] = vect_args_n_inputs_51.504_86;
Dense.c:227:9: note: vectorizing stmts using SLP.
Dense.c:227:9: optimized: basic block part vectorized using 16 byte vectors
Dense.c:227:9: note: Vectorizing SLP tree:
Dense.c:227:9: note: node 0x82295e8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Dense.c:227:9: note: op template: <retval>.inputs = IO_41(D);
Dense.c:227:9: note: 	stmt 0 <retval>.inputs = IO_41(D);
Dense.c:227:9: note: 	stmt 1 <retval>.outputs = _29;
Dense.c:227:9: note: 	children 0x8229668
Dense.c:227:9: note: node (external) 0x8229668 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Dense.c:227:9: note: 	{ IO_41(D), _29 }
Dense.c:227:9: note: ------>vectorizing SLP node starting from: <retval>.inputs = IO_41(D);
Dense.c:227:9: note: vect_is_simple_use: operand IO_41(D) + _28, type of def: internal
Dense.c:227:9: note: transform store. ncopies = 1
Dense.c:227:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.inputs
Dense.c:227:9: note: created &<retval>
Dense.c:227:9: note: add new stmt: MEM <vector(2) long unsigned int> [(float * *)&<retval>] = _92;
Dense.c:227:9: note: vectorizing stmts using SLP.
Dense.c:227:9: optimized: basic block part vectorized using 16 byte vectors
Dense.c:227:9: note: Vectorizing SLP tree:
Dense.c:227:9: note: node 0x8229768 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Dense.c:227:9: note: op template: <retval>.feed = layer$feed_40;
Dense.c:227:9: note: 	stmt 0 <retval>.feed = layer$feed_40;
Dense.c:227:9: note: 	stmt 1 <retval>.back = layer$back_49;
Dense.c:227:9: note: 	children 0x8229968
Dense.c:227:9: note: node (external) 0x8229968 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Dense.c:227:9: note: 	{ layer$feed_40, layer$back_49 }
Dense.c:227:9: note: ------>vectorizing SLP node starting from: <retval>.feed = layer$feed_40;
Dense.c:227:9: note: vect_is_simple_use: operand layer$back_49 = PHI <layer$back_55(D)(11), _BackDense(9), _SIMD_BackDense(15)>, type of def: internal
Dense.c:227:9: note: transform store. ncopies = 1
Dense.c:227:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.feed
Dense.c:227:9: note: created &<retval>.feed
Dense.c:227:9: note: add new stmt: MEM <vector(2) long unsigned int> [(void (*<T921>) (struct PULSE_Layer *) *)&<retval> + 32B] = _96;
Dense.c:227:9: note: vectorizing stmts using SLP.
Dense.c:227:9: optimized: basic block part vectorized using 16 byte vectors
Dense.c:227:9: note: Vectorizing SLP tree:
Dense.c:227:9: note: node 0x8229868 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Dense.c:227:9: note: op template: <retval>.parent = 0B;
Dense.c:227:9: note: 	stmt 0 <retval>.parent = 0B;
Dense.c:227:9: note: 	stmt 1 <retval>.child = 0B;
Dense.c:227:9: note: 	children 0x82299e8
Dense.c:227:9: note: node (constant) 0x82299e8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Dense.c:227:9: note: 	{ 0B, 0B }
Dense.c:227:9: note: ------>vectorizing SLP node starting from: <retval>.parent = 0B;
Dense.c:227:9: note: vect_is_simple_use: operand 0B, type of def: constant
Dense.c:227:9: note: transform store. ncopies = 1
Dense.c:227:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.parent
Dense.c:227:9: note: created &<retval>.parent
Dense.c:227:9: note: add new stmt: MEM <vector(2) long unsigned int> [(struct PULSE_Layer * *)&<retval> + 72B] = { 0, 0 };
Dense.c:227:9: note: vectorizing stmts using SLP.
Dense.c:227:9: optimized: basic block part vectorized using 32 byte vectors
Dense.c:227:9: note: Vectorizing SLP tree:
Dense.c:227:9: note: node 0x8229ae8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Dense.c:227:9: note: op template: MEM <float *> [(struct PULSE_Layer *)&<retval> + 88B] = MODEL_36(D);
Dense.c:227:9: note: 	stmt 0 MEM <float *> [(struct PULSE_Layer *)&<retval> + 88B] = MODEL_36(D);
Dense.c:227:9: note: 	stmt 1 MEM <float *> [(struct PULSE_Layer *)&<retval> + 96B] = _4;
Dense.c:227:9: note: 	stmt 2 MEM <float *> [(struct PULSE_Layer *)&<retval> + 104B] = _11;
Dense.c:227:9: note: 	stmt 3 MEM <float *> [(struct PULSE_Layer *)&<retval> + 112B] = _12;
Dense.c:227:9: note: 	children 0x8229b68
Dense.c:227:9: note: node (external) 0x8229b68 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Dense.c:227:9: note: 	{ MODEL_36(D), _4, _11, _12 }
Dense.c:227:9: note: ------>vectorizing SLP node starting from: MEM <float *> [(struct PULSE_Layer *)&<retval> + 88B] = MODEL_36(D);
Dense.c:227:9: note: vect_is_simple_use: operand MODEL_36(D) + _3, type of def: internal
Dense.c:227:9: note: vect_is_simple_use: operand aligned_alloc (64, _10), type of def: internal
Dense.c:227:9: note: vect_is_simple_use: operand aligned_alloc (64, _10), type of def: internal
Dense.c:227:9: note: transform store. ncopies = 1
Dense.c:227:9: note: create vector_type-pointer variable to type: vector(4) long unsigned int  vectorizing a pointer ref: MEM <float *> [(struct PULSE_Layer *)&<retval> + 88B]
Dense.c:227:9: note: created &MEM <float *> [(struct PULSE_Layer *)&<retval> + 88B]
Dense.c:227:9: note: add new stmt: MEM <vector(4) long unsigned int> [(struct PULSE_Layer *)&<retval> + 88B] = _103;
Dense.c:227:9: note: vectorizing stmts using SLP.
Dense.c:227:9: note: ***** The result for vector mode V32QI would be the same
Dense.c:9:27: missed: couldn't vectorize loop
Dense.c:9:27: missed: not vectorized: unsupported outerloop form.
Dense.c:12:20: missed: couldn't vectorize loop
Dense.c:13:21: missed: not vectorized: complicated access pattern.
Dense.c:6:13: note: vectorized 0 loops in function.
Dense.c:16:2: missed: statement clobbers memory: _28 (pretmp_91, _51, 0);
Dense.c:9:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:9:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:24:27: missed: couldn't vectorize loop
Dense.c:24:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:28:20: optimized: loop vectorized using 32 byte vectors
Dense.c:28:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:28:20: optimized: loop vectorized using 16 byte vectors
Dense.c:28:20: missed: couldn't vectorize loop
Dense.c:30:19: missed: not vectorized: no vectype for stmt: _22 = *_21;
 scalar_type: float
Dense.c:20:13: note: vectorized 1 loops in function.
Dense.c:23:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:24:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:24:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:41:28: missed: couldn't vectorize loop
Dense.c:41:28: missed: not vectorized: unsupported outerloop form.
Dense.c:45:21: optimized: loop vectorized using 32 byte vectors
Dense.c:45:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:45:21: optimized: loop vectorized using 16 byte vectors
Dense.c:37:13: note: vectorized 1 loops in function.
Dense.c:37:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:37:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:41:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:170:10: optimized: loop vectorized using 32 byte vectors
Dense.c:170:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:170:10: optimized: loop vectorized using 16 byte vectors
Dense.c:161:10: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_27, _64);
Dense.c:154:10: optimized: loop vectorized using 32 byte vectors
Dense.c:154:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:154:10: optimized: loop vectorized using 16 byte vectors
Dense.c:145:10: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_14, _56);
Dense.c:136:13: note: vectorized 2 loops in function.
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_14, _56);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_15, { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 });
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_27, _64);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_28, { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 });
Dense.c:136:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:136:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:105:24: missed: couldn't vectorize loop
Dense.c:105:24: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:108:17: missed: couldn't vectorize loop
Dense.c:108:17: missed: not vectorized: number of iterations cannot be computed.
Dense.c:122:24: missed: couldn't vectorize loop
Dense.c:122:24: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:125:17: missed: couldn't vectorize loop
Dense.c:125:17: missed: not vectorized: number of iterations cannot be computed.
Dense.c:90:15: missed: couldn't vectorize loop
Dense.c:90:15: missed: not vectorized: number of iterations cannot be computed.
Dense.c:83:13: note: vectorized 0 loops in function.
Dense.c:86:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:110:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:110:17: note: SLPing BB part
Dense.c:127:17: note: Costing subgraph: 
Dense.c:127:17: note: node 0x868d448 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:127:17: note: op template: _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 0 _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 1 _198 = (sizetype) wi_137;
Dense.c:127:17: note: 	children 0x868d548
Dense.c:127:17: note: node (external) 0x868d548 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:127:17: note: 	{ j_135, wi_137 }
Dense.c:127:17: note: Cost model analysis: 
Dense.c:127:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:127:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:127:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: Costing subgraph: 
Dense.c:110:17: note: node 0x868d648 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:110:17: note: op template: _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 0 _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 1 _217 = (sizetype) wi_136;
Dense.c:110:17: note: 	children 0x868d748
Dense.c:110:17: note: node (external) 0x868d748 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:110:17: note: 	{ j_134, wi_136 }
Dense.c:110:17: note: Cost model analysis: 
Dense.c:110:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:110:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:110:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:110:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:110:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:110:17: note: SLPing BB part
Dense.c:127:17: note: Costing subgraph: 
Dense.c:127:17: note: node 0x868d648 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:127:17: note: op template: _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 0 _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 1 _198 = (sizetype) wi_137;
Dense.c:127:17: note: 	children 0x868d448
Dense.c:127:17: note: node (external) 0x868d448 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:127:17: note: 	{ j_135, wi_137 }
Dense.c:127:17: note: Cost model analysis: 
Dense.c:127:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:127:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:127:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: Costing subgraph: 
Dense.c:110:17: note: node 0x868d5c8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:110:17: note: op template: _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 0 _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 1 _217 = (sizetype) wi_136;
Dense.c:110:17: note: 	children 0x868d6c8
Dense.c:110:17: note: node (external) 0x868d6c8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:110:17: note: 	{ j_134, wi_136 }
Dense.c:110:17: note: Cost model analysis: 
Dense.c:110:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:110:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:110:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:105:51: note: ***** Analysis failed with vector mode V8QI
Dense.c:105:51: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:105:51: note: ***** Analysis failed with vector mode V4QI
Dense.c:62:15: missed: couldn't vectorize loop
Dense.c:62:15: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:75:11: optimized: loop vectorized using 32 byte vectors
Dense.c:75:11: optimized: loop vectorized using 16 byte vectors
Dense.c:66:11: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:881:10: missed: not vectorized: no vectype for stmt: _53 = MEM[(__m256 * {ref-all})w_ptr_82];
 scalar_type: __m256
Dense.c:54:13: note: vectorized 1 loops in function.
Dense.c:57:2: missed: statement clobbers memory: memcpy (_4, dense$baiases_63, _3);
Dense.c:79:2: missed: statement clobbers memory: _27 (pretmp_163, _68, 0);
Dense.c:54:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:54:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:179:107: note: ***** Analysis failed with vector mode V8SI
Dense.c:179:107: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
Dense.c:180:85: note: ***** Analysis failed with vector mode V8SI
Dense.c:180:85: note: ***** The result for vector mode V32QI would be the same
Dense.c:180:85: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:180:85: note: ***** Analysis failed with vector mode V16QI
Dense.c:180:85: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:180:85: note: ***** Analysis failed with vector mode V8QI
Dense.c:180:85: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:180:85: note: ***** Analysis failed with vector mode V4QI
Dense.c:192:19: missed: couldn't vectorize loop
Dense.c:192:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:182:13: note: vectorized 0 loops in function.
Dense.c:188:37: missed: statement clobbers memory: _9 = aligned_alloc (64, _8);
Dense.c:189:34: missed: statement clobbers memory: _11 = aligned_alloc (64, _10);
Dense.c:190:35: missed: statement clobbers memory: _12 = aligned_alloc (64, _10);
Dense.c:193:38: missed: statement clobbers memory: _13 = rand ();
Dense.c:193:72: missed: statement clobbers memory: _77 = sqrt (_20);
Dense.c:206:19: missed: statement clobbers memory: _31 = PULSE_GetActivationFunctionPtr (_30);
Dense.c:222:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:223:4: missed: statement clobbers memory: exit (1);
Dense.c:227:9: note: ***** Analysis succeeded with vector mode V8SI
Dense.c:227:9: note: SLPing BB part
Dense.c:227:9: note: Costing subgraph: 
Dense.c:227:9: note: node 0x855e458 (max_nunits=2, refcnt=1) vector(2) unsigned int
Dense.c:227:9: note: op template: <retval>.n_inputs = args$n_inputs_51;
Dense.c:227:9: note: 	stmt 0 <retval>.n_inputs = args$n_inputs_51;
Dense.c:227:9: note: 	stmt 1 <retval>.n_outputs = args$n_outputs_52;
Dense.c:227:9: note: 	children 0x855e4d8
Dense.c:227:9: note: node 0x855e4d8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Dense.c:227:9: note: op template: args$n_inputs_51 = args.n_inputs;
Dense.c:227:9: note: 	stmt 0 args$n_inputs_51 = args.n_inputs;
Dense.c:227:9: note: 	stmt 1 args$n_outputs_52 = args.n_outputs;
Dense.c:227:9: note: Cost model analysis: 
Dense.c:227:9: note: Cost model analysis for part in loop 0:
  Vector cost: 40
  Scalar cost: 56
Dense.c:227:9: note: Costing subgraph: 
Dense.c:227:9: note: node 0x855e5d8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Dense.c:227:9: note: op template: <retval>.inputs = IO_41(D);
Dense.c:227:9: note: 	stmt 0 <retval>.inputs = IO_41(D);
Dense.c:227:9: note: 	stmt 1 <retval>.outputs = _29;
Dense.c:227:9: note: 	children 0x855e658
Dense.c:227:9: note: node (external) 0x855e658 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Dense.c:227:9: note: 	{ IO_41(D), _29 }
Dense.c:227:9: note: Cost model analysis: 
Dense.c:227:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Dense.c:227:9: note: Costing subgraph: 
Dense.c:227:9: note: node 0x855e758 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Dense.c:227:9: note: op template: <retval>.feed = layer$feed_40;
Dense.c:227:9: note: 	stmt 0 <retval>.feed = layer$feed_40;
Dense.c:227:9: note: 	stmt 1 <retval>.back = layer$back_49;
Dense.c:227:9: note: 	children 0x855e958
Dense.c:227:9: note: node (external) 0x855e958 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Dense.c:227:9: note: 	{ layer$feed_40, layer$back_49 }
Dense.c:227:9: note: Cost model analysis: 
Dense.c:227:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Dense.c:227:9: note: Costing subgraph: 
Dense.c:227:9: note: node 0x855e858 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Dense.c:227:9: note: op template: <retval>.parent = 0B;
Dense.c:227:9: note: 	stmt 0 <retval>.parent = 0B;
Dense.c:227:9: note: 	stmt 1 <retval>.child = 0B;
Dense.c:227:9: note: 	children 0x855e9d8
Dense.c:227:9: note: node (constant) 0x855e9d8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Dense.c:227:9: note: 	{ 0B, 0B }
Dense.c:227:9: note: Cost model analysis: 
Dense.c:227:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Dense.c:227:9: note: Costing subgraph: 
Dense.c:227:9: note: node 0x855ead8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Dense.c:227:9: note: op template: MEM <float *> [(struct PULSE_Layer *)&<retval> + 88B] = MODEL_36(D);
Dense.c:227:9: note: 	stmt 0 MEM <float *> [(struct PULSE_Layer *)&<retval> + 88B] = MODEL_36(D);
Dense.c:227:9: note: 	stmt 1 MEM <float *> [(struct PULSE_Layer *)&<retval> + 96B] = _4;
Dense.c:227:9: note: 	stmt 2 MEM <float *> [(struct PULSE_Layer *)&<retval> + 104B] = _11;
Dense.c:227:9: note: 	stmt 3 MEM <float *> [(struct PULSE_Layer *)&<retval> + 112B] = _12;
Dense.c:227:9: note: 	children 0x855eb58
Dense.c:227:9: note: node (external) 0x855eb58 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Dense.c:227:9: note: 	{ MODEL_36(D), _4, _11, _12 }
Dense.c:227:9: note: Cost model analysis: 
Dense.c:227:9: note: Cost model analysis for part in loop 0:
  Vector cost: 64
  Scalar cost: 64
Dense.c:227:9: note: Basic block will be vectorized using SLP
Dense.c:227:9: optimized: basic block part vectorized using 8 byte vectors
Dense.c:227:9: note: Vectorizing SLP tree:
Dense.c:227:9: note: node 0x855e458 (max_nunits=2, refcnt=1) vector(2) unsigned int
Dense.c:227:9: note: op template: <retval>.n_inputs = args$n_inputs_51;
Dense.c:227:9: note: 	stmt 0 <retval>.n_inputs = args$n_inputs_51;
Dense.c:227:9: note: 	stmt 1 <retval>.n_outputs = args$n_outputs_52;
Dense.c:227:9: note: 	children 0x855e4d8
Dense.c:227:9: note: node 0x855e4d8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Dense.c:227:9: note: op template: args$n_inputs_51 = args.n_inputs;
Dense.c:227:9: note: 	stmt 0 args$n_inputs_51 = args.n_inputs;
Dense.c:227:9: note: 	stmt 1 args$n_outputs_52 = args.n_outputs;
Dense.c:227:9: note: ------>vectorizing SLP node starting from: args$n_inputs_51 = args.n_inputs;
Dense.c:227:9: note: transform load. ncopies = 1
Dense.c:227:9: note: conflicting alias set types.
Dense.c:227:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: args.n_inputs
Dense.c:227:9: note: created &args
Dense.c:227:9: note: add new stmt: vect_args_n_inputs_51.504_86 = MEM <vector(2) unsigned int> [(void *)&args];
Dense.c:227:9: note: extracting lane for live stmt args$n_inputs_51 = args.n_inputs;
Dense.c:227:9: note: extracting lane for live stmt args$n_outputs_52 = args.n_outputs;
Dense.c:227:9: note: ------>vectorizing SLP node starting from: <retval>.n_inputs = args$n_inputs_51;
Dense.c:227:9: note: vect_is_simple_use: operand args.n_inputs, type of def: internal
Dense.c:227:9: note: vect_is_simple_use: operand args.n_outputs, type of def: internal
Dense.c:227:9: note: transform store. ncopies = 1
Dense.c:227:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: <retval>.n_inputs
Dense.c:227:9: note: created &<retval>.n_inputs
Dense.c:227:9: note: add new stmt: MEM <vector(2) unsigned int> [(unsigned int *)&<retval> + 128B] = vect_args_n_inputs_51.504_86;
Dense.c:227:9: note: vectorizing stmts using SLP.
Dense.c:227:9: optimized: basic block part vectorized using 16 byte vectors
Dense.c:227:9: note: Vectorizing SLP tree:
Dense.c:227:9: note: node 0x855e5d8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Dense.c:227:9: note: op template: <retval>.inputs = IO_41(D);
Dense.c:227:9: note: 	stmt 0 <retval>.inputs = IO_41(D);
Dense.c:227:9: note: 	stmt 1 <retval>.outputs = _29;
Dense.c:227:9: note: 	children 0x855e658
Dense.c:227:9: note: node (external) 0x855e658 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Dense.c:227:9: note: 	{ IO_41(D), _29 }
Dense.c:227:9: note: ------>vectorizing SLP node starting from: <retval>.inputs = IO_41(D);
Dense.c:227:9: note: vect_is_simple_use: operand IO_41(D) + _28, type of def: internal
Dense.c:227:9: note: transform store. ncopies = 1
Dense.c:227:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.inputs
Dense.c:227:9: note: created &<retval>
Dense.c:227:9: note: add new stmt: MEM <vector(2) long unsigned int> [(float * *)&<retval>] = _92;
Dense.c:227:9: note: vectorizing stmts using SLP.
Dense.c:227:9: optimized: basic block part vectorized using 16 byte vectors
Dense.c:227:9: note: Vectorizing SLP tree:
Dense.c:227:9: note: node 0x855e758 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Dense.c:227:9: note: op template: <retval>.feed = layer$feed_40;
Dense.c:227:9: note: 	stmt 0 <retval>.feed = layer$feed_40;
Dense.c:227:9: note: 	stmt 1 <retval>.back = layer$back_49;
Dense.c:227:9: note: 	children 0x855e958
Dense.c:227:9: note: node (external) 0x855e958 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Dense.c:227:9: note: 	{ layer$feed_40, layer$back_49 }
Dense.c:227:9: note: ------>vectorizing SLP node starting from: <retval>.feed = layer$feed_40;
Dense.c:227:9: note: vect_is_simple_use: operand layer$back_49 = PHI <layer$back_55(D)(11), _BackDense(9), _SIMD_BackDense(15)>, type of def: internal
Dense.c:227:9: note: transform store. ncopies = 1
Dense.c:227:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.feed
Dense.c:227:9: note: created &<retval>.feed
Dense.c:227:9: note: add new stmt: MEM <vector(2) long unsigned int> [(void (*<T921>) (struct PULSE_Layer *) *)&<retval> + 32B] = _96;
Dense.c:227:9: note: vectorizing stmts using SLP.
Dense.c:227:9: optimized: basic block part vectorized using 16 byte vectors
Dense.c:227:9: note: Vectorizing SLP tree:
Dense.c:227:9: note: node 0x855e858 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Dense.c:227:9: note: op template: <retval>.parent = 0B;
Dense.c:227:9: note: 	stmt 0 <retval>.parent = 0B;
Dense.c:227:9: note: 	stmt 1 <retval>.child = 0B;
Dense.c:227:9: note: 	children 0x855e9d8
Dense.c:227:9: note: node (constant) 0x855e9d8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Dense.c:227:9: note: 	{ 0B, 0B }
Dense.c:227:9: note: ------>vectorizing SLP node starting from: <retval>.parent = 0B;
Dense.c:227:9: note: vect_is_simple_use: operand 0B, type of def: constant
Dense.c:227:9: note: transform store. ncopies = 1
Dense.c:227:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.parent
Dense.c:227:9: note: created &<retval>.parent
Dense.c:227:9: note: add new stmt: MEM <vector(2) long unsigned int> [(struct PULSE_Layer * *)&<retval> + 72B] = { 0, 0 };
Dense.c:227:9: note: vectorizing stmts using SLP.
Dense.c:227:9: optimized: basic block part vectorized using 32 byte vectors
Dense.c:227:9: note: Vectorizing SLP tree:
Dense.c:227:9: note: node 0x855ead8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Dense.c:227:9: note: op template: MEM <float *> [(struct PULSE_Layer *)&<retval> + 88B] = MODEL_36(D);
Dense.c:227:9: note: 	stmt 0 MEM <float *> [(struct PULSE_Layer *)&<retval> + 88B] = MODEL_36(D);
Dense.c:227:9: note: 	stmt 1 MEM <float *> [(struct PULSE_Layer *)&<retval> + 96B] = _4;
Dense.c:227:9: note: 	stmt 2 MEM <float *> [(struct PULSE_Layer *)&<retval> + 104B] = _11;
Dense.c:227:9: note: 	stmt 3 MEM <float *> [(struct PULSE_Layer *)&<retval> + 112B] = _12;
Dense.c:227:9: note: 	children 0x855eb58
Dense.c:227:9: note: node (external) 0x855eb58 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Dense.c:227:9: note: 	{ MODEL_36(D), _4, _11, _12 }
Dense.c:227:9: note: ------>vectorizing SLP node starting from: MEM <float *> [(struct PULSE_Layer *)&<retval> + 88B] = MODEL_36(D);
Dense.c:227:9: note: vect_is_simple_use: operand MODEL_36(D) + _3, type of def: internal
Dense.c:227:9: note: vect_is_simple_use: operand aligned_alloc (64, _10), type of def: internal
Dense.c:227:9: note: vect_is_simple_use: operand aligned_alloc (64, _10), type of def: internal
Dense.c:227:9: note: transform store. ncopies = 1
Dense.c:227:9: note: create vector_type-pointer variable to type: vector(4) long unsigned int  vectorizing a pointer ref: MEM <float *> [(struct PULSE_Layer *)&<retval> + 88B]
Dense.c:227:9: note: created &MEM <float *> [(struct PULSE_Layer *)&<retval> + 88B]
Dense.c:227:9: note: add new stmt: MEM <vector(4) long unsigned int> [(struct PULSE_Layer *)&<retval> + 88B] = _103;
Dense.c:227:9: note: vectorizing stmts using SLP.
Dense.c:227:9: note: ***** The result for vector mode V32QI would be the same
Activations.c:17:19: optimized: loop vectorized using 32 byte vectors
Activations.c:17:19: optimized: loop vectorized using 16 byte vectors
Activations.c:17:19: optimized: loop vectorized using 32 byte vectors
Activations.c:17:19: optimized: loop vectorized using 16 byte vectors
Activations.c:14:13: note: vectorized 2 loops in function.
Activations.c:14:13: note: ***** Analysis failed with vector mode V8SF
Activations.c:14:13: note: ***** The result for vector mode V32QI would be the same
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V16QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V16QI
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V8QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V8QI
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V4QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V4QI
Activations.c:28:19: missed: couldn't vectorize loop
Activations.c:28:19: missed: not vectorized: unsupported control flow in loop.
Activations.c:28:19: optimized: loop vectorized using 32 byte vectors
Activations.c:28:19: optimized: loop vectorized using 16 byte vectors
Activations.c:25:13: note: vectorized 1 loops in function.
Activations.c:25:13: note: ***** Analysis failed with vector mode V8SF
Activations.c:25:13: note: ***** The result for vector mode V32QI would be the same
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V16QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V16QI
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V8QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V8QI
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V4QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V4QI
Activations.c:38:1: note: ***** Analysis failed with vector mode VOID
Activations.c:5:19: missed: couldn't vectorize loop
Activations.c:9:21: missed: statement clobbers memory: _36 = expf (_18);
Activations.c:5:19: missed: couldn't vectorize loop
Activations.c:9:21: missed: statement clobbers memory: _12 = expf (_11);
Activations.c:3:13: note: vectorized 0 loops in function.
Activations.c:9:21: missed: statement clobbers memory: _12 = expf (_11);
Activations.c:9:21: missed: statement clobbers memory: _36 = expf (_18);
Activations.c:11:1: note: ***** Analysis failed with vector mode V8SF
Activations.c:11:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Activations.c:44:2: note: ***** Analysis failed with vector mode VOID
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:4:18: note: vectorized 0 loops in function.
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_4, inputs_15, _3);
PULSE.c:8:2: missed: statement clobbers memory: _5 (layer_17);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_12, pretmp_26, _9);
PULSE.c:13:28: note: ***** Analysis failed with vector mode V8SI
PULSE.c:13:28: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:22:2: missed: statement clobbers memory: _1 (layer_10(D));
PULSE.c:22:2: missed: statement clobbers memory: _14 (_2);
PULSE.c:22:2: missed: statement clobbers memory: _21 (_15);
PULSE.c:22:2: missed: statement clobbers memory: _28 (_22);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_29);
PULSE.c:26:3: missed: statement clobbers memory: memset (_34, 0, _32);
PULSE.c:26:3: missed: statement clobbers memory: memset (_27, 0, _25);
PULSE.c:26:3: missed: statement clobbers memory: memset (_20, 0, _18);
PULSE.c:26:3: missed: statement clobbers memory: memset (_7, 0, _5);
PULSE.c:28:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:28:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:32:6: note: vectorized 1 loops in function.
PULSE.c:34:8: missed: statement clobbers memory: _1 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_2);
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _9 = rand ();
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8SI
PULSE.c:32:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:61:16: missed: couldn't vectorize loop
PULSE.c:61:16: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:64:17: missed: couldn't vectorize loop
PULSE.c:64:17: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:73:19: missed: couldn't vectorize loop
PULSE.c:73:19: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:53:22: missed: couldn't vectorize loop
PULSE.c:53:22: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:47:6: note: vectorized 1 loops in function.
PULSE.c:48:1: missed: statement clobbers memory: saved_stack.7_39 = __builtin_stack_save ();
PULSE.c:49:46: missed: statement clobbers memory: _1 = PULSE_GetLossFunctionPtr (loss_function_40(D));
PULSE.c:60:10: missed: statement clobbers memory: random.4_46 = __builtin_alloca_with_align (_4, 32);
PULSE.c:34:8: missed: statement clobbers memory: _61 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_62);
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _72 = rand ();
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_98, inputs_93, _97);
PULSE.c:8:2: missed: statement clobbers memory: _99 (layer_94);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_105, _104, _103);
PULSE.c:67:11: missed: statement clobbers memory: loss_55 = PULSE_GetLoss_42 (_17, _16, _12, _11);
PULSE.c:22:2: missed: statement clobbers memory: _86 (output_34);
PULSE.c:22:2: missed: statement clobbers memory: _108 (_87);
PULSE.c:22:2: missed: statement clobbers memory: _115 (_109);
PULSE.c:22:2: missed: statement clobbers memory: _122 (_116);
PULSE.c:22:2: missed: statement clobbers memory: _129 (_123);
PULSE.c:22:2: missed: statement clobbers memory: _136 (_130);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_137);
PULSE.c:26:3: missed: statement clobbers memory: memset (_142, 0, _140);
PULSE.c:26:3: missed: statement clobbers memory: memset (_135, 0, _133);
PULSE.c:26:3: missed: statement clobbers memory: memset (_128, 0, _126);
PULSE.c:26:3: missed: statement clobbers memory: memset (_121, 0, _119);
PULSE.c:26:3: missed: statement clobbers memory: memset (_114, 0, _112);
PULSE.c:26:3: missed: statement clobbers memory: memset (_92, 0, _90);
PULSE.c:75:6: missed: statement clobbers memory: _21 (current_191, args);
PULSE.c:81:4: missed: statement clobbers memory: printf ("Epoch: %d | Item: %d | Loss: %.10f | Batch Loss: %.10f\r", i_188, j_189, _25, _24);
PULSE.c:47:6: missed: statement clobbers memory: __builtin_stack_restore (saved_stack.7_39);
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4DI
PULSE.c:47:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:91:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:91:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:123:20: missed: couldn't vectorize loop
PULSE.c:123:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:123:20: missed: couldn't vectorize loop
PULSE.c:123:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:103:20: missed: couldn't vectorize loop
PULSE.c:103:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:103:20: missed: couldn't vectorize loop
PULSE.c:103:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:93:13: note: vectorized 0 loops in function.
PULSE.c:96:39: missed: statement clobbers memory: layers_35 = malloc (_3);
PULSE.c:99:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:116:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:117:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:118:46: missed: statement clobbers memory: WEIGHTS_128 = aligned_alloc (64, 0);
PULSE.c:109:26: missed: not vectorized: more than one data ref in stmt: args = MEM[(struct PULSE_DenseLayerArgs * {ref-all})addr.104_79];
PULSE.c:110:21: missed: statement clobbers memory: _64 = PULSE_GetDenseWeightsSize (args);
PULSE.c:111:16: missed: statement clobbers memory: _67 = PULSE_GetDenseIOSize (args);
PULSE.c:109:26: missed: not vectorized: more than one data ref in stmt: args = MEM[(struct PULSE_DenseLayerArgs * {ref-all})_195];
PULSE.c:110:21: missed: statement clobbers memory: _184 = PULSE_GetDenseWeightsSize (args);
PULSE.c:111:16: missed: statement clobbers memory: _187 = PULSE_GetDenseIOSize (args);
PULSE.c:116:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:117:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:118:46: missed: statement clobbers memory: WEIGHTS_40 = aligned_alloc (64, _5);
PULSE.c:119:41: missed: statement clobbers memory: IO_42 = aligned_alloc (64, _7);
PULSE.c:129:26: missed: not vectorized: more than one data ref in stmt: args = MEM[(struct PULSE_DenseLayerArgs * {ref-all})addr.106_81];
PULSE.c:130:17: missed: statement clobbers memory: *_10 = PULSE_CreateDenseLayer (args, WEIGHTS_PTR_134, IO_42); [return slot optimization]
PULSE.c:131:20: missed: statement clobbers memory: _55 = PULSE_GetDenseWeightsSize (args);
PULSE.c:132:15: missed: statement clobbers memory: PULSE_GetDenseIOSize (args);
PULSE.c:129:26: missed: not vectorized: more than one data ref in stmt: args = MEM[(struct PULSE_DenseLayerArgs * {ref-all})addr.106_132];
PULSE.c:130:17: missed: statement clobbers memory: *_112 = PULSE_CreateDenseLayer (args, WEIGHTS_PTR_143, IO_42); [return slot optimization]
PULSE.c:131:20: missed: statement clobbers memory: _96 = PULSE_GetDenseWeightsSize (args);
PULSE.c:132:15: missed: statement clobbers memory: PULSE_GetDenseIOSize (args);
PULSE.c:138:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:139:9: note: ***** Analysis succeeded with vector mode V8SI
PULSE.c:139:9: note: SLPing BB part
PULSE.c:139:9: note: Costing subgraph: 
PULSE.c:139:9: note: node 0x410ab08 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:139:9: note: op template: <retval>.layers = layers_35;
PULSE.c:139:9: note: 	stmt 0 <retval>.layers = layers_35;
PULSE.c:139:9: note: 	stmt 1 <retval>.weights = WEIGHTS_147;
PULSE.c:139:9: note: 	children 0x410ac08
PULSE.c:139:9: note: node (external) 0x410ac08 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:139:9: note: 	{ layers_35, WEIGHTS_147 }
PULSE.c:139:9: note: Cost model analysis: 
PULSE.c:139:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
PULSE.c:139:9: note: Costing subgraph: 
PULSE.c:139:9: note: node 0x410ac88 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:139:9: note: op template: <retval>.io = 0B;
PULSE.c:139:9: note: 	stmt 0 <retval>.io = 0B;
PULSE.c:139:9: note: 	stmt 1 <retval>.fixes = 0B;
PULSE.c:139:9: note: 	children 0x410ad08
PULSE.c:139:9: note: node (constant) 0x410ad08 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:139:9: note: 	{ 0B, 0B }
PULSE.c:139:9: note: Cost model analysis: 
PULSE.c:139:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
PULSE.c:139:9: note: Basic block will be vectorized using SLP
PULSE.c:139:9: optimized: basic block part vectorized using 16 byte vectors
PULSE.c:139:9: note: Vectorizing SLP tree:
PULSE.c:139:9: note: node 0x410ab08 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:139:9: note: op template: <retval>.layers = layers_35;
PULSE.c:139:9: note: 	stmt 0 <retval>.layers = layers_35;
PULSE.c:139:9: note: 	stmt 1 <retval>.weights = WEIGHTS_147;
PULSE.c:139:9: note: 	children 0x410ac08
PULSE.c:139:9: note: node (external) 0x410ac08 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:139:9: note: 	{ layers_35, WEIGHTS_147 }
PULSE.c:139:9: note: ------>vectorizing SLP node starting from: <retval>.layers = layers_35;
PULSE.c:139:9: note: vect_is_simple_use: operand WEIGHTS_147 = PHI <WEIGHTS_40(36), WEIGHTS_128(25)>, type of def: internal
PULSE.c:139:9: note: conflicting alias set types.
PULSE.c:139:9: note: transform store. ncopies = 1
PULSE.c:139:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.layers
PULSE.c:139:9: note: created &<retval>
PULSE.c:139:9: note: add new stmt: MEM <vector(2) long unsigned int> [(void *)&<retval>] = _15;
PULSE.c:139:9: note: vectorizing stmts using SLP.
PULSE.c:139:9: optimized: basic block part vectorized using 16 byte vectors
PULSE.c:139:9: note: Vectorizing SLP tree:
PULSE.c:139:9: note: node 0x410ac88 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:139:9: note: op template: <retval>.io = 0B;
PULSE.c:139:9: note: 	stmt 0 <retval>.io = 0B;
PULSE.c:139:9: note: 	stmt 1 <retval>.fixes = 0B;
PULSE.c:139:9: note: 	children 0x410ad08
PULSE.c:139:9: note: node (constant) 0x410ad08 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:139:9: note: 	{ 0B, 0B }
PULSE.c:139:9: note: ------>vectorizing SLP node starting from: <retval>.io = 0B;
PULSE.c:139:9: note: vect_is_simple_use: operand 0B, type of def: constant
PULSE.c:139:9: note: transform store. ncopies = 1
PULSE.c:139:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.io
PULSE.c:139:9: note: created &<retval>.io
PULSE.c:139:9: note: add new stmt: MEM <vector(2) long unsigned int> [(float * *)&<retval> + 16B] = { 0, 0 };
PULSE.c:139:9: note: vectorizing stmts using SLP.
PULSE.c:139:9: note: ***** The result for vector mode V32QI would be the same
PULSE.c:151:1: note: ***** Analysis failed with vector mode VOID
Loss.c:15:19: optimized: loop vectorized using 32 byte vectors
Loss.c:15:19: optimized:  loop versioned for vectorization because of possible aliasing
Loss.c:15:19: optimized: loop vectorized using 16 byte vectors
Loss.c:12:23: note: vectorized 1 loops in function.
Loss.c:12:23: note: ***** Analysis failed with vector mode V8SF
Loss.c:12:23: note: ***** The result for vector mode V32QI would be the same
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V16QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V16QI
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V8QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V8QI
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V4QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V4QI
Loss.c:7:19: missed: couldn't vectorize loop
Loss.c:8:38: missed: not vectorized: unsupported use in stmt.
Loss.c:4:23: note: vectorized 0 loops in function.
Loss.c:9:13: note: ***** Analysis failed with vector mode V8SF
Loss.c:9:13: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Loss.c:23:2: note: ***** Analysis failed with vector mode VOID
Dense.c:9:27: missed: couldn't vectorize loop
Dense.c:9:27: missed: not vectorized: unsupported outerloop form.
Dense.c:12:20: missed: couldn't vectorize loop
Dense.c:13:21: missed: not vectorized: complicated access pattern.
Dense.c:6:13: note: vectorized 0 loops in function.
Dense.c:16:2: missed: statement clobbers memory: _28 (pretmp_91, _51, 0);
Dense.c:9:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:9:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:24:27: missed: couldn't vectorize loop
Dense.c:24:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:28:20: optimized: loop vectorized using 32 byte vectors
Dense.c:28:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:28:20: optimized: loop vectorized using 16 byte vectors
Dense.c:28:20: missed: couldn't vectorize loop
Dense.c:30:19: missed: not vectorized: no vectype for stmt: _22 = *_21;
 scalar_type: float
Dense.c:20:13: note: vectorized 1 loops in function.
Dense.c:23:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:24:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:24:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:41:28: missed: couldn't vectorize loop
Dense.c:41:28: missed: not vectorized: unsupported outerloop form.
Dense.c:45:21: optimized: loop vectorized using 32 byte vectors
Dense.c:45:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:45:21: optimized: loop vectorized using 16 byte vectors
Dense.c:37:13: note: vectorized 1 loops in function.
Dense.c:37:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:37:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:41:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:170:10: optimized: loop vectorized using 32 byte vectors
Dense.c:170:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:170:10: optimized: loop vectorized using 16 byte vectors
Dense.c:161:10: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_27, _64);
Dense.c:154:10: optimized: loop vectorized using 32 byte vectors
Dense.c:154:10: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:154:10: optimized: loop vectorized using 16 byte vectors
Dense.c:145:10: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_14, _56);
Dense.c:136:13: note: vectorized 2 loops in function.
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_14, _56);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_15, { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 });
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_27, _64);
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:1029:3: missed: statement clobbers memory: __builtin_ia32_movntps256 (_28, { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 });
Dense.c:136:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:136:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:136:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:136:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:105:24: missed: couldn't vectorize loop
Dense.c:105:24: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:108:17: missed: couldn't vectorize loop
Dense.c:108:17: missed: not vectorized: number of iterations cannot be computed.
Dense.c:122:24: missed: couldn't vectorize loop
Dense.c:122:24: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:125:17: missed: couldn't vectorize loop
Dense.c:125:17: missed: not vectorized: number of iterations cannot be computed.
Dense.c:90:15: missed: couldn't vectorize loop
Dense.c:90:15: missed: not vectorized: number of iterations cannot be computed.
Dense.c:83:13: note: vectorized 0 loops in function.
Dense.c:86:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:110:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:110:17: note: SLPing BB part
Dense.c:127:17: note: Costing subgraph: 
Dense.c:127:17: note: node 0x84a3c88 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:127:17: note: op template: _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 0 _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 1 _198 = (sizetype) wi_137;
Dense.c:127:17: note: 	children 0x84a3d88
Dense.c:127:17: note: node (external) 0x84a3d88 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:127:17: note: 	{ j_135, wi_137 }
Dense.c:127:17: note: Cost model analysis: 
Dense.c:127:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:127:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:127:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: Costing subgraph: 
Dense.c:110:17: note: node 0x84a3e88 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:110:17: note: op template: _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 0 _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 1 _217 = (sizetype) wi_136;
Dense.c:110:17: note: 	children 0x84a3f88
Dense.c:110:17: note: node (external) 0x84a3f88 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:110:17: note: 	{ j_134, wi_136 }
Dense.c:110:17: note: Cost model analysis: 
Dense.c:110:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:110:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:110:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:110:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:110:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:110:17: note: SLPing BB part
Dense.c:127:17: note: Costing subgraph: 
Dense.c:127:17: note: node 0x84a3e88 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:127:17: note: op template: _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 0 _42 = (sizetype) j_135;
Dense.c:127:17: note: 	stmt 1 _198 = (sizetype) wi_137;
Dense.c:127:17: note: 	children 0x84a3c88
Dense.c:127:17: note: node (external) 0x84a3c88 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:127:17: note: 	{ j_135, wi_137 }
Dense.c:127:17: note: Cost model analysis: 
Dense.c:127:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:127:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:127:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: Costing subgraph: 
Dense.c:110:17: note: node 0x84a3e08 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:110:17: note: op template: _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 0 _20 = (sizetype) j_134;
Dense.c:110:17: note: 	stmt 1 _217 = (sizetype) wi_136;
Dense.c:110:17: note: 	children 0x84a3f08
Dense.c:110:17: note: node (external) 0x84a3f08 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:110:17: note: 	{ j_134, wi_136 }
Dense.c:110:17: note: Cost model analysis: 
Dense.c:110:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:110:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:110:17: missed: not vectorized: vectorization is not profitable.
Dense.c:110:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:105:51: note: ***** Analysis failed with vector mode V8QI
Dense.c:105:51: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:105:51: note: ***** Analysis failed with vector mode V4QI
Dense.c:62:15: missed: couldn't vectorize loop
Dense.c:62:15: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:75:11: optimized: loop vectorized using 32 byte vectors
Dense.c:75:11: optimized: loop vectorized using 16 byte vectors
Dense.c:66:11: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.2.1/include/avxintrin.h:881:10: missed: not vectorized: no vectype for stmt: _53 = MEM[(__m256 * {ref-all})w_ptr_82];
 scalar_type: __m256
Dense.c:54:13: note: vectorized 1 loops in function.
Dense.c:57:2: missed: statement clobbers memory: memcpy (_4, dense$baiases_63, _3);
Dense.c:79:2: missed: statement clobbers memory: _27 (pretmp_163, _68, 0);
Dense.c:54:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:54:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:54:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:54:13: note: ***** Analysis failed with vector mode V4QI
Dense.c:179:107: note: ***** Analysis failed with vector mode V8SI
Dense.c:179:107: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
Dense.c:180:85: note: ***** Analysis failed with vector mode V8SI
Dense.c:180:85: note: ***** The result for vector mode V32QI would be the same
Dense.c:180:85: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:180:85: note: ***** Analysis failed with vector mode V16QI
Dense.c:180:85: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:180:85: note: ***** Analysis failed with vector mode V8QI
Dense.c:180:85: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:180:85: note: ***** Analysis failed with vector mode V4QI
Dense.c:192:19: missed: couldn't vectorize loop
Dense.c:192:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:182:13: note: vectorized 0 loops in function.
Dense.c:188:37: missed: statement clobbers memory: _9 = aligned_alloc (64, _8);
Dense.c:189:34: missed: statement clobbers memory: _11 = aligned_alloc (64, _10);
Dense.c:190:35: missed: statement clobbers memory: _12 = aligned_alloc (64, _10);
Dense.c:193:38: missed: statement clobbers memory: _13 = rand ();
Dense.c:193:72: missed: statement clobbers memory: _79 = sqrt (_20);
Dense.c:206:19: missed: statement clobbers memory: _31 = PULSE_GetActivationFunctionPtr (_30);
Dense.c:208:34: missed: statement clobbers memory: _33 = aligned_alloc (64, _10);
Dense.c:224:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:225:4: missed: statement clobbers memory: exit (1);
Dense.c:229:9: note: ***** Analysis succeeded with vector mode V8SI
Dense.c:229:9: note: SLPing BB part
Dense.c:229:9: note: Costing subgraph: 
Dense.c:229:9: note: node 0x82bb2e8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Dense.c:229:9: note: op template: <retval>.n_inputs = args$n_inputs_53;
Dense.c:229:9: note: 	stmt 0 <retval>.n_inputs = args$n_inputs_53;
Dense.c:229:9: note: 	stmt 1 <retval>.n_outputs = args$n_outputs_54;
Dense.c:229:9: note: 	children 0x82bb368
Dense.c:229:9: note: node 0x82bb368 (max_nunits=2, refcnt=1) vector(2) unsigned int
Dense.c:229:9: note: op template: args$n_inputs_53 = args.n_inputs;
Dense.c:229:9: note: 	stmt 0 args$n_inputs_53 = args.n_inputs;
Dense.c:229:9: note: 	stmt 1 args$n_outputs_54 = args.n_outputs;
Dense.c:229:9: note: Cost model analysis: 
Dense.c:229:9: note: Cost model analysis for part in loop 0:
  Vector cost: 40
  Scalar cost: 56
Dense.c:229:9: note: Costing subgraph: 
Dense.c:229:9: note: node 0x82bb468 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Dense.c:229:9: note: op template: <retval>.inputs = IO_42(D);
Dense.c:229:9: note: 	stmt 0 <retval>.inputs = IO_42(D);
Dense.c:229:9: note: 	stmt 1 <retval>.outputs = _29;
Dense.c:229:9: note: 	children 0x82bb4e8
Dense.c:229:9: note: node (external) 0x82bb4e8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Dense.c:229:9: note: 	{ IO_42(D), _29 }
Dense.c:229:9: note: Cost model analysis: 
Dense.c:229:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Dense.c:229:9: note: Costing subgraph: 
Dense.c:229:9: note: node 0x82bb5e8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Dense.c:229:9: note: op template: <retval>.feed = layer$feed_41;
Dense.c:229:9: note: 	stmt 0 <retval>.feed = layer$feed_41;
Dense.c:229:9: note: 	stmt 1 <retval>.back = layer$back_51;
Dense.c:229:9: note: 	children 0x82bb7e8
Dense.c:229:9: note: node (external) 0x82bb7e8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Dense.c:229:9: note: 	{ layer$feed_41, layer$back_51 }
Dense.c:229:9: note: Cost model analysis: 
Dense.c:229:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Dense.c:229:9: note: Costing subgraph: 
Dense.c:229:9: note: node 0x82bb6e8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Dense.c:229:9: note: op template: <retval>.parent = 0B;
Dense.c:229:9: note: 	stmt 0 <retval>.parent = 0B;
Dense.c:229:9: note: 	stmt 1 <retval>.child = 0B;
Dense.c:229:9: note: 	children 0x82bb868
Dense.c:229:9: note: node (constant) 0x82bb868 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Dense.c:229:9: note: 	{ 0B, 0B }
Dense.c:229:9: note: Cost model analysis: 
Dense.c:229:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Dense.c:229:9: note: Costing subgraph: 
Dense.c:229:9: note: node 0x82bb968 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Dense.c:229:9: note: op template: MEM <float *> [(struct PULSE_Layer *)&<retval> + 88B] = MODEL_37(D);
Dense.c:229:9: note: 	stmt 0 MEM <float *> [(struct PULSE_Layer *)&<retval> + 88B] = MODEL_37(D);
Dense.c:229:9: note: 	stmt 1 MEM <float *> [(struct PULSE_Layer *)&<retval> + 96B] = _4;
Dense.c:229:9: note: 	stmt 2 MEM <float *> [(struct PULSE_Layer *)&<retval> + 104B] = _11;
Dense.c:229:9: note: 	stmt 3 MEM <float *> [(struct PULSE_Layer *)&<retval> + 112B] = _12;
Dense.c:229:9: note: 	children 0x82bb9e8
Dense.c:229:9: note: node (external) 0x82bb9e8 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Dense.c:229:9: note: 	{ MODEL_37(D), _4, _11, _12 }
Dense.c:229:9: note: Cost model analysis: 
Dense.c:229:9: note: Cost model analysis for part in loop 0:
  Vector cost: 64
  Scalar cost: 64
Dense.c:229:9: note: Basic block will be vectorized using SLP
Dense.c:229:9: optimized: basic block part vectorized using 8 byte vectors
Dense.c:229:9: note: Vectorizing SLP tree:
Dense.c:229:9: note: node 0x82bb2e8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Dense.c:229:9: note: op template: <retval>.n_inputs = args$n_inputs_53;
Dense.c:229:9: note: 	stmt 0 <retval>.n_inputs = args$n_inputs_53;
Dense.c:229:9: note: 	stmt 1 <retval>.n_outputs = args$n_outputs_54;
Dense.c:229:9: note: 	children 0x82bb368
Dense.c:229:9: note: node 0x82bb368 (max_nunits=2, refcnt=1) vector(2) unsigned int
Dense.c:229:9: note: op template: args$n_inputs_53 = args.n_inputs;
Dense.c:229:9: note: 	stmt 0 args$n_inputs_53 = args.n_inputs;
Dense.c:229:9: note: 	stmt 1 args$n_outputs_54 = args.n_outputs;
Dense.c:229:9: note: ------>vectorizing SLP node starting from: args$n_inputs_53 = args.n_inputs;
Dense.c:229:9: note: transform load. ncopies = 1
Dense.c:229:9: note: conflicting alias set types.
Dense.c:229:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: args.n_inputs
Dense.c:229:9: note: created &args
Dense.c:229:9: note: add new stmt: vect_args_n_inputs_53.504_88 = MEM <vector(2) unsigned int> [(void *)&args];
Dense.c:229:9: note: extracting lane for live stmt args$n_inputs_53 = args.n_inputs;
Dense.c:229:9: note: extracting lane for live stmt args$n_outputs_54 = args.n_outputs;
Dense.c:229:9: note: ------>vectorizing SLP node starting from: <retval>.n_inputs = args$n_inputs_53;
Dense.c:229:9: note: vect_is_simple_use: operand args.n_inputs, type of def: internal
Dense.c:229:9: note: vect_is_simple_use: operand args.n_outputs, type of def: internal
Dense.c:229:9: note: transform store. ncopies = 1
Dense.c:229:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: <retval>.n_inputs
Dense.c:229:9: note: created &<retval>.n_inputs
Dense.c:229:9: note: add new stmt: MEM <vector(2) unsigned int> [(unsigned int *)&<retval> + 128B] = vect_args_n_inputs_53.504_88;
Dense.c:229:9: note: vectorizing stmts using SLP.
Dense.c:229:9: optimized: basic block part vectorized using 16 byte vectors
Dense.c:229:9: note: Vectorizing SLP tree:
Dense.c:229:9: note: node 0x82bb468 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Dense.c:229:9: note: op template: <retval>.inputs = IO_42(D);
Dense.c:229:9: note: 	stmt 0 <retval>.inputs = IO_42(D);
Dense.c:229:9: note: 	stmt 1 <retval>.outputs = _29;
Dense.c:229:9: note: 	children 0x82bb4e8
Dense.c:229:9: note: node (external) 0x82bb4e8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Dense.c:229:9: note: 	{ IO_42(D), _29 }
Dense.c:229:9: note: ------>vectorizing SLP node starting from: <retval>.inputs = IO_42(D);
Dense.c:229:9: note: vect_is_simple_use: operand IO_42(D) + _28, type of def: internal
Dense.c:229:9: note: transform store. ncopies = 1
Dense.c:229:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.inputs
Dense.c:229:9: note: created &<retval>
Dense.c:229:9: note: add new stmt: MEM <vector(2) long unsigned int> [(float * *)&<retval>] = _94;
Dense.c:229:9: note: vectorizing stmts using SLP.
Dense.c:229:9: optimized: basic block part vectorized using 16 byte vectors
Dense.c:229:9: note: Vectorizing SLP tree:
Dense.c:229:9: note: node 0x82bb5e8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Dense.c:229:9: note: op template: <retval>.feed = layer$feed_41;
Dense.c:229:9: note: 	stmt 0 <retval>.feed = layer$feed_41;
Dense.c:229:9: note: 	stmt 1 <retval>.back = layer$back_51;
Dense.c:229:9: note: 	children 0x82bb7e8
Dense.c:229:9: note: node (external) 0x82bb7e8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Dense.c:229:9: note: 	{ layer$feed_41, layer$back_51 }
Dense.c:229:9: note: ------>vectorizing SLP node starting from: <retval>.feed = layer$feed_41;
Dense.c:229:9: note: vect_is_simple_use: operand layer$back_51 = PHI <layer$back_57(D)(11), _BackDense(9), _SIMD_BackDense(15)>, type of def: internal
Dense.c:229:9: note: transform store. ncopies = 1
Dense.c:229:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.feed
Dense.c:229:9: note: created &<retval>.feed
Dense.c:229:9: note: add new stmt: MEM <vector(2) long unsigned int> [(void (*<T921>) (struct PULSE_Layer *) *)&<retval> + 32B] = _98;
Dense.c:229:9: note: vectorizing stmts using SLP.
Dense.c:229:9: optimized: basic block part vectorized using 16 byte vectors
Dense.c:229:9: note: Vectorizing SLP tree:
Dense.c:229:9: note: node 0x82bb6e8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Dense.c:229:9: note: op template: <retval>.parent = 0B;
Dense.c:229:9: note: 	stmt 0 <retval>.parent = 0B;
Dense.c:229:9: note: 	stmt 1 <retval>.child = 0B;
Dense.c:229:9: note: 	children 0x82bb868
Dense.c:229:9: note: node (constant) 0x82bb868 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Dense.c:229:9: note: 	{ 0B, 0B }
Dense.c:229:9: note: ------>vectorizing SLP node starting from: <retval>.parent = 0B;
Dense.c:229:9: note: vect_is_simple_use: operand 0B, type of def: constant
Dense.c:229:9: note: transform store. ncopies = 1
Dense.c:229:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.parent
Dense.c:229:9: note: created &<retval>.parent
Dense.c:229:9: note: add new stmt: MEM <vector(2) long unsigned int> [(struct PULSE_Layer * *)&<retval> + 72B] = { 0, 0 };
Dense.c:229:9: note: vectorizing stmts using SLP.
Dense.c:229:9: optimized: basic block part vectorized using 32 byte vectors
Dense.c:229:9: note: Vectorizing SLP tree:
Dense.c:229:9: note: node 0x82bb968 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Dense.c:229:9: note: op template: MEM <float *> [(struct PULSE_Layer *)&<retval> + 88B] = MODEL_37(D);
Dense.c:229:9: note: 	stmt 0 MEM <float *> [(struct PULSE_Layer *)&<retval> + 88B] = MODEL_37(D);
Dense.c:229:9: note: 	stmt 1 MEM <float *> [(struct PULSE_Layer *)&<retval> + 96B] = _4;
Dense.c:229:9: note: 	stmt 2 MEM <float *> [(struct PULSE_Layer *)&<retval> + 104B] = _11;
Dense.c:229:9: note: 	stmt 3 MEM <float *> [(struct PULSE_Layer *)&<retval> + 112B] = _12;
Dense.c:229:9: note: 	children 0x82bb9e8
Dense.c:229:9: note: node (external) 0x82bb9e8 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Dense.c:229:9: note: 	{ MODEL_37(D), _4, _11, _12 }
Dense.c:229:9: note: ------>vectorizing SLP node starting from: MEM <float *> [(struct PULSE_Layer *)&<retval> + 88B] = MODEL_37(D);
Dense.c:229:9: note: vect_is_simple_use: operand MODEL_37(D) + _3, type of def: internal
Dense.c:229:9: note: vect_is_simple_use: operand aligned_alloc (64, _10), type of def: internal
Dense.c:229:9: note: vect_is_simple_use: operand aligned_alloc (64, _10), type of def: internal
Dense.c:229:9: note: transform store. ncopies = 1
Dense.c:229:9: note: create vector_type-pointer variable to type: vector(4) long unsigned int  vectorizing a pointer ref: MEM <float *> [(struct PULSE_Layer *)&<retval> + 88B]
Dense.c:229:9: note: created &MEM <float *> [(struct PULSE_Layer *)&<retval> + 88B]
Dense.c:229:9: note: add new stmt: MEM <vector(4) long unsigned int> [(struct PULSE_Layer *)&<retval> + 88B] = _105;
Dense.c:229:9: note: vectorizing stmts using SLP.
Dense.c:229:9: note: ***** The result for vector mode V32QI would be the same
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:4:18: note: vectorized 0 loops in function.
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_4, inputs_15, _3);
PULSE.c:8:2: missed: statement clobbers memory: _5 (layer_17);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_12, pretmp_26, _9);
PULSE.c:13:28: note: ***** Analysis failed with vector mode V8SI
PULSE.c:13:28: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:22:2: missed: statement clobbers memory: _1 (layer_10(D));
PULSE.c:22:2: missed: statement clobbers memory: _14 (_2);
PULSE.c:22:2: missed: statement clobbers memory: _21 (_15);
PULSE.c:22:2: missed: statement clobbers memory: _28 (_22);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_29);
PULSE.c:26:3: missed: statement clobbers memory: memset (_34, 0, _32);
PULSE.c:26:3: missed: statement clobbers memory: memset (_27, 0, _25);
PULSE.c:26:3: missed: statement clobbers memory: memset (_20, 0, _18);
PULSE.c:26:3: missed: statement clobbers memory: memset (_7, 0, _5);
PULSE.c:28:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:28:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:32:6: note: vectorized 1 loops in function.
PULSE.c:34:8: missed: statement clobbers memory: _1 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_2);
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _9 = rand ();
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8SI
PULSE.c:32:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:61:16: missed: couldn't vectorize loop
PULSE.c:61:16: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:64:17: missed: couldn't vectorize loop
PULSE.c:64:17: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:73:19: missed: couldn't vectorize loop
PULSE.c:73:19: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:53:22: missed: couldn't vectorize loop
PULSE.c:53:22: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:47:6: note: vectorized 1 loops in function.
PULSE.c:48:1: missed: statement clobbers memory: saved_stack.7_39 = __builtin_stack_save ();
PULSE.c:49:46: missed: statement clobbers memory: _1 = PULSE_GetLossFunctionPtr (loss_function_40(D));
PULSE.c:60:10: missed: statement clobbers memory: random.4_46 = __builtin_alloca_with_align (_4, 32);
PULSE.c:34:8: missed: statement clobbers memory: _61 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_62);
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _72 = rand ();
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_98, inputs_93, _97);
PULSE.c:8:2: missed: statement clobbers memory: _99 (layer_94);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_105, _104, _103);
PULSE.c:67:11: missed: statement clobbers memory: loss_55 = PULSE_GetLoss_42 (_17, _16, _12, _11);
PULSE.c:22:2: missed: statement clobbers memory: _86 (output_34);
PULSE.c:22:2: missed: statement clobbers memory: _108 (_87);
PULSE.c:22:2: missed: statement clobbers memory: _115 (_109);
PULSE.c:22:2: missed: statement clobbers memory: _122 (_116);
PULSE.c:22:2: missed: statement clobbers memory: _129 (_123);
PULSE.c:22:2: missed: statement clobbers memory: _136 (_130);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_137);
PULSE.c:26:3: missed: statement clobbers memory: memset (_142, 0, _140);
PULSE.c:26:3: missed: statement clobbers memory: memset (_135, 0, _133);
PULSE.c:26:3: missed: statement clobbers memory: memset (_128, 0, _126);
PULSE.c:26:3: missed: statement clobbers memory: memset (_121, 0, _119);
PULSE.c:26:3: missed: statement clobbers memory: memset (_114, 0, _112);
PULSE.c:26:3: missed: statement clobbers memory: memset (_92, 0, _90);
PULSE.c:75:6: missed: statement clobbers memory: _21 (current_191, args);
PULSE.c:81:4: missed: statement clobbers memory: printf ("Epoch: %d | Item: %d | Loss: %.10f | Batch Loss: %.10f\r", i_188, j_189, _25, _24);
PULSE.c:47:6: missed: statement clobbers memory: __builtin_stack_restore (saved_stack.7_39);
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4DI
PULSE.c:47:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:91:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:91:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:123:20: missed: couldn't vectorize loop
PULSE.c:123:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:123:20: missed: couldn't vectorize loop
PULSE.c:123:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:103:20: missed: couldn't vectorize loop
PULSE.c:103:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:103:20: missed: couldn't vectorize loop
PULSE.c:103:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:93:13: note: vectorized 0 loops in function.
PULSE.c:96:39: missed: statement clobbers memory: layers_39 = malloc (_3);
PULSE.c:99:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:116:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:117:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:118:46: missed: statement clobbers memory: WEIGHTS_56 = aligned_alloc (64, 0);
PULSE.c:109:26: missed: not vectorized: more than one data ref in stmt: args = MEM[(struct PULSE_DenseLayerArgs * {ref-all})addr.104_85];
PULSE.c:110:21: missed: statement clobbers memory: _70 = PULSE_GetDenseWeightsSize (args);
PULSE.c:111:16: missed: statement clobbers memory: _73 = PULSE_GetDenseIOSize (args);
PULSE.c:109:26: missed: not vectorized: more than one data ref in stmt: args = MEM[(struct PULSE_DenseLayerArgs * {ref-all})_208];
PULSE.c:110:21: missed: statement clobbers memory: _197 = PULSE_GetDenseWeightsSize (args);
PULSE.c:111:16: missed: statement clobbers memory: _200 = PULSE_GetDenseIOSize (args);
PULSE.c:116:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:117:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:118:46: missed: statement clobbers memory: WEIGHTS_44 = aligned_alloc (64, _5);
PULSE.c:119:41: missed: statement clobbers memory: IO_46 = aligned_alloc (64, _7);
PULSE.c:129:26: missed: not vectorized: more than one data ref in stmt: args = MEM[(struct PULSE_DenseLayerArgs * {ref-all})addr.106_87];
PULSE.c:130:17: missed: statement clobbers memory: *_10 = PULSE_CreateDenseLayer (args, WEIGHTS_PTR_141, IO_PTR_142); [return slot optimization]
PULSE.c:131:20: missed: statement clobbers memory: _59 = PULSE_GetDenseWeightsSize (args);
PULSE.c:132:15: missed: statement clobbers memory: _62 = PULSE_GetDenseIOSize (args);
PULSE.c:129:26: missed: not vectorized: more than one data ref in stmt: args = MEM[(struct PULSE_DenseLayerArgs * {ref-all})addr.106_127];
PULSE.c:130:17: missed: statement clobbers memory: *_109 = PULSE_CreateDenseLayer (args, WEIGHTS_PTR_149, IO_PTR_148); [return slot optimization]
PULSE.c:131:20: missed: statement clobbers memory: _97 = PULSE_GetDenseWeightsSize (args);
PULSE.c:132:15: missed: statement clobbers memory: _82 = PULSE_GetDenseIOSize (args);
PULSE.c:138:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:139:9: note: ***** Analysis succeeded with vector mode V8SI
PULSE.c:139:9: note: SLPing BB part
PULSE.c:139:9: note: Costing subgraph: 
PULSE.c:139:9: note: node 0x39ae368 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:139:9: note: op template: <retval>.layers = layers_39;
PULSE.c:139:9: note: 	stmt 0 <retval>.layers = layers_39;
PULSE.c:139:9: note: 	stmt 1 <retval>.weights = WEIGHTS_153;
PULSE.c:139:9: note: 	children 0x39ae468
PULSE.c:139:9: note: node (external) 0x39ae468 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:139:9: note: 	{ layers_39, WEIGHTS_153 }
PULSE.c:139:9: note: Cost model analysis: 
PULSE.c:139:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
PULSE.c:139:9: note: Costing subgraph: 
PULSE.c:139:9: note: node 0x39ae4e8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:139:9: note: op template: <retval>.io = 0B;
PULSE.c:139:9: note: 	stmt 0 <retval>.io = 0B;
PULSE.c:139:9: note: 	stmt 1 <retval>.fixes = 0B;
PULSE.c:139:9: note: 	children 0x39ae568
PULSE.c:139:9: note: node (constant) 0x39ae568 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:139:9: note: 	{ 0B, 0B }
PULSE.c:139:9: note: Cost model analysis: 
PULSE.c:139:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
PULSE.c:139:9: note: Basic block will be vectorized using SLP
PULSE.c:139:9: optimized: basic block part vectorized using 16 byte vectors
PULSE.c:139:9: note: Vectorizing SLP tree:
PULSE.c:139:9: note: node 0x39ae368 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:139:9: note: op template: <retval>.layers = layers_39;
PULSE.c:139:9: note: 	stmt 0 <retval>.layers = layers_39;
PULSE.c:139:9: note: 	stmt 1 <retval>.weights = WEIGHTS_153;
PULSE.c:139:9: note: 	children 0x39ae468
PULSE.c:139:9: note: node (external) 0x39ae468 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:139:9: note: 	{ layers_39, WEIGHTS_153 }
PULSE.c:139:9: note: ------>vectorizing SLP node starting from: <retval>.layers = layers_39;
PULSE.c:139:9: note: vect_is_simple_use: operand WEIGHTS_153 = PHI <WEIGHTS_44(36), WEIGHTS_56(25)>, type of def: internal
PULSE.c:139:9: note: conflicting alias set types.
PULSE.c:139:9: note: transform store. ncopies = 1
PULSE.c:139:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.layers
PULSE.c:139:9: note: created &<retval>
PULSE.c:139:9: note: add new stmt: MEM <vector(2) long unsigned int> [(void *)&<retval>] = _18;
PULSE.c:139:9: note: vectorizing stmts using SLP.
PULSE.c:139:9: optimized: basic block part vectorized using 16 byte vectors
PULSE.c:139:9: note: Vectorizing SLP tree:
PULSE.c:139:9: note: node 0x39ae4e8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:139:9: note: op template: <retval>.io = 0B;
PULSE.c:139:9: note: 	stmt 0 <retval>.io = 0B;
PULSE.c:139:9: note: 	stmt 1 <retval>.fixes = 0B;
PULSE.c:139:9: note: 	children 0x39ae568
PULSE.c:139:9: note: node (constant) 0x39ae568 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:139:9: note: 	{ 0B, 0B }
PULSE.c:139:9: note: ------>vectorizing SLP node starting from: <retval>.io = 0B;
PULSE.c:139:9: note: vect_is_simple_use: operand 0B, type of def: constant
PULSE.c:139:9: note: transform store. ncopies = 1
PULSE.c:139:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.io
PULSE.c:139:9: note: created &<retval>.io
PULSE.c:139:9: note: add new stmt: MEM <vector(2) long unsigned int> [(float * *)&<retval> + 16B] = { 0, 0 };
PULSE.c:139:9: note: vectorizing stmts using SLP.
PULSE.c:139:9: note: ***** The result for vector mode V32QI would be the same
PULSE.c:151:1: note: ***** Analysis failed with vector mode VOID
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:4:18: note: vectorized 0 loops in function.
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_4, inputs_15, _3);
PULSE.c:8:2: missed: statement clobbers memory: _5 (layer_17);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_12, pretmp_26, _9);
PULSE.c:13:28: note: ***** Analysis failed with vector mode V8SI
PULSE.c:13:28: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:22:2: missed: statement clobbers memory: _1 (layer_10(D));
PULSE.c:22:2: missed: statement clobbers memory: _14 (_2);
PULSE.c:22:2: missed: statement clobbers memory: _21 (_15);
PULSE.c:22:2: missed: statement clobbers memory: _28 (_22);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_29);
PULSE.c:26:3: missed: statement clobbers memory: memset (_34, 0, _32);
PULSE.c:26:3: missed: statement clobbers memory: memset (_27, 0, _25);
PULSE.c:26:3: missed: statement clobbers memory: memset (_20, 0, _18);
PULSE.c:26:3: missed: statement clobbers memory: memset (_7, 0, _5);
PULSE.c:28:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:28:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:32:6: note: vectorized 1 loops in function.
PULSE.c:34:8: missed: statement clobbers memory: _1 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_2);
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _9 = rand ();
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8SI
PULSE.c:32:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:61:16: missed: couldn't vectorize loop
PULSE.c:61:16: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:64:17: missed: couldn't vectorize loop
PULSE.c:64:17: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:73:19: missed: couldn't vectorize loop
PULSE.c:73:19: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:53:22: missed: couldn't vectorize loop
PULSE.c:53:22: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:47:6: note: vectorized 1 loops in function.
PULSE.c:48:1: missed: statement clobbers memory: saved_stack.7_39 = __builtin_stack_save ();
PULSE.c:49:46: missed: statement clobbers memory: _1 = PULSE_GetLossFunctionPtr (loss_function_40(D));
PULSE.c:60:10: missed: statement clobbers memory: random.4_46 = __builtin_alloca_with_align (_4, 32);
PULSE.c:34:8: missed: statement clobbers memory: _61 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_62);
PULSE.c:39:29: missed: statement clobbers memory: _69 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _72 = rand ();
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_98, inputs_93, _97);
PULSE.c:8:2: missed: statement clobbers memory: _99 (layer_94);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_105, _104, _103);
PULSE.c:67:11: missed: statement clobbers memory: loss_55 = PULSE_GetLoss_42 (_17, _16, _12, _11);
PULSE.c:22:2: missed: statement clobbers memory: _86 (output_34);
PULSE.c:22:2: missed: statement clobbers memory: _108 (_87);
PULSE.c:22:2: missed: statement clobbers memory: _115 (_109);
PULSE.c:22:2: missed: statement clobbers memory: _122 (_116);
PULSE.c:22:2: missed: statement clobbers memory: _129 (_123);
PULSE.c:22:2: missed: statement clobbers memory: _136 (_130);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_137);
PULSE.c:26:3: missed: statement clobbers memory: memset (_142, 0, _140);
PULSE.c:26:3: missed: statement clobbers memory: memset (_135, 0, _133);
PULSE.c:26:3: missed: statement clobbers memory: memset (_128, 0, _126);
PULSE.c:26:3: missed: statement clobbers memory: memset (_121, 0, _119);
PULSE.c:26:3: missed: statement clobbers memory: memset (_114, 0, _112);
PULSE.c:26:3: missed: statement clobbers memory: memset (_92, 0, _90);
PULSE.c:75:6: missed: statement clobbers memory: _21 (current_191, args);
PULSE.c:81:4: missed: statement clobbers memory: printf ("Epoch: %d | Item: %d | Loss: %.10f | Batch Loss: %.10f\r", i_188, j_189, _25, _24);
PULSE.c:47:6: missed: statement clobbers memory: __builtin_stack_restore (saved_stack.7_39);
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4DI
PULSE.c:47:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:91:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:91:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:123:20: missed: couldn't vectorize loop
PULSE.c:123:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:123:20: missed: couldn't vectorize loop
PULSE.c:123:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:103:20: missed: couldn't vectorize loop
PULSE.c:103:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:103:20: missed: couldn't vectorize loop
PULSE.c:103:20: missed: not vectorized: unsupported control flow in loop.
PULSE.c:93:13: note: vectorized 0 loops in function.
PULSE.c:96:39: missed: statement clobbers memory: layers_39 = malloc (_3);
PULSE.c:99:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:116:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:117:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:118:46: missed: statement clobbers memory: WEIGHTS_56 = aligned_alloc (64, 0);
PULSE.c:109:26: missed: not vectorized: more than one data ref in stmt: args = MEM[(struct PULSE_DenseLayerArgs * {ref-all})addr.104_85];
PULSE.c:110:21: missed: statement clobbers memory: _70 = PULSE_GetDenseWeightsSize (args);
PULSE.c:111:16: missed: statement clobbers memory: _73 = PULSE_GetDenseIOSize (args);
PULSE.c:109:26: missed: not vectorized: more than one data ref in stmt: args = MEM[(struct PULSE_DenseLayerArgs * {ref-all})_208];
PULSE.c:110:21: missed: statement clobbers memory: _197 = PULSE_GetDenseWeightsSize (args);
PULSE.c:111:16: missed: statement clobbers memory: _200 = PULSE_GetDenseIOSize (args);
PULSE.c:116:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:117:2: missed: statement clobbers memory: __builtin_va_start (&layers_info, 0);
PULSE.c:118:46: missed: statement clobbers memory: WEIGHTS_44 = aligned_alloc (64, _5);
PULSE.c:119:41: missed: statement clobbers memory: IO_46 = aligned_alloc (64, _7);
PULSE.c:129:26: missed: not vectorized: more than one data ref in stmt: args = MEM[(struct PULSE_DenseLayerArgs * {ref-all})addr.106_87];
PULSE.c:130:17: missed: statement clobbers memory: *_10 = PULSE_CreateDenseLayer (args, WEIGHTS_PTR_141, IO_PTR_142); [return slot optimization]
PULSE.c:131:20: missed: statement clobbers memory: _59 = PULSE_GetDenseWeightsSize (args);
PULSE.c:132:15: missed: statement clobbers memory: _62 = PULSE_GetDenseIOSize (args);
PULSE.c:129:26: missed: not vectorized: more than one data ref in stmt: args = MEM[(struct PULSE_DenseLayerArgs * {ref-all})addr.106_127];
PULSE.c:130:17: missed: statement clobbers memory: *_109 = PULSE_CreateDenseLayer (args, WEIGHTS_PTR_149, IO_PTR_148); [return slot optimization]
PULSE.c:131:20: missed: statement clobbers memory: _97 = PULSE_GetDenseWeightsSize (args);
PULSE.c:132:15: missed: statement clobbers memory: _82 = PULSE_GetDenseIOSize (args);
PULSE.c:138:2: missed: statement clobbers memory: __builtin_va_end (&layers_info);
PULSE.c:139:9: note: ***** Analysis succeeded with vector mode V8SI
PULSE.c:139:9: note: SLPing BB part
PULSE.c:139:9: note: Costing subgraph: 
PULSE.c:139:9: note: node 0x3deb488 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:139:9: note: op template: <retval>.layers = layers_39;
PULSE.c:139:9: note: 	stmt 0 <retval>.layers = layers_39;
PULSE.c:139:9: note: 	stmt 1 <retval>.weights = WEIGHTS_153;
PULSE.c:139:9: note: 	children 0x3deb588
PULSE.c:139:9: note: node (external) 0x3deb588 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:139:9: note: 	{ layers_39, WEIGHTS_153 }
PULSE.c:139:9: note: Cost model analysis: 
PULSE.c:139:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
PULSE.c:139:9: note: Costing subgraph: 
PULSE.c:139:9: note: node 0x3deb608 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:139:9: note: op template: <retval>.io = 0B;
PULSE.c:139:9: note: 	stmt 0 <retval>.io = 0B;
PULSE.c:139:9: note: 	stmt 1 <retval>.fixes = 0B;
PULSE.c:139:9: note: 	children 0x3deb688
PULSE.c:139:9: note: node (constant) 0x3deb688 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:139:9: note: 	{ 0B, 0B }
PULSE.c:139:9: note: Cost model analysis: 
PULSE.c:139:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
PULSE.c:139:9: note: Basic block will be vectorized using SLP
PULSE.c:139:9: optimized: basic block part vectorized using 16 byte vectors
PULSE.c:139:9: note: Vectorizing SLP tree:
PULSE.c:139:9: note: node 0x3deb488 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:139:9: note: op template: <retval>.layers = layers_39;
PULSE.c:139:9: note: 	stmt 0 <retval>.layers = layers_39;
PULSE.c:139:9: note: 	stmt 1 <retval>.weights = WEIGHTS_153;
PULSE.c:139:9: note: 	children 0x3deb588
PULSE.c:139:9: note: node (external) 0x3deb588 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:139:9: note: 	{ layers_39, WEIGHTS_153 }
PULSE.c:139:9: note: ------>vectorizing SLP node starting from: <retval>.layers = layers_39;
PULSE.c:139:9: note: vect_is_simple_use: operand WEIGHTS_153 = PHI <WEIGHTS_44(36), WEIGHTS_56(25)>, type of def: internal
PULSE.c:139:9: note: conflicting alias set types.
PULSE.c:139:9: note: transform store. ncopies = 1
PULSE.c:139:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.layers
PULSE.c:139:9: note: created &<retval>
PULSE.c:139:9: note: add new stmt: MEM <vector(2) long unsigned int> [(void *)&<retval>] = _18;
PULSE.c:139:9: note: vectorizing stmts using SLP.
PULSE.c:139:9: optimized: basic block part vectorized using 16 byte vectors
PULSE.c:139:9: note: Vectorizing SLP tree:
PULSE.c:139:9: note: node 0x3deb608 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:139:9: note: op template: <retval>.io = 0B;
PULSE.c:139:9: note: 	stmt 0 <retval>.io = 0B;
PULSE.c:139:9: note: 	stmt 1 <retval>.fixes = 0B;
PULSE.c:139:9: note: 	children 0x3deb688
PULSE.c:139:9: note: node (constant) 0x3deb688 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:139:9: note: 	{ 0B, 0B }
PULSE.c:139:9: note: ------>vectorizing SLP node starting from: <retval>.io = 0B;
PULSE.c:139:9: note: vect_is_simple_use: operand 0B, type of def: constant
PULSE.c:139:9: note: transform store. ncopies = 1
PULSE.c:139:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.io
PULSE.c:139:9: note: created &<retval>.io
PULSE.c:139:9: note: add new stmt: MEM <vector(2) long unsigned int> [(float * *)&<retval> + 16B] = { 0, 0 };
PULSE.c:139:9: note: vectorizing stmts using SLP.
PULSE.c:139:9: note: ***** The result for vector mode V32QI would be the same
PULSE.c:147:3: missed: statement clobbers memory: free (_1);
PULSE.c:153:3: missed: statement clobbers memory: free (prephitmp_16);
PULSE.c:159:3: missed: statement clobbers memory: free (_4);
PULSE.c:162:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:162:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
