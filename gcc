Layer.c:7:34: missed: statement clobbers memory: _3 = aligned_alloc (64, _2);
Layer.c:8:35: missed: statement clobbers memory: _6 = aligned_alloc (64, _5);
Layer.c:9:34: missed: statement clobbers memory: _7 = aligned_alloc (64, _5);
Layer.c:14:19: missed: statement clobbers memory: _8 = PULSE_GetActivationFunctionPtr (activation_function_18(D));
Layer.c:19:9: note: ***** Analysis succeeded with vector mode V8SI
Layer.c:19:9: note: SLPing BB part
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x35fc7c8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 0 MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 1 MEM <unsigned int> [(struct PULSE_Layer *)&<retval> + 4B] = optimization_type_17(D);
Layer.c:19:9: note: 	children 0x35fc848
Layer.c:19:9: note: node (external) 0x35fc848 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ type_16(D), optimization_type_17(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x35fc8c8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 0 <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 1 <retval>.n_outputs = n_outputs_12(D);
Layer.c:19:9: note: 	children 0x35fc948
Layer.c:19:9: note: node (external) 0x35fc948 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x35fca48 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 0 <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 1 <retval>.outputs = _6;
Layer.c:19:9: note: 	children 0x35fcac8
Layer.c:19:9: note: node (external) 0x35fcac8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	stmt 0 _3 = aligned_alloc (64, _2);
Layer.c:19:9: note: 	stmt 1 _6 = aligned_alloc (64, _5);
Layer.c:19:9: note: 	children 0x35fcb48 0x35fcbc8
Layer.c:19:9: note: node (constant) 0x35fcb48 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 64, 64 }
Layer.c:19:9: note: node 0x35fcbc8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: patt_40 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 0 patt_40 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 1 patt_41 = n_outputs_12(D) w* 4;
Layer.c:19:9: note: 	children 0x35fcc48 0x35fccc8
Layer.c:19:9: note: node (external) 0x35fcc48 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: node (constant) 0x35fccc8 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ 4, 4 }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x35fcdc8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: op template: <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 0 <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 1 <retval>.back = back_21(D);
Layer.c:19:9: note: 	stmt 2 <retval>.fix = fix_22(D);
Layer.c:19:9: note: 	stmt 3 <retval>.destroy = destroy_23(D);
Layer.c:19:9: note: 	children 0x35fce48
Layer.c:19:9: note: node (external) 0x35fce48 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: 	{ feed_20(D), back_21(D), fix_22(D), destroy_23(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 64
  Scalar cost: 64
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x35fcf48 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 0 <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 1 <retval>.child = 0B;
Layer.c:19:9: note: 	children 0x35fcfc8
Layer.c:19:9: note: node (constant) 0x35fcfc8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ 0B, 0B }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Basic block will be vectorized using SLP
Layer.c:19:9: optimized: basic block part vectorized using 8 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x35fc7c8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 0 MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 1 MEM <unsigned int> [(struct PULSE_Layer *)&<retval> + 4B] = optimization_type_17(D);
Layer.c:19:9: note: 	children 0x35fc848
Layer.c:19:9: note: node (external) 0x35fc848 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ type_16(D), optimization_type_17(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: vect_is_simple_use: operand optimization_type_17(D), type of def: external
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>]
Layer.c:19:9: note: created &MEM <unsigned int> [(struct PULSE_Layer *)&<retval>]
Layer.c:19:9: note: add new stmt: MEM <vector(2) unsigned int> [(struct PULSE_Layer *)&<retval>] = _42;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 8 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x35fc8c8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 0 <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 1 <retval>.n_outputs = n_outputs_12(D);
Layer.c:19:9: note: 	children 0x35fc948
Layer.c:19:9: note: node (external) 0x35fc948 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: vect_is_simple_use: operand n_outputs_12(D), type of def: external
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: <retval>.n_inputs
Layer.c:19:9: note: created &<retval>.n_inputs
Layer.c:19:9: note: add new stmt: MEM <vector(2) unsigned int> [(unsigned int *)&<retval> + 96B] = _44;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 16 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x35fca48 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 0 <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 1 <retval>.outputs = _6;
Layer.c:19:9: note: 	children 0x35fcac8
Layer.c:19:9: note: node (external) 0x35fcac8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	stmt 0 _3 = aligned_alloc (64, _2);
Layer.c:19:9: note: 	stmt 1 _6 = aligned_alloc (64, _5);
Layer.c:19:9: note: 	children 0x35fcb48 0x35fcbc8
Layer.c:19:9: note: node (constant) 0x35fcb48 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 64, 64 }
Layer.c:19:9: note: node 0x35fcbc8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: patt_40 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 0 patt_40 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 1 patt_41 = n_outputs_12(D) w* 4;
Layer.c:19:9: note: 	children 0x35fcc48 0x35fccc8
Layer.c:19:9: note: node (external) 0x35fcc48 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: node (constant) 0x35fccc8 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ 4, 4 }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.inputs = _3;
Layer.c:19:9: note: vect_is_simple_use: operand aligned_alloc (64, _5), type of def: internal
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.inputs
Layer.c:19:9: note: created &<retval>.inputs
Layer.c:19:9: note: add new stmt: MEM <vector(2) long unsigned int> [(float * *)&<retval> + 8B] = _48;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 32 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x35fcdc8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: op template: <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 0 <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 1 <retval>.back = back_21(D);
Layer.c:19:9: note: 	stmt 2 <retval>.fix = fix_22(D);
Layer.c:19:9: note: 	stmt 3 <retval>.destroy = destroy_23(D);
Layer.c:19:9: note: 	children 0x35fce48
Layer.c:19:9: note: node (external) 0x35fce48 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: 	{ feed_20(D), back_21(D), fix_22(D), destroy_23(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.feed = feed_20(D);
Layer.c:19:9: note: vect_is_simple_use: operand back_21(D), type of def: external
Layer.c:19:9: note: vect_is_simple_use: operand fix_22(D), type of def: external
Layer.c:19:9: note: vect_is_simple_use: operand destroy_23(D), type of def: external
Layer.c:19:9: note: conflicting alias set types.
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(4) long unsigned int  vectorizing a pointer ref: <retval>.feed
Layer.c:19:9: note: created &<retval>.feed
Layer.c:19:9: note: add new stmt: MEM <vector(4) long unsigned int> [(void *)&<retval> + 32B] = _54;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 16 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x35fcf48 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 0 <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 1 <retval>.child = 0B;
Layer.c:19:9: note: 	children 0x35fcfc8
Layer.c:19:9: note: node (constant) 0x35fcfc8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ 0B, 0B }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.parent = 0B;
Layer.c:19:9: note: vect_is_simple_use: operand 0B, type of def: constant
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.parent
Layer.c:19:9: note: created &<retval>.parent
Layer.c:19:9: note: add new stmt: MEM <vector(2) long unsigned int> [(struct PULSE_Layer * *)&<retval> + 72B] = { 0, 0 };
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: note: ***** The result for vector mode V32QI would be the same
Layer.c:24:2: missed: statement clobbers memory: free (_1);
Layer.c:25:2: missed: statement clobbers memory: free (_2);
Layer.c:26:2: missed: statement clobbers memory: free (_3);
Layer.c:27:1: note: ***** Analysis failed with vector mode V4DI
Layer.c:27:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:9:27: missed: couldn't vectorize loop
Dense.c:9:27: missed: not vectorized: unsupported outerloop form.
Dense.c:12:20: missed: couldn't vectorize loop
Dense.c:13:21: missed: not vectorized: complicated access pattern.
Dense.c:6:13: note: vectorized 0 loops in function.
Dense.c:16:2: missed: statement clobbers memory: _30 (pretmp_91, _50, 0);
Dense.c:9:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:9:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:24:27: missed: couldn't vectorize loop
Dense.c:24:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:28:20: optimized: loop vectorized using 32 byte vectors
Dense.c:28:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:28:20: optimized: loop vectorized using 16 byte vectors
Dense.c:28:20: missed: couldn't vectorize loop
Dense.c:30:20: missed: not vectorized: no vectype for stmt: _21 = *_20;
 scalar_type: float
Dense.c:20:13: note: vectorized 1 loops in function.
Dense.c:23:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:24:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:24:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:41:28: missed: couldn't vectorize loop
Dense.c:41:28: missed: not vectorized: unsupported outerloop form.
Dense.c:45:21: optimized: loop vectorized using 32 byte vectors
Dense.c:45:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:45:21: optimized: loop vectorized using 16 byte vectors
Dense.c:37:13: note: vectorized 1 loops in function.
Dense.c:37:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:37:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:41:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:132:19: missed: couldn't vectorize loop
Dense.c:132:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:123:19: missed: couldn't vectorize loop
Dense.c:123:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:116:13: note: vectorized 0 loops in function.
Dense.c:140:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:140:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:96:27: missed: couldn't vectorize loop
Dense.c:96:27: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:99:20: missed: couldn't vectorize loop
Dense.c:99:20: missed: not vectorized: unsupported control flow in loop.
Dense.c:84:19: missed: couldn't vectorize loop
Dense.c:84:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:78:13: note: vectorized 0 loops in function.
Dense.c:81:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:101:16: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:101:16: note: SLPing BB part
Dense.c:101:16: note: Costing subgraph: 
Dense.c:101:16: note: node 0x7566438 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:101:16: note: op template: _23 = (sizetype) j_90;
Dense.c:101:16: note: 	stmt 0 _23 = (sizetype) j_90;
Dense.c:101:16: note: 	stmt 1 _145 = (sizetype) wi_89;
Dense.c:101:16: note: 	children 0x7566538
Dense.c:101:16: note: node (external) 0x7566538 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:101:16: note: 	{ j_90, wi_89 }
Dense.c:101:16: note: Cost model analysis: 
Dense.c:101:16: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:101:16: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:101:16: missed: not vectorized: vectorization is not profitable.
Dense.c:101:16: note: ***** The result for vector mode V32QI would be the same
Dense.c:101:16: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:101:16: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:101:16: note: SLPing BB part
Dense.c:101:16: note: Costing subgraph: 
Dense.c:101:16: note: node 0x7566438 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:101:16: note: op template: _23 = (sizetype) j_90;
Dense.c:101:16: note: 	stmt 0 _23 = (sizetype) j_90;
Dense.c:101:16: note: 	stmt 1 _145 = (sizetype) wi_89;
Dense.c:101:16: note: 	children 0x75664b8
Dense.c:101:16: note: node (external) 0x75664b8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:101:16: note: 	{ j_90, wi_89 }
Dense.c:101:16: note: Cost model analysis: 
Dense.c:101:16: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:101:16: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:101:16: missed: not vectorized: vectorization is not profitable.
Dense.c:101:16: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:96:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:96:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:96:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:58:27: missed: couldn't vectorize loop
Dense.c:58:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:61:20: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:905:10: missed: not vectorized: no vectype for stmt: _41 = MEM[(__m256_u * {ref-all})_6];
 scalar_type: __m256_u
Dense.c:61:20: note: ***** Analysis failed with vector mode VOID
Dense.c:54:13: note: vectorized 0 loops in function.
Dense.c:54:13: missed: splitting region at dont-vectorize loop 3 entry at bb18
Dense.c:63:14: note: ***** Analysis failed with vector mode V4DI
Dense.c:63:14: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:63:14: missed: splitting region at dominance boundary bb8
Dense.c:63:14: note: ***** Analysis failed with vector mode VOID
Dense.c:63:14: missed: splitting region at loop 1 exit at bb16
Dense.c:58:27: note: ***** Analysis failed with vector mode V8SF
Dense.c:58:27: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Dense.c:58:27: missed: splitting region at dominance boundary bb10
Dense.c:58:27: note: ***** Analysis failed with vector mode VOID
Dense.c:74:2: missed: statement clobbers memory: _27 (pretmp_153, _61, 0);
Dense.c:75:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:75:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:147:2: missed: statement clobbers memory: free (_1);
Dense.c:148:2: missed: statement clobbers memory: free (_2);
Dense.c:149:2: missed: statement clobbers memory: free (_3);
Dense.c:150:2: missed: statement clobbers memory: free (_4);
Dense.c:151:2: missed: statement clobbers memory: free (dense_7);
Dense.c:152:2: missed: statement clobbers memory: PULSE_DestroyLayer (this_6(D));
Dense.c:153:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:153:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:167:19: missed: couldn't vectorize loop
Dense.c:167:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:157:13: note: vectorized 0 loops in function.
Dense.c:159:47: missed: statement clobbers memory: dense_35 = malloc (40);
Dense.c:161:36: missed: statement clobbers memory: _5 = aligned_alloc (64, _4);
Dense.c:162:38: missed: statement clobbers memory: _6 = aligned_alloc (64, _4);
Dense.c:163:36: missed: statement clobbers memory: _8 = aligned_alloc (64, _7);
Dense.c:164:35: missed: statement clobbers memory: _9 = aligned_alloc (64, _7);
Dense.c:165:36: missed: statement clobbers memory: _10 = aligned_alloc (64, _7);
Dense.c:168:39: missed: statement clobbers memory: _11 = rand ();
Dense.c:168:73: missed: statement clobbers memory: _63 = sqrt (_18);
Dense.c:185:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:186:4: missed: statement clobbers memory: exit (1);
Dense.c:178:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.3_29, n_outputs.2_28, 1, activation_function_51(D), _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:174:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.1_27, n_outputs.0_26, 1, activation_function_51(D), _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:192:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Dense.c:192:9: note: ***** Analysis failed with vector mode V4DI
Dense.c:192:9: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Activations.c:17:19: optimized: loop vectorized using 32 byte vectors
Activations.c:17:19: optimized: loop vectorized using 16 byte vectors
Activations.c:17:19: optimized: loop vectorized using 32 byte vectors
Activations.c:17:19: optimized: loop vectorized using 16 byte vectors
Activations.c:14:13: note: vectorized 2 loops in function.
Activations.c:14:13: note: ***** Analysis failed with vector mode V8SF
Activations.c:14:13: note: ***** The result for vector mode V32QI would be the same
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V16QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V16QI
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V8QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V8QI
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V4QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V4QI
Activations.c:28:19: missed: couldn't vectorize loop
Activations.c:28:19: missed: not vectorized: unsupported control flow in loop.
Activations.c:28:19: optimized: loop vectorized using 32 byte vectors
Activations.c:28:19: optimized: loop vectorized using 16 byte vectors
Activations.c:25:13: note: vectorized 1 loops in function.
Activations.c:25:13: note: ***** Analysis failed with vector mode V8SF
Activations.c:25:13: note: ***** The result for vector mode V32QI would be the same
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V16QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V16QI
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V8QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V8QI
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V4QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V4QI
Activations.c:38:1: note: ***** Analysis failed with vector mode VOID
Activations.c:5:19: missed: couldn't vectorize loop
Activations.c:9:21: missed: statement clobbers memory: _36 = expf (_18);
Activations.c:5:19: missed: couldn't vectorize loop
Activations.c:9:21: missed: statement clobbers memory: _12 = expf (_11);
Activations.c:3:13: note: vectorized 0 loops in function.
Activations.c:9:21: missed: statement clobbers memory: _12 = expf (_11);
Activations.c:9:21: missed: statement clobbers memory: _36 = expf (_18);
Activations.c:11:1: note: ***** Analysis failed with vector mode V8SF
Activations.c:11:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Activations.c:44:2: note: ***** Analysis failed with vector mode VOID
PULSE.c:58:34: missed: couldn't vectorize loop
PULSE.c:58:34: missed: not vectorized: unsupported outerloop form.
PULSE.c:55:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:55:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:49:15: note: vectorized 1 loops in function.
PULSE.c:57:3: missed: statement clobbers memory: printf ("Epoch: %d Item: %d Error: %f\r", prephitmp_60, prephitmp_87, _14);
PULSE.c:49:15: note: ***** Analysis failed with vector mode V4DI
PULSE.c:49:15: note: ***** The result for vector mode V32QI would be the same
PULSE.c:49:15: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:49:15: note: ***** Analysis failed with vector mode V16QI
PULSE.c:49:15: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:49:15: note: ***** Analysis failed with vector mode V8QI
PULSE.c:49:15: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:49:15: note: ***** Analysis failed with vector mode V4QI
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:4:18: note: vectorized 0 loops in function.
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_4, inputs_15, _3);
PULSE.c:8:2: missed: statement clobbers memory: _5 (layer_17);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_12, pretmp_26, _9);
PULSE.c:13:28: note: ***** Analysis failed with vector mode V8SI
PULSE.c:13:28: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:22:2: missed: statement clobbers memory: _1 (layer_10(D));
PULSE.c:22:2: missed: statement clobbers memory: _14 (_2);
PULSE.c:22:2: missed: statement clobbers memory: _21 (_15);
PULSE.c:22:2: missed: statement clobbers memory: _28 (_22);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_29);
PULSE.c:26:3: missed: statement clobbers memory: memset (_34, 0, _32);
PULSE.c:26:3: missed: statement clobbers memory: memset (_27, 0, _25);
PULSE.c:26:3: missed: statement clobbers memory: memset (_20, 0, _18);
PULSE.c:26:3: missed: statement clobbers memory: memset (_7, 0, _5);
PULSE.c:28:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:28:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:32:6: note: vectorized 1 loops in function.
PULSE.c:34:8: missed: statement clobbers memory: _1 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_2);
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _9 = rand ();
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8SI
PULSE.c:32:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:82:16: missed: couldn't vectorize loop
PULSE.c:82:16: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:85:17: missed: couldn't vectorize loop
PULSE.c:85:17: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:96:19: missed: couldn't vectorize loop
PULSE.c:96:19: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _89 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:70:22: missed: couldn't vectorize loop
PULSE.c:70:22: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:64:6: note: vectorized 1 loops in function.
PULSE.c:65:1: missed: statement clobbers memory: saved_stack.17_44 = __builtin_stack_save ();
PULSE.c:66:46: missed: statement clobbers memory: _1 = PULSE_GetLossFunctionPtr (loss_45(D));
PULSE.c:79:2: missed: statement clobbers memory: pthread_create (&logger_thread, 0B, PULSE_TrainLogger, &infos);
PULSE.c:81:10: missed: statement clobbers memory: random.6_62 = __builtin_alloca_with_align (_9, 32);
PULSE.c:34:8: missed: statement clobbers memory: _81 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_82);
PULSE.c:39:29: missed: statement clobbers memory: _89 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _92 = rand ();
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_118, inputs_113, _117);
PULSE.c:8:2: missed: statement clobbers memory: _119 (layer_114);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_125, _124, _123);
PULSE.c:90:4: missed: statement clobbers memory: PULSE_GetLoss_47 (_21, y_ptr_74, _20, _19);
PULSE.c:22:2: missed: statement clobbers memory: _106 (output_212);
PULSE.c:22:2: missed: statement clobbers memory: _128 (_107);
PULSE.c:22:2: missed: statement clobbers memory: _135 (_129);
PULSE.c:22:2: missed: statement clobbers memory: _142 (_136);
PULSE.c:22:2: missed: statement clobbers memory: _149 (_143);
PULSE.c:22:2: missed: statement clobbers memory: _156 (_150);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_157);
PULSE.c:26:3: missed: statement clobbers memory: memset (_162, 0, _160);
PULSE.c:26:3: missed: statement clobbers memory: memset (_155, 0, _153);
PULSE.c:26:3: missed: statement clobbers memory: memset (_148, 0, _146);
PULSE.c:26:3: missed: statement clobbers memory: memset (_141, 0, _139);
PULSE.c:26:3: missed: statement clobbers memory: memset (_134, 0, _132);
PULSE.c:26:3: missed: statement clobbers memory: memset (_112, 0, _110);
PULSE.c:98:6: missed: statement clobbers memory: _26 (current_207, args);
PULSE.c:105:2: missed: statement clobbers memory: pthread_join (logger_thread.16_35, 0B);
PULSE.c:64:6: missed: statement clobbers memory: __builtin_stack_restore (saved_stack.17_44);
PULSE.c:78:36: note: ***** Analysis succeeded with vector mode V4DI
PULSE.c:78:36: note: SLPing BB part
PULSE.c:78:36: note: Costing subgraph: 
PULSE.c:78:36: note: node 0x3d329c8 (max_nunits=2, refcnt=1) vector(2) int
PULSE.c:78:36: note: op template: infos.size = _4;
PULSE.c:78:36: note: 	stmt 0 infos.size = _4;
PULSE.c:78:36: note: 	stmt 1 infos.i_limit = epoch.3_5;
PULSE.c:78:36: note: 	children 0x3d32a48
PULSE.c:78:36: note: node 0x3d32a48 (max_nunits=2, refcnt=1) vector(2) int
PULSE.c:78:36: note: op template: _4 = (int) _3;
PULSE.c:78:36: note: 	stmt 0 _4 = (int) _3;
PULSE.c:78:36: note: 	stmt 1 epoch.3_5 = (int) epoch_54(D);
PULSE.c:78:36: note: 	children 0x3d32ac8
PULSE.c:78:36: note: node (external) 0x3d32ac8 (max_nunits=1, refcnt=1) vector(2) unsigned int
PULSE.c:78:36: note: 	{ _3, epoch_54(D) }
PULSE.c:78:36: note: Cost model analysis: 
PULSE.c:78:36: note: Cost model analysis for part in loop 0:
  Vector cost: 26
  Scalar cost: 32
PULSE.c:78:36: note: Costing subgraph: 
PULSE.c:78:36: note: node 0x3d32b48 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:78:36: note: op template: infos.i = &i;
PULSE.c:78:36: note: 	stmt 0 infos.i = &i;
PULSE.c:78:36: note: 	stmt 1 infos.j = &j;
PULSE.c:78:36: note: 	children 0x3d32bc8
PULSE.c:78:36: note: node (external) 0x3d32bc8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:78:36: note: 	{ &i, &j }
PULSE.c:78:36: note: Cost model analysis: 
PULSE.c:78:36: note: Cost model analysis for part in loop 0:
  Vector cost: 20
  Scalar cost: 32
PULSE.c:78:36: note: Costing subgraph: 
PULSE.c:78:36: note: node 0x3d32c48 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:78:36: note: op template: infos.x = _7;
PULSE.c:78:36: note: 	stmt 0 infos.x = _7;
PULSE.c:78:36: note: 	stmt 1 infos.y = y_50(D);
PULSE.c:78:36: note: 	children 0x3d32cc8
PULSE.c:78:36: note: node (external) 0x3d32cc8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:78:36: note: 	{ _7, y_50(D) }
PULSE.c:78:36: note: Cost model analysis: 
PULSE.c:78:36: note: Cost model analysis for part in loop 0:
  Vector cost: 26
  Scalar cost: 32
PULSE.c:78:36: note: Basic block will be vectorized using SLP
PULSE.c:78:36: optimized: basic block part vectorized using 8 byte vectors
PULSE.c:78:36: note: Vectorizing SLP tree:
PULSE.c:78:36: note: node 0x3d329c8 (max_nunits=2, refcnt=1) vector(2) int
PULSE.c:78:36: note: op template: infos.size = _4;
PULSE.c:78:36: note: 	stmt 0 infos.size = _4;
PULSE.c:78:36: note: 	stmt 1 infos.i_limit = epoch.3_5;
PULSE.c:78:36: note: 	children 0x3d32a48
PULSE.c:78:36: note: node 0x3d32a48 (max_nunits=2, refcnt=1) vector(2) int
PULSE.c:78:36: note: op template: _4 = (int) _3;
PULSE.c:78:36: note: 	stmt 0 _4 = (int) _3;
PULSE.c:78:36: note: 	stmt 1 epoch.3_5 = (int) epoch_54(D);
PULSE.c:78:36: note: 	children 0x3d32ac8
PULSE.c:78:36: note: node (external) 0x3d32ac8 (max_nunits=1, refcnt=1) vector(2) unsigned int
PULSE.c:78:36: note: 	{ _3, epoch_54(D) }
PULSE.c:78:36: note: ------>vectorizing SLP node starting from: _4 = (int) _3;
PULSE.c:78:36: note: transform assignment.
PULSE.c:78:36: note: add new stmt: vect__4.132_284 = VIEW_CONVERT_EXPR<vector(2) int>(_283);
PULSE.c:78:36: note: ------>vectorizing SLP node starting from: infos.size = _4;
PULSE.c:78:36: note: vect_is_simple_use: operand (int) _3, type of def: internal
PULSE.c:78:36: note: vect_is_simple_use: operand (int) epoch_54(D), type of def: internal
PULSE.c:78:36: note: transform store. ncopies = 1
PULSE.c:78:36: note: create vector_type-pointer variable to type: vector(2) int  vectorizing a pointer ref: infos.size
PULSE.c:78:36: note: created &infos.size
PULSE.c:78:36: note: add new stmt: MEM <vector(2) int> [(int *)&infos + 16B] = vect__4.132_284;
PULSE.c:78:36: note: vectorizing stmts using SLP.
PULSE.c:78:36: optimized: basic block part vectorized using 16 byte vectors
PULSE.c:78:36: note: Vectorizing SLP tree:
PULSE.c:78:36: note: node 0x3d32b48 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:78:36: note: op template: infos.i = &i;
PULSE.c:78:36: note: 	stmt 0 infos.i = &i;
PULSE.c:78:36: note: 	stmt 1 infos.j = &j;
PULSE.c:78:36: note: 	children 0x3d32bc8
PULSE.c:78:36: note: node (external) 0x3d32bc8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:78:36: note: 	{ &i, &j }
PULSE.c:78:36: note: ------>vectorizing SLP node starting from: infos.i = &i;
PULSE.c:78:36: note: vect_is_simple_use: operand &j, type of def: external
PULSE.c:78:36: note: transform store. ncopies = 1
PULSE.c:78:36: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: infos.i
PULSE.c:78:36: note: created &infos
PULSE.c:78:36: note: add new stmt: MEM <vector(2) long unsigned int> [(int * *)&infos] = _282;
PULSE.c:78:36: note: vectorizing stmts using SLP.
PULSE.c:78:36: optimized: basic block part vectorized using 16 byte vectors
PULSE.c:78:36: note: Vectorizing SLP tree:
PULSE.c:78:36: note: node 0x3d32c48 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:78:36: note: op template: infos.x = _7;
PULSE.c:78:36: note: 	stmt 0 infos.x = _7;
PULSE.c:78:36: note: 	stmt 1 infos.y = y_50(D);
PULSE.c:78:36: note: 	children 0x3d32cc8
PULSE.c:78:36: note: node (external) 0x3d32cc8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:78:36: note: 	{ _7, y_50(D) }
PULSE.c:78:36: note: ------>vectorizing SLP node starting from: infos.x = _7;
PULSE.c:78:36: note: vect_is_simple_use: operand y_50(D), type of def: external
PULSE.c:78:36: note: transform store. ncopies = 1
PULSE.c:78:36: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: infos.x
PULSE.c:78:36: note: created &infos.x
PULSE.c:78:36: note: add new stmt: MEM <vector(2) long unsigned int> [(float * *)&infos + 32B] = _70;
PULSE.c:78:36: note: vectorizing stmts using SLP.
PULSE.c:78:36: note: ***** The result for vector mode V32QI would be the same
PULSE.c:112:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:112:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:117:8: missed: couldn't vectorize loop
PULSE.c:117:8: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:114:6: note: vectorized 0 loops in function.
PULSE.c:119:3: missed: statement clobbers memory: _1 (current_10);
PULSE.c:122:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:122:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Loss.c:6:19: optimized: loop vectorized using 32 byte vectors
Loss.c:6:19: optimized:  loop versioned for vectorization because of possible aliasing
Loss.c:6:19: optimized: loop vectorized using 16 byte vectors
Loss.c:4:13: note: vectorized 1 loops in function.
Loss.c:4:13: note: ***** Analysis failed with vector mode V8SF
Loss.c:4:13: note: ***** The result for vector mode V32QI would be the same
Loss.c:4:13: note: ***** Re-trying analysis with vector mode V16QI
Loss.c:4:13: note: ***** Analysis failed with vector mode V16QI
Loss.c:4:13: note: ***** Re-trying analysis with vector mode V8QI
Loss.c:4:13: note: ***** Analysis failed with vector mode V8QI
Loss.c:4:13: note: ***** Re-trying analysis with vector mode V4QI
Loss.c:4:13: note: ***** Analysis failed with vector mode V4QI
Loss.c:12:19: optimized: loop vectorized using 32 byte vectors
Loss.c:12:19: optimized:  loop versioned for vectorization because of possible aliasing
Loss.c:12:19: optimized: loop vectorized using 16 byte vectors
Loss.c:10:13: note: vectorized 1 loops in function.
Loss.c:10:13: note: ***** Analysis failed with vector mode V8SF
Loss.c:10:13: note: ***** The result for vector mode V32QI would be the same
Loss.c:10:13: note: ***** Re-trying analysis with vector mode V16QI
Loss.c:10:13: note: ***** Analysis failed with vector mode V16QI
Loss.c:10:13: note: ***** Re-trying analysis with vector mode V8QI
Loss.c:10:13: note: ***** Analysis failed with vector mode V8QI
Loss.c:10:13: note: ***** Re-trying analysis with vector mode V4QI
Loss.c:10:13: note: ***** Analysis failed with vector mode V4QI
Loss.c:19:2: note: ***** Analysis failed with vector mode VOID
Dense.c:9:27: missed: couldn't vectorize loop
Dense.c:9:27: missed: not vectorized: unsupported outerloop form.
Dense.c:12:20: missed: couldn't vectorize loop
Dense.c:13:21: missed: not vectorized: complicated access pattern.
Dense.c:6:13: note: vectorized 0 loops in function.
Dense.c:16:2: missed: statement clobbers memory: _30 (pretmp_91, _50, 0);
Dense.c:9:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:9:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:24:27: missed: couldn't vectorize loop
Dense.c:24:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:28:20: optimized: loop vectorized using 32 byte vectors
Dense.c:28:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:28:20: optimized: loop vectorized using 16 byte vectors
Dense.c:28:20: missed: couldn't vectorize loop
Dense.c:30:20: missed: not vectorized: no vectype for stmt: _21 = *_20;
 scalar_type: float
Dense.c:20:13: note: vectorized 1 loops in function.
Dense.c:23:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:24:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:24:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:41:28: missed: couldn't vectorize loop
Dense.c:41:28: missed: not vectorized: unsupported outerloop form.
Dense.c:45:21: optimized: loop vectorized using 32 byte vectors
Dense.c:45:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:45:21: optimized: loop vectorized using 16 byte vectors
Dense.c:37:13: note: vectorized 1 loops in function.
Dense.c:37:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:37:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:41:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:145:19: missed: couldn't vectorize loop
Dense.c:145:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:136:19: missed: couldn't vectorize loop
Dense.c:136:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:129:13: note: vectorized 0 loops in function.
Dense.c:153:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:153:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:98:28: missed: couldn't vectorize loop
Dense.c:98:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:101:21: missed: couldn't vectorize loop
Dense.c:101:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:115:28: missed: couldn't vectorize loop
Dense.c:115:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:118:21: missed: couldn't vectorize loop
Dense.c:118:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:84:19: missed: couldn't vectorize loop
Dense.c:84:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:78:13: note: vectorized 0 loops in function.
Dense.c:81:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:103:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:103:17: note: SLPing BB part
Dense.c:120:17: note: Costing subgraph: 
Dense.c:120:17: note: node 0x770f918 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:120:17: note: op template: _49 = (sizetype) j_137;
Dense.c:120:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:120:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:120:17: note: 	children 0x770fa18
Dense.c:120:17: note: node (external) 0x770fa18 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:120:17: note: 	{ j_137, wi_136 }
Dense.c:120:17: note: Cost model analysis: 
Dense.c:120:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:120:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:120:17: missed: not vectorized: vectorization is not profitable.
Dense.c:103:17: note: Costing subgraph: 
Dense.c:103:17: note: node 0x770fb18 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:103:17: note: op template: _24 = (sizetype) j_134;
Dense.c:103:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:103:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:103:17: note: 	children 0x770fc18
Dense.c:103:17: note: node (external) 0x770fc18 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:103:17: note: 	{ j_134, wi_133 }
Dense.c:103:17: note: Cost model analysis: 
Dense.c:103:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:103:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:103:17: missed: not vectorized: vectorization is not profitable.
Dense.c:103:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:103:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:103:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:103:17: note: SLPing BB part
Dense.c:120:17: note: Costing subgraph: 
Dense.c:120:17: note: node 0x770fb18 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:120:17: note: op template: _49 = (sizetype) j_137;
Dense.c:120:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:120:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:120:17: note: 	children 0x770f918
Dense.c:120:17: note: node (external) 0x770f918 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:120:17: note: 	{ j_137, wi_136 }
Dense.c:120:17: note: Cost model analysis: 
Dense.c:120:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:120:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:120:17: missed: not vectorized: vectorization is not profitable.
Dense.c:103:17: note: Costing subgraph: 
Dense.c:103:17: note: node 0x770fc98 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:103:17: note: op template: _24 = (sizetype) j_134;
Dense.c:103:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:103:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:103:17: note: 	children 0x770fb98
Dense.c:103:17: note: node (external) 0x770fb98 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:103:17: note: 	{ j_134, wi_133 }
Dense.c:103:17: note: Cost model analysis: 
Dense.c:103:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:103:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:103:17: missed: not vectorized: vectorization is not profitable.
Dense.c:103:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:98:55: note: ***** Analysis failed with vector mode V8QI
Dense.c:98:55: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:98:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:58:27: missed: couldn't vectorize loop
Dense.c:58:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:61:20: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:905:10: missed: not vectorized: no vectype for stmt: _41 = MEM[(__m256_u * {ref-all})_6];
 scalar_type: __m256_u
Dense.c:61:20: note: ***** Analysis failed with vector mode VOID
Dense.c:54:13: note: vectorized 0 loops in function.
Dense.c:54:13: missed: splitting region at dont-vectorize loop 3 entry at bb18
Dense.c:63:14: note: ***** Analysis failed with vector mode V4DI
Dense.c:63:14: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:63:14: missed: splitting region at dominance boundary bb8
Dense.c:63:14: note: ***** Analysis failed with vector mode VOID
Dense.c:63:14: missed: splitting region at loop 1 exit at bb16
Dense.c:58:27: note: ***** Analysis failed with vector mode V8SF
Dense.c:58:27: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Dense.c:58:27: missed: splitting region at dominance boundary bb10
Dense.c:58:27: note: ***** Analysis failed with vector mode VOID
Dense.c:74:2: missed: statement clobbers memory: _27 (pretmp_153, _61, 0);
Dense.c:75:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:75:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:160:2: missed: statement clobbers memory: free (_1);
Dense.c:161:2: missed: statement clobbers memory: free (_2);
Dense.c:162:2: missed: statement clobbers memory: free (_3);
Dense.c:163:2: missed: statement clobbers memory: free (_4);
Dense.c:164:2: missed: statement clobbers memory: free (dense_7);
Dense.c:165:2: missed: statement clobbers memory: PULSE_DestroyLayer (this_6(D));
Dense.c:166:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:166:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:180:19: missed: couldn't vectorize loop
Dense.c:180:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:170:13: note: vectorized 0 loops in function.
Dense.c:172:47: missed: statement clobbers memory: dense_35 = malloc (40);
Dense.c:174:36: missed: statement clobbers memory: _5 = aligned_alloc (64, _4);
Dense.c:175:38: missed: statement clobbers memory: _6 = aligned_alloc (64, _4);
Dense.c:176:36: missed: statement clobbers memory: _8 = aligned_alloc (64, _7);
Dense.c:177:35: missed: statement clobbers memory: _9 = aligned_alloc (64, _7);
Dense.c:178:36: missed: statement clobbers memory: _10 = aligned_alloc (64, _7);
Dense.c:181:39: missed: statement clobbers memory: _11 = rand ();
Dense.c:181:73: missed: statement clobbers memory: _63 = sqrt (_18);
Dense.c:198:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:199:4: missed: statement clobbers memory: exit (1);
Dense.c:191:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.3_29, n_outputs.2_28, 1, activation_function_51(D), _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:187:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.1_27, n_outputs.0_26, 1, activation_function_51(D), _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:205:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Dense.c:205:9: note: ***** Analysis failed with vector mode V4DI
Dense.c:205:9: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Layer.c:7:34: missed: statement clobbers memory: _3 = aligned_alloc (64, _2);
Layer.c:8:35: missed: statement clobbers memory: _6 = aligned_alloc (64, _5);
Layer.c:9:34: missed: statement clobbers memory: _7 = aligned_alloc (64, _5);
Layer.c:14:19: missed: statement clobbers memory: _8 = PULSE_GetActivationFunctionPtr (activation_function_18(D));
Layer.c:19:9: note: ***** Analysis succeeded with vector mode V8SI
Layer.c:19:9: note: SLPing BB part
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x38937d8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 0 MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 1 MEM <unsigned int> [(struct PULSE_Layer *)&<retval> + 4B] = optimization_type_17(D);
Layer.c:19:9: note: 	children 0x3893858
Layer.c:19:9: note: node (external) 0x3893858 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ type_16(D), optimization_type_17(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x38938d8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 0 <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 1 <retval>.n_outputs = n_outputs_12(D);
Layer.c:19:9: note: 	children 0x3893958
Layer.c:19:9: note: node (external) 0x3893958 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x3893a58 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 0 <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 1 <retval>.outputs = _6;
Layer.c:19:9: note: 	children 0x3893ad8
Layer.c:19:9: note: node (external) 0x3893ad8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	stmt 0 _3 = aligned_alloc (64, _2);
Layer.c:19:9: note: 	stmt 1 _6 = aligned_alloc (64, _5);
Layer.c:19:9: note: 	children 0x3893b58 0x3893bd8
Layer.c:19:9: note: node (constant) 0x3893b58 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 64, 64 }
Layer.c:19:9: note: node 0x3893bd8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: patt_40 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 0 patt_40 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 1 patt_41 = n_outputs_12(D) w* 4;
Layer.c:19:9: note: 	children 0x3893c58 0x3893cd8
Layer.c:19:9: note: node (external) 0x3893c58 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: node (constant) 0x3893cd8 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ 4, 4 }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x3893dd8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: op template: <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 0 <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 1 <retval>.back = back_21(D);
Layer.c:19:9: note: 	stmt 2 <retval>.fix = fix_22(D);
Layer.c:19:9: note: 	stmt 3 <retval>.destroy = destroy_23(D);
Layer.c:19:9: note: 	children 0x3893e58
Layer.c:19:9: note: node (external) 0x3893e58 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: 	{ feed_20(D), back_21(D), fix_22(D), destroy_23(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 64
  Scalar cost: 64
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x3893f58 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 0 <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 1 <retval>.child = 0B;
Layer.c:19:9: note: 	children 0x3893fd8
Layer.c:19:9: note: node (constant) 0x3893fd8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ 0B, 0B }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Basic block will be vectorized using SLP
Layer.c:19:9: optimized: basic block part vectorized using 8 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x38937d8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 0 MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 1 MEM <unsigned int> [(struct PULSE_Layer *)&<retval> + 4B] = optimization_type_17(D);
Layer.c:19:9: note: 	children 0x3893858
Layer.c:19:9: note: node (external) 0x3893858 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ type_16(D), optimization_type_17(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: vect_is_simple_use: operand optimization_type_17(D), type of def: external
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>]
Layer.c:19:9: note: created &MEM <unsigned int> [(struct PULSE_Layer *)&<retval>]
Layer.c:19:9: note: add new stmt: MEM <vector(2) unsigned int> [(struct PULSE_Layer *)&<retval>] = _42;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 8 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x38938d8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 0 <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 1 <retval>.n_outputs = n_outputs_12(D);
Layer.c:19:9: note: 	children 0x3893958
Layer.c:19:9: note: node (external) 0x3893958 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: vect_is_simple_use: operand n_outputs_12(D), type of def: external
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: <retval>.n_inputs
Layer.c:19:9: note: created &<retval>.n_inputs
Layer.c:19:9: note: add new stmt: MEM <vector(2) unsigned int> [(unsigned int *)&<retval> + 96B] = _44;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 16 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x3893a58 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 0 <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 1 <retval>.outputs = _6;
Layer.c:19:9: note: 	children 0x3893ad8
Layer.c:19:9: note: node (external) 0x3893ad8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	stmt 0 _3 = aligned_alloc (64, _2);
Layer.c:19:9: note: 	stmt 1 _6 = aligned_alloc (64, _5);
Layer.c:19:9: note: 	children 0x3893b58 0x3893bd8
Layer.c:19:9: note: node (constant) 0x3893b58 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 64, 64 }
Layer.c:19:9: note: node 0x3893bd8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: patt_40 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 0 patt_40 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 1 patt_41 = n_outputs_12(D) w* 4;
Layer.c:19:9: note: 	children 0x3893c58 0x3893cd8
Layer.c:19:9: note: node (external) 0x3893c58 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: node (constant) 0x3893cd8 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ 4, 4 }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.inputs = _3;
Layer.c:19:9: note: vect_is_simple_use: operand aligned_alloc (64, _5), type of def: internal
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.inputs
Layer.c:19:9: note: created &<retval>.inputs
Layer.c:19:9: note: add new stmt: MEM <vector(2) long unsigned int> [(float * *)&<retval> + 8B] = _48;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 32 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x3893dd8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: op template: <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 0 <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 1 <retval>.back = back_21(D);
Layer.c:19:9: note: 	stmt 2 <retval>.fix = fix_22(D);
Layer.c:19:9: note: 	stmt 3 <retval>.destroy = destroy_23(D);
Layer.c:19:9: note: 	children 0x3893e58
Layer.c:19:9: note: node (external) 0x3893e58 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: 	{ feed_20(D), back_21(D), fix_22(D), destroy_23(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.feed = feed_20(D);
Layer.c:19:9: note: vect_is_simple_use: operand back_21(D), type of def: external
Layer.c:19:9: note: vect_is_simple_use: operand fix_22(D), type of def: external
Layer.c:19:9: note: vect_is_simple_use: operand destroy_23(D), type of def: external
Layer.c:19:9: note: conflicting alias set types.
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(4) long unsigned int  vectorizing a pointer ref: <retval>.feed
Layer.c:19:9: note: created &<retval>.feed
Layer.c:19:9: note: add new stmt: MEM <vector(4) long unsigned int> [(void *)&<retval> + 32B] = _54;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 16 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x3893f58 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 0 <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 1 <retval>.child = 0B;
Layer.c:19:9: note: 	children 0x3893fd8
Layer.c:19:9: note: node (constant) 0x3893fd8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ 0B, 0B }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.parent = 0B;
Layer.c:19:9: note: vect_is_simple_use: operand 0B, type of def: constant
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.parent
Layer.c:19:9: note: created &<retval>.parent
Layer.c:19:9: note: add new stmt: MEM <vector(2) long unsigned int> [(struct PULSE_Layer * *)&<retval> + 72B] = { 0, 0 };
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: note: ***** The result for vector mode V32QI would be the same
Layer.c:24:2: missed: statement clobbers memory: free (_1);
Layer.c:25:2: missed: statement clobbers memory: free (_2);
Layer.c:26:2: missed: statement clobbers memory: free (_3);
Layer.c:27:1: note: ***** Analysis failed with vector mode V4DI
Layer.c:27:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:9:27: missed: couldn't vectorize loop
Dense.c:9:27: missed: not vectorized: unsupported outerloop form.
Dense.c:12:20: missed: couldn't vectorize loop
Dense.c:13:21: missed: not vectorized: complicated access pattern.
Dense.c:6:13: note: vectorized 0 loops in function.
Dense.c:16:2: missed: statement clobbers memory: _30 (pretmp_91, _50, 0);
Dense.c:9:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:9:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:24:27: missed: couldn't vectorize loop
Dense.c:24:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:28:20: optimized: loop vectorized using 32 byte vectors
Dense.c:28:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:28:20: optimized: loop vectorized using 16 byte vectors
Dense.c:28:20: missed: couldn't vectorize loop
Dense.c:30:20: missed: not vectorized: no vectype for stmt: _21 = *_20;
 scalar_type: float
Dense.c:20:13: note: vectorized 1 loops in function.
Dense.c:23:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:24:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:24:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:41:28: missed: couldn't vectorize loop
Dense.c:41:28: missed: not vectorized: unsupported outerloop form.
Dense.c:45:21: optimized: loop vectorized using 32 byte vectors
Dense.c:45:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:45:21: optimized: loop vectorized using 16 byte vectors
Dense.c:37:13: note: vectorized 1 loops in function.
Dense.c:37:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:37:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:41:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:145:19: missed: couldn't vectorize loop
Dense.c:145:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:136:19: missed: couldn't vectorize loop
Dense.c:136:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:129:13: note: vectorized 0 loops in function.
Dense.c:153:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:153:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:98:28: missed: couldn't vectorize loop
Dense.c:98:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:101:21: missed: couldn't vectorize loop
Dense.c:101:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:115:28: missed: couldn't vectorize loop
Dense.c:115:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:118:21: missed: couldn't vectorize loop
Dense.c:118:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:84:19: missed: couldn't vectorize loop
Dense.c:84:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:78:13: note: vectorized 0 loops in function.
Dense.c:81:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:103:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:103:17: note: SLPing BB part
Dense.c:120:17: note: Costing subgraph: 
Dense.c:120:17: note: node 0x72332a8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:120:17: note: op template: _49 = (sizetype) j_137;
Dense.c:120:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:120:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:120:17: note: 	children 0x72333a8
Dense.c:120:17: note: node (external) 0x72333a8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:120:17: note: 	{ j_137, wi_136 }
Dense.c:120:17: note: Cost model analysis: 
Dense.c:120:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:120:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:120:17: missed: not vectorized: vectorization is not profitable.
Dense.c:103:17: note: Costing subgraph: 
Dense.c:103:17: note: node 0x72334a8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:103:17: note: op template: _24 = (sizetype) j_134;
Dense.c:103:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:103:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:103:17: note: 	children 0x72335a8
Dense.c:103:17: note: node (external) 0x72335a8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:103:17: note: 	{ j_134, wi_133 }
Dense.c:103:17: note: Cost model analysis: 
Dense.c:103:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:103:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:103:17: missed: not vectorized: vectorization is not profitable.
Dense.c:103:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:103:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:103:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:103:17: note: SLPing BB part
Dense.c:120:17: note: Costing subgraph: 
Dense.c:120:17: note: node 0x72334a8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:120:17: note: op template: _49 = (sizetype) j_137;
Dense.c:120:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:120:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:120:17: note: 	children 0x72332a8
Dense.c:120:17: note: node (external) 0x72332a8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:120:17: note: 	{ j_137, wi_136 }
Dense.c:120:17: note: Cost model analysis: 
Dense.c:120:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:120:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:120:17: missed: not vectorized: vectorization is not profitable.
Dense.c:103:17: note: Costing subgraph: 
Dense.c:103:17: note: node 0x7233628 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:103:17: note: op template: _24 = (sizetype) j_134;
Dense.c:103:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:103:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:103:17: note: 	children 0x7233528
Dense.c:103:17: note: node (external) 0x7233528 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:103:17: note: 	{ j_134, wi_133 }
Dense.c:103:17: note: Cost model analysis: 
Dense.c:103:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:103:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:103:17: missed: not vectorized: vectorization is not profitable.
Dense.c:103:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:98:55: note: ***** Analysis failed with vector mode V8QI
Dense.c:98:55: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:98:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:58:27: missed: couldn't vectorize loop
Dense.c:58:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:61:20: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:905:10: missed: not vectorized: no vectype for stmt: _41 = MEM[(__m256_u * {ref-all})_6];
 scalar_type: __m256_u
Dense.c:61:20: note: ***** Analysis failed with vector mode VOID
Dense.c:54:13: note: vectorized 0 loops in function.
Dense.c:54:13: missed: splitting region at dont-vectorize loop 3 entry at bb18
Dense.c:63:14: note: ***** Analysis failed with vector mode V4DI
Dense.c:63:14: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:63:14: missed: splitting region at dominance boundary bb8
Dense.c:63:14: note: ***** Analysis failed with vector mode VOID
Dense.c:63:14: missed: splitting region at loop 1 exit at bb16
Dense.c:58:27: note: ***** Analysis failed with vector mode V8SF
Dense.c:58:27: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Dense.c:58:27: missed: splitting region at dominance boundary bb10
Dense.c:58:27: note: ***** Analysis failed with vector mode VOID
Dense.c:74:2: missed: statement clobbers memory: _27 (pretmp_153, _61, 0);
Dense.c:75:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:75:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:160:2: missed: statement clobbers memory: free (_1);
Dense.c:161:2: missed: statement clobbers memory: free (_2);
Dense.c:162:2: missed: statement clobbers memory: free (_3);
Dense.c:163:2: missed: statement clobbers memory: free (_4);
Dense.c:164:2: missed: statement clobbers memory: free (dense_7);
Dense.c:165:2: missed: statement clobbers memory: PULSE_DestroyLayer (this_6(D));
Dense.c:166:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:166:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:180:19: missed: couldn't vectorize loop
Dense.c:180:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:170:13: note: vectorized 0 loops in function.
Dense.c:172:47: missed: statement clobbers memory: dense_35 = malloc (40);
Dense.c:174:36: missed: statement clobbers memory: _5 = aligned_alloc (64, _4);
Dense.c:175:38: missed: statement clobbers memory: _6 = aligned_alloc (64, _4);
Dense.c:176:36: missed: statement clobbers memory: _8 = aligned_alloc (64, _7);
Dense.c:177:35: missed: statement clobbers memory: _9 = aligned_alloc (64, _7);
Dense.c:178:36: missed: statement clobbers memory: _10 = aligned_alloc (64, _7);
Dense.c:181:39: missed: statement clobbers memory: _11 = rand ();
Dense.c:181:73: missed: statement clobbers memory: _63 = sqrt (_18);
Dense.c:198:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:199:4: missed: statement clobbers memory: exit (1);
Dense.c:191:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.3_29, n_outputs.2_28, 1, activation_function_51(D), _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:187:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.1_27, n_outputs.0_26, 1, activation_function_51(D), _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:205:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Dense.c:205:9: note: ***** Analysis failed with vector mode V4DI
Dense.c:205:9: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Activations.c:17:19: optimized: loop vectorized using 32 byte vectors
Activations.c:17:19: optimized: loop vectorized using 16 byte vectors
Activations.c:17:19: optimized: loop vectorized using 32 byte vectors
Activations.c:17:19: optimized: loop vectorized using 16 byte vectors
Activations.c:14:13: note: vectorized 2 loops in function.
Activations.c:14:13: note: ***** Analysis failed with vector mode V8SF
Activations.c:14:13: note: ***** The result for vector mode V32QI would be the same
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V16QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V16QI
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V8QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V8QI
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V4QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V4QI
Activations.c:28:19: missed: couldn't vectorize loop
Activations.c:28:19: missed: not vectorized: unsupported control flow in loop.
Activations.c:28:19: optimized: loop vectorized using 32 byte vectors
Activations.c:28:19: optimized: loop vectorized using 16 byte vectors
Activations.c:25:13: note: vectorized 1 loops in function.
Activations.c:25:13: note: ***** Analysis failed with vector mode V8SF
Activations.c:25:13: note: ***** The result for vector mode V32QI would be the same
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V16QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V16QI
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V8QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V8QI
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V4QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V4QI
Activations.c:38:1: note: ***** Analysis failed with vector mode VOID
Activations.c:5:19: missed: couldn't vectorize loop
Activations.c:9:21: missed: statement clobbers memory: _36 = expf (_18);
Activations.c:5:19: missed: couldn't vectorize loop
Activations.c:9:21: missed: statement clobbers memory: _12 = expf (_11);
Activations.c:3:13: note: vectorized 0 loops in function.
Activations.c:9:21: missed: statement clobbers memory: _12 = expf (_11);
Activations.c:9:21: missed: statement clobbers memory: _36 = expf (_18);
Activations.c:11:1: note: ***** Analysis failed with vector mode V8SF
Activations.c:11:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Activations.c:44:2: note: ***** Analysis failed with vector mode VOID
PULSE.c:58:34: missed: couldn't vectorize loop
PULSE.c:58:34: missed: not vectorized: unsupported outerloop form.
PULSE.c:55:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:55:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:49:15: note: vectorized 1 loops in function.
PULSE.c:57:3: missed: statement clobbers memory: printf ("Epoch: %d Item: %d Error: %f\r", prephitmp_60, prephitmp_87, _14);
PULSE.c:49:15: note: ***** Analysis failed with vector mode V4DI
PULSE.c:49:15: note: ***** The result for vector mode V32QI would be the same
PULSE.c:49:15: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:49:15: note: ***** Analysis failed with vector mode V16QI
PULSE.c:49:15: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:49:15: note: ***** Analysis failed with vector mode V8QI
PULSE.c:49:15: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:49:15: note: ***** Analysis failed with vector mode V4QI
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:4:18: note: vectorized 0 loops in function.
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_4, inputs_15, _3);
PULSE.c:8:2: missed: statement clobbers memory: _5 (layer_17);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_12, pretmp_26, _9);
PULSE.c:13:28: note: ***** Analysis failed with vector mode V8SI
PULSE.c:13:28: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:22:2: missed: statement clobbers memory: _1 (layer_10(D));
PULSE.c:22:2: missed: statement clobbers memory: _14 (_2);
PULSE.c:22:2: missed: statement clobbers memory: _21 (_15);
PULSE.c:22:2: missed: statement clobbers memory: _28 (_22);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_29);
PULSE.c:26:3: missed: statement clobbers memory: memset (_34, 0, _32);
PULSE.c:26:3: missed: statement clobbers memory: memset (_27, 0, _25);
PULSE.c:26:3: missed: statement clobbers memory: memset (_20, 0, _18);
PULSE.c:26:3: missed: statement clobbers memory: memset (_7, 0, _5);
PULSE.c:28:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:28:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:32:6: note: vectorized 1 loops in function.
PULSE.c:34:8: missed: statement clobbers memory: _1 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_2);
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _9 = rand ();
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8SI
PULSE.c:32:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:82:16: missed: couldn't vectorize loop
PULSE.c:82:16: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:85:17: missed: couldn't vectorize loop
PULSE.c:85:17: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:96:19: missed: couldn't vectorize loop
PULSE.c:96:19: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _89 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:70:22: missed: couldn't vectorize loop
PULSE.c:70:22: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:64:6: note: vectorized 1 loops in function.
PULSE.c:65:1: missed: statement clobbers memory: saved_stack.17_44 = __builtin_stack_save ();
PULSE.c:66:46: missed: statement clobbers memory: _1 = PULSE_GetLossFunctionPtr (loss_45(D));
PULSE.c:79:2: missed: statement clobbers memory: pthread_create (&logger_thread, 0B, PULSE_TrainLogger, &infos);
PULSE.c:81:10: missed: statement clobbers memory: random.6_62 = __builtin_alloca_with_align (_9, 32);
PULSE.c:34:8: missed: statement clobbers memory: _81 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_82);
PULSE.c:39:29: missed: statement clobbers memory: _89 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _92 = rand ();
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_118, inputs_113, _117);
PULSE.c:8:2: missed: statement clobbers memory: _119 (layer_114);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_125, _124, _123);
PULSE.c:90:4: missed: statement clobbers memory: PULSE_GetLoss_47 (_21, y_ptr_74, _20, _19);
PULSE.c:22:2: missed: statement clobbers memory: _106 (output_212);
PULSE.c:22:2: missed: statement clobbers memory: _128 (_107);
PULSE.c:22:2: missed: statement clobbers memory: _135 (_129);
PULSE.c:22:2: missed: statement clobbers memory: _142 (_136);
PULSE.c:22:2: missed: statement clobbers memory: _149 (_143);
PULSE.c:22:2: missed: statement clobbers memory: _156 (_150);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_157);
PULSE.c:26:3: missed: statement clobbers memory: memset (_162, 0, _160);
PULSE.c:26:3: missed: statement clobbers memory: memset (_155, 0, _153);
PULSE.c:26:3: missed: statement clobbers memory: memset (_148, 0, _146);
PULSE.c:26:3: missed: statement clobbers memory: memset (_141, 0, _139);
PULSE.c:26:3: missed: statement clobbers memory: memset (_134, 0, _132);
PULSE.c:26:3: missed: statement clobbers memory: memset (_112, 0, _110);
PULSE.c:98:6: missed: statement clobbers memory: _26 (current_207, args);
PULSE.c:105:2: missed: statement clobbers memory: pthread_join (logger_thread.16_35, 0B);
PULSE.c:64:6: missed: statement clobbers memory: __builtin_stack_restore (saved_stack.17_44);
PULSE.c:78:36: note: ***** Analysis succeeded with vector mode V4DI
PULSE.c:78:36: note: SLPing BB part
PULSE.c:78:36: note: Costing subgraph: 
PULSE.c:78:36: note: node 0x3ef39c8 (max_nunits=2, refcnt=1) vector(2) int
PULSE.c:78:36: note: op template: infos.size = _4;
PULSE.c:78:36: note: 	stmt 0 infos.size = _4;
PULSE.c:78:36: note: 	stmt 1 infos.i_limit = epoch.3_5;
PULSE.c:78:36: note: 	children 0x3ef3a48
PULSE.c:78:36: note: node 0x3ef3a48 (max_nunits=2, refcnt=1) vector(2) int
PULSE.c:78:36: note: op template: _4 = (int) _3;
PULSE.c:78:36: note: 	stmt 0 _4 = (int) _3;
PULSE.c:78:36: note: 	stmt 1 epoch.3_5 = (int) epoch_54(D);
PULSE.c:78:36: note: 	children 0x3ef3ac8
PULSE.c:78:36: note: node (external) 0x3ef3ac8 (max_nunits=1, refcnt=1) vector(2) unsigned int
PULSE.c:78:36: note: 	{ _3, epoch_54(D) }
PULSE.c:78:36: note: Cost model analysis: 
PULSE.c:78:36: note: Cost model analysis for part in loop 0:
  Vector cost: 26
  Scalar cost: 32
PULSE.c:78:36: note: Costing subgraph: 
PULSE.c:78:36: note: node 0x3ef3b48 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:78:36: note: op template: infos.i = &i;
PULSE.c:78:36: note: 	stmt 0 infos.i = &i;
PULSE.c:78:36: note: 	stmt 1 infos.j = &j;
PULSE.c:78:36: note: 	children 0x3ef3bc8
PULSE.c:78:36: note: node (external) 0x3ef3bc8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:78:36: note: 	{ &i, &j }
PULSE.c:78:36: note: Cost model analysis: 
PULSE.c:78:36: note: Cost model analysis for part in loop 0:
  Vector cost: 20
  Scalar cost: 32
PULSE.c:78:36: note: Costing subgraph: 
PULSE.c:78:36: note: node 0x3ef3c48 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:78:36: note: op template: infos.x = _7;
PULSE.c:78:36: note: 	stmt 0 infos.x = _7;
PULSE.c:78:36: note: 	stmt 1 infos.y = y_50(D);
PULSE.c:78:36: note: 	children 0x3ef3cc8
PULSE.c:78:36: note: node (external) 0x3ef3cc8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:78:36: note: 	{ _7, y_50(D) }
PULSE.c:78:36: note: Cost model analysis: 
PULSE.c:78:36: note: Cost model analysis for part in loop 0:
  Vector cost: 26
  Scalar cost: 32
PULSE.c:78:36: note: Basic block will be vectorized using SLP
PULSE.c:78:36: optimized: basic block part vectorized using 8 byte vectors
PULSE.c:78:36: note: Vectorizing SLP tree:
PULSE.c:78:36: note: node 0x3ef39c8 (max_nunits=2, refcnt=1) vector(2) int
PULSE.c:78:36: note: op template: infos.size = _4;
PULSE.c:78:36: note: 	stmt 0 infos.size = _4;
PULSE.c:78:36: note: 	stmt 1 infos.i_limit = epoch.3_5;
PULSE.c:78:36: note: 	children 0x3ef3a48
PULSE.c:78:36: note: node 0x3ef3a48 (max_nunits=2, refcnt=1) vector(2) int
PULSE.c:78:36: note: op template: _4 = (int) _3;
PULSE.c:78:36: note: 	stmt 0 _4 = (int) _3;
PULSE.c:78:36: note: 	stmt 1 epoch.3_5 = (int) epoch_54(D);
PULSE.c:78:36: note: 	children 0x3ef3ac8
PULSE.c:78:36: note: node (external) 0x3ef3ac8 (max_nunits=1, refcnt=1) vector(2) unsigned int
PULSE.c:78:36: note: 	{ _3, epoch_54(D) }
PULSE.c:78:36: note: ------>vectorizing SLP node starting from: _4 = (int) _3;
PULSE.c:78:36: note: transform assignment.
PULSE.c:78:36: note: add new stmt: vect__4.132_284 = VIEW_CONVERT_EXPR<vector(2) int>(_283);
PULSE.c:78:36: note: ------>vectorizing SLP node starting from: infos.size = _4;
PULSE.c:78:36: note: vect_is_simple_use: operand (int) _3, type of def: internal
PULSE.c:78:36: note: vect_is_simple_use: operand (int) epoch_54(D), type of def: internal
PULSE.c:78:36: note: transform store. ncopies = 1
PULSE.c:78:36: note: create vector_type-pointer variable to type: vector(2) int  vectorizing a pointer ref: infos.size
PULSE.c:78:36: note: created &infos.size
PULSE.c:78:36: note: add new stmt: MEM <vector(2) int> [(int *)&infos + 16B] = vect__4.132_284;
PULSE.c:78:36: note: vectorizing stmts using SLP.
PULSE.c:78:36: optimized: basic block part vectorized using 16 byte vectors
PULSE.c:78:36: note: Vectorizing SLP tree:
PULSE.c:78:36: note: node 0x3ef3b48 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:78:36: note: op template: infos.i = &i;
PULSE.c:78:36: note: 	stmt 0 infos.i = &i;
PULSE.c:78:36: note: 	stmt 1 infos.j = &j;
PULSE.c:78:36: note: 	children 0x3ef3bc8
PULSE.c:78:36: note: node (external) 0x3ef3bc8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:78:36: note: 	{ &i, &j }
PULSE.c:78:36: note: ------>vectorizing SLP node starting from: infos.i = &i;
PULSE.c:78:36: note: vect_is_simple_use: operand &j, type of def: external
PULSE.c:78:36: note: transform store. ncopies = 1
PULSE.c:78:36: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: infos.i
PULSE.c:78:36: note: created &infos
PULSE.c:78:36: note: add new stmt: MEM <vector(2) long unsigned int> [(int * *)&infos] = _282;
PULSE.c:78:36: note: vectorizing stmts using SLP.
PULSE.c:78:36: optimized: basic block part vectorized using 16 byte vectors
PULSE.c:78:36: note: Vectorizing SLP tree:
PULSE.c:78:36: note: node 0x3ef3c48 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:78:36: note: op template: infos.x = _7;
PULSE.c:78:36: note: 	stmt 0 infos.x = _7;
PULSE.c:78:36: note: 	stmt 1 infos.y = y_50(D);
PULSE.c:78:36: note: 	children 0x3ef3cc8
PULSE.c:78:36: note: node (external) 0x3ef3cc8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:78:36: note: 	{ _7, y_50(D) }
PULSE.c:78:36: note: ------>vectorizing SLP node starting from: infos.x = _7;
PULSE.c:78:36: note: vect_is_simple_use: operand y_50(D), type of def: external
PULSE.c:78:36: note: transform store. ncopies = 1
PULSE.c:78:36: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: infos.x
PULSE.c:78:36: note: created &infos.x
PULSE.c:78:36: note: add new stmt: MEM <vector(2) long unsigned int> [(float * *)&infos + 32B] = _70;
PULSE.c:78:36: note: vectorizing stmts using SLP.
PULSE.c:78:36: note: ***** The result for vector mode V32QI would be the same
PULSE.c:112:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:112:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:117:8: missed: couldn't vectorize loop
PULSE.c:117:8: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:114:6: note: vectorized 0 loops in function.
PULSE.c:119:3: missed: statement clobbers memory: _1 (current_10);
PULSE.c:122:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:122:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Loss.c:6:19: optimized: loop vectorized using 32 byte vectors
Loss.c:6:19: optimized:  loop versioned for vectorization because of possible aliasing
Loss.c:6:19: optimized: loop vectorized using 16 byte vectors
Loss.c:4:13: note: vectorized 1 loops in function.
Loss.c:4:13: note: ***** Analysis failed with vector mode V8SF
Loss.c:4:13: note: ***** The result for vector mode V32QI would be the same
Loss.c:4:13: note: ***** Re-trying analysis with vector mode V16QI
Loss.c:4:13: note: ***** Analysis failed with vector mode V16QI
Loss.c:4:13: note: ***** Re-trying analysis with vector mode V8QI
Loss.c:4:13: note: ***** Analysis failed with vector mode V8QI
Loss.c:4:13: note: ***** Re-trying analysis with vector mode V4QI
Loss.c:4:13: note: ***** Analysis failed with vector mode V4QI
Loss.c:12:19: optimized: loop vectorized using 32 byte vectors
Loss.c:12:19: optimized:  loop versioned for vectorization because of possible aliasing
Loss.c:12:19: optimized: loop vectorized using 16 byte vectors
Loss.c:10:13: note: vectorized 1 loops in function.
Loss.c:10:13: note: ***** Analysis failed with vector mode V8SF
Loss.c:10:13: note: ***** The result for vector mode V32QI would be the same
Loss.c:10:13: note: ***** Re-trying analysis with vector mode V16QI
Loss.c:10:13: note: ***** Analysis failed with vector mode V16QI
Loss.c:10:13: note: ***** Re-trying analysis with vector mode V8QI
Loss.c:10:13: note: ***** Analysis failed with vector mode V8QI
Loss.c:10:13: note: ***** Re-trying analysis with vector mode V4QI
Loss.c:10:13: note: ***** Analysis failed with vector mode V4QI
Loss.c:19:2: note: ***** Analysis failed with vector mode VOID
PULSE.c:57:34: missed: couldn't vectorize loop
PULSE.c:57:34: missed: not vectorized: unsupported outerloop form.
PULSE.c:54:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:54:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:48:15: note: vectorized 1 loops in function.
PULSE.c:56:3: missed: statement clobbers memory: printf ("Epoch: %d Item: %d Error: %f\r", prephitmp_60, prephitmp_87, _14);
PULSE.c:48:15: note: ***** Analysis failed with vector mode V4DI
PULSE.c:48:15: note: ***** The result for vector mode V32QI would be the same
PULSE.c:48:15: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:48:15: note: ***** Analysis failed with vector mode V16QI
PULSE.c:48:15: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:48:15: note: ***** Analysis failed with vector mode V8QI
PULSE.c:48:15: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:48:15: note: ***** Analysis failed with vector mode V4QI
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:4:18: note: vectorized 0 loops in function.
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_4, inputs_15, _3);
PULSE.c:8:2: missed: statement clobbers memory: _5 (layer_17);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_12, pretmp_26, _9);
PULSE.c:13:28: note: ***** Analysis failed with vector mode V8SI
PULSE.c:13:28: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:22:2: missed: statement clobbers memory: _1 (layer_10(D));
PULSE.c:22:2: missed: statement clobbers memory: _14 (_2);
PULSE.c:22:2: missed: statement clobbers memory: _21 (_15);
PULSE.c:22:2: missed: statement clobbers memory: _28 (_22);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_29);
PULSE.c:26:3: missed: statement clobbers memory: memset (_34, 0, _32);
PULSE.c:26:3: missed: statement clobbers memory: memset (_27, 0, _25);
PULSE.c:26:3: missed: statement clobbers memory: memset (_20, 0, _18);
PULSE.c:26:3: missed: statement clobbers memory: memset (_7, 0, _5);
PULSE.c:28:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:28:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:32:6: note: vectorized 1 loops in function.
PULSE.c:34:8: missed: statement clobbers memory: _1 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_2);
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _9 = rand ();
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8SI
PULSE.c:32:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:82:16: missed: couldn't vectorize loop
PULSE.c:82:16: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:85:17: missed: couldn't vectorize loop
PULSE.c:85:17: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:96:19: missed: couldn't vectorize loop
PULSE.c:96:19: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _89 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:70:22: missed: couldn't vectorize loop
PULSE.c:70:22: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:64:6: note: vectorized 1 loops in function.
PULSE.c:65:1: missed: statement clobbers memory: saved_stack.17_44 = __builtin_stack_save ();
PULSE.c:66:46: missed: statement clobbers memory: _1 = PULSE_GetLossFunctionPtr (loss_45(D));
PULSE.c:79:2: missed: statement clobbers memory: pthread_create (&logger_thread, 0B, PULSE_TrainLogger, &infos);
PULSE.c:81:10: missed: statement clobbers memory: random.6_62 = __builtin_alloca_with_align (_9, 32);
PULSE.c:34:8: missed: statement clobbers memory: _81 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_82);
PULSE.c:39:29: missed: statement clobbers memory: _89 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _92 = rand ();
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_118, inputs_113, _117);
PULSE.c:8:2: missed: statement clobbers memory: _119 (layer_114);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_125, _124, _123);
PULSE.c:90:4: missed: statement clobbers memory: PULSE_GetLoss_47 (_21, y_ptr_74, _20, _19);
PULSE.c:22:2: missed: statement clobbers memory: _106 (output_212);
PULSE.c:22:2: missed: statement clobbers memory: _128 (_107);
PULSE.c:22:2: missed: statement clobbers memory: _135 (_129);
PULSE.c:22:2: missed: statement clobbers memory: _142 (_136);
PULSE.c:22:2: missed: statement clobbers memory: _149 (_143);
PULSE.c:22:2: missed: statement clobbers memory: _156 (_150);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_157);
PULSE.c:26:3: missed: statement clobbers memory: memset (_162, 0, _160);
PULSE.c:26:3: missed: statement clobbers memory: memset (_155, 0, _153);
PULSE.c:26:3: missed: statement clobbers memory: memset (_148, 0, _146);
PULSE.c:26:3: missed: statement clobbers memory: memset (_141, 0, _139);
PULSE.c:26:3: missed: statement clobbers memory: memset (_134, 0, _132);
PULSE.c:26:3: missed: statement clobbers memory: memset (_112, 0, _110);
PULSE.c:98:6: missed: statement clobbers memory: _26 (current_207, args);
PULSE.c:105:2: missed: statement clobbers memory: pthread_join (logger_thread.16_35, 0B);
PULSE.c:64:6: missed: statement clobbers memory: __builtin_stack_restore (saved_stack.17_44);
PULSE.c:78:36: note: ***** Analysis succeeded with vector mode V4DI
PULSE.c:78:36: note: SLPing BB part
PULSE.c:78:36: note: Costing subgraph: 
PULSE.c:78:36: note: node 0x35ac868 (max_nunits=2, refcnt=1) vector(2) int
PULSE.c:78:36: note: op template: infos.size = _4;
PULSE.c:78:36: note: 	stmt 0 infos.size = _4;
PULSE.c:78:36: note: 	stmt 1 infos.i_limit = epoch.3_5;
PULSE.c:78:36: note: 	children 0x35ac8e8
PULSE.c:78:36: note: node 0x35ac8e8 (max_nunits=2, refcnt=1) vector(2) int
PULSE.c:78:36: note: op template: _4 = (int) _3;
PULSE.c:78:36: note: 	stmt 0 _4 = (int) _3;
PULSE.c:78:36: note: 	stmt 1 epoch.3_5 = (int) epoch_54(D);
PULSE.c:78:36: note: 	children 0x35ac968
PULSE.c:78:36: note: node (external) 0x35ac968 (max_nunits=1, refcnt=1) vector(2) unsigned int
PULSE.c:78:36: note: 	{ _3, epoch_54(D) }
PULSE.c:78:36: note: Cost model analysis: 
PULSE.c:78:36: note: Cost model analysis for part in loop 0:
  Vector cost: 26
  Scalar cost: 32
PULSE.c:78:36: note: Costing subgraph: 
PULSE.c:78:36: note: node 0x35ac9e8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:78:36: note: op template: infos.i = &i;
PULSE.c:78:36: note: 	stmt 0 infos.i = &i;
PULSE.c:78:36: note: 	stmt 1 infos.j = &j;
PULSE.c:78:36: note: 	children 0x35aca68
PULSE.c:78:36: note: node (external) 0x35aca68 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:78:36: note: 	{ &i, &j }
PULSE.c:78:36: note: Cost model analysis: 
PULSE.c:78:36: note: Cost model analysis for part in loop 0:
  Vector cost: 20
  Scalar cost: 32
PULSE.c:78:36: note: Costing subgraph: 
PULSE.c:78:36: note: node 0x35acae8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:78:36: note: op template: infos.x = _7;
PULSE.c:78:36: note: 	stmt 0 infos.x = _7;
PULSE.c:78:36: note: 	stmt 1 infos.y = y_50(D);
PULSE.c:78:36: note: 	children 0x35acb68
PULSE.c:78:36: note: node (external) 0x35acb68 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:78:36: note: 	{ _7, y_50(D) }
PULSE.c:78:36: note: Cost model analysis: 
PULSE.c:78:36: note: Cost model analysis for part in loop 0:
  Vector cost: 26
  Scalar cost: 32
PULSE.c:78:36: note: Basic block will be vectorized using SLP
PULSE.c:78:36: optimized: basic block part vectorized using 8 byte vectors
PULSE.c:78:36: note: Vectorizing SLP tree:
PULSE.c:78:36: note: node 0x35ac868 (max_nunits=2, refcnt=1) vector(2) int
PULSE.c:78:36: note: op template: infos.size = _4;
PULSE.c:78:36: note: 	stmt 0 infos.size = _4;
PULSE.c:78:36: note: 	stmt 1 infos.i_limit = epoch.3_5;
PULSE.c:78:36: note: 	children 0x35ac8e8
PULSE.c:78:36: note: node 0x35ac8e8 (max_nunits=2, refcnt=1) vector(2) int
PULSE.c:78:36: note: op template: _4 = (int) _3;
PULSE.c:78:36: note: 	stmt 0 _4 = (int) _3;
PULSE.c:78:36: note: 	stmt 1 epoch.3_5 = (int) epoch_54(D);
PULSE.c:78:36: note: 	children 0x35ac968
PULSE.c:78:36: note: node (external) 0x35ac968 (max_nunits=1, refcnt=1) vector(2) unsigned int
PULSE.c:78:36: note: 	{ _3, epoch_54(D) }
PULSE.c:78:36: note: ------>vectorizing SLP node starting from: _4 = (int) _3;
PULSE.c:78:36: note: transform assignment.
PULSE.c:78:36: note: add new stmt: vect__4.132_284 = VIEW_CONVERT_EXPR<vector(2) int>(_283);
PULSE.c:78:36: note: ------>vectorizing SLP node starting from: infos.size = _4;
PULSE.c:78:36: note: vect_is_simple_use: operand (int) _3, type of def: internal
PULSE.c:78:36: note: vect_is_simple_use: operand (int) epoch_54(D), type of def: internal
PULSE.c:78:36: note: transform store. ncopies = 1
PULSE.c:78:36: note: create vector_type-pointer variable to type: vector(2) int  vectorizing a pointer ref: infos.size
PULSE.c:78:36: note: created &infos.size
PULSE.c:78:36: note: add new stmt: MEM <vector(2) int> [(int *)&infos + 16B] = vect__4.132_284;
PULSE.c:78:36: note: vectorizing stmts using SLP.
PULSE.c:78:36: optimized: basic block part vectorized using 16 byte vectors
PULSE.c:78:36: note: Vectorizing SLP tree:
PULSE.c:78:36: note: node 0x35ac9e8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:78:36: note: op template: infos.i = &i;
PULSE.c:78:36: note: 	stmt 0 infos.i = &i;
PULSE.c:78:36: note: 	stmt 1 infos.j = &j;
PULSE.c:78:36: note: 	children 0x35aca68
PULSE.c:78:36: note: node (external) 0x35aca68 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:78:36: note: 	{ &i, &j }
PULSE.c:78:36: note: ------>vectorizing SLP node starting from: infos.i = &i;
PULSE.c:78:36: note: vect_is_simple_use: operand &j, type of def: external
PULSE.c:78:36: note: transform store. ncopies = 1
PULSE.c:78:36: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: infos.i
PULSE.c:78:36: note: created &infos
PULSE.c:78:36: note: add new stmt: MEM <vector(2) long unsigned int> [(int * *)&infos] = _282;
PULSE.c:78:36: note: vectorizing stmts using SLP.
PULSE.c:78:36: optimized: basic block part vectorized using 16 byte vectors
PULSE.c:78:36: note: Vectorizing SLP tree:
PULSE.c:78:36: note: node 0x35acae8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:78:36: note: op template: infos.x = _7;
PULSE.c:78:36: note: 	stmt 0 infos.x = _7;
PULSE.c:78:36: note: 	stmt 1 infos.y = y_50(D);
PULSE.c:78:36: note: 	children 0x35acb68
PULSE.c:78:36: note: node (external) 0x35acb68 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:78:36: note: 	{ _7, y_50(D) }
PULSE.c:78:36: note: ------>vectorizing SLP node starting from: infos.x = _7;
PULSE.c:78:36: note: vect_is_simple_use: operand y_50(D), type of def: external
PULSE.c:78:36: note: transform store. ncopies = 1
PULSE.c:78:36: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: infos.x
PULSE.c:78:36: note: created &infos.x
PULSE.c:78:36: note: add new stmt: MEM <vector(2) long unsigned int> [(float * *)&infos + 32B] = _70;
PULSE.c:78:36: note: vectorizing stmts using SLP.
PULSE.c:78:36: note: ***** The result for vector mode V32QI would be the same
PULSE.c:112:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:112:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:117:8: missed: couldn't vectorize loop
PULSE.c:117:8: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:114:6: note: vectorized 0 loops in function.
PULSE.c:119:3: missed: statement clobbers memory: _1 (current_10);
PULSE.c:122:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:122:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:54:34: missed: couldn't vectorize loop
PULSE.c:54:34: missed: not vectorized: unsupported control flow in loop.
PULSE.c:48:15: note: vectorized 0 loops in function.
PULSE.c:53:3: missed: statement clobbers memory: printf ("Epoch: %d Item: %d Error: %f\r", prephitmp_25, prephitmp_33, _2);
PULSE.c:55:11: note: ***** Analysis failed with vector mode V4DI
PULSE.c:55:11: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:4:18: note: vectorized 0 loops in function.
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_4, inputs_15, _3);
PULSE.c:8:2: missed: statement clobbers memory: _5 (layer_17);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_12, pretmp_26, _9);
PULSE.c:13:28: note: ***** Analysis failed with vector mode V8SI
PULSE.c:13:28: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:22:2: missed: statement clobbers memory: _1 (layer_10(D));
PULSE.c:22:2: missed: statement clobbers memory: _14 (_2);
PULSE.c:22:2: missed: statement clobbers memory: _21 (_15);
PULSE.c:22:2: missed: statement clobbers memory: _28 (_22);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_29);
PULSE.c:26:3: missed: statement clobbers memory: memset (_34, 0, _32);
PULSE.c:26:3: missed: statement clobbers memory: memset (_27, 0, _25);
PULSE.c:26:3: missed: statement clobbers memory: memset (_20, 0, _18);
PULSE.c:26:3: missed: statement clobbers memory: memset (_7, 0, _5);
PULSE.c:28:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:28:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:32:6: note: vectorized 1 loops in function.
PULSE.c:34:8: missed: statement clobbers memory: _1 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_2);
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _9 = rand ();
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8SI
PULSE.c:32:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:77:16: missed: couldn't vectorize loop
PULSE.c:77:16: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:80:17: missed: couldn't vectorize loop
PULSE.c:80:17: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:89:19: missed: couldn't vectorize loop
PULSE.c:89:19: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _89 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:66:22: missed: couldn't vectorize loop
PULSE.c:66:22: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:60:6: note: vectorized 1 loops in function.
PULSE.c:61:1: missed: statement clobbers memory: saved_stack.17_46 = __builtin_stack_save ();
PULSE.c:62:46: missed: statement clobbers memory: _1 = PULSE_GetLossFunctionPtr (loss_function_47(D));
PULSE.c:74:2: missed: statement clobbers memory: pthread_create (&logger_thread, 0B, PULSE_TrainLogger, &infos);
PULSE.c:76:10: missed: statement clobbers memory: random.6_62 = __builtin_alloca_with_align (_8, 32);
PULSE.c:34:8: missed: statement clobbers memory: _81 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_82);
PULSE.c:39:29: missed: statement clobbers memory: _89 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _92 = rand ();
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_118, inputs_113, _117);
PULSE.c:8:2: missed: statement clobbers memory: _119 (layer_114);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_125, _124, _123);
PULSE.c:83:11: missed: statement clobbers memory: PULSE_GetLoss_49 (_23, _22, _16, _15);
PULSE.c:22:2: missed: statement clobbers memory: _106 (output_212);
PULSE.c:22:2: missed: statement clobbers memory: _128 (_107);
PULSE.c:22:2: missed: statement clobbers memory: _135 (_129);
PULSE.c:22:2: missed: statement clobbers memory: _142 (_136);
PULSE.c:22:2: missed: statement clobbers memory: _149 (_143);
PULSE.c:22:2: missed: statement clobbers memory: _156 (_150);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_157);
PULSE.c:26:3: missed: statement clobbers memory: memset (_162, 0, _160);
PULSE.c:26:3: missed: statement clobbers memory: memset (_155, 0, _153);
PULSE.c:26:3: missed: statement clobbers memory: memset (_148, 0, _146);
PULSE.c:26:3: missed: statement clobbers memory: memset (_141, 0, _139);
PULSE.c:26:3: missed: statement clobbers memory: memset (_134, 0, _132);
PULSE.c:26:3: missed: statement clobbers memory: memset (_112, 0, _110);
PULSE.c:91:6: missed: statement clobbers memory: _28 (current_207, args);
PULSE.c:98:2: missed: statement clobbers memory: pthread_join (logger_thread.16_37, 0B);
PULSE.c:60:6: missed: statement clobbers memory: __builtin_stack_restore (saved_stack.17_46);
PULSE.c:73:36: note: ***** Analysis succeeded with vector mode V4DI
PULSE.c:73:36: note: SLPing BB part
PULSE.c:73:36: note: Costing subgraph: 
PULSE.c:73:36: note: node 0x3cb1968 (max_nunits=2, refcnt=1) vector(2) int
PULSE.c:73:36: note: op template: infos.size = _4;
PULSE.c:73:36: note: 	stmt 0 infos.size = _4;
PULSE.c:73:36: note: 	stmt 1 infos.i_limit = epoch.3_5;
PULSE.c:73:36: note: 	children 0x3cb19e8
PULSE.c:73:36: note: node 0x3cb19e8 (max_nunits=2, refcnt=1) vector(2) int
PULSE.c:73:36: note: op template: _4 = (int) _3;
PULSE.c:73:36: note: 	stmt 0 _4 = (int) _3;
PULSE.c:73:36: note: 	stmt 1 epoch.3_5 = (int) epoch_54(D);
PULSE.c:73:36: note: 	children 0x3cb1a68
PULSE.c:73:36: note: node (external) 0x3cb1a68 (max_nunits=1, refcnt=1) vector(2) unsigned int
PULSE.c:73:36: note: 	{ _3, epoch_54(D) }
PULSE.c:73:36: note: Cost model analysis: 
PULSE.c:73:36: note: Cost model analysis for part in loop 0:
  Vector cost: 26
  Scalar cost: 32
PULSE.c:73:36: note: Costing subgraph: 
PULSE.c:73:36: note: node 0x3cb1ae8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:73:36: note: op template: infos.i = &i;
PULSE.c:73:36: note: 	stmt 0 infos.i = &i;
PULSE.c:73:36: note: 	stmt 1 infos.j = &j;
PULSE.c:73:36: note: 	children 0x3cb1b68
PULSE.c:73:36: note: node (external) 0x3cb1b68 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:73:36: note: 	{ &i, &j }
PULSE.c:73:36: note: Cost model analysis: 
PULSE.c:73:36: note: Cost model analysis for part in loop 0:
  Vector cost: 20
  Scalar cost: 32
PULSE.c:73:36: note: Basic block will be vectorized using SLP
PULSE.c:73:36: optimized: basic block part vectorized using 8 byte vectors
PULSE.c:73:36: note: Vectorizing SLP tree:
PULSE.c:73:36: note: node 0x3cb1968 (max_nunits=2, refcnt=1) vector(2) int
PULSE.c:73:36: note: op template: infos.size = _4;
PULSE.c:73:36: note: 	stmt 0 infos.size = _4;
PULSE.c:73:36: note: 	stmt 1 infos.i_limit = epoch.3_5;
PULSE.c:73:36: note: 	children 0x3cb19e8
PULSE.c:73:36: note: node 0x3cb19e8 (max_nunits=2, refcnt=1) vector(2) int
PULSE.c:73:36: note: op template: _4 = (int) _3;
PULSE.c:73:36: note: 	stmt 0 _4 = (int) _3;
PULSE.c:73:36: note: 	stmt 1 epoch.3_5 = (int) epoch_54(D);
PULSE.c:73:36: note: 	children 0x3cb1a68
PULSE.c:73:36: note: node (external) 0x3cb1a68 (max_nunits=1, refcnt=1) vector(2) unsigned int
PULSE.c:73:36: note: 	{ _3, epoch_54(D) }
PULSE.c:73:36: note: ------>vectorizing SLP node starting from: _4 = (int) _3;
PULSE.c:73:36: note: transform assignment.
PULSE.c:73:36: note: add new stmt: vect__4.94_266 = VIEW_CONVERT_EXPR<vector(2) int>(_265);
PULSE.c:73:36: note: ------>vectorizing SLP node starting from: infos.size = _4;
PULSE.c:73:36: note: vect_is_simple_use: operand (int) _3, type of def: internal
PULSE.c:73:36: note: vect_is_simple_use: operand (int) epoch_54(D), type of def: internal
PULSE.c:73:36: note: transform store. ncopies = 1
PULSE.c:73:36: note: create vector_type-pointer variable to type: vector(2) int  vectorizing a pointer ref: infos.size
PULSE.c:73:36: note: created &infos.size
PULSE.c:73:36: note: add new stmt: MEM <vector(2) int> [(int *)&infos + 16B] = vect__4.94_266;
PULSE.c:73:36: note: vectorizing stmts using SLP.
PULSE.c:73:36: optimized: basic block part vectorized using 16 byte vectors
PULSE.c:73:36: note: Vectorizing SLP tree:
PULSE.c:73:36: note: node 0x3cb1ae8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:73:36: note: op template: infos.i = &i;
PULSE.c:73:36: note: 	stmt 0 infos.i = &i;
PULSE.c:73:36: note: 	stmt 1 infos.j = &j;
PULSE.c:73:36: note: 	children 0x3cb1b68
PULSE.c:73:36: note: node (external) 0x3cb1b68 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:73:36: note: 	{ &i, &j }
PULSE.c:73:36: note: ------>vectorizing SLP node starting from: infos.i = &i;
PULSE.c:73:36: note: vect_is_simple_use: operand &j, type of def: external
PULSE.c:73:36: note: transform store. ncopies = 1
PULSE.c:73:36: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: infos.i
PULSE.c:73:36: note: created &infos
PULSE.c:73:36: note: add new stmt: MEM <vector(2) long unsigned int> [(int * *)&infos] = _264;
PULSE.c:73:36: note: vectorizing stmts using SLP.
PULSE.c:73:36: note: ***** The result for vector mode V32QI would be the same
PULSE.c:105:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:105:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:110:8: missed: couldn't vectorize loop
PULSE.c:110:8: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:107:6: note: vectorized 0 loops in function.
PULSE.c:112:3: missed: statement clobbers memory: _1 (current_10);
PULSE.c:115:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:115:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Loss.c:15:19: optimized: loop vectorized using 32 byte vectors
Loss.c:15:19: optimized:  loop versioned for vectorization because of possible aliasing
Loss.c:15:19: optimized: loop vectorized using 16 byte vectors
Loss.c:12:23: note: vectorized 1 loops in function.
Loss.c:12:23: note: ***** Analysis failed with vector mode V8SF
Loss.c:12:23: note: ***** The result for vector mode V32QI would be the same
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V16QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V16QI
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V8QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V8QI
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V4QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V4QI
Loss.c:7:19: missed: couldn't vectorize loop
Loss.c:8:38: missed: not vectorized: unsupported use in stmt.
Loss.c:4:23: note: vectorized 0 loops in function.
Loss.c:9:13: note: ***** Analysis failed with vector mode V8SF
Loss.c:9:13: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Loss.c:23:2: note: ***** Analysis failed with vector mode VOID
Layer.c:7:34: missed: statement clobbers memory: _3 = aligned_alloc (64, _2);
Layer.c:8:35: missed: statement clobbers memory: _6 = aligned_alloc (64, _5);
Layer.c:9:34: missed: statement clobbers memory: _7 = aligned_alloc (64, _5);
Layer.c:14:19: missed: statement clobbers memory: _8 = PULSE_GetActivationFunctionPtr (activation_function_18(D));
Layer.c:19:9: note: ***** Analysis succeeded with vector mode V8SI
Layer.c:19:9: note: SLPing BB part
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x370a7f8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 0 MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 1 MEM <unsigned int> [(struct PULSE_Layer *)&<retval> + 4B] = optimization_type_17(D);
Layer.c:19:9: note: 	children 0x370a878
Layer.c:19:9: note: node (external) 0x370a878 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ type_16(D), optimization_type_17(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x370a8f8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 0 <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 1 <retval>.n_outputs = n_outputs_12(D);
Layer.c:19:9: note: 	children 0x370a978
Layer.c:19:9: note: node (external) 0x370a978 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x370aa78 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 0 <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 1 <retval>.outputs = _6;
Layer.c:19:9: note: 	children 0x370aaf8
Layer.c:19:9: note: node (external) 0x370aaf8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	stmt 0 _3 = aligned_alloc (64, _2);
Layer.c:19:9: note: 	stmt 1 _6 = aligned_alloc (64, _5);
Layer.c:19:9: note: 	children 0x370ab78 0x370abf8
Layer.c:19:9: note: node (constant) 0x370ab78 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 64, 64 }
Layer.c:19:9: note: node 0x370abf8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: patt_40 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 0 patt_40 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 1 patt_41 = n_outputs_12(D) w* 4;
Layer.c:19:9: note: 	children 0x370ac78 0x370acf8
Layer.c:19:9: note: node (external) 0x370ac78 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: node (constant) 0x370acf8 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ 4, 4 }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x370adf8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: op template: <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 0 <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 1 <retval>.back = back_21(D);
Layer.c:19:9: note: 	stmt 2 <retval>.fix = fix_22(D);
Layer.c:19:9: note: 	stmt 3 <retval>.destroy = destroy_23(D);
Layer.c:19:9: note: 	children 0x370ae78
Layer.c:19:9: note: node (external) 0x370ae78 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: 	{ feed_20(D), back_21(D), fix_22(D), destroy_23(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 64
  Scalar cost: 64
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x370af78 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 0 <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 1 <retval>.child = 0B;
Layer.c:19:9: note: 	children 0x370aff8
Layer.c:19:9: note: node (constant) 0x370aff8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ 0B, 0B }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Basic block will be vectorized using SLP
Layer.c:19:9: optimized: basic block part vectorized using 8 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x370a7f8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 0 MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 1 MEM <unsigned int> [(struct PULSE_Layer *)&<retval> + 4B] = optimization_type_17(D);
Layer.c:19:9: note: 	children 0x370a878
Layer.c:19:9: note: node (external) 0x370a878 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ type_16(D), optimization_type_17(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: vect_is_simple_use: operand optimization_type_17(D), type of def: external
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>]
Layer.c:19:9: note: created &MEM <unsigned int> [(struct PULSE_Layer *)&<retval>]
Layer.c:19:9: note: add new stmt: MEM <vector(2) unsigned int> [(struct PULSE_Layer *)&<retval>] = _42;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 8 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x370a8f8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 0 <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 1 <retval>.n_outputs = n_outputs_12(D);
Layer.c:19:9: note: 	children 0x370a978
Layer.c:19:9: note: node (external) 0x370a978 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: vect_is_simple_use: operand n_outputs_12(D), type of def: external
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: <retval>.n_inputs
Layer.c:19:9: note: created &<retval>.n_inputs
Layer.c:19:9: note: add new stmt: MEM <vector(2) unsigned int> [(unsigned int *)&<retval> + 96B] = _44;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 16 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x370aa78 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 0 <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 1 <retval>.outputs = _6;
Layer.c:19:9: note: 	children 0x370aaf8
Layer.c:19:9: note: node (external) 0x370aaf8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	stmt 0 _3 = aligned_alloc (64, _2);
Layer.c:19:9: note: 	stmt 1 _6 = aligned_alloc (64, _5);
Layer.c:19:9: note: 	children 0x370ab78 0x370abf8
Layer.c:19:9: note: node (constant) 0x370ab78 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 64, 64 }
Layer.c:19:9: note: node 0x370abf8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: patt_40 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 0 patt_40 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 1 patt_41 = n_outputs_12(D) w* 4;
Layer.c:19:9: note: 	children 0x370ac78 0x370acf8
Layer.c:19:9: note: node (external) 0x370ac78 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: node (constant) 0x370acf8 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ 4, 4 }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.inputs = _3;
Layer.c:19:9: note: vect_is_simple_use: operand aligned_alloc (64, _5), type of def: internal
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.inputs
Layer.c:19:9: note: created &<retval>.inputs
Layer.c:19:9: note: add new stmt: MEM <vector(2) long unsigned int> [(float * *)&<retval> + 8B] = _48;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 32 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x370adf8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: op template: <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 0 <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 1 <retval>.back = back_21(D);
Layer.c:19:9: note: 	stmt 2 <retval>.fix = fix_22(D);
Layer.c:19:9: note: 	stmt 3 <retval>.destroy = destroy_23(D);
Layer.c:19:9: note: 	children 0x370ae78
Layer.c:19:9: note: node (external) 0x370ae78 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: 	{ feed_20(D), back_21(D), fix_22(D), destroy_23(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.feed = feed_20(D);
Layer.c:19:9: note: vect_is_simple_use: operand back_21(D), type of def: external
Layer.c:19:9: note: vect_is_simple_use: operand fix_22(D), type of def: external
Layer.c:19:9: note: vect_is_simple_use: operand destroy_23(D), type of def: external
Layer.c:19:9: note: conflicting alias set types.
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(4) long unsigned int  vectorizing a pointer ref: <retval>.feed
Layer.c:19:9: note: created &<retval>.feed
Layer.c:19:9: note: add new stmt: MEM <vector(4) long unsigned int> [(void *)&<retval> + 32B] = _54;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 16 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x370af78 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 0 <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 1 <retval>.child = 0B;
Layer.c:19:9: note: 	children 0x370aff8
Layer.c:19:9: note: node (constant) 0x370aff8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ 0B, 0B }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.parent = 0B;
Layer.c:19:9: note: vect_is_simple_use: operand 0B, type of def: constant
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.parent
Layer.c:19:9: note: created &<retval>.parent
Layer.c:19:9: note: add new stmt: MEM <vector(2) long unsigned int> [(struct PULSE_Layer * *)&<retval> + 72B] = { 0, 0 };
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: note: ***** The result for vector mode V32QI would be the same
Layer.c:24:2: missed: statement clobbers memory: free (_1);
Layer.c:25:2: missed: statement clobbers memory: free (_2);
Layer.c:26:2: missed: statement clobbers memory: free (_3);
Layer.c:27:1: note: ***** Analysis failed with vector mode V4DI
Layer.c:27:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:9:27: missed: couldn't vectorize loop
Dense.c:9:27: missed: not vectorized: unsupported outerloop form.
Dense.c:12:20: missed: couldn't vectorize loop
Dense.c:13:21: missed: not vectorized: complicated access pattern.
Dense.c:6:13: note: vectorized 0 loops in function.
Dense.c:16:2: missed: statement clobbers memory: _30 (pretmp_91, _50, 0);
Dense.c:9:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:9:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:24:27: missed: couldn't vectorize loop
Dense.c:24:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:28:20: optimized: loop vectorized using 32 byte vectors
Dense.c:28:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:28:20: optimized: loop vectorized using 16 byte vectors
Dense.c:28:20: missed: couldn't vectorize loop
Dense.c:30:20: missed: not vectorized: no vectype for stmt: _21 = *_20;
 scalar_type: float
Dense.c:20:13: note: vectorized 1 loops in function.
Dense.c:23:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:24:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:24:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:41:28: missed: couldn't vectorize loop
Dense.c:41:28: missed: not vectorized: unsupported outerloop form.
Dense.c:45:21: optimized: loop vectorized using 32 byte vectors
Dense.c:45:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:45:21: optimized: loop vectorized using 16 byte vectors
Dense.c:37:13: note: vectorized 1 loops in function.
Dense.c:37:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:37:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:41:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:145:19: missed: couldn't vectorize loop
Dense.c:145:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:136:19: missed: couldn't vectorize loop
Dense.c:136:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:129:13: note: vectorized 0 loops in function.
Dense.c:153:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:153:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:98:28: missed: couldn't vectorize loop
Dense.c:98:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:101:21: missed: couldn't vectorize loop
Dense.c:101:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:115:28: missed: couldn't vectorize loop
Dense.c:115:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:118:21: missed: couldn't vectorize loop
Dense.c:118:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:84:19: missed: couldn't vectorize loop
Dense.c:84:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:78:13: note: vectorized 0 loops in function.
Dense.c:81:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:103:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:103:17: note: SLPing BB part
Dense.c:120:17: note: Costing subgraph: 
Dense.c:120:17: note: node 0x7155048 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:120:17: note: op template: _49 = (sizetype) j_137;
Dense.c:120:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:120:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:120:17: note: 	children 0x7155148
Dense.c:120:17: note: node (external) 0x7155148 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:120:17: note: 	{ j_137, wi_136 }
Dense.c:120:17: note: Cost model analysis: 
Dense.c:120:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:120:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:120:17: missed: not vectorized: vectorization is not profitable.
Dense.c:103:17: note: Costing subgraph: 
Dense.c:103:17: note: node 0x7155248 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:103:17: note: op template: _24 = (sizetype) j_134;
Dense.c:103:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:103:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:103:17: note: 	children 0x7155348
Dense.c:103:17: note: node (external) 0x7155348 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:103:17: note: 	{ j_134, wi_133 }
Dense.c:103:17: note: Cost model analysis: 
Dense.c:103:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:103:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:103:17: missed: not vectorized: vectorization is not profitable.
Dense.c:103:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:103:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:103:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:103:17: note: SLPing BB part
Dense.c:120:17: note: Costing subgraph: 
Dense.c:120:17: note: node 0x7155248 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:120:17: note: op template: _49 = (sizetype) j_137;
Dense.c:120:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:120:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:120:17: note: 	children 0x7155048
Dense.c:120:17: note: node (external) 0x7155048 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:120:17: note: 	{ j_137, wi_136 }
Dense.c:120:17: note: Cost model analysis: 
Dense.c:120:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:120:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:120:17: missed: not vectorized: vectorization is not profitable.
Dense.c:103:17: note: Costing subgraph: 
Dense.c:103:17: note: node 0x71553c8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:103:17: note: op template: _24 = (sizetype) j_134;
Dense.c:103:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:103:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:103:17: note: 	children 0x71552c8
Dense.c:103:17: note: node (external) 0x71552c8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:103:17: note: 	{ j_134, wi_133 }
Dense.c:103:17: note: Cost model analysis: 
Dense.c:103:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:103:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:103:17: missed: not vectorized: vectorization is not profitable.
Dense.c:103:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:98:55: note: ***** Analysis failed with vector mode V8QI
Dense.c:98:55: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:98:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:58:27: missed: couldn't vectorize loop
Dense.c:58:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:61:20: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:905:10: missed: not vectorized: no vectype for stmt: _41 = MEM[(__m256_u * {ref-all})_6];
 scalar_type: __m256_u
Dense.c:61:20: note: ***** Analysis failed with vector mode VOID
Dense.c:54:13: note: vectorized 0 loops in function.
Dense.c:54:13: missed: splitting region at dont-vectorize loop 3 entry at bb18
Dense.c:63:14: note: ***** Analysis failed with vector mode V4DI
Dense.c:63:14: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:63:14: missed: splitting region at dominance boundary bb8
Dense.c:63:14: note: ***** Analysis failed with vector mode VOID
Dense.c:63:14: missed: splitting region at loop 1 exit at bb16
Dense.c:58:27: note: ***** Analysis failed with vector mode V8SF
Dense.c:58:27: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Dense.c:58:27: missed: splitting region at dominance boundary bb10
Dense.c:58:27: note: ***** Analysis failed with vector mode VOID
Dense.c:74:2: missed: statement clobbers memory: _27 (pretmp_153, _61, 0);
Dense.c:75:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:75:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:160:2: missed: statement clobbers memory: free (_1);
Dense.c:161:2: missed: statement clobbers memory: free (_2);
Dense.c:162:2: missed: statement clobbers memory: free (_3);
Dense.c:163:2: missed: statement clobbers memory: free (_4);
Dense.c:164:2: missed: statement clobbers memory: free (dense_7);
Dense.c:165:2: missed: statement clobbers memory: PULSE_DestroyLayer (this_6(D));
Dense.c:166:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:166:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:180:19: missed: couldn't vectorize loop
Dense.c:180:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:170:13: note: vectorized 0 loops in function.
Dense.c:172:47: missed: statement clobbers memory: dense_35 = malloc (40);
Dense.c:174:36: missed: statement clobbers memory: _5 = aligned_alloc (64, _4);
Dense.c:175:38: missed: statement clobbers memory: _6 = aligned_alloc (64, _4);
Dense.c:176:36: missed: statement clobbers memory: _8 = aligned_alloc (64, _7);
Dense.c:177:35: missed: statement clobbers memory: _9 = aligned_alloc (64, _7);
Dense.c:178:36: missed: statement clobbers memory: _10 = aligned_alloc (64, _7);
Dense.c:181:39: missed: statement clobbers memory: _11 = rand ();
Dense.c:181:73: missed: statement clobbers memory: _63 = sqrt (_18);
Dense.c:198:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:199:4: missed: statement clobbers memory: exit (1);
Dense.c:191:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.3_29, n_outputs.2_28, 1, activation_function_51(D), _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:187:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.1_27, n_outputs.0_26, 1, activation_function_51(D), _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:205:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Dense.c:205:9: note: ***** Analysis failed with vector mode V4DI
Dense.c:205:9: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Activations.c:17:19: optimized: loop vectorized using 32 byte vectors
Activations.c:17:19: optimized: loop vectorized using 16 byte vectors
Activations.c:17:19: optimized: loop vectorized using 32 byte vectors
Activations.c:17:19: optimized: loop vectorized using 16 byte vectors
Activations.c:14:13: note: vectorized 2 loops in function.
Activations.c:14:13: note: ***** Analysis failed with vector mode V8SF
Activations.c:14:13: note: ***** The result for vector mode V32QI would be the same
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V16QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V16QI
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V8QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V8QI
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V4QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V4QI
Activations.c:28:19: missed: couldn't vectorize loop
Activations.c:28:19: missed: not vectorized: unsupported control flow in loop.
Activations.c:28:19: optimized: loop vectorized using 32 byte vectors
Activations.c:28:19: optimized: loop vectorized using 16 byte vectors
Activations.c:25:13: note: vectorized 1 loops in function.
Activations.c:25:13: note: ***** Analysis failed with vector mode V8SF
Activations.c:25:13: note: ***** The result for vector mode V32QI would be the same
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V16QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V16QI
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V8QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V8QI
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V4QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V4QI
Activations.c:38:1: note: ***** Analysis failed with vector mode VOID
Activations.c:5:19: missed: couldn't vectorize loop
Activations.c:9:21: missed: statement clobbers memory: _36 = expf (_18);
Activations.c:5:19: missed: couldn't vectorize loop
Activations.c:9:21: missed: statement clobbers memory: _12 = expf (_11);
Activations.c:3:13: note: vectorized 0 loops in function.
Activations.c:9:21: missed: statement clobbers memory: _12 = expf (_11);
Activations.c:9:21: missed: statement clobbers memory: _36 = expf (_18);
Activations.c:11:1: note: ***** Analysis failed with vector mode V8SF
Activations.c:11:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Activations.c:44:2: note: ***** Analysis failed with vector mode VOID
PULSE.c:54:34: missed: couldn't vectorize loop
PULSE.c:54:34: missed: not vectorized: unsupported control flow in loop.
PULSE.c:48:15: note: vectorized 0 loops in function.
PULSE.c:53:3: missed: statement clobbers memory: printf ("Epoch: %d Item: %d Error: %f\r", prephitmp_25, prephitmp_33, _2);
PULSE.c:55:11: note: ***** Analysis failed with vector mode V4DI
PULSE.c:55:11: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:4:18: note: vectorized 0 loops in function.
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_4, inputs_15, _3);
PULSE.c:8:2: missed: statement clobbers memory: _5 (layer_17);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_12, pretmp_26, _9);
PULSE.c:13:28: note: ***** Analysis failed with vector mode V8SI
PULSE.c:13:28: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:22:2: missed: statement clobbers memory: _1 (layer_10(D));
PULSE.c:22:2: missed: statement clobbers memory: _14 (_2);
PULSE.c:22:2: missed: statement clobbers memory: _21 (_15);
PULSE.c:22:2: missed: statement clobbers memory: _28 (_22);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_29);
PULSE.c:26:3: missed: statement clobbers memory: memset (_34, 0, _32);
PULSE.c:26:3: missed: statement clobbers memory: memset (_27, 0, _25);
PULSE.c:26:3: missed: statement clobbers memory: memset (_20, 0, _18);
PULSE.c:26:3: missed: statement clobbers memory: memset (_7, 0, _5);
PULSE.c:28:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:28:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:32:6: note: vectorized 1 loops in function.
PULSE.c:34:8: missed: statement clobbers memory: _1 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_2);
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _9 = rand ();
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8SI
PULSE.c:32:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:77:16: missed: couldn't vectorize loop
PULSE.c:77:16: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:80:17: missed: couldn't vectorize loop
PULSE.c:80:17: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:89:19: missed: couldn't vectorize loop
PULSE.c:89:19: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _89 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:66:22: missed: couldn't vectorize loop
PULSE.c:66:22: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:60:6: note: vectorized 1 loops in function.
PULSE.c:61:1: missed: statement clobbers memory: saved_stack.17_46 = __builtin_stack_save ();
PULSE.c:62:46: missed: statement clobbers memory: _1 = PULSE_GetLossFunctionPtr (loss_function_47(D));
PULSE.c:74:2: missed: statement clobbers memory: pthread_create (&logger_thread, 0B, PULSE_TrainLogger, &infos);
PULSE.c:76:10: missed: statement clobbers memory: random.6_62 = __builtin_alloca_with_align (_8, 32);
PULSE.c:34:8: missed: statement clobbers memory: _81 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_82);
PULSE.c:39:29: missed: statement clobbers memory: _89 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _92 = rand ();
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_118, inputs_113, _117);
PULSE.c:8:2: missed: statement clobbers memory: _119 (layer_114);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_125, _124, _123);
PULSE.c:83:11: missed: statement clobbers memory: PULSE_GetLoss_49 (_23, _22, _16, _15);
PULSE.c:22:2: missed: statement clobbers memory: _106 (output_212);
PULSE.c:22:2: missed: statement clobbers memory: _128 (_107);
PULSE.c:22:2: missed: statement clobbers memory: _135 (_129);
PULSE.c:22:2: missed: statement clobbers memory: _142 (_136);
PULSE.c:22:2: missed: statement clobbers memory: _149 (_143);
PULSE.c:22:2: missed: statement clobbers memory: _156 (_150);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_157);
PULSE.c:26:3: missed: statement clobbers memory: memset (_162, 0, _160);
PULSE.c:26:3: missed: statement clobbers memory: memset (_155, 0, _153);
PULSE.c:26:3: missed: statement clobbers memory: memset (_148, 0, _146);
PULSE.c:26:3: missed: statement clobbers memory: memset (_141, 0, _139);
PULSE.c:26:3: missed: statement clobbers memory: memset (_134, 0, _132);
PULSE.c:26:3: missed: statement clobbers memory: memset (_112, 0, _110);
PULSE.c:91:6: missed: statement clobbers memory: _28 (current_207, args);
PULSE.c:98:2: missed: statement clobbers memory: pthread_join (logger_thread.16_37, 0B);
PULSE.c:60:6: missed: statement clobbers memory: __builtin_stack_restore (saved_stack.17_46);
PULSE.c:73:36: note: ***** Analysis succeeded with vector mode V4DI
PULSE.c:73:36: note: SLPing BB part
PULSE.c:73:36: note: Costing subgraph: 
PULSE.c:73:36: note: node 0x46b5968 (max_nunits=2, refcnt=1) vector(2) int
PULSE.c:73:36: note: op template: infos.size = _4;
PULSE.c:73:36: note: 	stmt 0 infos.size = _4;
PULSE.c:73:36: note: 	stmt 1 infos.i_limit = epoch.3_5;
PULSE.c:73:36: note: 	children 0x46b59e8
PULSE.c:73:36: note: node 0x46b59e8 (max_nunits=2, refcnt=1) vector(2) int
PULSE.c:73:36: note: op template: _4 = (int) _3;
PULSE.c:73:36: note: 	stmt 0 _4 = (int) _3;
PULSE.c:73:36: note: 	stmt 1 epoch.3_5 = (int) epoch_54(D);
PULSE.c:73:36: note: 	children 0x46b5a68
PULSE.c:73:36: note: node (external) 0x46b5a68 (max_nunits=1, refcnt=1) vector(2) unsigned int
PULSE.c:73:36: note: 	{ _3, epoch_54(D) }
PULSE.c:73:36: note: Cost model analysis: 
PULSE.c:73:36: note: Cost model analysis for part in loop 0:
  Vector cost: 26
  Scalar cost: 32
PULSE.c:73:36: note: Costing subgraph: 
PULSE.c:73:36: note: node 0x46b5ae8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:73:36: note: op template: infos.i = &i;
PULSE.c:73:36: note: 	stmt 0 infos.i = &i;
PULSE.c:73:36: note: 	stmt 1 infos.j = &j;
PULSE.c:73:36: note: 	children 0x46b5b68
PULSE.c:73:36: note: node (external) 0x46b5b68 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:73:36: note: 	{ &i, &j }
PULSE.c:73:36: note: Cost model analysis: 
PULSE.c:73:36: note: Cost model analysis for part in loop 0:
  Vector cost: 20
  Scalar cost: 32
PULSE.c:73:36: note: Basic block will be vectorized using SLP
PULSE.c:73:36: optimized: basic block part vectorized using 8 byte vectors
PULSE.c:73:36: note: Vectorizing SLP tree:
PULSE.c:73:36: note: node 0x46b5968 (max_nunits=2, refcnt=1) vector(2) int
PULSE.c:73:36: note: op template: infos.size = _4;
PULSE.c:73:36: note: 	stmt 0 infos.size = _4;
PULSE.c:73:36: note: 	stmt 1 infos.i_limit = epoch.3_5;
PULSE.c:73:36: note: 	children 0x46b59e8
PULSE.c:73:36: note: node 0x46b59e8 (max_nunits=2, refcnt=1) vector(2) int
PULSE.c:73:36: note: op template: _4 = (int) _3;
PULSE.c:73:36: note: 	stmt 0 _4 = (int) _3;
PULSE.c:73:36: note: 	stmt 1 epoch.3_5 = (int) epoch_54(D);
PULSE.c:73:36: note: 	children 0x46b5a68
PULSE.c:73:36: note: node (external) 0x46b5a68 (max_nunits=1, refcnt=1) vector(2) unsigned int
PULSE.c:73:36: note: 	{ _3, epoch_54(D) }
PULSE.c:73:36: note: ------>vectorizing SLP node starting from: _4 = (int) _3;
PULSE.c:73:36: note: transform assignment.
PULSE.c:73:36: note: add new stmt: vect__4.94_266 = VIEW_CONVERT_EXPR<vector(2) int>(_265);
PULSE.c:73:36: note: ------>vectorizing SLP node starting from: infos.size = _4;
PULSE.c:73:36: note: vect_is_simple_use: operand (int) _3, type of def: internal
PULSE.c:73:36: note: vect_is_simple_use: operand (int) epoch_54(D), type of def: internal
PULSE.c:73:36: note: transform store. ncopies = 1
PULSE.c:73:36: note: create vector_type-pointer variable to type: vector(2) int  vectorizing a pointer ref: infos.size
PULSE.c:73:36: note: created &infos.size
PULSE.c:73:36: note: add new stmt: MEM <vector(2) int> [(int *)&infos + 16B] = vect__4.94_266;
PULSE.c:73:36: note: vectorizing stmts using SLP.
PULSE.c:73:36: optimized: basic block part vectorized using 16 byte vectors
PULSE.c:73:36: note: Vectorizing SLP tree:
PULSE.c:73:36: note: node 0x46b5ae8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
PULSE.c:73:36: note: op template: infos.i = &i;
PULSE.c:73:36: note: 	stmt 0 infos.i = &i;
PULSE.c:73:36: note: 	stmt 1 infos.j = &j;
PULSE.c:73:36: note: 	children 0x46b5b68
PULSE.c:73:36: note: node (external) 0x46b5b68 (max_nunits=1, refcnt=1) vector(2) long unsigned int
PULSE.c:73:36: note: 	{ &i, &j }
PULSE.c:73:36: note: ------>vectorizing SLP node starting from: infos.i = &i;
PULSE.c:73:36: note: vect_is_simple_use: operand &j, type of def: external
PULSE.c:73:36: note: transform store. ncopies = 1
PULSE.c:73:36: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: infos.i
PULSE.c:73:36: note: created &infos
PULSE.c:73:36: note: add new stmt: MEM <vector(2) long unsigned int> [(int * *)&infos] = _264;
PULSE.c:73:36: note: vectorizing stmts using SLP.
PULSE.c:73:36: note: ***** The result for vector mode V32QI would be the same
PULSE.c:105:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:105:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:110:8: missed: couldn't vectorize loop
PULSE.c:110:8: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:107:6: note: vectorized 0 loops in function.
PULSE.c:112:3: missed: statement clobbers memory: _1 (current_10);
PULSE.c:115:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:115:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Loss.c:15:19: optimized: loop vectorized using 32 byte vectors
Loss.c:15:19: optimized:  loop versioned for vectorization because of possible aliasing
Loss.c:15:19: optimized: loop vectorized using 16 byte vectors
Loss.c:12:23: note: vectorized 1 loops in function.
Loss.c:12:23: note: ***** Analysis failed with vector mode V8SF
Loss.c:12:23: note: ***** The result for vector mode V32QI would be the same
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V16QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V16QI
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V8QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V8QI
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V4QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V4QI
Loss.c:7:19: missed: couldn't vectorize loop
Loss.c:8:38: missed: not vectorized: unsupported use in stmt.
Loss.c:4:23: note: vectorized 0 loops in function.
Loss.c:9:13: note: ***** Analysis failed with vector mode V8SF
Loss.c:9:13: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Loss.c:23:2: note: ***** Analysis failed with vector mode VOID
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:4:18: note: vectorized 0 loops in function.
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_4, inputs_15, _3);
PULSE.c:8:2: missed: statement clobbers memory: _5 (layer_17);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_12, pretmp_26, _9);
PULSE.c:13:28: note: ***** Analysis failed with vector mode V8SI
PULSE.c:13:28: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:22:2: missed: statement clobbers memory: _1 (layer_10(D));
PULSE.c:22:2: missed: statement clobbers memory: _14 (_2);
PULSE.c:22:2: missed: statement clobbers memory: _21 (_15);
PULSE.c:22:2: missed: statement clobbers memory: _28 (_22);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_29);
PULSE.c:26:3: missed: statement clobbers memory: memset (_34, 0, _32);
PULSE.c:26:3: missed: statement clobbers memory: memset (_27, 0, _25);
PULSE.c:26:3: missed: statement clobbers memory: memset (_20, 0, _18);
PULSE.c:26:3: missed: statement clobbers memory: memset (_7, 0, _5);
PULSE.c:28:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:28:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:32:6: note: vectorized 1 loops in function.
PULSE.c:34:8: missed: statement clobbers memory: _1 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_2);
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _9 = rand ();
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8SI
PULSE.c:32:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:61:16: missed: couldn't vectorize loop
PULSE.c:61:16: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:64:17: missed: couldn't vectorize loop
PULSE.c:64:17: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:73:19: missed: couldn't vectorize loop
PULSE.c:73:19: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _64 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:53:22: missed: couldn't vectorize loop
PULSE.c:53:22: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:47:6: note: vectorized 1 loops in function.
PULSE.c:48:1: missed: statement clobbers memory: saved_stack.7_35 = __builtin_stack_save ();
PULSE.c:49:46: missed: statement clobbers memory: _1 = PULSE_GetLossFunctionPtr (loss_function_36(D));
PULSE.c:60:10: missed: statement clobbers memory: random.4_42 = __builtin_alloca_with_align (_4, 32);
PULSE.c:34:8: missed: statement clobbers memory: _56 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_57);
PULSE.c:39:29: missed: statement clobbers memory: _64 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _67 = rand ();
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_93, inputs_88, _92);
PULSE.c:8:2: missed: statement clobbers memory: _94 (layer_89);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_100, _99, _98);
PULSE.c:67:11: missed: statement clobbers memory: loss_51 = PULSE_GetLoss_38 (_17, _16, _12, _11);
PULSE.c:22:2: missed: statement clobbers memory: _81 (output_30);
PULSE.c:22:2: missed: statement clobbers memory: _103 (_82);
PULSE.c:22:2: missed: statement clobbers memory: _110 (_104);
PULSE.c:22:2: missed: statement clobbers memory: _117 (_111);
PULSE.c:22:2: missed: statement clobbers memory: _124 (_118);
PULSE.c:22:2: missed: statement clobbers memory: _131 (_125);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_132);
PULSE.c:26:3: missed: statement clobbers memory: memset (_137, 0, _135);
PULSE.c:26:3: missed: statement clobbers memory: memset (_130, 0, _128);
PULSE.c:26:3: missed: statement clobbers memory: memset (_123, 0, _121);
PULSE.c:26:3: missed: statement clobbers memory: memset (_116, 0, _114);
PULSE.c:26:3: missed: statement clobbers memory: memset (_109, 0, _107);
PULSE.c:26:3: missed: statement clobbers memory: memset (_87, 0, _85);
PULSE.c:75:6: missed: statement clobbers memory: _21 (current_183, args);
PULSE.c:80:4: missed: statement clobbers memory: printf ("Epoch: %d Item: %d Error: %.10f\r", i_181, j_182, _22);
PULSE.c:47:6: missed: statement clobbers memory: __builtin_stack_restore (saved_stack.7_35);
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4DI
PULSE.c:47:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:89:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:89:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:94:8: missed: couldn't vectorize loop
PULSE.c:94:8: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:91:6: note: vectorized 0 loops in function.
PULSE.c:96:3: missed: statement clobbers memory: _1 (current_10);
PULSE.c:99:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:99:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:9:27: missed: couldn't vectorize loop
Dense.c:9:27: missed: not vectorized: unsupported outerloop form.
Dense.c:12:20: missed: couldn't vectorize loop
Dense.c:13:21: missed: not vectorized: complicated access pattern.
Dense.c:6:13: note: vectorized 0 loops in function.
Dense.c:16:2: missed: statement clobbers memory: _30 (pretmp_91, _50, 0);
Dense.c:9:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:9:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:24:27: missed: couldn't vectorize loop
Dense.c:24:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:28:20: optimized: loop vectorized using 32 byte vectors
Dense.c:28:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:28:20: optimized: loop vectorized using 16 byte vectors
Dense.c:28:20: missed: couldn't vectorize loop
Dense.c:30:20: missed: not vectorized: no vectype for stmt: _21 = *_20;
 scalar_type: float
Dense.c:20:13: note: vectorized 1 loops in function.
Dense.c:23:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:24:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:24:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:41:28: missed: couldn't vectorize loop
Dense.c:41:28: missed: not vectorized: unsupported outerloop form.
Dense.c:45:21: optimized: loop vectorized using 32 byte vectors
Dense.c:45:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:45:21: optimized: loop vectorized using 16 byte vectors
Dense.c:37:13: note: vectorized 1 loops in function.
Dense.c:37:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:37:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:41:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:145:19: missed: couldn't vectorize loop
Dense.c:145:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:136:19: missed: couldn't vectorize loop
Dense.c:136:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:129:13: note: vectorized 0 loops in function.
Dense.c:153:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:153:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:98:28: missed: couldn't vectorize loop
Dense.c:98:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:101:21: missed: couldn't vectorize loop
Dense.c:101:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:115:28: missed: couldn't vectorize loop
Dense.c:115:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:118:21: missed: couldn't vectorize loop
Dense.c:118:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:84:19: missed: couldn't vectorize loop
Dense.c:84:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:78:13: note: vectorized 0 loops in function.
Dense.c:81:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:103:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:103:17: note: SLPing BB part
Dense.c:120:17: note: Costing subgraph: 
Dense.c:120:17: note: node 0x7727c78 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:120:17: note: op template: _49 = (sizetype) j_137;
Dense.c:120:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:120:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:120:17: note: 	children 0x7727d78
Dense.c:120:17: note: node (external) 0x7727d78 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:120:17: note: 	{ j_137, wi_136 }
Dense.c:120:17: note: Cost model analysis: 
Dense.c:120:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:120:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:120:17: missed: not vectorized: vectorization is not profitable.
Dense.c:103:17: note: Costing subgraph: 
Dense.c:103:17: note: node 0x7727e78 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:103:17: note: op template: _24 = (sizetype) j_134;
Dense.c:103:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:103:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:103:17: note: 	children 0x7727f78
Dense.c:103:17: note: node (external) 0x7727f78 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:103:17: note: 	{ j_134, wi_133 }
Dense.c:103:17: note: Cost model analysis: 
Dense.c:103:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:103:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:103:17: missed: not vectorized: vectorization is not profitable.
Dense.c:103:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:103:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:103:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:103:17: note: SLPing BB part
Dense.c:120:17: note: Costing subgraph: 
Dense.c:120:17: note: node 0x7727e78 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:120:17: note: op template: _49 = (sizetype) j_137;
Dense.c:120:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:120:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:120:17: note: 	children 0x7727c78
Dense.c:120:17: note: node (external) 0x7727c78 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:120:17: note: 	{ j_137, wi_136 }
Dense.c:120:17: note: Cost model analysis: 
Dense.c:120:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:120:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:120:17: missed: not vectorized: vectorization is not profitable.
Dense.c:103:17: note: Costing subgraph: 
Dense.c:103:17: note: node 0x7727ff8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:103:17: note: op template: _24 = (sizetype) j_134;
Dense.c:103:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:103:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:103:17: note: 	children 0x7727ef8
Dense.c:103:17: note: node (external) 0x7727ef8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:103:17: note: 	{ j_134, wi_133 }
Dense.c:103:17: note: Cost model analysis: 
Dense.c:103:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:103:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:103:17: missed: not vectorized: vectorization is not profitable.
Dense.c:103:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:98:55: note: ***** Analysis failed with vector mode V8QI
Dense.c:98:55: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:98:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:58:27: missed: couldn't vectorize loop
Dense.c:58:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:61:20: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:905:10: missed: not vectorized: no vectype for stmt: _41 = MEM[(__m256_u * {ref-all})_6];
 scalar_type: __m256_u
Dense.c:61:20: note: ***** Analysis failed with vector mode VOID
Dense.c:54:13: note: vectorized 0 loops in function.
Dense.c:54:13: missed: splitting region at dont-vectorize loop 3 entry at bb18
Dense.c:63:14: note: ***** Analysis failed with vector mode V4DI
Dense.c:63:14: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:63:14: missed: splitting region at dominance boundary bb8
Dense.c:63:14: note: ***** Analysis failed with vector mode VOID
Dense.c:63:14: missed: splitting region at loop 1 exit at bb16
Dense.c:58:27: note: ***** Analysis failed with vector mode V8SF
Dense.c:58:27: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Dense.c:58:27: missed: splitting region at dominance boundary bb10
Dense.c:58:27: note: ***** Analysis failed with vector mode VOID
Dense.c:74:2: missed: statement clobbers memory: _27 (pretmp_153, _61, 0);
Dense.c:75:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:75:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:160:2: missed: statement clobbers memory: free (_1);
Dense.c:161:2: missed: statement clobbers memory: free (_2);
Dense.c:162:2: missed: statement clobbers memory: free (_3);
Dense.c:163:2: missed: statement clobbers memory: free (_4);
Dense.c:164:2: missed: statement clobbers memory: free (dense_7);
Dense.c:165:2: missed: statement clobbers memory: PULSE_DestroyLayer (this_6(D));
Dense.c:166:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:166:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:180:19: missed: couldn't vectorize loop
Dense.c:180:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:170:13: note: vectorized 0 loops in function.
Dense.c:172:47: missed: statement clobbers memory: dense_35 = malloc (40);
Dense.c:174:36: missed: statement clobbers memory: _5 = aligned_alloc (64, _4);
Dense.c:175:38: missed: statement clobbers memory: _6 = aligned_alloc (64, _4);
Dense.c:176:36: missed: statement clobbers memory: _8 = aligned_alloc (64, _7);
Dense.c:177:35: missed: statement clobbers memory: _9 = aligned_alloc (64, _7);
Dense.c:178:36: missed: statement clobbers memory: _10 = aligned_alloc (64, _7);
Dense.c:181:39: missed: statement clobbers memory: _11 = rand ();
Dense.c:181:73: missed: statement clobbers memory: _63 = sqrt (_18);
Dense.c:198:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:199:4: missed: statement clobbers memory: exit (1);
Dense.c:191:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.3_29, n_outputs.2_28, 1, activation_function_51(D), _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:187:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.1_27, n_outputs.0_26, 1, activation_function_51(D), _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:205:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Dense.c:205:9: note: ***** Analysis failed with vector mode V4DI
Dense.c:205:9: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Loss.c:15:19: optimized: loop vectorized using 32 byte vectors
Loss.c:15:19: optimized:  loop versioned for vectorization because of possible aliasing
Loss.c:15:19: optimized: loop vectorized using 16 byte vectors
Loss.c:12:23: note: vectorized 1 loops in function.
Loss.c:12:23: note: ***** Analysis failed with vector mode V8SF
Loss.c:12:23: note: ***** The result for vector mode V32QI would be the same
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V16QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V16QI
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V8QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V8QI
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V4QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V4QI
Loss.c:7:19: missed: couldn't vectorize loop
Loss.c:8:38: missed: not vectorized: unsupported use in stmt.
Loss.c:4:23: note: vectorized 0 loops in function.
Loss.c:9:13: note: ***** Analysis failed with vector mode V8SF
Loss.c:9:13: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Loss.c:23:2: note: ***** Analysis failed with vector mode VOID
Layer.c:7:34: missed: statement clobbers memory: _3 = aligned_alloc (64, _2);
Layer.c:8:35: missed: statement clobbers memory: _6 = aligned_alloc (64, _5);
Layer.c:9:34: missed: statement clobbers memory: _7 = aligned_alloc (64, _5);
Layer.c:14:19: missed: statement clobbers memory: _8 = PULSE_GetActivationFunctionPtr (activation_function_18(D));
Layer.c:19:9: note: ***** Analysis succeeded with vector mode V8SI
Layer.c:19:9: note: SLPing BB part
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x4c057d8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 0 MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 1 MEM <unsigned int> [(struct PULSE_Layer *)&<retval> + 4B] = optimization_type_17(D);
Layer.c:19:9: note: 	children 0x4c05858
Layer.c:19:9: note: node (external) 0x4c05858 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ type_16(D), optimization_type_17(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x4c058d8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 0 <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 1 <retval>.n_outputs = n_outputs_12(D);
Layer.c:19:9: note: 	children 0x4c05958
Layer.c:19:9: note: node (external) 0x4c05958 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x4c05a58 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 0 <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 1 <retval>.outputs = _6;
Layer.c:19:9: note: 	children 0x4c05ad8
Layer.c:19:9: note: node (external) 0x4c05ad8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	stmt 0 _3 = aligned_alloc (64, _2);
Layer.c:19:9: note: 	stmt 1 _6 = aligned_alloc (64, _5);
Layer.c:19:9: note: 	children 0x4c05b58 0x4c05bd8
Layer.c:19:9: note: node (constant) 0x4c05b58 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 64, 64 }
Layer.c:19:9: note: node 0x4c05bd8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: patt_40 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 0 patt_40 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 1 patt_41 = n_outputs_12(D) w* 4;
Layer.c:19:9: note: 	children 0x4c05c58 0x4c05cd8
Layer.c:19:9: note: node (external) 0x4c05c58 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: node (constant) 0x4c05cd8 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ 4, 4 }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x4c05dd8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: op template: <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 0 <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 1 <retval>.back = back_21(D);
Layer.c:19:9: note: 	stmt 2 <retval>.fix = fix_22(D);
Layer.c:19:9: note: 	stmt 3 <retval>.destroy = destroy_23(D);
Layer.c:19:9: note: 	children 0x4c05e58
Layer.c:19:9: note: node (external) 0x4c05e58 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: 	{ feed_20(D), back_21(D), fix_22(D), destroy_23(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 64
  Scalar cost: 64
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x4c05f58 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 0 <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 1 <retval>.child = 0B;
Layer.c:19:9: note: 	children 0x4c05fd8
Layer.c:19:9: note: node (constant) 0x4c05fd8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ 0B, 0B }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Basic block will be vectorized using SLP
Layer.c:19:9: optimized: basic block part vectorized using 8 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x4c057d8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 0 MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 1 MEM <unsigned int> [(struct PULSE_Layer *)&<retval> + 4B] = optimization_type_17(D);
Layer.c:19:9: note: 	children 0x4c05858
Layer.c:19:9: note: node (external) 0x4c05858 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ type_16(D), optimization_type_17(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: vect_is_simple_use: operand optimization_type_17(D), type of def: external
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>]
Layer.c:19:9: note: created &MEM <unsigned int> [(struct PULSE_Layer *)&<retval>]
Layer.c:19:9: note: add new stmt: MEM <vector(2) unsigned int> [(struct PULSE_Layer *)&<retval>] = _42;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 8 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x4c058d8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 0 <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 1 <retval>.n_outputs = n_outputs_12(D);
Layer.c:19:9: note: 	children 0x4c05958
Layer.c:19:9: note: node (external) 0x4c05958 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: vect_is_simple_use: operand n_outputs_12(D), type of def: external
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: <retval>.n_inputs
Layer.c:19:9: note: created &<retval>.n_inputs
Layer.c:19:9: note: add new stmt: MEM <vector(2) unsigned int> [(unsigned int *)&<retval> + 96B] = _44;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 16 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x4c05a58 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 0 <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 1 <retval>.outputs = _6;
Layer.c:19:9: note: 	children 0x4c05ad8
Layer.c:19:9: note: node (external) 0x4c05ad8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	stmt 0 _3 = aligned_alloc (64, _2);
Layer.c:19:9: note: 	stmt 1 _6 = aligned_alloc (64, _5);
Layer.c:19:9: note: 	children 0x4c05b58 0x4c05bd8
Layer.c:19:9: note: node (constant) 0x4c05b58 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 64, 64 }
Layer.c:19:9: note: node 0x4c05bd8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: patt_40 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 0 patt_40 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 1 patt_41 = n_outputs_12(D) w* 4;
Layer.c:19:9: note: 	children 0x4c05c58 0x4c05cd8
Layer.c:19:9: note: node (external) 0x4c05c58 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: node (constant) 0x4c05cd8 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ 4, 4 }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.inputs = _3;
Layer.c:19:9: note: vect_is_simple_use: operand aligned_alloc (64, _5), type of def: internal
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.inputs
Layer.c:19:9: note: created &<retval>.inputs
Layer.c:19:9: note: add new stmt: MEM <vector(2) long unsigned int> [(float * *)&<retval> + 8B] = _48;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 32 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x4c05dd8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: op template: <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 0 <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 1 <retval>.back = back_21(D);
Layer.c:19:9: note: 	stmt 2 <retval>.fix = fix_22(D);
Layer.c:19:9: note: 	stmt 3 <retval>.destroy = destroy_23(D);
Layer.c:19:9: note: 	children 0x4c05e58
Layer.c:19:9: note: node (external) 0x4c05e58 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: 	{ feed_20(D), back_21(D), fix_22(D), destroy_23(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.feed = feed_20(D);
Layer.c:19:9: note: vect_is_simple_use: operand back_21(D), type of def: external
Layer.c:19:9: note: vect_is_simple_use: operand fix_22(D), type of def: external
Layer.c:19:9: note: vect_is_simple_use: operand destroy_23(D), type of def: external
Layer.c:19:9: note: conflicting alias set types.
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(4) long unsigned int  vectorizing a pointer ref: <retval>.feed
Layer.c:19:9: note: created &<retval>.feed
Layer.c:19:9: note: add new stmt: MEM <vector(4) long unsigned int> [(void *)&<retval> + 32B] = _54;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 16 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x4c05f58 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 0 <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 1 <retval>.child = 0B;
Layer.c:19:9: note: 	children 0x4c05fd8
Layer.c:19:9: note: node (constant) 0x4c05fd8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ 0B, 0B }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.parent = 0B;
Layer.c:19:9: note: vect_is_simple_use: operand 0B, type of def: constant
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.parent
Layer.c:19:9: note: created &<retval>.parent
Layer.c:19:9: note: add new stmt: MEM <vector(2) long unsigned int> [(struct PULSE_Layer * *)&<retval> + 72B] = { 0, 0 };
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: note: ***** The result for vector mode V32QI would be the same
Layer.c:24:2: missed: statement clobbers memory: free (_1);
Layer.c:25:2: missed: statement clobbers memory: free (_2);
Layer.c:26:2: missed: statement clobbers memory: free (_3);
Layer.c:27:1: note: ***** Analysis failed with vector mode V4DI
Layer.c:27:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:9:27: missed: couldn't vectorize loop
Dense.c:9:27: missed: not vectorized: unsupported outerloop form.
Dense.c:12:20: missed: couldn't vectorize loop
Dense.c:13:21: missed: not vectorized: complicated access pattern.
Dense.c:6:13: note: vectorized 0 loops in function.
Dense.c:16:2: missed: statement clobbers memory: _30 (pretmp_91, _50, 0);
Dense.c:9:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:9:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:9:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:9:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:24:27: missed: couldn't vectorize loop
Dense.c:24:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:28:20: optimized: loop vectorized using 32 byte vectors
Dense.c:28:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:28:20: optimized: loop vectorized using 16 byte vectors
Dense.c:28:20: missed: couldn't vectorize loop
Dense.c:30:20: missed: not vectorized: no vectype for stmt: _21 = *_20;
 scalar_type: float
Dense.c:20:13: note: vectorized 1 loops in function.
Dense.c:23:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:24:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:24:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:24:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:24:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:41:28: missed: couldn't vectorize loop
Dense.c:41:28: missed: not vectorized: unsupported outerloop form.
Dense.c:45:21: optimized: loop vectorized using 32 byte vectors
Dense.c:45:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:45:21: optimized: loop vectorized using 16 byte vectors
Dense.c:37:13: note: vectorized 1 loops in function.
Dense.c:37:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:37:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:37:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:37:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:41:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:145:19: missed: couldn't vectorize loop
Dense.c:145:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:136:19: missed: couldn't vectorize loop
Dense.c:136:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:129:13: note: vectorized 0 loops in function.
Dense.c:153:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:153:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:98:28: missed: couldn't vectorize loop
Dense.c:98:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:101:21: missed: couldn't vectorize loop
Dense.c:101:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:115:28: missed: couldn't vectorize loop
Dense.c:115:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:118:21: missed: couldn't vectorize loop
Dense.c:118:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:84:19: missed: couldn't vectorize loop
Dense.c:84:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:78:13: note: vectorized 0 loops in function.
Dense.c:81:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:103:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:103:17: note: SLPing BB part
Dense.c:120:17: note: Costing subgraph: 
Dense.c:120:17: note: node 0x70f25f8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:120:17: note: op template: _49 = (sizetype) j_137;
Dense.c:120:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:120:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:120:17: note: 	children 0x70f26f8
Dense.c:120:17: note: node (external) 0x70f26f8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:120:17: note: 	{ j_137, wi_136 }
Dense.c:120:17: note: Cost model analysis: 
Dense.c:120:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:120:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:120:17: missed: not vectorized: vectorization is not profitable.
Dense.c:103:17: note: Costing subgraph: 
Dense.c:103:17: note: node 0x70f27f8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:103:17: note: op template: _24 = (sizetype) j_134;
Dense.c:103:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:103:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:103:17: note: 	children 0x70f28f8
Dense.c:103:17: note: node (external) 0x70f28f8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:103:17: note: 	{ j_134, wi_133 }
Dense.c:103:17: note: Cost model analysis: 
Dense.c:103:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:103:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:103:17: missed: not vectorized: vectorization is not profitable.
Dense.c:103:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:103:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:103:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:103:17: note: SLPing BB part
Dense.c:120:17: note: Costing subgraph: 
Dense.c:120:17: note: node 0x70f27f8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:120:17: note: op template: _49 = (sizetype) j_137;
Dense.c:120:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:120:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:120:17: note: 	children 0x70f25f8
Dense.c:120:17: note: node (external) 0x70f25f8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:120:17: note: 	{ j_137, wi_136 }
Dense.c:120:17: note: Cost model analysis: 
Dense.c:120:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:120:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:120:17: missed: not vectorized: vectorization is not profitable.
Dense.c:103:17: note: Costing subgraph: 
Dense.c:103:17: note: node 0x70f2978 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:103:17: note: op template: _24 = (sizetype) j_134;
Dense.c:103:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:103:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:103:17: note: 	children 0x70f2878
Dense.c:103:17: note: node (external) 0x70f2878 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:103:17: note: 	{ j_134, wi_133 }
Dense.c:103:17: note: Cost model analysis: 
Dense.c:103:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:103:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:103:17: missed: not vectorized: vectorization is not profitable.
Dense.c:103:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:98:55: note: ***** Analysis failed with vector mode V8QI
Dense.c:98:55: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:98:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:58:27: missed: couldn't vectorize loop
Dense.c:58:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:61:20: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:905:10: missed: not vectorized: no vectype for stmt: _41 = MEM[(__m256_u * {ref-all})_6];
 scalar_type: __m256_u
Dense.c:61:20: note: ***** Analysis failed with vector mode VOID
Dense.c:54:13: note: vectorized 0 loops in function.
Dense.c:54:13: missed: splitting region at dont-vectorize loop 3 entry at bb18
Dense.c:63:14: note: ***** Analysis failed with vector mode V4DI
Dense.c:63:14: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:63:14: missed: splitting region at dominance boundary bb8
Dense.c:63:14: note: ***** Analysis failed with vector mode VOID
Dense.c:63:14: missed: splitting region at loop 1 exit at bb16
Dense.c:58:27: note: ***** Analysis failed with vector mode V8SF
Dense.c:58:27: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Dense.c:58:27: missed: splitting region at dominance boundary bb10
Dense.c:58:27: note: ***** Analysis failed with vector mode VOID
Dense.c:74:2: missed: statement clobbers memory: _27 (pretmp_153, _61, 0);
Dense.c:75:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:75:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:160:2: missed: statement clobbers memory: free (_1);
Dense.c:161:2: missed: statement clobbers memory: free (_2);
Dense.c:162:2: missed: statement clobbers memory: free (_3);
Dense.c:163:2: missed: statement clobbers memory: free (_4);
Dense.c:164:2: missed: statement clobbers memory: free (dense_7);
Dense.c:165:2: missed: statement clobbers memory: PULSE_DestroyLayer (this_6(D));
Dense.c:166:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:166:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:180:19: missed: couldn't vectorize loop
Dense.c:180:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:170:13: note: vectorized 0 loops in function.
Dense.c:172:47: missed: statement clobbers memory: dense_35 = malloc (40);
Dense.c:174:36: missed: statement clobbers memory: _5 = aligned_alloc (64, _4);
Dense.c:175:38: missed: statement clobbers memory: _6 = aligned_alloc (64, _4);
Dense.c:176:36: missed: statement clobbers memory: _8 = aligned_alloc (64, _7);
Dense.c:177:35: missed: statement clobbers memory: _9 = aligned_alloc (64, _7);
Dense.c:178:36: missed: statement clobbers memory: _10 = aligned_alloc (64, _7);
Dense.c:181:39: missed: statement clobbers memory: _11 = rand ();
Dense.c:181:73: missed: statement clobbers memory: _63 = sqrt (_18);
Dense.c:198:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:199:4: missed: statement clobbers memory: exit (1);
Dense.c:191:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.3_29, n_outputs.2_28, 1, activation_function_51(D), _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:187:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.1_27, n_outputs.0_26, 1, activation_function_51(D), _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:205:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Dense.c:205:9: note: ***** Analysis failed with vector mode V4DI
Dense.c:205:9: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Activations.c:17:19: optimized: loop vectorized using 32 byte vectors
Activations.c:17:19: optimized: loop vectorized using 16 byte vectors
Activations.c:17:19: optimized: loop vectorized using 32 byte vectors
Activations.c:17:19: optimized: loop vectorized using 16 byte vectors
Activations.c:14:13: note: vectorized 2 loops in function.
Activations.c:14:13: note: ***** Analysis failed with vector mode V8SF
Activations.c:14:13: note: ***** The result for vector mode V32QI would be the same
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V16QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V16QI
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V8QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V8QI
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V4QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V4QI
Activations.c:28:19: missed: couldn't vectorize loop
Activations.c:28:19: missed: not vectorized: unsupported control flow in loop.
Activations.c:28:19: optimized: loop vectorized using 32 byte vectors
Activations.c:28:19: optimized: loop vectorized using 16 byte vectors
Activations.c:25:13: note: vectorized 1 loops in function.
Activations.c:25:13: note: ***** Analysis failed with vector mode V8SF
Activations.c:25:13: note: ***** The result for vector mode V32QI would be the same
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V16QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V16QI
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V8QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V8QI
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V4QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V4QI
Activations.c:38:1: note: ***** Analysis failed with vector mode VOID
Activations.c:5:19: missed: couldn't vectorize loop
Activations.c:9:21: missed: statement clobbers memory: _36 = expf (_18);
Activations.c:5:19: missed: couldn't vectorize loop
Activations.c:9:21: missed: statement clobbers memory: _12 = expf (_11);
Activations.c:3:13: note: vectorized 0 loops in function.
Activations.c:9:21: missed: statement clobbers memory: _12 = expf (_11);
Activations.c:9:21: missed: statement clobbers memory: _36 = expf (_18);
Activations.c:11:1: note: ***** Analysis failed with vector mode V8SF
Activations.c:11:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Activations.c:44:2: note: ***** Analysis failed with vector mode VOID
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:4:18: note: vectorized 0 loops in function.
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_4, inputs_15, _3);
PULSE.c:8:2: missed: statement clobbers memory: _5 (layer_17);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_12, pretmp_26, _9);
PULSE.c:13:28: note: ***** Analysis failed with vector mode V8SI
PULSE.c:13:28: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:22:2: missed: statement clobbers memory: _1 (layer_10(D));
PULSE.c:22:2: missed: statement clobbers memory: _14 (_2);
PULSE.c:22:2: missed: statement clobbers memory: _21 (_15);
PULSE.c:22:2: missed: statement clobbers memory: _28 (_22);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_29);
PULSE.c:26:3: missed: statement clobbers memory: memset (_34, 0, _32);
PULSE.c:26:3: missed: statement clobbers memory: memset (_27, 0, _25);
PULSE.c:26:3: missed: statement clobbers memory: memset (_20, 0, _18);
PULSE.c:26:3: missed: statement clobbers memory: memset (_7, 0, _5);
PULSE.c:28:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:28:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:32:6: note: vectorized 1 loops in function.
PULSE.c:34:8: missed: statement clobbers memory: _1 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_2);
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _9 = rand ();
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8SI
PULSE.c:32:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:61:16: missed: couldn't vectorize loop
PULSE.c:61:16: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:64:17: missed: couldn't vectorize loop
PULSE.c:64:17: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:73:19: missed: couldn't vectorize loop
PULSE.c:73:19: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _64 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:53:22: missed: couldn't vectorize loop
PULSE.c:53:22: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:47:6: note: vectorized 1 loops in function.
PULSE.c:48:1: missed: statement clobbers memory: saved_stack.7_35 = __builtin_stack_save ();
PULSE.c:49:46: missed: statement clobbers memory: _1 = PULSE_GetLossFunctionPtr (loss_function_36(D));
PULSE.c:60:10: missed: statement clobbers memory: random.4_42 = __builtin_alloca_with_align (_4, 32);
PULSE.c:34:8: missed: statement clobbers memory: _56 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_57);
PULSE.c:39:29: missed: statement clobbers memory: _64 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _67 = rand ();
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_93, inputs_88, _92);
PULSE.c:8:2: missed: statement clobbers memory: _94 (layer_89);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_100, _99, _98);
PULSE.c:67:11: missed: statement clobbers memory: loss_51 = PULSE_GetLoss_38 (_17, _16, _12, _11);
PULSE.c:22:2: missed: statement clobbers memory: _81 (output_30);
PULSE.c:22:2: missed: statement clobbers memory: _103 (_82);
PULSE.c:22:2: missed: statement clobbers memory: _110 (_104);
PULSE.c:22:2: missed: statement clobbers memory: _117 (_111);
PULSE.c:22:2: missed: statement clobbers memory: _124 (_118);
PULSE.c:22:2: missed: statement clobbers memory: _131 (_125);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_132);
PULSE.c:26:3: missed: statement clobbers memory: memset (_137, 0, _135);
PULSE.c:26:3: missed: statement clobbers memory: memset (_130, 0, _128);
PULSE.c:26:3: missed: statement clobbers memory: memset (_123, 0, _121);
PULSE.c:26:3: missed: statement clobbers memory: memset (_116, 0, _114);
PULSE.c:26:3: missed: statement clobbers memory: memset (_109, 0, _107);
PULSE.c:26:3: missed: statement clobbers memory: memset (_87, 0, _85);
PULSE.c:75:6: missed: statement clobbers memory: _21 (current_183, args);
PULSE.c:80:4: missed: statement clobbers memory: printf ("Epoch: %d Item: %d Loss: %.10f\r", i_181, j_182, _22);
PULSE.c:47:6: missed: statement clobbers memory: __builtin_stack_restore (saved_stack.7_35);
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4DI
PULSE.c:47:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:89:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:89:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:94:8: missed: couldn't vectorize loop
PULSE.c:94:8: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:91:6: note: vectorized 0 loops in function.
PULSE.c:96:3: missed: statement clobbers memory: _1 (current_10);
PULSE.c:99:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:99:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Loss.c:15:19: optimized: loop vectorized using 32 byte vectors
Loss.c:15:19: optimized:  loop versioned for vectorization because of possible aliasing
Loss.c:15:19: optimized: loop vectorized using 16 byte vectors
Loss.c:12:23: note: vectorized 1 loops in function.
Loss.c:12:23: note: ***** Analysis failed with vector mode V8SF
Loss.c:12:23: note: ***** The result for vector mode V32QI would be the same
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V16QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V16QI
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V8QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V8QI
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V4QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V4QI
Loss.c:7:19: missed: couldn't vectorize loop
Loss.c:8:38: missed: not vectorized: unsupported use in stmt.
Loss.c:4:23: note: vectorized 0 loops in function.
Loss.c:9:13: note: ***** Analysis failed with vector mode V8SF
Loss.c:9:13: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Loss.c:23:2: note: ***** Analysis failed with vector mode VOID
Layer.c:7:34: missed: statement clobbers memory: _3 = aligned_alloc (64, _2);
Layer.c:8:35: missed: statement clobbers memory: _6 = aligned_alloc (64, _5);
Layer.c:9:34: missed: statement clobbers memory: _7 = aligned_alloc (64, _5);
Layer.c:14:19: missed: statement clobbers memory: _8 = PULSE_GetActivationFunctionPtr (activation_function_18(D));
Layer.c:19:9: note: ***** Analysis succeeded with vector mode V8SI
Layer.c:19:9: note: SLPing BB part
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x309e7c8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 0 MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 1 MEM <unsigned int> [(struct PULSE_Layer *)&<retval> + 4B] = optimization_type_17(D);
Layer.c:19:9: note: 	children 0x309e848
Layer.c:19:9: note: node (external) 0x309e848 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ type_16(D), optimization_type_17(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x309e8c8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 0 <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 1 <retval>.n_outputs = n_outputs_12(D);
Layer.c:19:9: note: 	children 0x309e948
Layer.c:19:9: note: node (external) 0x309e948 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x309ea48 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 0 <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 1 <retval>.outputs = _6;
Layer.c:19:9: note: 	children 0x309eac8
Layer.c:19:9: note: node (external) 0x309eac8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	stmt 0 _3 = aligned_alloc (64, _2);
Layer.c:19:9: note: 	stmt 1 _6 = aligned_alloc (64, _5);
Layer.c:19:9: note: 	children 0x309eb48 0x309ebc8
Layer.c:19:9: note: node (constant) 0x309eb48 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 64, 64 }
Layer.c:19:9: note: node 0x309ebc8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: patt_40 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 0 patt_40 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 1 patt_41 = n_outputs_12(D) w* 4;
Layer.c:19:9: note: 	children 0x309ec48 0x309ecc8
Layer.c:19:9: note: node (external) 0x309ec48 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: node (constant) 0x309ecc8 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ 4, 4 }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x309edc8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: op template: <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 0 <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 1 <retval>.back = back_21(D);
Layer.c:19:9: note: 	stmt 2 <retval>.fix = fix_22(D);
Layer.c:19:9: note: 	stmt 3 <retval>.destroy = destroy_23(D);
Layer.c:19:9: note: 	children 0x309ee48
Layer.c:19:9: note: node (external) 0x309ee48 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: 	{ feed_20(D), back_21(D), fix_22(D), destroy_23(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 64
  Scalar cost: 64
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x309ef48 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 0 <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 1 <retval>.child = 0B;
Layer.c:19:9: note: 	children 0x309efc8
Layer.c:19:9: note: node (constant) 0x309efc8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ 0B, 0B }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Basic block will be vectorized using SLP
Layer.c:19:9: optimized: basic block part vectorized using 8 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x309e7c8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 0 MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 1 MEM <unsigned int> [(struct PULSE_Layer *)&<retval> + 4B] = optimization_type_17(D);
Layer.c:19:9: note: 	children 0x309e848
Layer.c:19:9: note: node (external) 0x309e848 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ type_16(D), optimization_type_17(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: vect_is_simple_use: operand optimization_type_17(D), type of def: external
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>]
Layer.c:19:9: note: created &MEM <unsigned int> [(struct PULSE_Layer *)&<retval>]
Layer.c:19:9: note: add new stmt: MEM <vector(2) unsigned int> [(struct PULSE_Layer *)&<retval>] = _42;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 8 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x309e8c8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 0 <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 1 <retval>.n_outputs = n_outputs_12(D);
Layer.c:19:9: note: 	children 0x309e948
Layer.c:19:9: note: node (external) 0x309e948 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: vect_is_simple_use: operand n_outputs_12(D), type of def: external
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: <retval>.n_inputs
Layer.c:19:9: note: created &<retval>.n_inputs
Layer.c:19:9: note: add new stmt: MEM <vector(2) unsigned int> [(unsigned int *)&<retval> + 96B] = _44;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 16 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x309ea48 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 0 <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 1 <retval>.outputs = _6;
Layer.c:19:9: note: 	children 0x309eac8
Layer.c:19:9: note: node (external) 0x309eac8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	stmt 0 _3 = aligned_alloc (64, _2);
Layer.c:19:9: note: 	stmt 1 _6 = aligned_alloc (64, _5);
Layer.c:19:9: note: 	children 0x309eb48 0x309ebc8
Layer.c:19:9: note: node (constant) 0x309eb48 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 64, 64 }
Layer.c:19:9: note: node 0x309ebc8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: patt_40 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 0 patt_40 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 1 patt_41 = n_outputs_12(D) w* 4;
Layer.c:19:9: note: 	children 0x309ec48 0x309ecc8
Layer.c:19:9: note: node (external) 0x309ec48 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: node (constant) 0x309ecc8 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ 4, 4 }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.inputs = _3;
Layer.c:19:9: note: vect_is_simple_use: operand aligned_alloc (64, _5), type of def: internal
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.inputs
Layer.c:19:9: note: created &<retval>.inputs
Layer.c:19:9: note: add new stmt: MEM <vector(2) long unsigned int> [(float * *)&<retval> + 8B] = _48;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 32 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x309edc8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: op template: <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 0 <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 1 <retval>.back = back_21(D);
Layer.c:19:9: note: 	stmt 2 <retval>.fix = fix_22(D);
Layer.c:19:9: note: 	stmt 3 <retval>.destroy = destroy_23(D);
Layer.c:19:9: note: 	children 0x309ee48
Layer.c:19:9: note: node (external) 0x309ee48 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: 	{ feed_20(D), back_21(D), fix_22(D), destroy_23(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.feed = feed_20(D);
Layer.c:19:9: note: vect_is_simple_use: operand back_21(D), type of def: external
Layer.c:19:9: note: vect_is_simple_use: operand fix_22(D), type of def: external
Layer.c:19:9: note: vect_is_simple_use: operand destroy_23(D), type of def: external
Layer.c:19:9: note: conflicting alias set types.
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(4) long unsigned int  vectorizing a pointer ref: <retval>.feed
Layer.c:19:9: note: created &<retval>.feed
Layer.c:19:9: note: add new stmt: MEM <vector(4) long unsigned int> [(void *)&<retval> + 32B] = _54;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 16 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x309ef48 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 0 <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 1 <retval>.child = 0B;
Layer.c:19:9: note: 	children 0x309efc8
Layer.c:19:9: note: node (constant) 0x309efc8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ 0B, 0B }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.parent = 0B;
Layer.c:19:9: note: vect_is_simple_use: operand 0B, type of def: constant
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.parent
Layer.c:19:9: note: created &<retval>.parent
Layer.c:19:9: note: add new stmt: MEM <vector(2) long unsigned int> [(struct PULSE_Layer * *)&<retval> + 72B] = { 0, 0 };
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: note: ***** The result for vector mode V32QI would be the same
Layer.c:24:2: missed: statement clobbers memory: free (_1);
Layer.c:25:2: missed: statement clobbers memory: free (_2);
Layer.c:26:2: missed: statement clobbers memory: free (_3);
Layer.c:27:1: note: ***** Analysis failed with vector mode V4DI
Layer.c:27:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:10:27: missed: couldn't vectorize loop
Dense.c:10:27: missed: not vectorized: unsupported outerloop form.
Dense.c:13:20: missed: couldn't vectorize loop
Dense.c:14:21: missed: not vectorized: complicated access pattern.
Dense.c:7:13: note: vectorized 0 loops in function.
Dense.c:17:2: missed: statement clobbers memory: _30 (pretmp_91, _50, 0);
Dense.c:10:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:10:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:10:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:10:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:10:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:10:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:10:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:10:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:25:27: missed: couldn't vectorize loop
Dense.c:25:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:29:20: optimized: loop vectorized using 32 byte vectors
Dense.c:29:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:29:20: optimized: loop vectorized using 16 byte vectors
Dense.c:29:20: missed: couldn't vectorize loop
Dense.c:31:20: missed: not vectorized: no vectype for stmt: _21 = *_20;
 scalar_type: float
Dense.c:21:13: note: vectorized 1 loops in function.
Dense.c:24:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:25:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:25:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:25:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:25:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:25:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:25:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:25:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:25:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:42:28: missed: couldn't vectorize loop
Dense.c:42:28: missed: not vectorized: unsupported outerloop form.
Dense.c:46:21: optimized: loop vectorized using 32 byte vectors
Dense.c:46:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:46:21: optimized: loop vectorized using 16 byte vectors
Dense.c:38:13: note: vectorized 1 loops in function.
Dense.c:38:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:38:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:38:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:38:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:38:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:38:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:38:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:42:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:146:19: missed: couldn't vectorize loop
Dense.c:146:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:137:19: missed: couldn't vectorize loop
Dense.c:137:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:130:13: note: vectorized 0 loops in function.
Dense.c:154:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:154:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:99:28: missed: couldn't vectorize loop
Dense.c:99:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:102:21: missed: couldn't vectorize loop
Dense.c:102:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:116:28: missed: couldn't vectorize loop
Dense.c:116:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:119:21: missed: couldn't vectorize loop
Dense.c:119:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:85:19: missed: couldn't vectorize loop
Dense.c:85:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:79:13: note: vectorized 0 loops in function.
Dense.c:82:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:104:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:104:17: note: SLPing BB part
Dense.c:121:17: note: Costing subgraph: 
Dense.c:121:17: note: node 0x8037f98 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:121:17: note: op template: _49 = (sizetype) j_137;
Dense.c:121:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:121:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:121:17: note: 	children 0x8038098
Dense.c:121:17: note: node (external) 0x8038098 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:121:17: note: 	{ j_137, wi_136 }
Dense.c:121:17: note: Cost model analysis: 
Dense.c:121:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:121:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:121:17: missed: not vectorized: vectorization is not profitable.
Dense.c:104:17: note: Costing subgraph: 
Dense.c:104:17: note: node 0x8038198 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:104:17: note: op template: _24 = (sizetype) j_134;
Dense.c:104:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:104:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:104:17: note: 	children 0x8038298
Dense.c:104:17: note: node (external) 0x8038298 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:104:17: note: 	{ j_134, wi_133 }
Dense.c:104:17: note: Cost model analysis: 
Dense.c:104:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:104:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:104:17: missed: not vectorized: vectorization is not profitable.
Dense.c:104:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:104:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:104:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:104:17: note: SLPing BB part
Dense.c:121:17: note: Costing subgraph: 
Dense.c:121:17: note: node 0x8038198 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:121:17: note: op template: _49 = (sizetype) j_137;
Dense.c:121:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:121:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:121:17: note: 	children 0x8037f98
Dense.c:121:17: note: node (external) 0x8037f98 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:121:17: note: 	{ j_137, wi_136 }
Dense.c:121:17: note: Cost model analysis: 
Dense.c:121:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:121:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:121:17: missed: not vectorized: vectorization is not profitable.
Dense.c:104:17: note: Costing subgraph: 
Dense.c:104:17: note: node 0x8038318 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:104:17: note: op template: _24 = (sizetype) j_134;
Dense.c:104:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:104:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:104:17: note: 	children 0x8038218
Dense.c:104:17: note: node (external) 0x8038218 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:104:17: note: 	{ j_134, wi_133 }
Dense.c:104:17: note: Cost model analysis: 
Dense.c:104:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:104:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:104:17: missed: not vectorized: vectorization is not profitable.
Dense.c:104:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:99:55: note: ***** Analysis failed with vector mode V8QI
Dense.c:99:55: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:99:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:59:27: missed: couldn't vectorize loop
Dense.c:59:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:62:20: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:905:10: missed: not vectorized: no vectype for stmt: _41 = MEM[(__m256_u * {ref-all})_6];
 scalar_type: __m256_u
Dense.c:62:20: note: ***** Analysis failed with vector mode VOID
Dense.c:55:13: note: vectorized 0 loops in function.
Dense.c:55:13: missed: splitting region at dont-vectorize loop 3 entry at bb18
Dense.c:64:14: note: ***** Analysis failed with vector mode V4DI
Dense.c:64:14: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:64:14: missed: splitting region at dominance boundary bb8
Dense.c:64:14: note: ***** Analysis failed with vector mode VOID
Dense.c:64:14: missed: splitting region at loop 1 exit at bb16
Dense.c:59:27: note: ***** Analysis failed with vector mode V8SF
Dense.c:59:27: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Dense.c:59:27: missed: splitting region at dominance boundary bb10
Dense.c:59:27: note: ***** Analysis failed with vector mode VOID
Dense.c:75:2: missed: statement clobbers memory: _27 (pretmp_153, _61, 0);
Dense.c:76:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:76:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:161:2: missed: statement clobbers memory: free (_1);
Dense.c:162:2: missed: statement clobbers memory: free (_2);
Dense.c:163:2: missed: statement clobbers memory: free (_3);
Dense.c:164:2: missed: statement clobbers memory: free (_4);
Dense.c:165:2: missed: statement clobbers memory: free (dense_7);
Dense.c:166:2: missed: statement clobbers memory: PULSE_DestroyLayer (this_6(D));
Dense.c:167:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:167:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Include/PulseAlloc.h:14:11: missed: statement clobbers memory: _18 = aligned_alloc (64, _8);
Include/PulseAlloc.h:11:28: missed: statement clobbers memory: _20 = aligned_alloc (64, _2);
Include/PulseAlloc.h:19:2: missed: statement clobbers memory: exit (1);
Include/PulseAlloc.h:19:2: note: ***** Analysis failed with vector mode VOID
Include/PulseAlloc.h:33:11: missed: statement clobbers memory: _21 = aligned_alloc (64, _10);
Include/PulseAlloc.h:29:28: missed: statement clobbers memory: _23 = aligned_alloc (64, _3);
Include/PulseAlloc.h:38:2: missed: statement clobbers memory: exit (1);
Include/PulseAlloc.h:38:2: note: ***** Analysis failed with vector mode VOID
Dense.c:181:19: missed: couldn't vectorize loop
Dense.c:181:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:171:13: note: vectorized 0 loops in function.
Dense.c:173:47: missed: statement clobbers memory: dense_34 = malloc (40);
Dense.c:175:36: missed: statement clobbers memory: _5 = aligned_alloc (64, _4);
Dense.c:176:38: missed: statement clobbers memory: _6 = aligned_alloc (64, _4);
Include/PulseAlloc.h:14:11: missed: statement clobbers memory: _141 = aligned_alloc (64, _139);
Include/PulseAlloc.h:14:11: missed: statement clobbers memory: _132 = aligned_alloc (64, _139);
Include/PulseAlloc.h:14:11: missed: statement clobbers memory: _150 = aligned_alloc (64, _148);
Include/PulseAlloc.h:14:11: missed: statement clobbers memory: _123 = aligned_alloc (64, _148);
Include/PulseAlloc.h:14:11: missed: statement clobbers memory: _71 = aligned_alloc (64, prephitmp_105);
Include/PulseAlloc.h:11:28: missed: statement clobbers memory: _88 = aligned_alloc (64, _87);
Include/PulseAlloc.h:11:28: missed: statement clobbers memory: _75 = aligned_alloc (64, _87);
Include/PulseAlloc.h:11:28: missed: statement clobbers memory: _62 = aligned_alloc (64, _87);
Dense.c:182:39: missed: statement clobbers memory: _10 = rand ();
Dense.c:182:73: missed: statement clobbers memory: _49 = sqrt (_17);
Dense.c:188:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.3_26, n_outputs.2_25, 1, activation_function_50(D), _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:192:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.5_28, n_outputs.4_27, 1, activation_function_50(D), _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:206:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Include/PulseAlloc.h:19:2: missed: statement clobbers memory: exit (1);
Include/PulseAlloc.h:19:2: note: ***** Analysis failed with vector mode V4DI
Include/PulseAlloc.h:19:2: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Activations.c:17:19: optimized: loop vectorized using 32 byte vectors
Activations.c:17:19: optimized: loop vectorized using 16 byte vectors
Activations.c:17:19: optimized: loop vectorized using 32 byte vectors
Activations.c:17:19: optimized: loop vectorized using 16 byte vectors
Activations.c:14:13: note: vectorized 2 loops in function.
Activations.c:14:13: note: ***** Analysis failed with vector mode V8SF
Activations.c:14:13: note: ***** The result for vector mode V32QI would be the same
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V16QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V16QI
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V8QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V8QI
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V4QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V4QI
Activations.c:28:19: missed: couldn't vectorize loop
Activations.c:28:19: missed: not vectorized: unsupported control flow in loop.
Activations.c:28:19: optimized: loop vectorized using 32 byte vectors
Activations.c:28:19: optimized: loop vectorized using 16 byte vectors
Activations.c:25:13: note: vectorized 1 loops in function.
Activations.c:25:13: note: ***** Analysis failed with vector mode V8SF
Activations.c:25:13: note: ***** The result for vector mode V32QI would be the same
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V16QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V16QI
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V8QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V8QI
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V4QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V4QI
Activations.c:38:1: note: ***** Analysis failed with vector mode VOID
Activations.c:5:19: missed: couldn't vectorize loop
Activations.c:9:21: missed: statement clobbers memory: _36 = expf (_18);
Activations.c:5:19: missed: couldn't vectorize loop
Activations.c:9:21: missed: statement clobbers memory: _12 = expf (_11);
Activations.c:3:13: note: vectorized 0 loops in function.
Activations.c:9:21: missed: statement clobbers memory: _12 = expf (_11);
Activations.c:9:21: missed: statement clobbers memory: _36 = expf (_18);
Activations.c:11:1: note: ***** Analysis failed with vector mode V8SF
Activations.c:11:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Activations.c:44:2: note: ***** Analysis failed with vector mode VOID
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:4:18: note: vectorized 0 loops in function.
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_4, inputs_15, _3);
PULSE.c:8:2: missed: statement clobbers memory: _5 (layer_17);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_12, pretmp_26, _9);
PULSE.c:13:28: note: ***** Analysis failed with vector mode V8SI
PULSE.c:13:28: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:22:2: missed: statement clobbers memory: _1 (layer_10(D));
PULSE.c:22:2: missed: statement clobbers memory: _14 (_2);
PULSE.c:22:2: missed: statement clobbers memory: _21 (_15);
PULSE.c:22:2: missed: statement clobbers memory: _28 (_22);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_29);
PULSE.c:26:3: missed: statement clobbers memory: memset (_34, 0, _32);
PULSE.c:26:3: missed: statement clobbers memory: memset (_27, 0, _25);
PULSE.c:26:3: missed: statement clobbers memory: memset (_20, 0, _18);
PULSE.c:26:3: missed: statement clobbers memory: memset (_7, 0, _5);
PULSE.c:28:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:28:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:32:6: note: vectorized 1 loops in function.
PULSE.c:34:8: missed: statement clobbers memory: _1 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_2);
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _9 = rand ();
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8SI
PULSE.c:32:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:61:16: missed: couldn't vectorize loop
PULSE.c:61:16: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:64:17: missed: couldn't vectorize loop
PULSE.c:64:17: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:73:19: missed: couldn't vectorize loop
PULSE.c:73:19: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _64 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:53:22: missed: couldn't vectorize loop
PULSE.c:53:22: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:47:6: note: vectorized 1 loops in function.
PULSE.c:48:1: missed: statement clobbers memory: saved_stack.7_35 = __builtin_stack_save ();
PULSE.c:49:46: missed: statement clobbers memory: _1 = PULSE_GetLossFunctionPtr (loss_function_36(D));
PULSE.c:60:10: missed: statement clobbers memory: random.4_42 = __builtin_alloca_with_align (_4, 32);
PULSE.c:34:8: missed: statement clobbers memory: _56 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_57);
PULSE.c:39:29: missed: statement clobbers memory: _64 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _67 = rand ();
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_93, inputs_88, _92);
PULSE.c:8:2: missed: statement clobbers memory: _94 (layer_89);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_100, _99, _98);
PULSE.c:67:11: missed: statement clobbers memory: loss_51 = PULSE_GetLoss_38 (_17, _16, _12, _11);
PULSE.c:22:2: missed: statement clobbers memory: _81 (output_30);
PULSE.c:22:2: missed: statement clobbers memory: _103 (_82);
PULSE.c:22:2: missed: statement clobbers memory: _110 (_104);
PULSE.c:22:2: missed: statement clobbers memory: _117 (_111);
PULSE.c:22:2: missed: statement clobbers memory: _124 (_118);
PULSE.c:22:2: missed: statement clobbers memory: _131 (_125);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_132);
PULSE.c:26:3: missed: statement clobbers memory: memset (_137, 0, _135);
PULSE.c:26:3: missed: statement clobbers memory: memset (_130, 0, _128);
PULSE.c:26:3: missed: statement clobbers memory: memset (_123, 0, _121);
PULSE.c:26:3: missed: statement clobbers memory: memset (_116, 0, _114);
PULSE.c:26:3: missed: statement clobbers memory: memset (_109, 0, _107);
PULSE.c:26:3: missed: statement clobbers memory: memset (_87, 0, _85);
PULSE.c:75:6: missed: statement clobbers memory: _21 (current_183, args);
PULSE.c:80:4: missed: statement clobbers memory: printf ("Epoch: %d Item: %d Loss: %.10f\r", i_181, j_182, _22);
PULSE.c:47:6: missed: statement clobbers memory: __builtin_stack_restore (saved_stack.7_35);
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4DI
PULSE.c:47:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:89:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:89:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:94:8: missed: couldn't vectorize loop
PULSE.c:94:8: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:91:6: note: vectorized 0 loops in function.
PULSE.c:96:3: missed: statement clobbers memory: _1 (current_10);
PULSE.c:99:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:99:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Loss.c:15:19: optimized: loop vectorized using 32 byte vectors
Loss.c:15:19: optimized:  loop versioned for vectorization because of possible aliasing
Loss.c:15:19: optimized: loop vectorized using 16 byte vectors
Loss.c:12:23: note: vectorized 1 loops in function.
Loss.c:12:23: note: ***** Analysis failed with vector mode V8SF
Loss.c:12:23: note: ***** The result for vector mode V32QI would be the same
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V16QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V16QI
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V8QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V8QI
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V4QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V4QI
Loss.c:7:19: missed: couldn't vectorize loop
Loss.c:8:38: missed: not vectorized: unsupported use in stmt.
Loss.c:4:23: note: vectorized 0 loops in function.
Loss.c:9:13: note: ***** Analysis failed with vector mode V8SF
Loss.c:9:13: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Loss.c:23:2: note: ***** Analysis failed with vector mode VOID
Layer.c:7:34: missed: statement clobbers memory: _3 = aligned_alloc (64, _2);
Layer.c:8:35: missed: statement clobbers memory: _6 = aligned_alloc (64, _5);
Layer.c:9:34: missed: statement clobbers memory: _7 = aligned_alloc (64, _5);
Layer.c:14:19: missed: statement clobbers memory: _8 = PULSE_GetActivationFunctionPtr (activation_function_18(D));
Layer.c:19:9: note: ***** Analysis succeeded with vector mode V8SI
Layer.c:19:9: note: SLPing BB part
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x4c1c7f8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 0 MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 1 MEM <unsigned int> [(struct PULSE_Layer *)&<retval> + 4B] = optimization_type_17(D);
Layer.c:19:9: note: 	children 0x4c1c878
Layer.c:19:9: note: node (external) 0x4c1c878 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ type_16(D), optimization_type_17(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x4c1c8f8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 0 <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 1 <retval>.n_outputs = n_outputs_12(D);
Layer.c:19:9: note: 	children 0x4c1c978
Layer.c:19:9: note: node (external) 0x4c1c978 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x4c1ca78 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 0 <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 1 <retval>.outputs = _6;
Layer.c:19:9: note: 	children 0x4c1caf8
Layer.c:19:9: note: node (external) 0x4c1caf8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	stmt 0 _3 = aligned_alloc (64, _2);
Layer.c:19:9: note: 	stmt 1 _6 = aligned_alloc (64, _5);
Layer.c:19:9: note: 	children 0x4c1cb78 0x4c1cbf8
Layer.c:19:9: note: node (constant) 0x4c1cb78 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 64, 64 }
Layer.c:19:9: note: node 0x4c1cbf8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: patt_40 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 0 patt_40 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 1 patt_41 = n_outputs_12(D) w* 4;
Layer.c:19:9: note: 	children 0x4c1cc78 0x4c1ccf8
Layer.c:19:9: note: node (external) 0x4c1cc78 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: node (constant) 0x4c1ccf8 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ 4, 4 }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x4c1cdf8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: op template: <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 0 <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 1 <retval>.back = back_21(D);
Layer.c:19:9: note: 	stmt 2 <retval>.fix = fix_22(D);
Layer.c:19:9: note: 	stmt 3 <retval>.destroy = destroy_23(D);
Layer.c:19:9: note: 	children 0x4c1ce78
Layer.c:19:9: note: node (external) 0x4c1ce78 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: 	{ feed_20(D), back_21(D), fix_22(D), destroy_23(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 64
  Scalar cost: 64
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x4c1cf78 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 0 <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 1 <retval>.child = 0B;
Layer.c:19:9: note: 	children 0x4c1cff8
Layer.c:19:9: note: node (constant) 0x4c1cff8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ 0B, 0B }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Basic block will be vectorized using SLP
Layer.c:19:9: optimized: basic block part vectorized using 8 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x4c1c7f8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 0 MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 1 MEM <unsigned int> [(struct PULSE_Layer *)&<retval> + 4B] = optimization_type_17(D);
Layer.c:19:9: note: 	children 0x4c1c878
Layer.c:19:9: note: node (external) 0x4c1c878 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ type_16(D), optimization_type_17(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: vect_is_simple_use: operand optimization_type_17(D), type of def: external
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>]
Layer.c:19:9: note: created &MEM <unsigned int> [(struct PULSE_Layer *)&<retval>]
Layer.c:19:9: note: add new stmt: MEM <vector(2) unsigned int> [(struct PULSE_Layer *)&<retval>] = _42;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 8 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x4c1c8f8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 0 <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 1 <retval>.n_outputs = n_outputs_12(D);
Layer.c:19:9: note: 	children 0x4c1c978
Layer.c:19:9: note: node (external) 0x4c1c978 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: vect_is_simple_use: operand n_outputs_12(D), type of def: external
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: <retval>.n_inputs
Layer.c:19:9: note: created &<retval>.n_inputs
Layer.c:19:9: note: add new stmt: MEM <vector(2) unsigned int> [(unsigned int *)&<retval> + 96B] = _44;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 16 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x4c1ca78 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 0 <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 1 <retval>.outputs = _6;
Layer.c:19:9: note: 	children 0x4c1caf8
Layer.c:19:9: note: node (external) 0x4c1caf8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	stmt 0 _3 = aligned_alloc (64, _2);
Layer.c:19:9: note: 	stmt 1 _6 = aligned_alloc (64, _5);
Layer.c:19:9: note: 	children 0x4c1cb78 0x4c1cbf8
Layer.c:19:9: note: node (constant) 0x4c1cb78 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 64, 64 }
Layer.c:19:9: note: node 0x4c1cbf8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: patt_40 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 0 patt_40 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 1 patt_41 = n_outputs_12(D) w* 4;
Layer.c:19:9: note: 	children 0x4c1cc78 0x4c1ccf8
Layer.c:19:9: note: node (external) 0x4c1cc78 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: node (constant) 0x4c1ccf8 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ 4, 4 }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.inputs = _3;
Layer.c:19:9: note: vect_is_simple_use: operand aligned_alloc (64, _5), type of def: internal
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.inputs
Layer.c:19:9: note: created &<retval>.inputs
Layer.c:19:9: note: add new stmt: MEM <vector(2) long unsigned int> [(float * *)&<retval> + 8B] = _48;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 32 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x4c1cdf8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: op template: <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 0 <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 1 <retval>.back = back_21(D);
Layer.c:19:9: note: 	stmt 2 <retval>.fix = fix_22(D);
Layer.c:19:9: note: 	stmt 3 <retval>.destroy = destroy_23(D);
Layer.c:19:9: note: 	children 0x4c1ce78
Layer.c:19:9: note: node (external) 0x4c1ce78 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: 	{ feed_20(D), back_21(D), fix_22(D), destroy_23(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.feed = feed_20(D);
Layer.c:19:9: note: vect_is_simple_use: operand back_21(D), type of def: external
Layer.c:19:9: note: vect_is_simple_use: operand fix_22(D), type of def: external
Layer.c:19:9: note: vect_is_simple_use: operand destroy_23(D), type of def: external
Layer.c:19:9: note: conflicting alias set types.
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(4) long unsigned int  vectorizing a pointer ref: <retval>.feed
Layer.c:19:9: note: created &<retval>.feed
Layer.c:19:9: note: add new stmt: MEM <vector(4) long unsigned int> [(void *)&<retval> + 32B] = _54;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 16 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x4c1cf78 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 0 <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 1 <retval>.child = 0B;
Layer.c:19:9: note: 	children 0x4c1cff8
Layer.c:19:9: note: node (constant) 0x4c1cff8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ 0B, 0B }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.parent = 0B;
Layer.c:19:9: note: vect_is_simple_use: operand 0B, type of def: constant
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.parent
Layer.c:19:9: note: created &<retval>.parent
Layer.c:19:9: note: add new stmt: MEM <vector(2) long unsigned int> [(struct PULSE_Layer * *)&<retval> + 72B] = { 0, 0 };
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: note: ***** The result for vector mode V32QI would be the same
Layer.c:24:2: missed: statement clobbers memory: free (_1);
Layer.c:25:2: missed: statement clobbers memory: free (_2);
Layer.c:26:2: missed: statement clobbers memory: free (_3);
Layer.c:27:1: note: ***** Analysis failed with vector mode V4DI
Layer.c:27:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:10:27: missed: couldn't vectorize loop
Dense.c:10:27: missed: not vectorized: unsupported outerloop form.
Dense.c:13:20: missed: couldn't vectorize loop
Dense.c:14:21: missed: not vectorized: complicated access pattern.
Dense.c:7:13: note: vectorized 0 loops in function.
Dense.c:17:2: missed: statement clobbers memory: _30 (pretmp_91, _50, 0);
Dense.c:10:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:10:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:10:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:10:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:10:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:10:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:10:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:10:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:25:27: missed: couldn't vectorize loop
Dense.c:25:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:29:20: optimized: loop vectorized using 32 byte vectors
Dense.c:29:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:29:20: optimized: loop vectorized using 16 byte vectors
Dense.c:29:20: missed: couldn't vectorize loop
Dense.c:31:20: missed: not vectorized: no vectype for stmt: _21 = *_20;
 scalar_type: float
Dense.c:21:13: note: vectorized 1 loops in function.
Dense.c:24:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:25:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:25:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:25:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:25:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:25:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:25:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:25:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:25:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:42:28: missed: couldn't vectorize loop
Dense.c:42:28: missed: not vectorized: unsupported outerloop form.
Dense.c:46:21: optimized: loop vectorized using 32 byte vectors
Dense.c:46:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:46:21: optimized: loop vectorized using 16 byte vectors
Dense.c:38:13: note: vectorized 1 loops in function.
Dense.c:38:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:38:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:38:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:38:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:38:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:38:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:38:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:42:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:146:19: missed: couldn't vectorize loop
Dense.c:146:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:137:19: missed: couldn't vectorize loop
Dense.c:137:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:130:13: note: vectorized 0 loops in function.
Dense.c:154:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:154:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:99:28: missed: couldn't vectorize loop
Dense.c:99:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:102:21: missed: couldn't vectorize loop
Dense.c:102:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:116:28: missed: couldn't vectorize loop
Dense.c:116:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:119:21: missed: couldn't vectorize loop
Dense.c:119:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:85:19: missed: couldn't vectorize loop
Dense.c:85:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:79:13: note: vectorized 0 loops in function.
Dense.c:82:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:104:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:104:17: note: SLPing BB part
Dense.c:121:17: note: Costing subgraph: 
Dense.c:121:17: note: node 0x8816278 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:121:17: note: op template: _49 = (sizetype) j_137;
Dense.c:121:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:121:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:121:17: note: 	children 0x8816378
Dense.c:121:17: note: node (external) 0x8816378 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:121:17: note: 	{ j_137, wi_136 }
Dense.c:121:17: note: Cost model analysis: 
Dense.c:121:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:121:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:121:17: missed: not vectorized: vectorization is not profitable.
Dense.c:104:17: note: Costing subgraph: 
Dense.c:104:17: note: node 0x8816478 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:104:17: note: op template: _24 = (sizetype) j_134;
Dense.c:104:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:104:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:104:17: note: 	children 0x8816578
Dense.c:104:17: note: node (external) 0x8816578 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:104:17: note: 	{ j_134, wi_133 }
Dense.c:104:17: note: Cost model analysis: 
Dense.c:104:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:104:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:104:17: missed: not vectorized: vectorization is not profitable.
Dense.c:104:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:104:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:104:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:104:17: note: SLPing BB part
Dense.c:121:17: note: Costing subgraph: 
Dense.c:121:17: note: node 0x8816478 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:121:17: note: op template: _49 = (sizetype) j_137;
Dense.c:121:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:121:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:121:17: note: 	children 0x8816278
Dense.c:121:17: note: node (external) 0x8816278 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:121:17: note: 	{ j_137, wi_136 }
Dense.c:121:17: note: Cost model analysis: 
Dense.c:121:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:121:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:121:17: missed: not vectorized: vectorization is not profitable.
Dense.c:104:17: note: Costing subgraph: 
Dense.c:104:17: note: node 0x88165f8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:104:17: note: op template: _24 = (sizetype) j_134;
Dense.c:104:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:104:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:104:17: note: 	children 0x88164f8
Dense.c:104:17: note: node (external) 0x88164f8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:104:17: note: 	{ j_134, wi_133 }
Dense.c:104:17: note: Cost model analysis: 
Dense.c:104:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:104:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:104:17: missed: not vectorized: vectorization is not profitable.
Dense.c:104:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:99:55: note: ***** Analysis failed with vector mode V8QI
Dense.c:99:55: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:99:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:59:27: missed: couldn't vectorize loop
Dense.c:59:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:62:20: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:905:10: missed: not vectorized: no vectype for stmt: _41 = MEM[(__m256_u * {ref-all})_6];
 scalar_type: __m256_u
Dense.c:62:20: note: ***** Analysis failed with vector mode VOID
Dense.c:55:13: note: vectorized 0 loops in function.
Dense.c:55:13: missed: splitting region at dont-vectorize loop 3 entry at bb18
Dense.c:64:14: note: ***** Analysis failed with vector mode V4DI
Dense.c:64:14: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:64:14: missed: splitting region at dominance boundary bb8
Dense.c:64:14: note: ***** Analysis failed with vector mode VOID
Dense.c:64:14: missed: splitting region at loop 1 exit at bb16
Dense.c:59:27: note: ***** Analysis failed with vector mode V8SF
Dense.c:59:27: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Dense.c:59:27: missed: splitting region at dominance boundary bb10
Dense.c:59:27: note: ***** Analysis failed with vector mode VOID
Dense.c:75:2: missed: statement clobbers memory: _27 (pretmp_153, _61, 0);
Dense.c:76:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:76:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:161:2: missed: statement clobbers memory: free (_1);
Dense.c:162:2: missed: statement clobbers memory: free (_2);
Dense.c:163:2: missed: statement clobbers memory: free (_3);
Dense.c:164:2: missed: statement clobbers memory: free (_4);
Dense.c:165:2: missed: statement clobbers memory: free (dense_7);
Dense.c:166:2: missed: statement clobbers memory: PULSE_DestroyLayer (this_6(D));
Dense.c:167:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:167:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Include/PulseAlloc.h:14:11: missed: statement clobbers memory: _18 = aligned_alloc (64, _8);
Include/PulseAlloc.h:11:28: missed: statement clobbers memory: _20 = aligned_alloc (64, _2);
Include/PulseAlloc.h:19:2: missed: statement clobbers memory: exit (1);
Include/PulseAlloc.h:19:2: note: ***** Analysis failed with vector mode VOID
Include/PulseAlloc.h:33:11: missed: statement clobbers memory: _21 = aligned_alloc (64, _10);
Include/PulseAlloc.h:29:28: missed: statement clobbers memory: _23 = aligned_alloc (64, _3);
Include/PulseAlloc.h:38:2: missed: statement clobbers memory: exit (1);
Include/PulseAlloc.h:38:2: note: ***** Analysis failed with vector mode VOID
Dense.c:181:19: missed: couldn't vectorize loop
Dense.c:181:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:171:13: note: vectorized 0 loops in function.
Dense.c:173:47: missed: statement clobbers memory: dense_30 = malloc (40);
Include/PulseAlloc.h:33:11: missed: statement clobbers memory: _187 = aligned_alloc (64, _185);
Include/PulseAlloc.h:33:11: missed: statement clobbers memory: _177 = aligned_alloc (64, _175);
Include/PulseAlloc.h:33:11: missed: statement clobbers memory: _108 = aligned_alloc (64, prephitmp_182);
Include/PulseAlloc.h:14:11: missed: statement clobbers memory: _140 = aligned_alloc (64, _148);
Include/PulseAlloc.h:14:11: missed: statement clobbers memory: _109 = aligned_alloc (64, _148);
Include/PulseAlloc.h:14:11: missed: statement clobbers memory: _167 = aligned_alloc (64, _165);
Include/PulseAlloc.h:14:11: missed: statement clobbers memory: _157 = aligned_alloc (64, _165);
Include/PulseAlloc.h:14:11: missed: statement clobbers memory: _67 = aligned_alloc (64, prephitmp_171);
Include/PulseAlloc.h:29:28: missed: statement clobbers memory: _113 = aligned_alloc (64, _112);
Include/PulseAlloc.h:29:28: missed: statement clobbers memory: _98 = aligned_alloc (64, _112);
Include/PulseAlloc.h:11:28: missed: statement clobbers memory: _84 = aligned_alloc (64, _83);
Include/PulseAlloc.h:11:28: missed: statement clobbers memory: _71 = aligned_alloc (64, _83);
Include/PulseAlloc.h:11:28: missed: statement clobbers memory: _58 = aligned_alloc (64, _83);
Dense.c:182:39: missed: statement clobbers memory: _6 = rand ();
Dense.c:182:73: missed: statement clobbers memory: _45 = sqrt (_13);
Dense.c:188:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (_161, _162, 1, activation_function_46(D), _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:192:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (_161, _162, 1, activation_function_46(D), _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:206:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Include/PulseAlloc.h:38:2: missed: statement clobbers memory: exit (1);
Include/PulseAlloc.h:38:2: note: ***** Analysis failed with vector mode V4DI
Include/PulseAlloc.h:38:2: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Activations.c:17:19: optimized: loop vectorized using 32 byte vectors
Activations.c:17:19: optimized: loop vectorized using 16 byte vectors
Activations.c:17:19: optimized: loop vectorized using 32 byte vectors
Activations.c:17:19: optimized: loop vectorized using 16 byte vectors
Activations.c:14:13: note: vectorized 2 loops in function.
Activations.c:14:13: note: ***** Analysis failed with vector mode V8SF
Activations.c:14:13: note: ***** The result for vector mode V32QI would be the same
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V16QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V16QI
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V8QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V8QI
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V4QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V4QI
Activations.c:28:19: missed: couldn't vectorize loop
Activations.c:28:19: missed: not vectorized: unsupported control flow in loop.
Activations.c:28:19: optimized: loop vectorized using 32 byte vectors
Activations.c:28:19: optimized: loop vectorized using 16 byte vectors
Activations.c:25:13: note: vectorized 1 loops in function.
Activations.c:25:13: note: ***** Analysis failed with vector mode V8SF
Activations.c:25:13: note: ***** The result for vector mode V32QI would be the same
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V16QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V16QI
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V8QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V8QI
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V4QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V4QI
Activations.c:38:1: note: ***** Analysis failed with vector mode VOID
Activations.c:5:19: missed: couldn't vectorize loop
Activations.c:9:21: missed: statement clobbers memory: _36 = expf (_18);
Activations.c:5:19: missed: couldn't vectorize loop
Activations.c:9:21: missed: statement clobbers memory: _12 = expf (_11);
Activations.c:3:13: note: vectorized 0 loops in function.
Activations.c:9:21: missed: statement clobbers memory: _12 = expf (_11);
Activations.c:9:21: missed: statement clobbers memory: _36 = expf (_18);
Activations.c:11:1: note: ***** Analysis failed with vector mode V8SF
Activations.c:11:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Activations.c:44:2: note: ***** Analysis failed with vector mode VOID
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:4:18: note: vectorized 0 loops in function.
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_4, inputs_15, _3);
PULSE.c:8:2: missed: statement clobbers memory: _5 (layer_17);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_12, pretmp_26, _9);
PULSE.c:13:28: note: ***** Analysis failed with vector mode V8SI
PULSE.c:13:28: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:22:2: missed: statement clobbers memory: _1 (layer_10(D));
PULSE.c:22:2: missed: statement clobbers memory: _14 (_2);
PULSE.c:22:2: missed: statement clobbers memory: _21 (_15);
PULSE.c:22:2: missed: statement clobbers memory: _28 (_22);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_29);
PULSE.c:26:3: missed: statement clobbers memory: memset (_34, 0, _32);
PULSE.c:26:3: missed: statement clobbers memory: memset (_27, 0, _25);
PULSE.c:26:3: missed: statement clobbers memory: memset (_20, 0, _18);
PULSE.c:26:3: missed: statement clobbers memory: memset (_7, 0, _5);
PULSE.c:28:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:28:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:32:6: note: vectorized 1 loops in function.
PULSE.c:34:8: missed: statement clobbers memory: _1 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_2);
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _9 = rand ();
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8SI
PULSE.c:32:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:61:16: missed: couldn't vectorize loop
PULSE.c:61:16: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:64:17: missed: couldn't vectorize loop
PULSE.c:64:17: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:73:19: missed: couldn't vectorize loop
PULSE.c:73:19: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _64 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:53:22: missed: couldn't vectorize loop
PULSE.c:53:22: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:47:6: note: vectorized 1 loops in function.
PULSE.c:48:1: missed: statement clobbers memory: saved_stack.7_35 = __builtin_stack_save ();
PULSE.c:49:46: missed: statement clobbers memory: _1 = PULSE_GetLossFunctionPtr (loss_function_36(D));
PULSE.c:60:10: missed: statement clobbers memory: random.4_42 = __builtin_alloca_with_align (_4, 32);
PULSE.c:34:8: missed: statement clobbers memory: _56 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_57);
PULSE.c:39:29: missed: statement clobbers memory: _64 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _67 = rand ();
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_93, inputs_88, _92);
PULSE.c:8:2: missed: statement clobbers memory: _94 (layer_89);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_100, _99, _98);
PULSE.c:67:11: missed: statement clobbers memory: loss_51 = PULSE_GetLoss_38 (_17, _16, _12, _11);
PULSE.c:22:2: missed: statement clobbers memory: _81 (output_30);
PULSE.c:22:2: missed: statement clobbers memory: _103 (_82);
PULSE.c:22:2: missed: statement clobbers memory: _110 (_104);
PULSE.c:22:2: missed: statement clobbers memory: _117 (_111);
PULSE.c:22:2: missed: statement clobbers memory: _124 (_118);
PULSE.c:22:2: missed: statement clobbers memory: _131 (_125);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_132);
PULSE.c:26:3: missed: statement clobbers memory: memset (_137, 0, _135);
PULSE.c:26:3: missed: statement clobbers memory: memset (_130, 0, _128);
PULSE.c:26:3: missed: statement clobbers memory: memset (_123, 0, _121);
PULSE.c:26:3: missed: statement clobbers memory: memset (_116, 0, _114);
PULSE.c:26:3: missed: statement clobbers memory: memset (_109, 0, _107);
PULSE.c:26:3: missed: statement clobbers memory: memset (_87, 0, _85);
PULSE.c:75:6: missed: statement clobbers memory: _21 (current_183, args);
PULSE.c:80:4: missed: statement clobbers memory: printf ("Epoch: %d Item: %d Loss: %.10f\r", i_181, j_182, _22);
PULSE.c:47:6: missed: statement clobbers memory: __builtin_stack_restore (saved_stack.7_35);
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4DI
PULSE.c:47:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:89:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:89:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:94:8: missed: couldn't vectorize loop
PULSE.c:94:8: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:91:6: note: vectorized 0 loops in function.
PULSE.c:96:3: missed: statement clobbers memory: _1 (current_10);
PULSE.c:99:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:99:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Loss.c:15:19: optimized: loop vectorized using 32 byte vectors
Loss.c:15:19: optimized:  loop versioned for vectorization because of possible aliasing
Loss.c:15:19: optimized: loop vectorized using 16 byte vectors
Loss.c:12:23: note: vectorized 1 loops in function.
Loss.c:12:23: note: ***** Analysis failed with vector mode V8SF
Loss.c:12:23: note: ***** The result for vector mode V32QI would be the same
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V16QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V16QI
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V8QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V8QI
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V4QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V4QI
Loss.c:7:19: missed: couldn't vectorize loop
Loss.c:8:38: missed: not vectorized: unsupported use in stmt.
Loss.c:4:23: note: vectorized 0 loops in function.
Loss.c:9:13: note: ***** Analysis failed with vector mode V8SF
Loss.c:9:13: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Loss.c:23:2: note: ***** Analysis failed with vector mode VOID
Dense.c:10:27: missed: couldn't vectorize loop
Dense.c:10:27: missed: not vectorized: unsupported outerloop form.
Dense.c:13:20: missed: couldn't vectorize loop
Dense.c:14:21: missed: not vectorized: complicated access pattern.
Dense.c:7:13: note: vectorized 0 loops in function.
Dense.c:17:2: missed: statement clobbers memory: _30 (pretmp_91, _50, 0);
Dense.c:10:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:10:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:10:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:10:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:10:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:10:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:10:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:10:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:25:27: missed: couldn't vectorize loop
Dense.c:25:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:29:20: optimized: loop vectorized using 32 byte vectors
Dense.c:29:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:29:20: optimized: loop vectorized using 16 byte vectors
Dense.c:29:20: missed: couldn't vectorize loop
Dense.c:31:20: missed: not vectorized: no vectype for stmt: _21 = *_20;
 scalar_type: float
Dense.c:21:13: note: vectorized 1 loops in function.
Dense.c:24:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:25:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:25:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:25:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:25:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:25:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:25:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:25:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:25:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:42:28: missed: couldn't vectorize loop
Dense.c:42:28: missed: not vectorized: unsupported outerloop form.
Dense.c:46:21: optimized: loop vectorized using 32 byte vectors
Dense.c:46:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:46:21: optimized: loop vectorized using 16 byte vectors
Dense.c:38:13: note: vectorized 1 loops in function.
Dense.c:38:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:38:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:38:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:38:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:38:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:38:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:38:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:42:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:146:19: missed: couldn't vectorize loop
Dense.c:146:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:137:19: missed: couldn't vectorize loop
Dense.c:137:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:130:13: note: vectorized 0 loops in function.
Dense.c:154:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:154:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:99:28: missed: couldn't vectorize loop
Dense.c:99:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:102:21: missed: couldn't vectorize loop
Dense.c:102:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:116:28: missed: couldn't vectorize loop
Dense.c:116:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:119:21: missed: couldn't vectorize loop
Dense.c:119:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:85:19: missed: couldn't vectorize loop
Dense.c:85:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:79:13: note: vectorized 0 loops in function.
Dense.c:82:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:104:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:104:17: note: SLPing BB part
Dense.c:121:17: note: Costing subgraph: 
Dense.c:121:17: note: node 0x840e018 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:121:17: note: op template: _49 = (sizetype) j_137;
Dense.c:121:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:121:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:121:17: note: 	children 0x840e118
Dense.c:121:17: note: node (external) 0x840e118 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:121:17: note: 	{ j_137, wi_136 }
Dense.c:121:17: note: Cost model analysis: 
Dense.c:121:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:121:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:121:17: missed: not vectorized: vectorization is not profitable.
Dense.c:104:17: note: Costing subgraph: 
Dense.c:104:17: note: node 0x840e218 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:104:17: note: op template: _24 = (sizetype) j_134;
Dense.c:104:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:104:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:104:17: note: 	children 0x840e318
Dense.c:104:17: note: node (external) 0x840e318 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:104:17: note: 	{ j_134, wi_133 }
Dense.c:104:17: note: Cost model analysis: 
Dense.c:104:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:104:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:104:17: missed: not vectorized: vectorization is not profitable.
Dense.c:104:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:104:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:104:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:104:17: note: SLPing BB part
Dense.c:121:17: note: Costing subgraph: 
Dense.c:121:17: note: node 0x840e218 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:121:17: note: op template: _49 = (sizetype) j_137;
Dense.c:121:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:121:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:121:17: note: 	children 0x840e018
Dense.c:121:17: note: node (external) 0x840e018 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:121:17: note: 	{ j_137, wi_136 }
Dense.c:121:17: note: Cost model analysis: 
Dense.c:121:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:121:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:121:17: missed: not vectorized: vectorization is not profitable.
Dense.c:104:17: note: Costing subgraph: 
Dense.c:104:17: note: node 0x840e398 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:104:17: note: op template: _24 = (sizetype) j_134;
Dense.c:104:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:104:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:104:17: note: 	children 0x840e298
Dense.c:104:17: note: node (external) 0x840e298 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:104:17: note: 	{ j_134, wi_133 }
Dense.c:104:17: note: Cost model analysis: 
Dense.c:104:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:104:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:104:17: missed: not vectorized: vectorization is not profitable.
Dense.c:104:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:99:55: note: ***** Analysis failed with vector mode V8QI
Dense.c:99:55: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:99:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:59:27: missed: couldn't vectorize loop
Dense.c:59:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:62:20: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:905:10: missed: not vectorized: no vectype for stmt: _41 = MEM[(__m256_u * {ref-all})_6];
 scalar_type: __m256_u
Dense.c:62:20: note: ***** Analysis failed with vector mode VOID
Dense.c:55:13: note: vectorized 0 loops in function.
Dense.c:55:13: missed: splitting region at dont-vectorize loop 3 entry at bb18
Dense.c:64:14: note: ***** Analysis failed with vector mode V4DI
Dense.c:64:14: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:64:14: missed: splitting region at dominance boundary bb8
Dense.c:64:14: note: ***** Analysis failed with vector mode VOID
Dense.c:64:14: missed: splitting region at loop 1 exit at bb16
Dense.c:59:27: note: ***** Analysis failed with vector mode V8SF
Dense.c:59:27: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Dense.c:59:27: missed: splitting region at dominance boundary bb10
Dense.c:59:27: note: ***** Analysis failed with vector mode VOID
Dense.c:75:2: missed: statement clobbers memory: _27 (pretmp_153, _61, 0);
Dense.c:76:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:76:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Include/PulseAlloc.h:42:37: missed: statement clobbers memory: free (_1);
Include/PulseAlloc.h:42:37: missed: statement clobbers memory: free (_2);
Include/PulseAlloc.h:42:37: missed: statement clobbers memory: free (_3);
Include/PulseAlloc.h:42:37: missed: statement clobbers memory: free (_4);
Include/PulseAlloc.h:42:37: missed: statement clobbers memory: free (dense_7);
Dense.c:166:2: missed: statement clobbers memory: PULSE_DestroyLayer (this_6(D));
Dense.c:167:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:167:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Include/PulseAlloc.h:14:11: missed: statement clobbers memory: _18 = aligned_alloc (64, _8);
Include/PulseAlloc.h:11:28: missed: statement clobbers memory: _20 = aligned_alloc (64, _2);
Include/PulseAlloc.h:19:2: missed: statement clobbers memory: exit (1);
Include/PulseAlloc.h:19:2: note: ***** Analysis failed with vector mode VOID
Include/PulseAlloc.h:33:11: missed: statement clobbers memory: _21 = aligned_alloc (64, _10);
Include/PulseAlloc.h:29:28: missed: statement clobbers memory: _23 = aligned_alloc (64, _3);
Include/PulseAlloc.h:38:2: missed: statement clobbers memory: exit (1);
Include/PulseAlloc.h:38:2: note: ***** Analysis failed with vector mode VOID
Dense.c:181:19: missed: couldn't vectorize loop
Dense.c:181:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:171:13: note: vectorized 0 loops in function.
Dense.c:173:47: missed: statement clobbers memory: dense_30 = malloc (40);
Include/PulseAlloc.h:33:11: missed: statement clobbers memory: _187 = aligned_alloc (64, _185);
Include/PulseAlloc.h:33:11: missed: statement clobbers memory: _177 = aligned_alloc (64, _175);
Include/PulseAlloc.h:33:11: missed: statement clobbers memory: _108 = aligned_alloc (64, prephitmp_182);
Include/PulseAlloc.h:14:11: missed: statement clobbers memory: _140 = aligned_alloc (64, _148);
Include/PulseAlloc.h:14:11: missed: statement clobbers memory: _109 = aligned_alloc (64, _148);
Include/PulseAlloc.h:14:11: missed: statement clobbers memory: _167 = aligned_alloc (64, _165);
Include/PulseAlloc.h:14:11: missed: statement clobbers memory: _157 = aligned_alloc (64, _165);
Include/PulseAlloc.h:14:11: missed: statement clobbers memory: _67 = aligned_alloc (64, prephitmp_171);
Include/PulseAlloc.h:29:28: missed: statement clobbers memory: _113 = aligned_alloc (64, _112);
Include/PulseAlloc.h:29:28: missed: statement clobbers memory: _98 = aligned_alloc (64, _112);
Include/PulseAlloc.h:11:28: missed: statement clobbers memory: _84 = aligned_alloc (64, _83);
Include/PulseAlloc.h:11:28: missed: statement clobbers memory: _71 = aligned_alloc (64, _83);
Include/PulseAlloc.h:11:28: missed: statement clobbers memory: _58 = aligned_alloc (64, _83);
Dense.c:182:39: missed: statement clobbers memory: _6 = rand ();
Dense.c:182:73: missed: statement clobbers memory: _45 = sqrt (_13);
Dense.c:188:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (_161, _162, 1, activation_function_46(D), _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:192:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (_161, _162, 1, activation_function_46(D), _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:206:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Include/PulseAlloc.h:38:2: missed: statement clobbers memory: exit (1);
Include/PulseAlloc.h:38:2: note: ***** Analysis failed with vector mode V4DI
Include/PulseAlloc.h:38:2: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Layer.c:7:34: missed: statement clobbers memory: _3 = aligned_alloc (64, _2);
Layer.c:8:35: missed: statement clobbers memory: _6 = aligned_alloc (64, _5);
Layer.c:9:34: missed: statement clobbers memory: _7 = aligned_alloc (64, _5);
Layer.c:14:19: missed: statement clobbers memory: _8 = PULSE_GetActivationFunctionPtr (activation_function_18(D));
Layer.c:19:9: note: ***** Analysis succeeded with vector mode V8SI
Layer.c:19:9: note: SLPing BB part
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x33b27f8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 0 MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 1 MEM <unsigned int> [(struct PULSE_Layer *)&<retval> + 4B] = optimization_type_17(D);
Layer.c:19:9: note: 	children 0x33b2878
Layer.c:19:9: note: node (external) 0x33b2878 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ type_16(D), optimization_type_17(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x33b28f8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 0 <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 1 <retval>.n_outputs = n_outputs_12(D);
Layer.c:19:9: note: 	children 0x33b2978
Layer.c:19:9: note: node (external) 0x33b2978 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x33b2a78 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 0 <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 1 <retval>.outputs = _6;
Layer.c:19:9: note: 	children 0x33b2af8
Layer.c:19:9: note: node (external) 0x33b2af8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	stmt 0 _3 = aligned_alloc (64, _2);
Layer.c:19:9: note: 	stmt 1 _6 = aligned_alloc (64, _5);
Layer.c:19:9: note: 	children 0x33b2b78 0x33b2bf8
Layer.c:19:9: note: node (constant) 0x33b2b78 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 64, 64 }
Layer.c:19:9: note: node 0x33b2bf8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: patt_40 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 0 patt_40 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 1 patt_41 = n_outputs_12(D) w* 4;
Layer.c:19:9: note: 	children 0x33b2c78 0x33b2cf8
Layer.c:19:9: note: node (external) 0x33b2c78 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: node (constant) 0x33b2cf8 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ 4, 4 }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x33b2df8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: op template: <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 0 <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 1 <retval>.back = back_21(D);
Layer.c:19:9: note: 	stmt 2 <retval>.fix = fix_22(D);
Layer.c:19:9: note: 	stmt 3 <retval>.destroy = destroy_23(D);
Layer.c:19:9: note: 	children 0x33b2e78
Layer.c:19:9: note: node (external) 0x33b2e78 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: 	{ feed_20(D), back_21(D), fix_22(D), destroy_23(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 64
  Scalar cost: 64
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x33b2f78 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 0 <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 1 <retval>.child = 0B;
Layer.c:19:9: note: 	children 0x33b2ff8
Layer.c:19:9: note: node (constant) 0x33b2ff8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ 0B, 0B }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Basic block will be vectorized using SLP
Layer.c:19:9: optimized: basic block part vectorized using 8 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x33b27f8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 0 MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: 	stmt 1 MEM <unsigned int> [(struct PULSE_Layer *)&<retval> + 4B] = optimization_type_17(D);
Layer.c:19:9: note: 	children 0x33b2878
Layer.c:19:9: note: node (external) 0x33b2878 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ type_16(D), optimization_type_17(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_16(D);
Layer.c:19:9: note: vect_is_simple_use: operand optimization_type_17(D), type of def: external
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>]
Layer.c:19:9: note: created &MEM <unsigned int> [(struct PULSE_Layer *)&<retval>]
Layer.c:19:9: note: add new stmt: MEM <vector(2) unsigned int> [(struct PULSE_Layer *)&<retval>] = _42;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 8 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x33b28f8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 0 <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: 	stmt 1 <retval>.n_outputs = n_outputs_12(D);
Layer.c:19:9: note: 	children 0x33b2978
Layer.c:19:9: note: node (external) 0x33b2978 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.n_inputs = n_inputs_11(D);
Layer.c:19:9: note: vect_is_simple_use: operand n_outputs_12(D), type of def: external
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: <retval>.n_inputs
Layer.c:19:9: note: created &<retval>.n_inputs
Layer.c:19:9: note: add new stmt: MEM <vector(2) unsigned int> [(unsigned int *)&<retval> + 96B] = _44;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 16 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x33b2a78 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 0 <retval>.inputs = _3;
Layer.c:19:9: note: 	stmt 1 <retval>.outputs = _6;
Layer.c:19:9: note: 	children 0x33b2af8
Layer.c:19:9: note: node (external) 0x33b2af8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	stmt 0 _3 = aligned_alloc (64, _2);
Layer.c:19:9: note: 	stmt 1 _6 = aligned_alloc (64, _5);
Layer.c:19:9: note: 	children 0x33b2b78 0x33b2bf8
Layer.c:19:9: note: node (constant) 0x33b2b78 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 64, 64 }
Layer.c:19:9: note: node 0x33b2bf8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: patt_40 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 0 patt_40 = n_inputs_11(D) w* 4;
Layer.c:19:9: note: 	stmt 1 patt_41 = n_outputs_12(D) w* 4;
Layer.c:19:9: note: 	children 0x33b2c78 0x33b2cf8
Layer.c:19:9: note: node (external) 0x33b2c78 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_11(D), n_outputs_12(D) }
Layer.c:19:9: note: node (constant) 0x33b2cf8 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ 4, 4 }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.inputs = _3;
Layer.c:19:9: note: vect_is_simple_use: operand aligned_alloc (64, _5), type of def: internal
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.inputs
Layer.c:19:9: note: created &<retval>.inputs
Layer.c:19:9: note: add new stmt: MEM <vector(2) long unsigned int> [(float * *)&<retval> + 8B] = _48;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 32 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x33b2df8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: op template: <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 0 <retval>.feed = feed_20(D);
Layer.c:19:9: note: 	stmt 1 <retval>.back = back_21(D);
Layer.c:19:9: note: 	stmt 2 <retval>.fix = fix_22(D);
Layer.c:19:9: note: 	stmt 3 <retval>.destroy = destroy_23(D);
Layer.c:19:9: note: 	children 0x33b2e78
Layer.c:19:9: note: node (external) 0x33b2e78 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: 	{ feed_20(D), back_21(D), fix_22(D), destroy_23(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.feed = feed_20(D);
Layer.c:19:9: note: vect_is_simple_use: operand back_21(D), type of def: external
Layer.c:19:9: note: vect_is_simple_use: operand fix_22(D), type of def: external
Layer.c:19:9: note: vect_is_simple_use: operand destroy_23(D), type of def: external
Layer.c:19:9: note: conflicting alias set types.
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(4) long unsigned int  vectorizing a pointer ref: <retval>.feed
Layer.c:19:9: note: created &<retval>.feed
Layer.c:19:9: note: add new stmt: MEM <vector(4) long unsigned int> [(void *)&<retval> + 32B] = _54;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 16 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x33b2f78 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 0 <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 1 <retval>.child = 0B;
Layer.c:19:9: note: 	children 0x33b2ff8
Layer.c:19:9: note: node (constant) 0x33b2ff8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ 0B, 0B }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.parent = 0B;
Layer.c:19:9: note: vect_is_simple_use: operand 0B, type of def: constant
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.parent
Layer.c:19:9: note: created &<retval>.parent
Layer.c:19:9: note: add new stmt: MEM <vector(2) long unsigned int> [(struct PULSE_Layer * *)&<retval> + 72B] = { 0, 0 };
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: note: ***** The result for vector mode V32QI would be the same
Layer.c:24:2: missed: statement clobbers memory: free (_1);
Layer.c:25:2: missed: statement clobbers memory: free (_2);
Layer.c:26:2: missed: statement clobbers memory: free (_3);
Layer.c:27:1: note: ***** Analysis failed with vector mode V4DI
Layer.c:27:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:10:27: missed: couldn't vectorize loop
Dense.c:10:27: missed: not vectorized: unsupported outerloop form.
Dense.c:13:20: missed: couldn't vectorize loop
Dense.c:14:21: missed: not vectorized: complicated access pattern.
Dense.c:7:13: note: vectorized 0 loops in function.
Dense.c:17:2: missed: statement clobbers memory: _30 (pretmp_91, _50, 0);
Dense.c:10:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:10:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:10:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:10:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:10:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:10:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:10:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:10:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:25:27: missed: couldn't vectorize loop
Dense.c:25:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:29:20: optimized: loop vectorized using 32 byte vectors
Dense.c:29:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:29:20: optimized: loop vectorized using 16 byte vectors
Dense.c:29:20: missed: couldn't vectorize loop
Dense.c:31:20: missed: not vectorized: no vectype for stmt: _21 = *_20;
 scalar_type: float
Dense.c:21:13: note: vectorized 1 loops in function.
Dense.c:24:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:25:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:25:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:25:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:25:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:25:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:25:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:25:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:25:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:42:28: missed: couldn't vectorize loop
Dense.c:42:28: missed: not vectorized: unsupported outerloop form.
Dense.c:46:21: optimized: loop vectorized using 32 byte vectors
Dense.c:46:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:46:21: optimized: loop vectorized using 16 byte vectors
Dense.c:38:13: note: vectorized 1 loops in function.
Dense.c:38:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:38:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:38:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:38:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:38:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:38:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:38:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:42:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:146:19: missed: couldn't vectorize loop
Dense.c:146:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:137:19: missed: couldn't vectorize loop
Dense.c:137:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:130:13: note: vectorized 0 loops in function.
Dense.c:154:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:154:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:99:28: missed: couldn't vectorize loop
Dense.c:99:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:102:21: missed: couldn't vectorize loop
Dense.c:102:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:116:28: missed: couldn't vectorize loop
Dense.c:116:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:119:21: missed: couldn't vectorize loop
Dense.c:119:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:85:19: missed: couldn't vectorize loop
Dense.c:85:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:79:13: note: vectorized 0 loops in function.
Dense.c:82:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:104:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:104:17: note: SLPing BB part
Dense.c:121:17: note: Costing subgraph: 
Dense.c:121:17: note: node 0x81a11a8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:121:17: note: op template: _49 = (sizetype) j_137;
Dense.c:121:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:121:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:121:17: note: 	children 0x81a12a8
Dense.c:121:17: note: node (external) 0x81a12a8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:121:17: note: 	{ j_137, wi_136 }
Dense.c:121:17: note: Cost model analysis: 
Dense.c:121:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:121:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:121:17: missed: not vectorized: vectorization is not profitable.
Dense.c:104:17: note: Costing subgraph: 
Dense.c:104:17: note: node 0x81a13a8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:104:17: note: op template: _24 = (sizetype) j_134;
Dense.c:104:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:104:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:104:17: note: 	children 0x81a14a8
Dense.c:104:17: note: node (external) 0x81a14a8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:104:17: note: 	{ j_134, wi_133 }
Dense.c:104:17: note: Cost model analysis: 
Dense.c:104:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:104:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:104:17: missed: not vectorized: vectorization is not profitable.
Dense.c:104:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:104:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:104:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:104:17: note: SLPing BB part
Dense.c:121:17: note: Costing subgraph: 
Dense.c:121:17: note: node 0x81a13a8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:121:17: note: op template: _49 = (sizetype) j_137;
Dense.c:121:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:121:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:121:17: note: 	children 0x81a11a8
Dense.c:121:17: note: node (external) 0x81a11a8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:121:17: note: 	{ j_137, wi_136 }
Dense.c:121:17: note: Cost model analysis: 
Dense.c:121:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:121:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:121:17: missed: not vectorized: vectorization is not profitable.
Dense.c:104:17: note: Costing subgraph: 
Dense.c:104:17: note: node 0x81a1528 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:104:17: note: op template: _24 = (sizetype) j_134;
Dense.c:104:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:104:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:104:17: note: 	children 0x81a1428
Dense.c:104:17: note: node (external) 0x81a1428 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:104:17: note: 	{ j_134, wi_133 }
Dense.c:104:17: note: Cost model analysis: 
Dense.c:104:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:104:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:104:17: missed: not vectorized: vectorization is not profitable.
Dense.c:104:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:99:55: note: ***** Analysis failed with vector mode V8QI
Dense.c:99:55: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:99:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:59:27: missed: couldn't vectorize loop
Dense.c:59:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:62:20: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:905:10: missed: not vectorized: no vectype for stmt: _41 = MEM[(__m256_u * {ref-all})_6];
 scalar_type: __m256_u
Dense.c:62:20: note: ***** Analysis failed with vector mode VOID
Dense.c:55:13: note: vectorized 0 loops in function.
Dense.c:55:13: missed: splitting region at dont-vectorize loop 3 entry at bb18
Dense.c:64:14: note: ***** Analysis failed with vector mode V4DI
Dense.c:64:14: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:64:14: missed: splitting region at dominance boundary bb8
Dense.c:64:14: note: ***** Analysis failed with vector mode VOID
Dense.c:64:14: missed: splitting region at loop 1 exit at bb16
Dense.c:59:27: note: ***** Analysis failed with vector mode V8SF
Dense.c:59:27: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Dense.c:59:27: missed: splitting region at dominance boundary bb10
Dense.c:59:27: note: ***** Analysis failed with vector mode VOID
Dense.c:75:2: missed: statement clobbers memory: _27 (pretmp_153, _61, 0);
Dense.c:76:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:76:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Include/PulseAlloc.h:42:37: missed: statement clobbers memory: free (_1);
Include/PulseAlloc.h:42:37: missed: statement clobbers memory: free (_2);
Include/PulseAlloc.h:42:37: missed: statement clobbers memory: free (_3);
Include/PulseAlloc.h:42:37: missed: statement clobbers memory: free (_4);
Include/PulseAlloc.h:42:37: missed: statement clobbers memory: free (dense_7);
Dense.c:166:2: missed: statement clobbers memory: PULSE_DestroyLayer (this_6(D));
Dense.c:167:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:167:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Include/PulseAlloc.h:14:11: missed: statement clobbers memory: _18 = aligned_alloc (64, _8);
Include/PulseAlloc.h:11:28: missed: statement clobbers memory: _20 = aligned_alloc (64, _2);
Include/PulseAlloc.h:19:2: missed: statement clobbers memory: exit (1);
Include/PulseAlloc.h:19:2: note: ***** Analysis failed with vector mode VOID
Include/PulseAlloc.h:33:11: missed: statement clobbers memory: _21 = aligned_alloc (64, _10);
Include/PulseAlloc.h:29:28: missed: statement clobbers memory: _23 = aligned_alloc (64, _3);
Include/PulseAlloc.h:38:2: missed: statement clobbers memory: exit (1);
Include/PulseAlloc.h:38:2: note: ***** Analysis failed with vector mode VOID
Dense.c:181:19: missed: couldn't vectorize loop
Dense.c:181:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:171:13: note: vectorized 0 loops in function.
Dense.c:173:47: missed: statement clobbers memory: dense_30 = malloc (40);
Include/PulseAlloc.h:33:11: missed: statement clobbers memory: _187 = aligned_alloc (64, _185);
Include/PulseAlloc.h:33:11: missed: statement clobbers memory: _177 = aligned_alloc (64, _175);
Include/PulseAlloc.h:33:11: missed: statement clobbers memory: _108 = aligned_alloc (64, prephitmp_182);
Include/PulseAlloc.h:14:11: missed: statement clobbers memory: _140 = aligned_alloc (64, _148);
Include/PulseAlloc.h:14:11: missed: statement clobbers memory: _109 = aligned_alloc (64, _148);
Include/PulseAlloc.h:14:11: missed: statement clobbers memory: _167 = aligned_alloc (64, _165);
Include/PulseAlloc.h:14:11: missed: statement clobbers memory: _157 = aligned_alloc (64, _165);
Include/PulseAlloc.h:14:11: missed: statement clobbers memory: _67 = aligned_alloc (64, prephitmp_171);
Include/PulseAlloc.h:29:28: missed: statement clobbers memory: _113 = aligned_alloc (64, _112);
Include/PulseAlloc.h:29:28: missed: statement clobbers memory: _98 = aligned_alloc (64, _112);
Include/PulseAlloc.h:11:28: missed: statement clobbers memory: _84 = aligned_alloc (64, _83);
Include/PulseAlloc.h:11:28: missed: statement clobbers memory: _71 = aligned_alloc (64, _83);
Include/PulseAlloc.h:11:28: missed: statement clobbers memory: _58 = aligned_alloc (64, _83);
Dense.c:182:39: missed: statement clobbers memory: _6 = rand ();
Dense.c:182:73: missed: statement clobbers memory: _45 = sqrt (_13);
Dense.c:188:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (_161, _162, 1, activation_function_46(D), _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:191:4: missed: statement clobbers memory: layer = PULSE_CreateLayer (_161, _162, 1, activation_function_46(D), _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:201:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Include/PulseAlloc.h:38:2: missed: statement clobbers memory: exit (1);
Include/PulseAlloc.h:38:2: note: ***** Analysis failed with vector mode V4DI
Include/PulseAlloc.h:38:2: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Activations.c:17:19: optimized: loop vectorized using 32 byte vectors
Activations.c:17:19: optimized: loop vectorized using 16 byte vectors
Activations.c:17:19: optimized: loop vectorized using 32 byte vectors
Activations.c:17:19: optimized: loop vectorized using 16 byte vectors
Activations.c:14:13: note: vectorized 2 loops in function.
Activations.c:14:13: note: ***** Analysis failed with vector mode V8SF
Activations.c:14:13: note: ***** The result for vector mode V32QI would be the same
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V16QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V16QI
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V8QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V8QI
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V4QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V4QI
Activations.c:28:19: missed: couldn't vectorize loop
Activations.c:28:19: missed: not vectorized: unsupported control flow in loop.
Activations.c:28:19: optimized: loop vectorized using 32 byte vectors
Activations.c:28:19: optimized: loop vectorized using 16 byte vectors
Activations.c:25:13: note: vectorized 1 loops in function.
Activations.c:25:13: note: ***** Analysis failed with vector mode V8SF
Activations.c:25:13: note: ***** The result for vector mode V32QI would be the same
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V16QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V16QI
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V8QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V8QI
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V4QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V4QI
Activations.c:38:1: note: ***** Analysis failed with vector mode VOID
Activations.c:5:19: missed: couldn't vectorize loop
Activations.c:9:21: missed: statement clobbers memory: _36 = expf (_18);
Activations.c:5:19: missed: couldn't vectorize loop
Activations.c:9:21: missed: statement clobbers memory: _12 = expf (_11);
Activations.c:3:13: note: vectorized 0 loops in function.
Activations.c:9:21: missed: statement clobbers memory: _12 = expf (_11);
Activations.c:9:21: missed: statement clobbers memory: _36 = expf (_18);
Activations.c:11:1: note: ***** Analysis failed with vector mode V8SF
Activations.c:11:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Activations.c:44:2: note: ***** Analysis failed with vector mode VOID
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:4:18: note: vectorized 0 loops in function.
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_4, inputs_15, _3);
PULSE.c:8:2: missed: statement clobbers memory: _5 (layer_17);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_12, pretmp_26, _9);
PULSE.c:13:28: note: ***** Analysis failed with vector mode V8SI
PULSE.c:13:28: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:22:2: missed: statement clobbers memory: _1 (layer_10(D));
PULSE.c:22:2: missed: statement clobbers memory: _14 (_2);
PULSE.c:22:2: missed: statement clobbers memory: _21 (_15);
PULSE.c:22:2: missed: statement clobbers memory: _28 (_22);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_29);
PULSE.c:26:3: missed: statement clobbers memory: memset (_34, 0, _32);
PULSE.c:26:3: missed: statement clobbers memory: memset (_27, 0, _25);
PULSE.c:26:3: missed: statement clobbers memory: memset (_20, 0, _18);
PULSE.c:26:3: missed: statement clobbers memory: memset (_7, 0, _5);
PULSE.c:28:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:28:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:32:6: note: vectorized 1 loops in function.
PULSE.c:34:8: missed: statement clobbers memory: _1 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_2);
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _9 = rand ();
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8SI
PULSE.c:32:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:61:16: missed: couldn't vectorize loop
PULSE.c:61:16: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:64:17: missed: couldn't vectorize loop
PULSE.c:64:17: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:73:19: missed: couldn't vectorize loop
PULSE.c:73:19: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _64 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:53:22: missed: couldn't vectorize loop
PULSE.c:53:22: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:47:6: note: vectorized 1 loops in function.
PULSE.c:48:1: missed: statement clobbers memory: saved_stack.7_35 = __builtin_stack_save ();
PULSE.c:49:46: missed: statement clobbers memory: _1 = PULSE_GetLossFunctionPtr (loss_function_36(D));
PULSE.c:60:10: missed: statement clobbers memory: random.4_42 = __builtin_alloca_with_align (_4, 32);
PULSE.c:34:8: missed: statement clobbers memory: _56 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_57);
PULSE.c:39:29: missed: statement clobbers memory: _64 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _67 = rand ();
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_93, inputs_88, _92);
PULSE.c:8:2: missed: statement clobbers memory: _94 (layer_89);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_100, _99, _98);
PULSE.c:67:11: missed: statement clobbers memory: loss_51 = PULSE_GetLoss_38 (_17, _16, _12, _11);
PULSE.c:22:2: missed: statement clobbers memory: _81 (output_30);
PULSE.c:22:2: missed: statement clobbers memory: _103 (_82);
PULSE.c:22:2: missed: statement clobbers memory: _110 (_104);
PULSE.c:22:2: missed: statement clobbers memory: _117 (_111);
PULSE.c:22:2: missed: statement clobbers memory: _124 (_118);
PULSE.c:22:2: missed: statement clobbers memory: _131 (_125);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_132);
PULSE.c:26:3: missed: statement clobbers memory: memset (_137, 0, _135);
PULSE.c:26:3: missed: statement clobbers memory: memset (_130, 0, _128);
PULSE.c:26:3: missed: statement clobbers memory: memset (_123, 0, _121);
PULSE.c:26:3: missed: statement clobbers memory: memset (_116, 0, _114);
PULSE.c:26:3: missed: statement clobbers memory: memset (_109, 0, _107);
PULSE.c:26:3: missed: statement clobbers memory: memset (_87, 0, _85);
PULSE.c:75:6: missed: statement clobbers memory: _21 (current_183, args);
PULSE.c:80:4: missed: statement clobbers memory: printf ("Epoch: %d Item: %d Loss: %.10f\r", i_181, j_182, _22);
PULSE.c:47:6: missed: statement clobbers memory: __builtin_stack_restore (saved_stack.7_35);
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4DI
PULSE.c:47:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:89:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:89:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:94:8: missed: couldn't vectorize loop
PULSE.c:94:8: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:91:6: note: vectorized 0 loops in function.
PULSE.c:96:3: missed: statement clobbers memory: _1 (current_10);
PULSE.c:99:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:99:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Loss.c:15:19: optimized: loop vectorized using 32 byte vectors
Loss.c:15:19: optimized:  loop versioned for vectorization because of possible aliasing
Loss.c:15:19: optimized: loop vectorized using 16 byte vectors
Loss.c:12:23: note: vectorized 1 loops in function.
Loss.c:12:23: note: ***** Analysis failed with vector mode V8SF
Loss.c:12:23: note: ***** The result for vector mode V32QI would be the same
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V16QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V16QI
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V8QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V8QI
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V4QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V4QI
Loss.c:7:19: missed: couldn't vectorize loop
Loss.c:8:38: missed: not vectorized: unsupported use in stmt.
Loss.c:4:23: note: vectorized 0 loops in function.
Loss.c:9:13: note: ***** Analysis failed with vector mode V8SF
Loss.c:9:13: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Loss.c:23:2: note: ***** Analysis failed with vector mode VOID
Include/PulseAlloc.h:14:11: missed: statement clobbers memory: _18 = aligned_alloc (64, _8);
Include/PulseAlloc.h:11:28: missed: statement clobbers memory: _20 = aligned_alloc (64, _2);
Include/PulseAlloc.h:19:2: missed: statement clobbers memory: exit (1);
Include/PulseAlloc.h:19:2: note: ***** Analysis failed with vector mode VOID
Include/PulseAlloc.h:33:11: missed: statement clobbers memory: _21 = aligned_alloc (64, _10);
Include/PulseAlloc.h:29:28: missed: statement clobbers memory: _23 = aligned_alloc (64, _3);
Include/PulseAlloc.h:38:2: missed: statement clobbers memory: exit (1);
Include/PulseAlloc.h:38:2: note: ***** Analysis failed with vector mode VOID
Include/PulseAlloc.h:14:11: missed: statement clobbers memory: _75 = aligned_alloc (64, _74);
Include/PulseAlloc.h:14:11: missed: statement clobbers memory: _3 = aligned_alloc (64, _76);
Include/PulseAlloc.h:14:11: missed: statement clobbers memory: _14 = aligned_alloc (64, _91);
Include/PulseAlloc.h:14:11: missed: statement clobbers memory: _49 = aligned_alloc (64, prephitmp_83);
Include/PulseAlloc.h:11:28: missed: statement clobbers memory: _66 = aligned_alloc (64, _65);
Include/PulseAlloc.h:11:28: missed: statement clobbers memory: _53 = aligned_alloc (64, _52);
Include/PulseAlloc.h:11:28: missed: statement clobbers memory: _40 = aligned_alloc (64, _52);
Layer.c:14:19: missed: statement clobbers memory: _6 = PULSE_GetActivationFunctionPtr (activation_function_16(D));
Include/PulseAlloc.h:19:2: missed: statement clobbers memory: exit (1);
Layer.c:19:9: note: ***** Analysis succeeded with vector mode V8SI
Layer.c:19:9: note: SLPing BB part
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x7b5b308 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_15(D);
Layer.c:19:9: note: 	stmt 0 MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_15(D);
Layer.c:19:9: note: 	stmt 1 MEM <unsigned int> [(struct PULSE_Layer *)&<retval> + 4B] = optimization_11(D);
Layer.c:19:9: note: 	children 0x7b5b388
Layer.c:19:9: note: node (external) 0x7b5b388 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ type_15(D), optimization_11(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x7b5b408 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: <retval>.n_inputs = n_inputs_9(D);
Layer.c:19:9: note: 	stmt 0 <retval>.n_inputs = n_inputs_9(D);
Layer.c:19:9: note: 	stmt 1 <retval>.n_outputs = n_outputs_10(D);
Layer.c:19:9: note: 	children 0x7b5b488
Layer.c:19:9: note: node (external) 0x7b5b488 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_9(D), n_outputs_10(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x7b5b588 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.inputs = _94;
Layer.c:19:9: note: 	stmt 0 <retval>.inputs = _94;
Layer.c:19:9: note: 	stmt 1 <retval>.outputs = _93;
Layer.c:19:9: note: 	children 0x7b5b608
Layer.c:19:9: note: node 0x7b5b608 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: _94 = PHI <_66(3), _75(9)>
Layer.c:19:9: note: 	stmt 0 _94 = PHI <_66(3), _75(9)>
Layer.c:19:9: note: 	stmt 1 _93 = PHI <_53(3), _96(9)>
Layer.c:19:9: note: 	children 0x7b5b688 0x7b5ba88
Layer.c:19:9: note: node (external) 0x7b5b688 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	stmt 0 _66 = aligned_alloc (64, _65);
Layer.c:19:9: note: 	stmt 1 _53 = aligned_alloc (64, _52);
Layer.c:19:9: note: 	children 0x7b5b708 0x7b5b788
Layer.c:19:9: note: node (constant) 0x7b5b708 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 64, 64 }
Layer.c:19:9: note: node 0x7b5b788 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: _65 = (long unsigned int) _64;
Layer.c:19:9: note: 	stmt 0 _65 = (long unsigned int) _64;
Layer.c:19:9: note: 	stmt 1 _52 = (long unsigned int) _51;
Layer.c:19:9: note: 	children 0x7b5b808
Layer.c:19:9: note: node 0x7b5b808 (max_nunits=2, refcnt=1) vector(2) int
Layer.c:19:9: note: op template: _64 = n_inputs.2_1 * 4;
Layer.c:19:9: note: 	stmt 0 _64 = n_inputs.2_1 * 4;
Layer.c:19:9: note: 	stmt 1 _51 = n_outputs.3_87 * 4;
Layer.c:19:9: note: 	children 0x7b5b888 0x7b5b988
Layer.c:19:9: note: node 0x7b5b888 (max_nunits=2, refcnt=1) vector(2) int
Layer.c:19:9: note: op template: n_inputs.2_1 = (int) n_inputs_9(D);
Layer.c:19:9: note: 	stmt 0 n_inputs.2_1 = (int) n_inputs_9(D);
Layer.c:19:9: note: 	stmt 1 n_outputs.3_87 = (int) n_outputs_10(D);
Layer.c:19:9: note: 	children 0x7b5b908
Layer.c:19:9: note: node (external) 0x7b5b908 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_9(D), n_outputs_10(D) }
Layer.c:19:9: note: node (constant) 0x7b5b988 (max_nunits=1, refcnt=1) vector(2) int
Layer.c:19:9: note: 	{ 4, 4 }
Layer.c:19:9: note: node (external) 0x7b5ba88 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ _75, _96 }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 52
  Scalar cost: 40
Layer.c:19:9: missed: not vectorized: vectorization is not profitable.
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x7b5bb88 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: op template: <retval>.feed = feed_18(D);
Layer.c:19:9: note: 	stmt 0 <retval>.feed = feed_18(D);
Layer.c:19:9: note: 	stmt 1 <retval>.back = back_19(D);
Layer.c:19:9: note: 	stmt 2 <retval>.fix = fix_20(D);
Layer.c:19:9: note: 	stmt 3 <retval>.destroy = destroy_21(D);
Layer.c:19:9: note: 	children 0x7b5bc08
Layer.c:19:9: note: node (external) 0x7b5bc08 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: 	{ feed_18(D), back_19(D), fix_20(D), destroy_21(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 64
  Scalar cost: 64
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x7b5bd08 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 0 <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 1 <retval>.child = 0B;
Layer.c:19:9: note: 	children 0x7b5bd88
Layer.c:19:9: note: node (constant) 0x7b5bd88 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ 0B, 0B }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Basic block will be vectorized using SLP
Layer.c:19:9: optimized: basic block part vectorized using 8 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x7b5b308 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_15(D);
Layer.c:19:9: note: 	stmt 0 MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_15(D);
Layer.c:19:9: note: 	stmt 1 MEM <unsigned int> [(struct PULSE_Layer *)&<retval> + 4B] = optimization_11(D);
Layer.c:19:9: note: 	children 0x7b5b388
Layer.c:19:9: note: node (external) 0x7b5b388 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ type_15(D), optimization_11(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_15(D);
Layer.c:19:9: note: vect_is_simple_use: operand optimization_11(D), type of def: external
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>]
Layer.c:19:9: note: created &MEM <unsigned int> [(struct PULSE_Layer *)&<retval>]
Layer.c:19:9: note: add new stmt: MEM <vector(2) unsigned int> [(struct PULSE_Layer *)&<retval>] = _59;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 8 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x7b5b408 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: <retval>.n_inputs = n_inputs_9(D);
Layer.c:19:9: note: 	stmt 0 <retval>.n_inputs = n_inputs_9(D);
Layer.c:19:9: note: 	stmt 1 <retval>.n_outputs = n_outputs_10(D);
Layer.c:19:9: note: 	children 0x7b5b488
Layer.c:19:9: note: node (external) 0x7b5b488 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_9(D), n_outputs_10(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.n_inputs = n_inputs_9(D);
Layer.c:19:9: note: vect_is_simple_use: operand n_outputs_10(D), type of def: external
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: <retval>.n_inputs
Layer.c:19:9: note: created &<retval>.n_inputs
Layer.c:19:9: note: add new stmt: MEM <vector(2) unsigned int> [(unsigned int *)&<retval> + 96B] = _42;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 32 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x7b5bb88 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: op template: <retval>.feed = feed_18(D);
Layer.c:19:9: note: 	stmt 0 <retval>.feed = feed_18(D);
Layer.c:19:9: note: 	stmt 1 <retval>.back = back_19(D);
Layer.c:19:9: note: 	stmt 2 <retval>.fix = fix_20(D);
Layer.c:19:9: note: 	stmt 3 <retval>.destroy = destroy_21(D);
Layer.c:19:9: note: 	children 0x7b5bc08
Layer.c:19:9: note: node (external) 0x7b5bc08 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: 	{ feed_18(D), back_19(D), fix_20(D), destroy_21(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.feed = feed_18(D);
Layer.c:19:9: note: vect_is_simple_use: operand back_19(D), type of def: external
Layer.c:19:9: note: vect_is_simple_use: operand fix_20(D), type of def: external
Layer.c:19:9: note: vect_is_simple_use: operand destroy_21(D), type of def: external
Layer.c:19:9: note: conflicting alias set types.
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(4) long unsigned int  vectorizing a pointer ref: <retval>.feed
Layer.c:19:9: note: created &<retval>.feed
Layer.c:19:9: note: add new stmt: MEM <vector(4) long unsigned int> [(void *)&<retval> + 32B] = _102;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 16 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x7b5bd08 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 0 <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 1 <retval>.child = 0B;
Layer.c:19:9: note: 	children 0x7b5bd88
Layer.c:19:9: note: node (constant) 0x7b5bd88 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ 0B, 0B }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.parent = 0B;
Layer.c:19:9: note: vect_is_simple_use: operand 0B, type of def: constant
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.parent
Layer.c:19:9: note: created &<retval>.parent
Layer.c:19:9: note: add new stmt: MEM <vector(2) long unsigned int> [(struct PULSE_Layer * *)&<retval> + 72B] = { 0, 0 };
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: note: ***** The result for vector mode V32QI would be the same
Layer.c:24:2: missed: statement clobbers memory: free (_1);
Layer.c:25:2: missed: statement clobbers memory: free (_2);
Layer.c:26:2: missed: statement clobbers memory: free (_3);
Layer.c:27:1: note: ***** Analysis failed with vector mode V4DI
Layer.c:27:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:7:27: missed: couldn't vectorize loop
Dense.c:7:27: missed: not vectorized: unsupported outerloop form.
Dense.c:10:20: missed: couldn't vectorize loop
Dense.c:11:21: missed: not vectorized: complicated access pattern.
Dense.c:4:13: note: vectorized 0 loops in function.
Dense.c:14:2: missed: statement clobbers memory: _30 (pretmp_91, _50, 0);
Dense.c:7:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:7:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:7:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:7:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:7:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:7:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:7:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:7:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:22:27: missed: couldn't vectorize loop
Dense.c:22:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:26:20: optimized: loop vectorized using 32 byte vectors
Dense.c:26:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:26:20: optimized: loop vectorized using 16 byte vectors
Dense.c:26:20: missed: couldn't vectorize loop
Dense.c:28:20: missed: not vectorized: no vectype for stmt: _21 = *_20;
 scalar_type: float
Dense.c:18:13: note: vectorized 1 loops in function.
Dense.c:21:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:22:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:22:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:22:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:22:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:22:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:22:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:22:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:22:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:39:28: missed: couldn't vectorize loop
Dense.c:39:28: missed: not vectorized: unsupported outerloop form.
Dense.c:43:21: optimized: loop vectorized using 32 byte vectors
Dense.c:43:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:43:21: optimized: loop vectorized using 16 byte vectors
Dense.c:35:13: note: vectorized 1 loops in function.
Dense.c:35:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:35:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:35:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:35:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:35:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:35:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:35:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:39:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:143:19: missed: couldn't vectorize loop
Dense.c:143:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:134:19: missed: couldn't vectorize loop
Dense.c:134:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:127:13: note: vectorized 0 loops in function.
Dense.c:151:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:151:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:96:28: missed: couldn't vectorize loop
Dense.c:96:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:99:21: missed: couldn't vectorize loop
Dense.c:99:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:113:28: missed: couldn't vectorize loop
Dense.c:113:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:116:21: missed: couldn't vectorize loop
Dense.c:116:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:82:19: missed: couldn't vectorize loop
Dense.c:82:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:76:13: note: vectorized 0 loops in function.
Dense.c:79:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:101:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:101:17: note: SLPing BB part
Dense.c:118:17: note: Costing subgraph: 
Dense.c:118:17: note: node 0x8ac9208 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:118:17: note: op template: _49 = (sizetype) j_137;
Dense.c:118:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:118:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:118:17: note: 	children 0x8ac9308
Dense.c:118:17: note: node (external) 0x8ac9308 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:118:17: note: 	{ j_137, wi_136 }
Dense.c:118:17: note: Cost model analysis: 
Dense.c:118:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:118:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:118:17: missed: not vectorized: vectorization is not profitable.
Dense.c:101:17: note: Costing subgraph: 
Dense.c:101:17: note: node 0x8ac9408 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:101:17: note: op template: _24 = (sizetype) j_134;
Dense.c:101:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:101:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:101:17: note: 	children 0x8ac9508
Dense.c:101:17: note: node (external) 0x8ac9508 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:101:17: note: 	{ j_134, wi_133 }
Dense.c:101:17: note: Cost model analysis: 
Dense.c:101:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:101:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:101:17: missed: not vectorized: vectorization is not profitable.
Dense.c:101:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:101:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:101:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:101:17: note: SLPing BB part
Dense.c:118:17: note: Costing subgraph: 
Dense.c:118:17: note: node 0x8ac9408 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:118:17: note: op template: _49 = (sizetype) j_137;
Dense.c:118:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:118:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:118:17: note: 	children 0x8ac9208
Dense.c:118:17: note: node (external) 0x8ac9208 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:118:17: note: 	{ j_137, wi_136 }
Dense.c:118:17: note: Cost model analysis: 
Dense.c:118:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:118:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:118:17: missed: not vectorized: vectorization is not profitable.
Dense.c:101:17: note: Costing subgraph: 
Dense.c:101:17: note: node 0x8ac9588 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:101:17: note: op template: _24 = (sizetype) j_134;
Dense.c:101:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:101:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:101:17: note: 	children 0x8ac9488
Dense.c:101:17: note: node (external) 0x8ac9488 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:101:17: note: 	{ j_134, wi_133 }
Dense.c:101:17: note: Cost model analysis: 
Dense.c:101:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:101:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:101:17: missed: not vectorized: vectorization is not profitable.
Dense.c:101:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:96:55: note: ***** Analysis failed with vector mode V8QI
Dense.c:96:55: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:96:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:56:27: missed: couldn't vectorize loop
Dense.c:56:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:59:20: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:905:10: missed: not vectorized: no vectype for stmt: _41 = MEM[(__m256_u * {ref-all})_6];
 scalar_type: __m256_u
Dense.c:59:20: note: ***** Analysis failed with vector mode VOID
Dense.c:52:13: note: vectorized 0 loops in function.
Dense.c:52:13: missed: splitting region at dont-vectorize loop 3 entry at bb18
Dense.c:61:14: note: ***** Analysis failed with vector mode V4DI
Dense.c:61:14: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:61:14: missed: splitting region at dominance boundary bb8
Dense.c:61:14: note: ***** Analysis failed with vector mode VOID
Dense.c:61:14: missed: splitting region at loop 1 exit at bb16
Dense.c:56:27: note: ***** Analysis failed with vector mode V8SF
Dense.c:56:27: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Dense.c:56:27: missed: splitting region at dominance boundary bb10
Dense.c:56:27: note: ***** Analysis failed with vector mode VOID
Dense.c:72:2: missed: statement clobbers memory: _27 (pretmp_153, _61, 0);
Dense.c:73:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:73:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Include/PulseAlloc.h:42:37: missed: statement clobbers memory: free (_1);
Include/PulseAlloc.h:42:37: missed: statement clobbers memory: free (_2);
Include/PulseAlloc.h:42:37: missed: statement clobbers memory: free (_3);
Include/PulseAlloc.h:42:37: missed: statement clobbers memory: free (_4);
Include/PulseAlloc.h:42:37: missed: statement clobbers memory: free (dense_7);
Dense.c:163:2: missed: statement clobbers memory: PULSE_DestroyLayer (this_6(D));
Dense.c:164:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:164:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Include/PulseAlloc.h:14:11: missed: statement clobbers memory: _18 = aligned_alloc (64, _8);
Include/PulseAlloc.h:11:28: missed: statement clobbers memory: _20 = aligned_alloc (64, _2);
Include/PulseAlloc.h:19:2: missed: statement clobbers memory: exit (1);
Include/PulseAlloc.h:19:2: note: ***** Analysis failed with vector mode VOID
Include/PulseAlloc.h:33:11: missed: statement clobbers memory: _21 = aligned_alloc (64, _10);
Include/PulseAlloc.h:29:28: missed: statement clobbers memory: _23 = aligned_alloc (64, _3);
Include/PulseAlloc.h:38:2: missed: statement clobbers memory: exit (1);
Include/PulseAlloc.h:38:2: note: ***** Analysis failed with vector mode VOID
Dense.c:178:19: missed: couldn't vectorize loop
Dense.c:178:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:168:13: note: vectorized 0 loops in function.
Dense.c:170:47: missed: statement clobbers memory: dense_30 = malloc (40);
Include/PulseAlloc.h:33:11: missed: statement clobbers memory: _187 = aligned_alloc (64, _185);
Include/PulseAlloc.h:33:11: missed: statement clobbers memory: _177 = aligned_alloc (64, _175);
Include/PulseAlloc.h:33:11: missed: statement clobbers memory: _108 = aligned_alloc (64, prephitmp_182);
Include/PulseAlloc.h:14:11: missed: statement clobbers memory: _140 = aligned_alloc (64, _148);
Include/PulseAlloc.h:14:11: missed: statement clobbers memory: _109 = aligned_alloc (64, _148);
Include/PulseAlloc.h:14:11: missed: statement clobbers memory: _167 = aligned_alloc (64, _165);
Include/PulseAlloc.h:14:11: missed: statement clobbers memory: _157 = aligned_alloc (64, _165);
Include/PulseAlloc.h:14:11: missed: statement clobbers memory: _67 = aligned_alloc (64, prephitmp_171);
Include/PulseAlloc.h:29:28: missed: statement clobbers memory: _113 = aligned_alloc (64, _112);
Include/PulseAlloc.h:29:28: missed: statement clobbers memory: _98 = aligned_alloc (64, _112);
Include/PulseAlloc.h:11:28: missed: statement clobbers memory: _84 = aligned_alloc (64, _83);
Include/PulseAlloc.h:11:28: missed: statement clobbers memory: _71 = aligned_alloc (64, _83);
Include/PulseAlloc.h:11:28: missed: statement clobbers memory: _58 = aligned_alloc (64, _83);
Dense.c:179:39: missed: statement clobbers memory: _6 = rand ();
Dense.c:179:73: missed: statement clobbers memory: _45 = sqrt (_13);
Dense.c:185:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (_161, _162, 1, activation_function_46(D), _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:188:4: missed: statement clobbers memory: layer = PULSE_CreateLayer (_161, _162, 1, activation_function_46(D), _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:198:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Include/PulseAlloc.h:38:2: missed: statement clobbers memory: exit (1);
Include/PulseAlloc.h:38:2: note: ***** Analysis failed with vector mode V4DI
Include/PulseAlloc.h:38:2: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Activations.c:17:19: optimized: loop vectorized using 32 byte vectors
Activations.c:17:19: optimized: loop vectorized using 16 byte vectors
Activations.c:17:19: optimized: loop vectorized using 32 byte vectors
Activations.c:17:19: optimized: loop vectorized using 16 byte vectors
Activations.c:14:13: note: vectorized 2 loops in function.
Activations.c:14:13: note: ***** Analysis failed with vector mode V8SF
Activations.c:14:13: note: ***** The result for vector mode V32QI would be the same
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V16QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V16QI
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V8QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V8QI
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V4QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V4QI
Activations.c:28:19: missed: couldn't vectorize loop
Activations.c:28:19: missed: not vectorized: unsupported control flow in loop.
Activations.c:28:19: optimized: loop vectorized using 32 byte vectors
Activations.c:28:19: optimized: loop vectorized using 16 byte vectors
Activations.c:25:13: note: vectorized 1 loops in function.
Activations.c:25:13: note: ***** Analysis failed with vector mode V8SF
Activations.c:25:13: note: ***** The result for vector mode V32QI would be the same
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V16QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V16QI
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V8QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V8QI
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V4QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V4QI
Activations.c:38:1: note: ***** Analysis failed with vector mode VOID
Activations.c:5:19: missed: couldn't vectorize loop
Activations.c:9:21: missed: statement clobbers memory: _36 = expf (_18);
Activations.c:5:19: missed: couldn't vectorize loop
Activations.c:9:21: missed: statement clobbers memory: _12 = expf (_11);
Activations.c:3:13: note: vectorized 0 loops in function.
Activations.c:9:21: missed: statement clobbers memory: _12 = expf (_11);
Activations.c:9:21: missed: statement clobbers memory: _36 = expf (_18);
Activations.c:11:1: note: ***** Analysis failed with vector mode V8SF
Activations.c:11:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Activations.c:44:2: note: ***** Analysis failed with vector mode VOID
Include/PulseAlloc.h:14:11: missed: statement clobbers memory: _18 = aligned_alloc (64, _8);
Include/PulseAlloc.h:11:28: missed: statement clobbers memory: _20 = aligned_alloc (64, _2);
Include/PulseAlloc.h:19:2: missed: statement clobbers memory: exit (1);
Include/PulseAlloc.h:19:2: note: ***** Analysis failed with vector mode VOID
Include/PulseAlloc.h:33:11: missed: statement clobbers memory: _21 = aligned_alloc (64, _10);
Include/PulseAlloc.h:29:28: missed: statement clobbers memory: _23 = aligned_alloc (64, _3);
Include/PulseAlloc.h:38:2: missed: statement clobbers memory: exit (1);
Include/PulseAlloc.h:38:2: note: ***** Analysis failed with vector mode VOID
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:4:18: note: vectorized 0 loops in function.
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_4, inputs_15, _3);
PULSE.c:8:2: missed: statement clobbers memory: _5 (layer_17);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_12, pretmp_26, _9);
PULSE.c:13:28: note: ***** Analysis failed with vector mode V8SI
PULSE.c:13:28: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:22:2: missed: statement clobbers memory: _1 (layer_10(D));
PULSE.c:22:2: missed: statement clobbers memory: _14 (_2);
PULSE.c:22:2: missed: statement clobbers memory: _21 (_15);
PULSE.c:22:2: missed: statement clobbers memory: _28 (_22);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_29);
PULSE.c:26:3: missed: statement clobbers memory: memset (_34, 0, _32);
PULSE.c:26:3: missed: statement clobbers memory: memset (_27, 0, _25);
PULSE.c:26:3: missed: statement clobbers memory: memset (_20, 0, _18);
PULSE.c:26:3: missed: statement clobbers memory: memset (_7, 0, _5);
PULSE.c:28:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:28:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:32:6: note: vectorized 1 loops in function.
PULSE.c:34:8: missed: statement clobbers memory: _1 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_2);
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _9 = rand ();
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8SI
PULSE.c:32:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:61:16: missed: couldn't vectorize loop
PULSE.c:61:16: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:64:17: missed: couldn't vectorize loop
PULSE.c:64:17: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:73:19: missed: couldn't vectorize loop
PULSE.c:73:19: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _64 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:53:22: missed: couldn't vectorize loop
PULSE.c:53:22: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:47:6: note: vectorized 1 loops in function.
PULSE.c:48:1: missed: statement clobbers memory: saved_stack.9_35 = __builtin_stack_save ();
PULSE.c:49:46: missed: statement clobbers memory: _1 = PULSE_GetLossFunctionPtr (loss_function_36(D));
PULSE.c:60:10: missed: statement clobbers memory: random.6_42 = __builtin_alloca_with_align (_4, 32);
PULSE.c:34:8: missed: statement clobbers memory: _56 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_57);
PULSE.c:39:29: missed: statement clobbers memory: _64 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _67 = rand ();
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_93, inputs_88, _92);
PULSE.c:8:2: missed: statement clobbers memory: _94 (layer_89);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_100, _99, _98);
PULSE.c:67:11: missed: statement clobbers memory: loss_51 = PULSE_GetLoss_38 (_17, _16, _12, _11);
PULSE.c:22:2: missed: statement clobbers memory: _81 (output_30);
PULSE.c:22:2: missed: statement clobbers memory: _103 (_82);
PULSE.c:22:2: missed: statement clobbers memory: _110 (_104);
PULSE.c:22:2: missed: statement clobbers memory: _117 (_111);
PULSE.c:22:2: missed: statement clobbers memory: _124 (_118);
PULSE.c:22:2: missed: statement clobbers memory: _131 (_125);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_132);
PULSE.c:26:3: missed: statement clobbers memory: memset (_137, 0, _135);
PULSE.c:26:3: missed: statement clobbers memory: memset (_130, 0, _128);
PULSE.c:26:3: missed: statement clobbers memory: memset (_123, 0, _121);
PULSE.c:26:3: missed: statement clobbers memory: memset (_116, 0, _114);
PULSE.c:26:3: missed: statement clobbers memory: memset (_109, 0, _107);
PULSE.c:26:3: missed: statement clobbers memory: memset (_87, 0, _85);
PULSE.c:75:6: missed: statement clobbers memory: _21 (current_183, args);
PULSE.c:80:4: missed: statement clobbers memory: printf ("Epoch: %d Item: %d Loss: %.10f\r", i_181, j_182, _22);
PULSE.c:47:6: missed: statement clobbers memory: __builtin_stack_restore (saved_stack.9_35);
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4DI
PULSE.c:47:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:89:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:89:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:94:8: missed: couldn't vectorize loop
PULSE.c:94:8: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:91:6: note: vectorized 0 loops in function.
PULSE.c:96:3: missed: statement clobbers memory: _1 (current_10);
PULSE.c:99:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:99:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Loss.c:15:19: optimized: loop vectorized using 32 byte vectors
Loss.c:15:19: optimized:  loop versioned for vectorization because of possible aliasing
Loss.c:15:19: optimized: loop vectorized using 16 byte vectors
Loss.c:12:23: note: vectorized 1 loops in function.
Loss.c:12:23: note: ***** Analysis failed with vector mode V8SF
Loss.c:12:23: note: ***** The result for vector mode V32QI would be the same
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V16QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V16QI
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V8QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V8QI
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V4QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V4QI
Loss.c:7:19: missed: couldn't vectorize loop
Loss.c:8:38: missed: not vectorized: unsupported use in stmt.
Loss.c:4:23: note: vectorized 0 loops in function.
Loss.c:9:13: note: ***** Analysis failed with vector mode V8SF
Loss.c:9:13: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Loss.c:23:2: note: ***** Analysis failed with vector mode VOID
Include/PulseAlloc.h:15:11: missed: statement clobbers memory: _18 = aligned_alloc (64, _8);
Include/PulseAlloc.h:12:28: missed: statement clobbers memory: _20 = aligned_alloc (64, _2);
Include/PulseAlloc.h:20:2: missed: statement clobbers memory: exit (1);
Include/PulseAlloc.h:20:2: note: ***** Analysis failed with vector mode VOID
Include/PulseAlloc.h:34:11: missed: statement clobbers memory: _21 = aligned_alloc (64, _10);
Include/PulseAlloc.h:30:28: missed: statement clobbers memory: _23 = aligned_alloc (64, _3);
Include/PulseAlloc.h:39:2: missed: statement clobbers memory: exit (1);
Include/PulseAlloc.h:39:2: note: ***** Analysis failed with vector mode VOID
Include/PulseAlloc.h:15:11: missed: statement clobbers memory: _75 = aligned_alloc (64, _74);
Include/PulseAlloc.h:15:11: missed: statement clobbers memory: _3 = aligned_alloc (64, _76);
Include/PulseAlloc.h:15:11: missed: statement clobbers memory: _14 = aligned_alloc (64, _91);
Include/PulseAlloc.h:15:11: missed: statement clobbers memory: _49 = aligned_alloc (64, prephitmp_83);
Include/PulseAlloc.h:12:28: missed: statement clobbers memory: _66 = aligned_alloc (64, _65);
Include/PulseAlloc.h:12:28: missed: statement clobbers memory: _53 = aligned_alloc (64, _52);
Include/PulseAlloc.h:12:28: missed: statement clobbers memory: _40 = aligned_alloc (64, _52);
Layer.c:14:19: missed: statement clobbers memory: _6 = PULSE_GetActivationFunctionPtr (activation_function_16(D));
Include/PulseAlloc.h:20:2: missed: statement clobbers memory: exit (1);
Layer.c:19:9: note: ***** Analysis succeeded with vector mode V8SI
Layer.c:19:9: note: SLPing BB part
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x872af28 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_15(D);
Layer.c:19:9: note: 	stmt 0 MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_15(D);
Layer.c:19:9: note: 	stmt 1 MEM <unsigned int> [(struct PULSE_Layer *)&<retval> + 4B] = optimization_11(D);
Layer.c:19:9: note: 	children 0x872afa8
Layer.c:19:9: note: node (external) 0x872afa8 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ type_15(D), optimization_11(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x872b028 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: <retval>.n_inputs = n_inputs_9(D);
Layer.c:19:9: note: 	stmt 0 <retval>.n_inputs = n_inputs_9(D);
Layer.c:19:9: note: 	stmt 1 <retval>.n_outputs = n_outputs_10(D);
Layer.c:19:9: note: 	children 0x872b0a8
Layer.c:19:9: note: node (external) 0x872b0a8 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_9(D), n_outputs_10(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x872b1a8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.inputs = _94;
Layer.c:19:9: note: 	stmt 0 <retval>.inputs = _94;
Layer.c:19:9: note: 	stmt 1 <retval>.outputs = _93;
Layer.c:19:9: note: 	children 0x872b228
Layer.c:19:9: note: node 0x872b228 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: _94 = PHI <_66(3), _75(9)>
Layer.c:19:9: note: 	stmt 0 _94 = PHI <_66(3), _75(9)>
Layer.c:19:9: note: 	stmt 1 _93 = PHI <_53(3), _96(9)>
Layer.c:19:9: note: 	children 0x872b2a8 0x872b6a8
Layer.c:19:9: note: node (external) 0x872b2a8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	stmt 0 _66 = aligned_alloc (64, _65);
Layer.c:19:9: note: 	stmt 1 _53 = aligned_alloc (64, _52);
Layer.c:19:9: note: 	children 0x872b328 0x872b3a8
Layer.c:19:9: note: node (constant) 0x872b328 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 64, 64 }
Layer.c:19:9: note: node 0x872b3a8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: _65 = (long unsigned int) _64;
Layer.c:19:9: note: 	stmt 0 _65 = (long unsigned int) _64;
Layer.c:19:9: note: 	stmt 1 _52 = (long unsigned int) _51;
Layer.c:19:9: note: 	children 0x872b428
Layer.c:19:9: note: node 0x872b428 (max_nunits=2, refcnt=1) vector(2) int
Layer.c:19:9: note: op template: _64 = n_inputs.2_1 * 4;
Layer.c:19:9: note: 	stmt 0 _64 = n_inputs.2_1 * 4;
Layer.c:19:9: note: 	stmt 1 _51 = n_outputs.3_87 * 4;
Layer.c:19:9: note: 	children 0x872b4a8 0x872b5a8
Layer.c:19:9: note: node 0x872b4a8 (max_nunits=2, refcnt=1) vector(2) int
Layer.c:19:9: note: op template: n_inputs.2_1 = (int) n_inputs_9(D);
Layer.c:19:9: note: 	stmt 0 n_inputs.2_1 = (int) n_inputs_9(D);
Layer.c:19:9: note: 	stmt 1 n_outputs.3_87 = (int) n_outputs_10(D);
Layer.c:19:9: note: 	children 0x872b528
Layer.c:19:9: note: node (external) 0x872b528 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_9(D), n_outputs_10(D) }
Layer.c:19:9: note: node (constant) 0x872b5a8 (max_nunits=1, refcnt=1) vector(2) int
Layer.c:19:9: note: 	{ 4, 4 }
Layer.c:19:9: note: node (external) 0x872b6a8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ _75, _96 }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 52
  Scalar cost: 40
Layer.c:19:9: missed: not vectorized: vectorization is not profitable.
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x872b7a8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: op template: <retval>.feed = feed_18(D);
Layer.c:19:9: note: 	stmt 0 <retval>.feed = feed_18(D);
Layer.c:19:9: note: 	stmt 1 <retval>.back = back_19(D);
Layer.c:19:9: note: 	stmt 2 <retval>.fix = fix_20(D);
Layer.c:19:9: note: 	stmt 3 <retval>.destroy = destroy_21(D);
Layer.c:19:9: note: 	children 0x872b828
Layer.c:19:9: note: node (external) 0x872b828 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: 	{ feed_18(D), back_19(D), fix_20(D), destroy_21(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 64
  Scalar cost: 64
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x872b928 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 0 <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 1 <retval>.child = 0B;
Layer.c:19:9: note: 	children 0x872b9a8
Layer.c:19:9: note: node (constant) 0x872b9a8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ 0B, 0B }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Basic block will be vectorized using SLP
Layer.c:19:9: optimized: basic block part vectorized using 8 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x872af28 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_15(D);
Layer.c:19:9: note: 	stmt 0 MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_15(D);
Layer.c:19:9: note: 	stmt 1 MEM <unsigned int> [(struct PULSE_Layer *)&<retval> + 4B] = optimization_11(D);
Layer.c:19:9: note: 	children 0x872afa8
Layer.c:19:9: note: node (external) 0x872afa8 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ type_15(D), optimization_11(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_15(D);
Layer.c:19:9: note: vect_is_simple_use: operand optimization_11(D), type of def: external
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>]
Layer.c:19:9: note: created &MEM <unsigned int> [(struct PULSE_Layer *)&<retval>]
Layer.c:19:9: note: add new stmt: MEM <vector(2) unsigned int> [(struct PULSE_Layer *)&<retval>] = _59;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 8 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x872b028 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: <retval>.n_inputs = n_inputs_9(D);
Layer.c:19:9: note: 	stmt 0 <retval>.n_inputs = n_inputs_9(D);
Layer.c:19:9: note: 	stmt 1 <retval>.n_outputs = n_outputs_10(D);
Layer.c:19:9: note: 	children 0x872b0a8
Layer.c:19:9: note: node (external) 0x872b0a8 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_9(D), n_outputs_10(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.n_inputs = n_inputs_9(D);
Layer.c:19:9: note: vect_is_simple_use: operand n_outputs_10(D), type of def: external
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: <retval>.n_inputs
Layer.c:19:9: note: created &<retval>.n_inputs
Layer.c:19:9: note: add new stmt: MEM <vector(2) unsigned int> [(unsigned int *)&<retval> + 96B] = _42;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 32 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x872b7a8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: op template: <retval>.feed = feed_18(D);
Layer.c:19:9: note: 	stmt 0 <retval>.feed = feed_18(D);
Layer.c:19:9: note: 	stmt 1 <retval>.back = back_19(D);
Layer.c:19:9: note: 	stmt 2 <retval>.fix = fix_20(D);
Layer.c:19:9: note: 	stmt 3 <retval>.destroy = destroy_21(D);
Layer.c:19:9: note: 	children 0x872b828
Layer.c:19:9: note: node (external) 0x872b828 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: 	{ feed_18(D), back_19(D), fix_20(D), destroy_21(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.feed = feed_18(D);
Layer.c:19:9: note: vect_is_simple_use: operand back_19(D), type of def: external
Layer.c:19:9: note: vect_is_simple_use: operand fix_20(D), type of def: external
Layer.c:19:9: note: vect_is_simple_use: operand destroy_21(D), type of def: external
Layer.c:19:9: note: conflicting alias set types.
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(4) long unsigned int  vectorizing a pointer ref: <retval>.feed
Layer.c:19:9: note: created &<retval>.feed
Layer.c:19:9: note: add new stmt: MEM <vector(4) long unsigned int> [(void *)&<retval> + 32B] = _102;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 16 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x872b928 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 0 <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 1 <retval>.child = 0B;
Layer.c:19:9: note: 	children 0x872b9a8
Layer.c:19:9: note: node (constant) 0x872b9a8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ 0B, 0B }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.parent = 0B;
Layer.c:19:9: note: vect_is_simple_use: operand 0B, type of def: constant
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.parent
Layer.c:19:9: note: created &<retval>.parent
Layer.c:19:9: note: add new stmt: MEM <vector(2) long unsigned int> [(struct PULSE_Layer * *)&<retval> + 72B] = { 0, 0 };
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: note: ***** The result for vector mode V32QI would be the same
Layer.c:24:2: missed: statement clobbers memory: free (_1);
Layer.c:25:2: missed: statement clobbers memory: free (_2);
Layer.c:26:2: missed: statement clobbers memory: free (_3);
Layer.c:27:1: note: ***** Analysis failed with vector mode V4DI
Layer.c:27:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:7:27: missed: couldn't vectorize loop
Dense.c:7:27: missed: not vectorized: unsupported outerloop form.
Dense.c:10:20: missed: couldn't vectorize loop
Dense.c:11:21: missed: not vectorized: complicated access pattern.
Dense.c:4:13: note: vectorized 0 loops in function.
Dense.c:14:2: missed: statement clobbers memory: _30 (pretmp_91, _50, 0);
Dense.c:7:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:7:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:7:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:7:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:7:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:7:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:7:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:7:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:22:27: missed: couldn't vectorize loop
Dense.c:22:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:26:20: optimized: loop vectorized using 32 byte vectors
Dense.c:26:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:26:20: optimized: loop vectorized using 16 byte vectors
Dense.c:26:20: missed: couldn't vectorize loop
Dense.c:28:20: missed: not vectorized: no vectype for stmt: _21 = *_20;
 scalar_type: float
Dense.c:18:13: note: vectorized 1 loops in function.
Dense.c:21:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:22:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:22:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:22:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:22:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:22:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:22:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:22:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:22:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:39:28: missed: couldn't vectorize loop
Dense.c:39:28: missed: not vectorized: unsupported outerloop form.
Dense.c:43:21: optimized: loop vectorized using 32 byte vectors
Dense.c:43:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:43:21: optimized: loop vectorized using 16 byte vectors
Dense.c:35:13: note: vectorized 1 loops in function.
Dense.c:35:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:35:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:35:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:35:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:35:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:35:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:35:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:39:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:143:19: missed: couldn't vectorize loop
Dense.c:143:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:134:19: missed: couldn't vectorize loop
Dense.c:134:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:127:13: note: vectorized 0 loops in function.
Dense.c:151:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:151:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:96:28: missed: couldn't vectorize loop
Dense.c:96:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:99:21: missed: couldn't vectorize loop
Dense.c:99:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:113:28: missed: couldn't vectorize loop
Dense.c:113:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:116:21: missed: couldn't vectorize loop
Dense.c:116:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:82:19: missed: couldn't vectorize loop
Dense.c:82:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:76:13: note: vectorized 0 loops in function.
Dense.c:79:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:101:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:101:17: note: SLPing BB part
Dense.c:118:17: note: Costing subgraph: 
Dense.c:118:17: note: node 0x7f126c8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:118:17: note: op template: _49 = (sizetype) j_137;
Dense.c:118:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:118:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:118:17: note: 	children 0x7f127c8
Dense.c:118:17: note: node (external) 0x7f127c8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:118:17: note: 	{ j_137, wi_136 }
Dense.c:118:17: note: Cost model analysis: 
Dense.c:118:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:118:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:118:17: missed: not vectorized: vectorization is not profitable.
Dense.c:101:17: note: Costing subgraph: 
Dense.c:101:17: note: node 0x7f128c8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:101:17: note: op template: _24 = (sizetype) j_134;
Dense.c:101:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:101:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:101:17: note: 	children 0x7f129c8
Dense.c:101:17: note: node (external) 0x7f129c8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:101:17: note: 	{ j_134, wi_133 }
Dense.c:101:17: note: Cost model analysis: 
Dense.c:101:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:101:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:101:17: missed: not vectorized: vectorization is not profitable.
Dense.c:101:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:101:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:101:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:101:17: note: SLPing BB part
Dense.c:118:17: note: Costing subgraph: 
Dense.c:118:17: note: node 0x7f128c8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:118:17: note: op template: _49 = (sizetype) j_137;
Dense.c:118:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:118:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:118:17: note: 	children 0x7f126c8
Dense.c:118:17: note: node (external) 0x7f126c8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:118:17: note: 	{ j_137, wi_136 }
Dense.c:118:17: note: Cost model analysis: 
Dense.c:118:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:118:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:118:17: missed: not vectorized: vectorization is not profitable.
Dense.c:101:17: note: Costing subgraph: 
Dense.c:101:17: note: node 0x7f12a48 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:101:17: note: op template: _24 = (sizetype) j_134;
Dense.c:101:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:101:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:101:17: note: 	children 0x7f12948
Dense.c:101:17: note: node (external) 0x7f12948 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:101:17: note: 	{ j_134, wi_133 }
Dense.c:101:17: note: Cost model analysis: 
Dense.c:101:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:101:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:101:17: missed: not vectorized: vectorization is not profitable.
Dense.c:101:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:96:55: note: ***** Analysis failed with vector mode V8QI
Dense.c:96:55: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:96:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:56:27: missed: couldn't vectorize loop
Dense.c:56:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:59:20: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:905:10: missed: not vectorized: no vectype for stmt: _41 = MEM[(__m256_u * {ref-all})_6];
 scalar_type: __m256_u
Dense.c:59:20: note: ***** Analysis failed with vector mode VOID
Dense.c:52:13: note: vectorized 0 loops in function.
Dense.c:52:13: missed: splitting region at dont-vectorize loop 3 entry at bb18
Dense.c:61:14: note: ***** Analysis failed with vector mode V4DI
Dense.c:61:14: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:61:14: missed: splitting region at dominance boundary bb8
Dense.c:61:14: note: ***** Analysis failed with vector mode VOID
Dense.c:61:14: missed: splitting region at loop 1 exit at bb16
Dense.c:56:27: note: ***** Analysis failed with vector mode V8SF
Dense.c:56:27: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Dense.c:56:27: missed: splitting region at dominance boundary bb10
Dense.c:56:27: note: ***** Analysis failed with vector mode VOID
Dense.c:72:2: missed: statement clobbers memory: _27 (pretmp_153, _61, 0);
Dense.c:73:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:73:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Include/PulseAlloc.h:43:37: missed: statement clobbers memory: free (_1);
Include/PulseAlloc.h:43:37: missed: statement clobbers memory: free (_2);
Include/PulseAlloc.h:43:37: missed: statement clobbers memory: free (_3);
Include/PulseAlloc.h:43:37: missed: statement clobbers memory: free (_4);
Include/PulseAlloc.h:43:37: missed: statement clobbers memory: free (dense_7);
Dense.c:163:2: missed: statement clobbers memory: PULSE_DestroyLayer (this_6(D));
Dense.c:164:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:164:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Include/PulseAlloc.h:15:11: missed: statement clobbers memory: _18 = aligned_alloc (64, _8);
Include/PulseAlloc.h:12:28: missed: statement clobbers memory: _20 = aligned_alloc (64, _2);
Include/PulseAlloc.h:20:2: missed: statement clobbers memory: exit (1);
Include/PulseAlloc.h:20:2: note: ***** Analysis failed with vector mode VOID
Include/PulseAlloc.h:34:11: missed: statement clobbers memory: _21 = aligned_alloc (64, _10);
Include/PulseAlloc.h:30:28: missed: statement clobbers memory: _23 = aligned_alloc (64, _3);
Include/PulseAlloc.h:39:2: missed: statement clobbers memory: exit (1);
Include/PulseAlloc.h:39:2: note: ***** Analysis failed with vector mode VOID
Dense.c:178:19: missed: couldn't vectorize loop
Dense.c:178:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:168:13: note: vectorized 0 loops in function.
Dense.c:170:47: missed: statement clobbers memory: dense_30 = malloc (40);
Include/PulseAlloc.h:34:11: missed: statement clobbers memory: _187 = aligned_alloc (64, _185);
Include/PulseAlloc.h:34:11: missed: statement clobbers memory: _177 = aligned_alloc (64, _175);
Include/PulseAlloc.h:34:11: missed: statement clobbers memory: _108 = aligned_alloc (64, prephitmp_182);
Include/PulseAlloc.h:15:11: missed: statement clobbers memory: _140 = aligned_alloc (64, _148);
Include/PulseAlloc.h:15:11: missed: statement clobbers memory: _109 = aligned_alloc (64, _148);
Include/PulseAlloc.h:15:11: missed: statement clobbers memory: _167 = aligned_alloc (64, _165);
Include/PulseAlloc.h:15:11: missed: statement clobbers memory: _157 = aligned_alloc (64, _165);
Include/PulseAlloc.h:15:11: missed: statement clobbers memory: _67 = aligned_alloc (64, prephitmp_171);
Include/PulseAlloc.h:30:28: missed: statement clobbers memory: _113 = aligned_alloc (64, _112);
Include/PulseAlloc.h:30:28: missed: statement clobbers memory: _98 = aligned_alloc (64, _112);
Include/PulseAlloc.h:12:28: missed: statement clobbers memory: _84 = aligned_alloc (64, _83);
Include/PulseAlloc.h:12:28: missed: statement clobbers memory: _71 = aligned_alloc (64, _83);
Include/PulseAlloc.h:12:28: missed: statement clobbers memory: _58 = aligned_alloc (64, _83);
Dense.c:179:39: missed: statement clobbers memory: _6 = rand ();
Dense.c:179:73: missed: statement clobbers memory: _45 = sqrt (_13);
Dense.c:185:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (_161, _162, 1, activation_function_46(D), _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:188:4: missed: statement clobbers memory: layer = PULSE_CreateLayer (_161, _162, 1, activation_function_46(D), _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:198:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Include/PulseAlloc.h:39:2: missed: statement clobbers memory: exit (1);
Include/PulseAlloc.h:39:2: note: ***** Analysis failed with vector mode V4DI
Include/PulseAlloc.h:39:2: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Activations.c:17:19: optimized: loop vectorized using 32 byte vectors
Activations.c:17:19: optimized: loop vectorized using 16 byte vectors
Activations.c:17:19: optimized: loop vectorized using 32 byte vectors
Activations.c:17:19: optimized: loop vectorized using 16 byte vectors
Activations.c:14:13: note: vectorized 2 loops in function.
Activations.c:14:13: note: ***** Analysis failed with vector mode V8SF
Activations.c:14:13: note: ***** The result for vector mode V32QI would be the same
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V16QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V16QI
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V8QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V8QI
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V4QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V4QI
Activations.c:28:19: missed: couldn't vectorize loop
Activations.c:28:19: missed: not vectorized: unsupported control flow in loop.
Activations.c:28:19: optimized: loop vectorized using 32 byte vectors
Activations.c:28:19: optimized: loop vectorized using 16 byte vectors
Activations.c:25:13: note: vectorized 1 loops in function.
Activations.c:25:13: note: ***** Analysis failed with vector mode V8SF
Activations.c:25:13: note: ***** The result for vector mode V32QI would be the same
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V16QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V16QI
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V8QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V8QI
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V4QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V4QI
Activations.c:38:1: note: ***** Analysis failed with vector mode VOID
Activations.c:5:19: missed: couldn't vectorize loop
Activations.c:9:21: missed: statement clobbers memory: _36 = expf (_18);
Activations.c:5:19: missed: couldn't vectorize loop
Activations.c:9:21: missed: statement clobbers memory: _12 = expf (_11);
Activations.c:3:13: note: vectorized 0 loops in function.
Activations.c:9:21: missed: statement clobbers memory: _12 = expf (_11);
Activations.c:9:21: missed: statement clobbers memory: _36 = expf (_18);
Activations.c:11:1: note: ***** Analysis failed with vector mode V8SF
Activations.c:11:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Activations.c:44:2: note: ***** Analysis failed with vector mode VOID
Include/PulseAlloc.h:15:11: missed: statement clobbers memory: _18 = aligned_alloc (64, _8);
Include/PulseAlloc.h:12:28: missed: statement clobbers memory: _20 = aligned_alloc (64, _2);
Include/PulseAlloc.h:20:2: missed: statement clobbers memory: exit (1);
Include/PulseAlloc.h:20:2: note: ***** Analysis failed with vector mode VOID
Include/PulseAlloc.h:34:11: missed: statement clobbers memory: _21 = aligned_alloc (64, _10);
Include/PulseAlloc.h:30:28: missed: statement clobbers memory: _23 = aligned_alloc (64, _3);
Include/PulseAlloc.h:39:2: missed: statement clobbers memory: exit (1);
Include/PulseAlloc.h:39:2: note: ***** Analysis failed with vector mode VOID
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:4:18: note: vectorized 0 loops in function.
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_4, inputs_15, _3);
PULSE.c:8:2: missed: statement clobbers memory: _5 (layer_17);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_12, pretmp_26, _9);
PULSE.c:13:28: note: ***** Analysis failed with vector mode V8SI
PULSE.c:13:28: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:22:2: missed: statement clobbers memory: _1 (layer_10(D));
PULSE.c:22:2: missed: statement clobbers memory: _14 (_2);
PULSE.c:22:2: missed: statement clobbers memory: _21 (_15);
PULSE.c:22:2: missed: statement clobbers memory: _28 (_22);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_29);
PULSE.c:26:3: missed: statement clobbers memory: memset (_34, 0, _32);
PULSE.c:26:3: missed: statement clobbers memory: memset (_27, 0, _25);
PULSE.c:26:3: missed: statement clobbers memory: memset (_20, 0, _18);
PULSE.c:26:3: missed: statement clobbers memory: memset (_7, 0, _5);
PULSE.c:28:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:28:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:32:6: note: vectorized 1 loops in function.
PULSE.c:34:8: missed: statement clobbers memory: _1 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_2);
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _9 = rand ();
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8SI
PULSE.c:32:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:61:16: missed: couldn't vectorize loop
PULSE.c:61:16: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:64:17: missed: couldn't vectorize loop
PULSE.c:64:17: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:73:19: missed: couldn't vectorize loop
PULSE.c:73:19: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _64 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:53:22: missed: couldn't vectorize loop
PULSE.c:53:22: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:47:6: note: vectorized 1 loops in function.
PULSE.c:48:1: missed: statement clobbers memory: saved_stack.9_35 = __builtin_stack_save ();
PULSE.c:49:46: missed: statement clobbers memory: _1 = PULSE_GetLossFunctionPtr (loss_function_36(D));
PULSE.c:60:10: missed: statement clobbers memory: random.6_42 = __builtin_alloca_with_align (_4, 32);
PULSE.c:34:8: missed: statement clobbers memory: _56 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_57);
PULSE.c:39:29: missed: statement clobbers memory: _64 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _67 = rand ();
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_93, inputs_88, _92);
PULSE.c:8:2: missed: statement clobbers memory: _94 (layer_89);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_100, _99, _98);
PULSE.c:67:11: missed: statement clobbers memory: loss_51 = PULSE_GetLoss_38 (_17, _16, _12, _11);
PULSE.c:22:2: missed: statement clobbers memory: _81 (output_30);
PULSE.c:22:2: missed: statement clobbers memory: _103 (_82);
PULSE.c:22:2: missed: statement clobbers memory: _110 (_104);
PULSE.c:22:2: missed: statement clobbers memory: _117 (_111);
PULSE.c:22:2: missed: statement clobbers memory: _124 (_118);
PULSE.c:22:2: missed: statement clobbers memory: _131 (_125);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_132);
PULSE.c:26:3: missed: statement clobbers memory: memset (_137, 0, _135);
PULSE.c:26:3: missed: statement clobbers memory: memset (_130, 0, _128);
PULSE.c:26:3: missed: statement clobbers memory: memset (_123, 0, _121);
PULSE.c:26:3: missed: statement clobbers memory: memset (_116, 0, _114);
PULSE.c:26:3: missed: statement clobbers memory: memset (_109, 0, _107);
PULSE.c:26:3: missed: statement clobbers memory: memset (_87, 0, _85);
PULSE.c:75:6: missed: statement clobbers memory: _21 (current_183, args);
PULSE.c:80:4: missed: statement clobbers memory: printf ("Epoch: %d Item: %d Loss: %.10f\r", i_181, j_182, _22);
PULSE.c:47:6: missed: statement clobbers memory: __builtin_stack_restore (saved_stack.9_35);
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4DI
PULSE.c:47:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:89:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:89:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:94:8: missed: couldn't vectorize loop
PULSE.c:94:8: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:91:6: note: vectorized 0 loops in function.
PULSE.c:96:3: missed: statement clobbers memory: _1 (current_10);
PULSE.c:99:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:99:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Loss.c:15:19: optimized: loop vectorized using 32 byte vectors
Loss.c:15:19: optimized:  loop versioned for vectorization because of possible aliasing
Loss.c:15:19: optimized: loop vectorized using 16 byte vectors
Loss.c:12:23: note: vectorized 1 loops in function.
Loss.c:12:23: note: ***** Analysis failed with vector mode V8SF
Loss.c:12:23: note: ***** The result for vector mode V32QI would be the same
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V16QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V16QI
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V8QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V8QI
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V4QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V4QI
Loss.c:7:19: missed: couldn't vectorize loop
Loss.c:8:38: missed: not vectorized: unsupported use in stmt.
Loss.c:4:23: note: vectorized 0 loops in function.
Loss.c:9:13: note: ***** Analysis failed with vector mode V8SF
Loss.c:9:13: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Loss.c:23:2: note: ***** Analysis failed with vector mode VOID
PulseAlloc.c:11:11: missed: statement clobbers memory: _18 = aligned_alloc (64, _8);
PulseAlloc.c:8:28: missed: statement clobbers memory: _20 = aligned_alloc (64, _2);
PulseAlloc.c:16:2: missed: statement clobbers memory: exit (1);
PulseAlloc.c:16:2: note: ***** Analysis failed with vector mode VOID
PulseAlloc.c:30:11: missed: statement clobbers memory: _21 = aligned_alloc (64, _10);
PulseAlloc.c:26:28: missed: statement clobbers memory: _23 = aligned_alloc (64, _3);
PulseAlloc.c:35:2: missed: statement clobbers memory: exit (1);
PulseAlloc.c:35:2: note: ***** Analysis failed with vector mode VOID
Layer.c:7:34: missed: statement clobbers memory: _2 = PULSE_Alloc (64, 4, n_inputs.0_1, optimization_11(D));
Layer.c:8:35: missed: statement clobbers memory: _4 = PULSE_Alloc (64, 4, n_outputs.1_3, optimization_11(D));
Layer.c:9:34: missed: statement clobbers memory: _5 = PULSE_Alloc (64, 4, n_outputs.1_3, optimization_11(D));
Layer.c:14:19: missed: statement clobbers memory: _6 = PULSE_GetActivationFunctionPtr (activation_function_16(D));
Layer.c:19:9: note: ***** Analysis succeeded with vector mode V8SI
Layer.c:19:9: note: SLPing BB part
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x756b588 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_15(D);
Layer.c:19:9: note: 	stmt 0 MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_15(D);
Layer.c:19:9: note: 	stmt 1 MEM <unsigned int> [(struct PULSE_Layer *)&<retval> + 4B] = optimization_11(D);
Layer.c:19:9: note: 	children 0x756b608
Layer.c:19:9: note: node (external) 0x756b608 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ type_15(D), optimization_11(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x756b688 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: <retval>.n_inputs = n_inputs_9(D);
Layer.c:19:9: note: 	stmt 0 <retval>.n_inputs = n_inputs_9(D);
Layer.c:19:9: note: 	stmt 1 <retval>.n_outputs = n_outputs_10(D);
Layer.c:19:9: note: 	children 0x756b708
Layer.c:19:9: note: node (external) 0x756b708 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_9(D), n_outputs_10(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x756b808 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.inputs = _2;
Layer.c:19:9: note: 	stmt 0 <retval>.inputs = _2;
Layer.c:19:9: note: 	stmt 1 <retval>.outputs = _4;
Layer.c:19:9: note: 	children 0x756b888
Layer.c:19:9: note: node (external) 0x756b888 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	stmt 0 _2 = PULSE_Alloc (64, 4, n_inputs.0_1, optimization_11(D));
Layer.c:19:9: note: 	stmt 1 _4 = PULSE_Alloc (64, 4, n_outputs.1_3, optimization_11(D));
Layer.c:19:9: note: 	children 0x756b908 0x756b988 0x756ba08 0x756bb08
Layer.c:19:9: note: node (constant) 0x756b908 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 64, 64 }
Layer.c:19:9: note: node (constant) 0x756b988 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 4, 4 }
Layer.c:19:9: note: node 0x756ba08 (max_nunits=2, refcnt=1) vector(2) int
Layer.c:19:9: note: op template: n_inputs.0_1 = (int) n_inputs_9(D);
Layer.c:19:9: note: 	stmt 0 n_inputs.0_1 = (int) n_inputs_9(D);
Layer.c:19:9: note: 	stmt 1 n_outputs.1_3 = (int) n_outputs_10(D);
Layer.c:19:9: note: 	children 0x756ba88
Layer.c:19:9: note: node (external) 0x756ba88 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_9(D), n_outputs_10(D) }
Layer.c:19:9: note: node (external) 0x756bb08 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ optimization_11(D), optimization_11(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x756bc08 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: op template: <retval>.feed = feed_18(D);
Layer.c:19:9: note: 	stmt 0 <retval>.feed = feed_18(D);
Layer.c:19:9: note: 	stmt 1 <retval>.back = back_19(D);
Layer.c:19:9: note: 	stmt 2 <retval>.fix = fix_20(D);
Layer.c:19:9: note: 	stmt 3 <retval>.destroy = destroy_21(D);
Layer.c:19:9: note: 	children 0x756bc88
Layer.c:19:9: note: node (external) 0x756bc88 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: 	{ feed_18(D), back_19(D), fix_20(D), destroy_21(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 64
  Scalar cost: 64
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x756bd88 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 0 <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 1 <retval>.child = 0B;
Layer.c:19:9: note: 	children 0x756be08
Layer.c:19:9: note: node (constant) 0x756be08 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ 0B, 0B }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Basic block will be vectorized using SLP
Layer.c:19:9: optimized: basic block part vectorized using 8 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x756b588 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_15(D);
Layer.c:19:9: note: 	stmt 0 MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_15(D);
Layer.c:19:9: note: 	stmt 1 MEM <unsigned int> [(struct PULSE_Layer *)&<retval> + 4B] = optimization_11(D);
Layer.c:19:9: note: 	children 0x756b608
Layer.c:19:9: note: node (external) 0x756b608 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ type_15(D), optimization_11(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_15(D);
Layer.c:19:9: note: vect_is_simple_use: operand optimization_11(D), type of def: external
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>]
Layer.c:19:9: note: created &MEM <unsigned int> [(struct PULSE_Layer *)&<retval>]
Layer.c:19:9: note: add new stmt: MEM <vector(2) unsigned int> [(struct PULSE_Layer *)&<retval>] = _38;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 8 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x756b688 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: <retval>.n_inputs = n_inputs_9(D);
Layer.c:19:9: note: 	stmt 0 <retval>.n_inputs = n_inputs_9(D);
Layer.c:19:9: note: 	stmt 1 <retval>.n_outputs = n_outputs_10(D);
Layer.c:19:9: note: 	children 0x756b708
Layer.c:19:9: note: node (external) 0x756b708 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_9(D), n_outputs_10(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.n_inputs = n_inputs_9(D);
Layer.c:19:9: note: vect_is_simple_use: operand n_outputs_10(D), type of def: external
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: <retval>.n_inputs
Layer.c:19:9: note: created &<retval>.n_inputs
Layer.c:19:9: note: add new stmt: MEM <vector(2) unsigned int> [(unsigned int *)&<retval> + 96B] = _40;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 16 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x756b808 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.inputs = _2;
Layer.c:19:9: note: 	stmt 0 <retval>.inputs = _2;
Layer.c:19:9: note: 	stmt 1 <retval>.outputs = _4;
Layer.c:19:9: note: 	children 0x756b888
Layer.c:19:9: note: node (external) 0x756b888 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	stmt 0 _2 = PULSE_Alloc (64, 4, n_inputs.0_1, optimization_11(D));
Layer.c:19:9: note: 	stmt 1 _4 = PULSE_Alloc (64, 4, n_outputs.1_3, optimization_11(D));
Layer.c:19:9: note: 	children 0x756b908 0x756b988 0x756ba08 0x756bb08
Layer.c:19:9: note: node (constant) 0x756b908 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 64, 64 }
Layer.c:19:9: note: node (constant) 0x756b988 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 4, 4 }
Layer.c:19:9: note: node 0x756ba08 (max_nunits=2, refcnt=1) vector(2) int
Layer.c:19:9: note: op template: n_inputs.0_1 = (int) n_inputs_9(D);
Layer.c:19:9: note: 	stmt 0 n_inputs.0_1 = (int) n_inputs_9(D);
Layer.c:19:9: note: 	stmt 1 n_outputs.1_3 = (int) n_outputs_10(D);
Layer.c:19:9: note: 	children 0x756ba88
Layer.c:19:9: note: node (external) 0x756ba88 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_9(D), n_outputs_10(D) }
Layer.c:19:9: note: node (external) 0x756bb08 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ optimization_11(D), optimization_11(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.inputs = _2;
Layer.c:19:9: note: vect_is_simple_use: operand PULSE_Alloc (64, 4, n_outputs.1_3, optimization_11(D)), type of def: internal
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.inputs
Layer.c:19:9: note: created &<retval>.inputs
Layer.c:19:9: note: add new stmt: MEM <vector(2) long unsigned int> [(float * *)&<retval> + 8B] = _44;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 32 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x756bc08 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: op template: <retval>.feed = feed_18(D);
Layer.c:19:9: note: 	stmt 0 <retval>.feed = feed_18(D);
Layer.c:19:9: note: 	stmt 1 <retval>.back = back_19(D);
Layer.c:19:9: note: 	stmt 2 <retval>.fix = fix_20(D);
Layer.c:19:9: note: 	stmt 3 <retval>.destroy = destroy_21(D);
Layer.c:19:9: note: 	children 0x756bc88
Layer.c:19:9: note: node (external) 0x756bc88 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: 	{ feed_18(D), back_19(D), fix_20(D), destroy_21(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.feed = feed_18(D);
Layer.c:19:9: note: vect_is_simple_use: operand back_19(D), type of def: external
Layer.c:19:9: note: vect_is_simple_use: operand fix_20(D), type of def: external
Layer.c:19:9: note: vect_is_simple_use: operand destroy_21(D), type of def: external
Layer.c:19:9: note: conflicting alias set types.
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(4) long unsigned int  vectorizing a pointer ref: <retval>.feed
Layer.c:19:9: note: created &<retval>.feed
Layer.c:19:9: note: add new stmt: MEM <vector(4) long unsigned int> [(void *)&<retval> + 32B] = _50;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 16 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x756bd88 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 0 <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 1 <retval>.child = 0B;
Layer.c:19:9: note: 	children 0x756be08
Layer.c:19:9: note: node (constant) 0x756be08 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ 0B, 0B }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.parent = 0B;
Layer.c:19:9: note: vect_is_simple_use: operand 0B, type of def: constant
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.parent
Layer.c:19:9: note: created &<retval>.parent
Layer.c:19:9: note: add new stmt: MEM <vector(2) long unsigned int> [(struct PULSE_Layer * *)&<retval> + 72B] = { 0, 0 };
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: note: ***** The result for vector mode V32QI would be the same
Layer.c:24:2: missed: statement clobbers memory: free (_1);
Layer.c:25:2: missed: statement clobbers memory: free (_2);
Layer.c:26:2: missed: statement clobbers memory: free (_3);
Layer.c:27:1: note: ***** Analysis failed with vector mode V4DI
Layer.c:27:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:7:27: missed: couldn't vectorize loop
Dense.c:7:27: missed: not vectorized: unsupported outerloop form.
Dense.c:10:20: missed: couldn't vectorize loop
Dense.c:11:21: missed: not vectorized: complicated access pattern.
Dense.c:4:13: note: vectorized 0 loops in function.
Dense.c:14:2: missed: statement clobbers memory: _30 (pretmp_91, _50, 0);
Dense.c:7:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:7:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:7:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:7:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:7:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:7:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:7:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:7:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:22:27: missed: couldn't vectorize loop
Dense.c:22:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:26:20: optimized: loop vectorized using 32 byte vectors
Dense.c:26:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:26:20: optimized: loop vectorized using 16 byte vectors
Dense.c:26:20: missed: couldn't vectorize loop
Dense.c:28:20: missed: not vectorized: no vectype for stmt: _21 = *_20;
 scalar_type: float
Dense.c:18:13: note: vectorized 1 loops in function.
Dense.c:21:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:22:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:22:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:22:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:22:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:22:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:22:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:22:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:22:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:39:28: missed: couldn't vectorize loop
Dense.c:39:28: missed: not vectorized: unsupported outerloop form.
Dense.c:43:21: optimized: loop vectorized using 32 byte vectors
Dense.c:43:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:43:21: optimized: loop vectorized using 16 byte vectors
Dense.c:35:13: note: vectorized 1 loops in function.
Dense.c:35:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:35:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:35:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:35:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:35:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:35:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:35:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:39:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:143:19: missed: couldn't vectorize loop
Dense.c:143:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:134:19: missed: couldn't vectorize loop
Dense.c:134:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:127:13: note: vectorized 0 loops in function.
Dense.c:151:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:151:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:96:28: missed: couldn't vectorize loop
Dense.c:96:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:99:21: missed: couldn't vectorize loop
Dense.c:99:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:113:28: missed: couldn't vectorize loop
Dense.c:113:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:116:21: missed: couldn't vectorize loop
Dense.c:116:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:82:19: missed: couldn't vectorize loop
Dense.c:82:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:76:13: note: vectorized 0 loops in function.
Dense.c:79:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:101:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:101:17: note: SLPing BB part
Dense.c:118:17: note: Costing subgraph: 
Dense.c:118:17: note: node 0x7a22198 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:118:17: note: op template: _49 = (sizetype) j_137;
Dense.c:118:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:118:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:118:17: note: 	children 0x7a22298
Dense.c:118:17: note: node (external) 0x7a22298 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:118:17: note: 	{ j_137, wi_136 }
Dense.c:118:17: note: Cost model analysis: 
Dense.c:118:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:118:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:118:17: missed: not vectorized: vectorization is not profitable.
Dense.c:101:17: note: Costing subgraph: 
Dense.c:101:17: note: node 0x7a22398 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:101:17: note: op template: _24 = (sizetype) j_134;
Dense.c:101:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:101:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:101:17: note: 	children 0x7a22498
Dense.c:101:17: note: node (external) 0x7a22498 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:101:17: note: 	{ j_134, wi_133 }
Dense.c:101:17: note: Cost model analysis: 
Dense.c:101:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:101:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:101:17: missed: not vectorized: vectorization is not profitable.
Dense.c:101:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:101:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:101:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:101:17: note: SLPing BB part
Dense.c:118:17: note: Costing subgraph: 
Dense.c:118:17: note: node 0x7a22398 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:118:17: note: op template: _49 = (sizetype) j_137;
Dense.c:118:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:118:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:118:17: note: 	children 0x7a22198
Dense.c:118:17: note: node (external) 0x7a22198 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:118:17: note: 	{ j_137, wi_136 }
Dense.c:118:17: note: Cost model analysis: 
Dense.c:118:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:118:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:118:17: missed: not vectorized: vectorization is not profitable.
Dense.c:101:17: note: Costing subgraph: 
Dense.c:101:17: note: node 0x7a22518 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:101:17: note: op template: _24 = (sizetype) j_134;
Dense.c:101:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:101:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:101:17: note: 	children 0x7a22418
Dense.c:101:17: note: node (external) 0x7a22418 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:101:17: note: 	{ j_134, wi_133 }
Dense.c:101:17: note: Cost model analysis: 
Dense.c:101:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:101:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:101:17: missed: not vectorized: vectorization is not profitable.
Dense.c:101:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:96:55: note: ***** Analysis failed with vector mode V8QI
Dense.c:96:55: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:96:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:56:27: missed: couldn't vectorize loop
Dense.c:56:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:59:20: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:905:10: missed: not vectorized: no vectype for stmt: _41 = MEM[(__m256_u * {ref-all})_6];
 scalar_type: __m256_u
Dense.c:59:20: note: ***** Analysis failed with vector mode VOID
Dense.c:52:13: note: vectorized 0 loops in function.
Dense.c:52:13: missed: splitting region at dont-vectorize loop 3 entry at bb18
Dense.c:61:14: note: ***** Analysis failed with vector mode V4DI
Dense.c:61:14: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:61:14: missed: splitting region at dominance boundary bb8
Dense.c:61:14: note: ***** Analysis failed with vector mode VOID
Dense.c:61:14: missed: splitting region at loop 1 exit at bb16
Dense.c:56:27: note: ***** Analysis failed with vector mode V8SF
Dense.c:56:27: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Dense.c:56:27: missed: splitting region at dominance boundary bb10
Dense.c:56:27: note: ***** Analysis failed with vector mode VOID
Dense.c:72:2: missed: statement clobbers memory: _27 (pretmp_153, _61, 0);
Dense.c:73:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:73:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:158:2: missed: statement clobbers memory: PULSE_Free (_1);
Dense.c:159:2: missed: statement clobbers memory: PULSE_Free (_2);
Dense.c:160:2: missed: statement clobbers memory: PULSE_Free (_3);
Dense.c:161:2: missed: statement clobbers memory: PULSE_Free (_4);
Dense.c:162:2: missed: statement clobbers memory: PULSE_Free (dense_7);
Dense.c:163:2: missed: statement clobbers memory: PULSE_DestroyLayer (this_6(D));
Dense.c:164:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:164:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:178:19: missed: couldn't vectorize loop
Dense.c:178:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:168:13: note: vectorized 0 loops in function.
Dense.c:170:47: missed: statement clobbers memory: dense_30 = malloc (40);
Dense.c:172:36: missed: statement clobbers memory: _1 = PULSE_Alloc2D (64, 4, n_inputs_31(D), n_outputs_32(D), optimization_33(D));
Dense.c:173:38: missed: statement clobbers memory: _2 = PULSE_Alloc2D (64, 4, n_inputs_31(D), n_outputs_32(D), optimization_33(D));
Dense.c:174:36: missed: statement clobbers memory: _3 = PULSE_Alloc (64, 4, n_outputs_32(D), optimization_33(D));
Dense.c:175:35: missed: statement clobbers memory: _4 = PULSE_Alloc (64, 4, n_outputs_32(D), optimization_33(D));
Dense.c:176:36: missed: statement clobbers memory: _5 = PULSE_Alloc (64, 4, n_outputs_32(D), optimization_33(D));
Dense.c:179:39: missed: statement clobbers memory: _6 = rand ();
Dense.c:179:73: missed: statement clobbers memory: _58 = sqrt (_13);
Dense.c:191:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:192:4: missed: statement clobbers memory: exit (1);
Dense.c:188:4: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.3_24, n_outputs.2_23, 1, activation_function_46(D), _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:185:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.1_22, n_outputs.0_21, 1, activation_function_46(D), _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:198:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Dense.c:198:9: note: ***** Analysis failed with vector mode V4DI
Dense.c:198:9: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Activations.c:17:19: optimized: loop vectorized using 32 byte vectors
Activations.c:17:19: optimized: loop vectorized using 16 byte vectors
Activations.c:17:19: optimized: loop vectorized using 32 byte vectors
Activations.c:17:19: optimized: loop vectorized using 16 byte vectors
Activations.c:14:13: note: vectorized 2 loops in function.
Activations.c:14:13: note: ***** Analysis failed with vector mode V8SF
Activations.c:14:13: note: ***** The result for vector mode V32QI would be the same
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V16QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V16QI
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V8QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V8QI
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V4QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V4QI
Activations.c:28:19: missed: couldn't vectorize loop
Activations.c:28:19: missed: not vectorized: unsupported control flow in loop.
Activations.c:28:19: optimized: loop vectorized using 32 byte vectors
Activations.c:28:19: optimized: loop vectorized using 16 byte vectors
Activations.c:25:13: note: vectorized 1 loops in function.
Activations.c:25:13: note: ***** Analysis failed with vector mode V8SF
Activations.c:25:13: note: ***** The result for vector mode V32QI would be the same
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V16QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V16QI
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V8QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V8QI
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V4QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V4QI
Activations.c:38:1: note: ***** Analysis failed with vector mode VOID
Activations.c:5:19: missed: couldn't vectorize loop
Activations.c:9:21: missed: statement clobbers memory: _36 = expf (_18);
Activations.c:5:19: missed: couldn't vectorize loop
Activations.c:9:21: missed: statement clobbers memory: _12 = expf (_11);
Activations.c:3:13: note: vectorized 0 loops in function.
Activations.c:9:21: missed: statement clobbers memory: _12 = expf (_11);
Activations.c:9:21: missed: statement clobbers memory: _36 = expf (_18);
Activations.c:11:1: note: ***** Analysis failed with vector mode V8SF
Activations.c:11:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Activations.c:44:2: note: ***** Analysis failed with vector mode VOID
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:4:18: note: vectorized 0 loops in function.
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_4, inputs_15, _3);
PULSE.c:8:2: missed: statement clobbers memory: _5 (layer_17);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_12, pretmp_26, _9);
PULSE.c:13:28: note: ***** Analysis failed with vector mode V8SI
PULSE.c:13:28: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:22:2: missed: statement clobbers memory: _1 (layer_10(D));
PULSE.c:22:2: missed: statement clobbers memory: _14 (_2);
PULSE.c:22:2: missed: statement clobbers memory: _21 (_15);
PULSE.c:22:2: missed: statement clobbers memory: _28 (_22);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_29);
PULSE.c:26:3: missed: statement clobbers memory: memset (_34, 0, _32);
PULSE.c:26:3: missed: statement clobbers memory: memset (_27, 0, _25);
PULSE.c:26:3: missed: statement clobbers memory: memset (_20, 0, _18);
PULSE.c:26:3: missed: statement clobbers memory: memset (_7, 0, _5);
PULSE.c:28:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:28:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:32:6: note: vectorized 1 loops in function.
PULSE.c:34:8: missed: statement clobbers memory: _1 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_2);
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _9 = rand ();
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8SI
PULSE.c:32:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:61:16: missed: couldn't vectorize loop
PULSE.c:61:16: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:64:17: missed: couldn't vectorize loop
PULSE.c:64:17: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:73:19: missed: couldn't vectorize loop
PULSE.c:73:19: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _64 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:53:22: missed: couldn't vectorize loop
PULSE.c:53:22: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:47:6: note: vectorized 1 loops in function.
PULSE.c:48:1: missed: statement clobbers memory: saved_stack.7_35 = __builtin_stack_save ();
PULSE.c:49:46: missed: statement clobbers memory: _1 = PULSE_GetLossFunctionPtr (loss_function_36(D));
PULSE.c:60:10: missed: statement clobbers memory: random.4_42 = __builtin_alloca_with_align (_4, 32);
PULSE.c:34:8: missed: statement clobbers memory: _56 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_57);
PULSE.c:39:29: missed: statement clobbers memory: _64 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _67 = rand ();
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_93, inputs_88, _92);
PULSE.c:8:2: missed: statement clobbers memory: _94 (layer_89);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_100, _99, _98);
PULSE.c:67:11: missed: statement clobbers memory: loss_51 = PULSE_GetLoss_38 (_17, _16, _12, _11);
PULSE.c:22:2: missed: statement clobbers memory: _81 (output_30);
PULSE.c:22:2: missed: statement clobbers memory: _103 (_82);
PULSE.c:22:2: missed: statement clobbers memory: _110 (_104);
PULSE.c:22:2: missed: statement clobbers memory: _117 (_111);
PULSE.c:22:2: missed: statement clobbers memory: _124 (_118);
PULSE.c:22:2: missed: statement clobbers memory: _131 (_125);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_132);
PULSE.c:26:3: missed: statement clobbers memory: memset (_137, 0, _135);
PULSE.c:26:3: missed: statement clobbers memory: memset (_130, 0, _128);
PULSE.c:26:3: missed: statement clobbers memory: memset (_123, 0, _121);
PULSE.c:26:3: missed: statement clobbers memory: memset (_116, 0, _114);
PULSE.c:26:3: missed: statement clobbers memory: memset (_109, 0, _107);
PULSE.c:26:3: missed: statement clobbers memory: memset (_87, 0, _85);
PULSE.c:75:6: missed: statement clobbers memory: _21 (current_183, args);
PULSE.c:80:4: missed: statement clobbers memory: printf ("Epoch: %d Item: %d Loss: %.10f\r", i_181, j_182, _22);
PULSE.c:47:6: missed: statement clobbers memory: __builtin_stack_restore (saved_stack.7_35);
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4DI
PULSE.c:47:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:89:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:89:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:94:8: missed: couldn't vectorize loop
PULSE.c:94:8: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:91:6: note: vectorized 0 loops in function.
PULSE.c:96:3: missed: statement clobbers memory: _1 (current_10);
PULSE.c:99:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:99:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Loss.c:15:19: optimized: loop vectorized using 32 byte vectors
Loss.c:15:19: optimized:  loop versioned for vectorization because of possible aliasing
Loss.c:15:19: optimized: loop vectorized using 16 byte vectors
Loss.c:12:23: note: vectorized 1 loops in function.
Loss.c:12:23: note: ***** Analysis failed with vector mode V8SF
Loss.c:12:23: note: ***** The result for vector mode V32QI would be the same
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V16QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V16QI
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V8QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V8QI
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V4QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V4QI
Loss.c:7:19: missed: couldn't vectorize loop
Loss.c:8:38: missed: not vectorized: unsupported use in stmt.
Loss.c:4:23: note: vectorized 0 loops in function.
Loss.c:9:13: note: ***** Analysis failed with vector mode V8SF
Loss.c:9:13: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Loss.c:23:2: note: ***** Analysis failed with vector mode VOID
PulseAlloc.c:11:11: missed: statement clobbers memory: _18 = aligned_alloc (64, _8);
PulseAlloc.c:8:28: missed: statement clobbers memory: _20 = aligned_alloc (64, _2);
PulseAlloc.c:16:2: missed: statement clobbers memory: exit (1);
PulseAlloc.c:16:2: note: ***** Analysis failed with vector mode VOID
PulseAlloc.c:30:11: missed: statement clobbers memory: _21 = aligned_alloc (64, _10);
PulseAlloc.c:26:28: missed: statement clobbers memory: _23 = aligned_alloc (64, _3);
PulseAlloc.c:35:2: missed: statement clobbers memory: exit (1);
PulseAlloc.c:35:2: note: ***** Analysis failed with vector mode VOID
Layer.c:7:34: missed: statement clobbers memory: _2 = PULSE_Alloc (64, 4, n_inputs.0_1, optimization_11(D));
Layer.c:8:35: missed: statement clobbers memory: _4 = PULSE_Alloc (64, 4, n_outputs.1_3, optimization_11(D));
Layer.c:9:34: missed: statement clobbers memory: _5 = PULSE_Alloc (64, 4, n_outputs.1_3, optimization_11(D));
Layer.c:14:19: missed: statement clobbers memory: _6 = PULSE_GetActivationFunctionPtr (activation_function_16(D));
Layer.c:19:9: note: ***** Analysis succeeded with vector mode V8SI
Layer.c:19:9: note: SLPing BB part
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x7fac7a8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_15(D);
Layer.c:19:9: note: 	stmt 0 MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_15(D);
Layer.c:19:9: note: 	stmt 1 MEM <unsigned int> [(struct PULSE_Layer *)&<retval> + 4B] = optimization_11(D);
Layer.c:19:9: note: 	children 0x7fac828
Layer.c:19:9: note: node (external) 0x7fac828 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ type_15(D), optimization_11(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x7fac8a8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: <retval>.n_inputs = n_inputs_9(D);
Layer.c:19:9: note: 	stmt 0 <retval>.n_inputs = n_inputs_9(D);
Layer.c:19:9: note: 	stmt 1 <retval>.n_outputs = n_outputs_10(D);
Layer.c:19:9: note: 	children 0x7fac928
Layer.c:19:9: note: node (external) 0x7fac928 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_9(D), n_outputs_10(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x7faca28 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.inputs = _2;
Layer.c:19:9: note: 	stmt 0 <retval>.inputs = _2;
Layer.c:19:9: note: 	stmt 1 <retval>.outputs = _4;
Layer.c:19:9: note: 	children 0x7facaa8
Layer.c:19:9: note: node (external) 0x7facaa8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	stmt 0 _2 = PULSE_Alloc (64, 4, n_inputs.0_1, optimization_11(D));
Layer.c:19:9: note: 	stmt 1 _4 = PULSE_Alloc (64, 4, n_outputs.1_3, optimization_11(D));
Layer.c:19:9: note: 	children 0x7facb28 0x7facba8 0x7facc28 0x7facd28
Layer.c:19:9: note: node (constant) 0x7facb28 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 64, 64 }
Layer.c:19:9: note: node (constant) 0x7facba8 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 4, 4 }
Layer.c:19:9: note: node 0x7facc28 (max_nunits=2, refcnt=1) vector(2) int
Layer.c:19:9: note: op template: n_inputs.0_1 = (int) n_inputs_9(D);
Layer.c:19:9: note: 	stmt 0 n_inputs.0_1 = (int) n_inputs_9(D);
Layer.c:19:9: note: 	stmt 1 n_outputs.1_3 = (int) n_outputs_10(D);
Layer.c:19:9: note: 	children 0x7facca8
Layer.c:19:9: note: node (external) 0x7facca8 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_9(D), n_outputs_10(D) }
Layer.c:19:9: note: node (external) 0x7facd28 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ optimization_11(D), optimization_11(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x7face28 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: op template: <retval>.feed = feed_18(D);
Layer.c:19:9: note: 	stmt 0 <retval>.feed = feed_18(D);
Layer.c:19:9: note: 	stmt 1 <retval>.back = back_19(D);
Layer.c:19:9: note: 	stmt 2 <retval>.fix = fix_20(D);
Layer.c:19:9: note: 	stmt 3 <retval>.destroy = destroy_21(D);
Layer.c:19:9: note: 	children 0x7facea8
Layer.c:19:9: note: node (external) 0x7facea8 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: 	{ feed_18(D), back_19(D), fix_20(D), destroy_21(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 64
  Scalar cost: 64
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x7facfa8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 0 <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 1 <retval>.child = 0B;
Layer.c:19:9: note: 	children 0x7fad028
Layer.c:19:9: note: node (constant) 0x7fad028 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ 0B, 0B }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Basic block will be vectorized using SLP
Layer.c:19:9: optimized: basic block part vectorized using 8 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x7fac7a8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_15(D);
Layer.c:19:9: note: 	stmt 0 MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_15(D);
Layer.c:19:9: note: 	stmt 1 MEM <unsigned int> [(struct PULSE_Layer *)&<retval> + 4B] = optimization_11(D);
Layer.c:19:9: note: 	children 0x7fac828
Layer.c:19:9: note: node (external) 0x7fac828 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ type_15(D), optimization_11(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_15(D);
Layer.c:19:9: note: vect_is_simple_use: operand optimization_11(D), type of def: external
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>]
Layer.c:19:9: note: created &MEM <unsigned int> [(struct PULSE_Layer *)&<retval>]
Layer.c:19:9: note: add new stmt: MEM <vector(2) unsigned int> [(struct PULSE_Layer *)&<retval>] = _38;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 8 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x7fac8a8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: <retval>.n_inputs = n_inputs_9(D);
Layer.c:19:9: note: 	stmt 0 <retval>.n_inputs = n_inputs_9(D);
Layer.c:19:9: note: 	stmt 1 <retval>.n_outputs = n_outputs_10(D);
Layer.c:19:9: note: 	children 0x7fac928
Layer.c:19:9: note: node (external) 0x7fac928 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_9(D), n_outputs_10(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.n_inputs = n_inputs_9(D);
Layer.c:19:9: note: vect_is_simple_use: operand n_outputs_10(D), type of def: external
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: <retval>.n_inputs
Layer.c:19:9: note: created &<retval>.n_inputs
Layer.c:19:9: note: add new stmt: MEM <vector(2) unsigned int> [(unsigned int *)&<retval> + 96B] = _40;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 16 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x7faca28 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.inputs = _2;
Layer.c:19:9: note: 	stmt 0 <retval>.inputs = _2;
Layer.c:19:9: note: 	stmt 1 <retval>.outputs = _4;
Layer.c:19:9: note: 	children 0x7facaa8
Layer.c:19:9: note: node (external) 0x7facaa8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	stmt 0 _2 = PULSE_Alloc (64, 4, n_inputs.0_1, optimization_11(D));
Layer.c:19:9: note: 	stmt 1 _4 = PULSE_Alloc (64, 4, n_outputs.1_3, optimization_11(D));
Layer.c:19:9: note: 	children 0x7facb28 0x7facba8 0x7facc28 0x7facd28
Layer.c:19:9: note: node (constant) 0x7facb28 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 64, 64 }
Layer.c:19:9: note: node (constant) 0x7facba8 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 4, 4 }
Layer.c:19:9: note: node 0x7facc28 (max_nunits=2, refcnt=1) vector(2) int
Layer.c:19:9: note: op template: n_inputs.0_1 = (int) n_inputs_9(D);
Layer.c:19:9: note: 	stmt 0 n_inputs.0_1 = (int) n_inputs_9(D);
Layer.c:19:9: note: 	stmt 1 n_outputs.1_3 = (int) n_outputs_10(D);
Layer.c:19:9: note: 	children 0x7facca8
Layer.c:19:9: note: node (external) 0x7facca8 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_9(D), n_outputs_10(D) }
Layer.c:19:9: note: node (external) 0x7facd28 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ optimization_11(D), optimization_11(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.inputs = _2;
Layer.c:19:9: note: vect_is_simple_use: operand PULSE_Alloc (64, 4, n_outputs.1_3, optimization_11(D)), type of def: internal
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.inputs
Layer.c:19:9: note: created &<retval>.inputs
Layer.c:19:9: note: add new stmt: MEM <vector(2) long unsigned int> [(float * *)&<retval> + 8B] = _44;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 32 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x7face28 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: op template: <retval>.feed = feed_18(D);
Layer.c:19:9: note: 	stmt 0 <retval>.feed = feed_18(D);
Layer.c:19:9: note: 	stmt 1 <retval>.back = back_19(D);
Layer.c:19:9: note: 	stmt 2 <retval>.fix = fix_20(D);
Layer.c:19:9: note: 	stmt 3 <retval>.destroy = destroy_21(D);
Layer.c:19:9: note: 	children 0x7facea8
Layer.c:19:9: note: node (external) 0x7facea8 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: 	{ feed_18(D), back_19(D), fix_20(D), destroy_21(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.feed = feed_18(D);
Layer.c:19:9: note: vect_is_simple_use: operand back_19(D), type of def: external
Layer.c:19:9: note: vect_is_simple_use: operand fix_20(D), type of def: external
Layer.c:19:9: note: vect_is_simple_use: operand destroy_21(D), type of def: external
Layer.c:19:9: note: conflicting alias set types.
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(4) long unsigned int  vectorizing a pointer ref: <retval>.feed
Layer.c:19:9: note: created &<retval>.feed
Layer.c:19:9: note: add new stmt: MEM <vector(4) long unsigned int> [(void *)&<retval> + 32B] = _50;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 16 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x7facfa8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 0 <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 1 <retval>.child = 0B;
Layer.c:19:9: note: 	children 0x7fad028
Layer.c:19:9: note: node (constant) 0x7fad028 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ 0B, 0B }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.parent = 0B;
Layer.c:19:9: note: vect_is_simple_use: operand 0B, type of def: constant
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.parent
Layer.c:19:9: note: created &<retval>.parent
Layer.c:19:9: note: add new stmt: MEM <vector(2) long unsigned int> [(struct PULSE_Layer * *)&<retval> + 72B] = { 0, 0 };
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: note: ***** The result for vector mode V32QI would be the same
Layer.c:24:2: missed: statement clobbers memory: free (_1);
Layer.c:25:2: missed: statement clobbers memory: free (_2);
Layer.c:26:2: missed: statement clobbers memory: free (_3);
Layer.c:27:1: note: ***** Analysis failed with vector mode V4DI
Layer.c:27:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:7:27: missed: couldn't vectorize loop
Dense.c:7:27: missed: not vectorized: unsupported outerloop form.
Dense.c:10:20: missed: couldn't vectorize loop
Dense.c:11:21: missed: not vectorized: complicated access pattern.
Dense.c:4:13: note: vectorized 0 loops in function.
Dense.c:14:2: missed: statement clobbers memory: _30 (pretmp_91, _50, 0);
Dense.c:7:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:7:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:7:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:7:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:7:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:7:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:7:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:7:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:22:27: missed: couldn't vectorize loop
Dense.c:22:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:26:20: optimized: loop vectorized using 32 byte vectors
Dense.c:26:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:26:20: optimized: loop vectorized using 16 byte vectors
Dense.c:26:20: missed: couldn't vectorize loop
Dense.c:28:20: missed: not vectorized: no vectype for stmt: _21 = *_20;
 scalar_type: float
Dense.c:18:13: note: vectorized 1 loops in function.
Dense.c:21:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:22:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:22:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:22:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:22:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:22:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:22:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:22:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:22:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:39:28: missed: couldn't vectorize loop
Dense.c:39:28: missed: not vectorized: unsupported outerloop form.
Dense.c:43:21: optimized: loop vectorized using 32 byte vectors
Dense.c:43:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:43:21: optimized: loop vectorized using 16 byte vectors
Dense.c:35:13: note: vectorized 1 loops in function.
Dense.c:35:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:35:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:35:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:35:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:35:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:35:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:35:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:39:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:143:19: missed: couldn't vectorize loop
Dense.c:143:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:134:19: missed: couldn't vectorize loop
Dense.c:134:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:127:13: note: vectorized 0 loops in function.
Dense.c:151:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:151:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:96:28: missed: couldn't vectorize loop
Dense.c:96:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:99:21: missed: couldn't vectorize loop
Dense.c:99:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:113:28: missed: couldn't vectorize loop
Dense.c:113:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:116:21: missed: couldn't vectorize loop
Dense.c:116:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:82:19: missed: couldn't vectorize loop
Dense.c:82:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:76:13: note: vectorized 0 loops in function.
Dense.c:79:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:101:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:101:17: note: SLPing BB part
Dense.c:118:17: note: Costing subgraph: 
Dense.c:118:17: note: node 0x8aeb198 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:118:17: note: op template: _49 = (sizetype) j_137;
Dense.c:118:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:118:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:118:17: note: 	children 0x8aeb298
Dense.c:118:17: note: node (external) 0x8aeb298 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:118:17: note: 	{ j_137, wi_136 }
Dense.c:118:17: note: Cost model analysis: 
Dense.c:118:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:118:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:118:17: missed: not vectorized: vectorization is not profitable.
Dense.c:101:17: note: Costing subgraph: 
Dense.c:101:17: note: node 0x8aeb398 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:101:17: note: op template: _24 = (sizetype) j_134;
Dense.c:101:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:101:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:101:17: note: 	children 0x8aeb498
Dense.c:101:17: note: node (external) 0x8aeb498 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:101:17: note: 	{ j_134, wi_133 }
Dense.c:101:17: note: Cost model analysis: 
Dense.c:101:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:101:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:101:17: missed: not vectorized: vectorization is not profitable.
Dense.c:101:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:101:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:101:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:101:17: note: SLPing BB part
Dense.c:118:17: note: Costing subgraph: 
Dense.c:118:17: note: node 0x8aeb398 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:118:17: note: op template: _49 = (sizetype) j_137;
Dense.c:118:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:118:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:118:17: note: 	children 0x8aeb198
Dense.c:118:17: note: node (external) 0x8aeb198 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:118:17: note: 	{ j_137, wi_136 }
Dense.c:118:17: note: Cost model analysis: 
Dense.c:118:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:118:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:118:17: missed: not vectorized: vectorization is not profitable.
Dense.c:101:17: note: Costing subgraph: 
Dense.c:101:17: note: node 0x8aeb518 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:101:17: note: op template: _24 = (sizetype) j_134;
Dense.c:101:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:101:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:101:17: note: 	children 0x8aeb418
Dense.c:101:17: note: node (external) 0x8aeb418 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:101:17: note: 	{ j_134, wi_133 }
Dense.c:101:17: note: Cost model analysis: 
Dense.c:101:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:101:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:101:17: missed: not vectorized: vectorization is not profitable.
Dense.c:101:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:96:55: note: ***** Analysis failed with vector mode V8QI
Dense.c:96:55: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:96:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:56:27: missed: couldn't vectorize loop
Dense.c:56:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:59:20: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:905:10: missed: not vectorized: no vectype for stmt: _41 = MEM[(__m256_u * {ref-all})_6];
 scalar_type: __m256_u
Dense.c:59:20: note: ***** Analysis failed with vector mode VOID
Dense.c:52:13: note: vectorized 0 loops in function.
Dense.c:52:13: missed: splitting region at dont-vectorize loop 3 entry at bb18
Dense.c:61:14: note: ***** Analysis failed with vector mode V4DI
Dense.c:61:14: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:61:14: missed: splitting region at dominance boundary bb8
Dense.c:61:14: note: ***** Analysis failed with vector mode VOID
Dense.c:61:14: missed: splitting region at loop 1 exit at bb16
Dense.c:56:27: note: ***** Analysis failed with vector mode V8SF
Dense.c:56:27: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Dense.c:56:27: missed: splitting region at dominance boundary bb10
Dense.c:56:27: note: ***** Analysis failed with vector mode VOID
Dense.c:72:2: missed: statement clobbers memory: _27 (pretmp_153, _61, 0);
Dense.c:73:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:73:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:158:2: missed: statement clobbers memory: PULSE_Free (_1);
Dense.c:159:2: missed: statement clobbers memory: PULSE_Free (_2);
Dense.c:160:2: missed: statement clobbers memory: PULSE_Free (_3);
Dense.c:161:2: missed: statement clobbers memory: PULSE_Free (_4);
Dense.c:162:2: missed: statement clobbers memory: PULSE_Free (dense_7);
Dense.c:163:2: missed: statement clobbers memory: PULSE_DestroyLayer (this_6(D));
Dense.c:164:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:164:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:178:19: missed: couldn't vectorize loop
Dense.c:178:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:168:13: note: vectorized 0 loops in function.
Dense.c:170:47: missed: statement clobbers memory: dense_30 = malloc (40);
Dense.c:172:36: missed: statement clobbers memory: _1 = PULSE_Alloc2D (64, 4, n_inputs_31(D), n_outputs_32(D), optimization_33(D));
Dense.c:173:38: missed: statement clobbers memory: _2 = PULSE_Alloc2D (64, 4, n_inputs_31(D), n_outputs_32(D), optimization_33(D));
Dense.c:174:36: missed: statement clobbers memory: _3 = PULSE_Alloc (64, 4, n_outputs_32(D), optimization_33(D));
Dense.c:175:35: missed: statement clobbers memory: _4 = PULSE_Alloc (64, 4, n_outputs_32(D), optimization_33(D));
Dense.c:176:36: missed: statement clobbers memory: _5 = PULSE_Alloc (64, 4, n_outputs_32(D), optimization_33(D));
Dense.c:179:39: missed: statement clobbers memory: _6 = rand ();
Dense.c:179:73: missed: statement clobbers memory: _58 = sqrt (_13);
Dense.c:191:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:192:4: missed: statement clobbers memory: exit (1);
Dense.c:188:4: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.3_24, n_outputs.2_23, 1, activation_function_46(D), _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:185:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.1_22, n_outputs.0_21, 1, activation_function_46(D), _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:198:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Dense.c:198:9: note: ***** Analysis failed with vector mode V4DI
Dense.c:198:9: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Activations.c:17:19: optimized: loop vectorized using 32 byte vectors
Activations.c:17:19: optimized: loop vectorized using 16 byte vectors
Activations.c:17:19: optimized: loop vectorized using 32 byte vectors
Activations.c:17:19: optimized: loop vectorized using 16 byte vectors
Activations.c:14:13: note: vectorized 2 loops in function.
Activations.c:14:13: note: ***** Analysis failed with vector mode V8SF
Activations.c:14:13: note: ***** The result for vector mode V32QI would be the same
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V16QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V16QI
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V8QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V8QI
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V4QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V4QI
Activations.c:28:19: missed: couldn't vectorize loop
Activations.c:28:19: missed: not vectorized: unsupported control flow in loop.
Activations.c:28:19: optimized: loop vectorized using 32 byte vectors
Activations.c:28:19: optimized: loop vectorized using 16 byte vectors
Activations.c:25:13: note: vectorized 1 loops in function.
Activations.c:25:13: note: ***** Analysis failed with vector mode V8SF
Activations.c:25:13: note: ***** The result for vector mode V32QI would be the same
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V16QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V16QI
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V8QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V8QI
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V4QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V4QI
Activations.c:38:1: note: ***** Analysis failed with vector mode VOID
Activations.c:5:19: missed: couldn't vectorize loop
Activations.c:9:21: missed: statement clobbers memory: _36 = expf (_18);
Activations.c:5:19: missed: couldn't vectorize loop
Activations.c:9:21: missed: statement clobbers memory: _12 = expf (_11);
Activations.c:3:13: note: vectorized 0 loops in function.
Activations.c:9:21: missed: statement clobbers memory: _12 = expf (_11);
Activations.c:9:21: missed: statement clobbers memory: _36 = expf (_18);
Activations.c:11:1: note: ***** Analysis failed with vector mode V8SF
Activations.c:11:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Activations.c:44:2: note: ***** Analysis failed with vector mode VOID
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:4:18: note: vectorized 0 loops in function.
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_4, inputs_15, _3);
PULSE.c:8:2: missed: statement clobbers memory: _5 (layer_17);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_12, pretmp_26, _9);
PULSE.c:13:28: note: ***** Analysis failed with vector mode V8SI
PULSE.c:13:28: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:22:2: missed: statement clobbers memory: _1 (layer_10(D));
PULSE.c:22:2: missed: statement clobbers memory: _14 (_2);
PULSE.c:22:2: missed: statement clobbers memory: _21 (_15);
PULSE.c:22:2: missed: statement clobbers memory: _28 (_22);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_29);
PULSE.c:26:3: missed: statement clobbers memory: memset (_34, 0, _32);
PULSE.c:26:3: missed: statement clobbers memory: memset (_27, 0, _25);
PULSE.c:26:3: missed: statement clobbers memory: memset (_20, 0, _18);
PULSE.c:26:3: missed: statement clobbers memory: memset (_7, 0, _5);
PULSE.c:28:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:28:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:32:6: note: vectorized 1 loops in function.
PULSE.c:34:8: missed: statement clobbers memory: _1 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_2);
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _9 = rand ();
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8SI
PULSE.c:32:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:61:16: missed: couldn't vectorize loop
PULSE.c:61:16: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:64:17: missed: couldn't vectorize loop
PULSE.c:64:17: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:73:19: missed: couldn't vectorize loop
PULSE.c:73:19: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _64 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:53:22: missed: couldn't vectorize loop
PULSE.c:53:22: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:47:6: note: vectorized 1 loops in function.
PULSE.c:48:1: missed: statement clobbers memory: saved_stack.7_35 = __builtin_stack_save ();
PULSE.c:49:46: missed: statement clobbers memory: _1 = PULSE_GetLossFunctionPtr (loss_function_36(D));
PULSE.c:60:10: missed: statement clobbers memory: random.4_42 = __builtin_alloca_with_align (_4, 32);
PULSE.c:34:8: missed: statement clobbers memory: _56 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_57);
PULSE.c:39:29: missed: statement clobbers memory: _64 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _67 = rand ();
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_93, inputs_88, _92);
PULSE.c:8:2: missed: statement clobbers memory: _94 (layer_89);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_100, _99, _98);
PULSE.c:67:11: missed: statement clobbers memory: loss_51 = PULSE_GetLoss_38 (_17, _16, _12, _11);
PULSE.c:22:2: missed: statement clobbers memory: _81 (output_30);
PULSE.c:22:2: missed: statement clobbers memory: _103 (_82);
PULSE.c:22:2: missed: statement clobbers memory: _110 (_104);
PULSE.c:22:2: missed: statement clobbers memory: _117 (_111);
PULSE.c:22:2: missed: statement clobbers memory: _124 (_118);
PULSE.c:22:2: missed: statement clobbers memory: _131 (_125);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_132);
PULSE.c:26:3: missed: statement clobbers memory: memset (_137, 0, _135);
PULSE.c:26:3: missed: statement clobbers memory: memset (_130, 0, _128);
PULSE.c:26:3: missed: statement clobbers memory: memset (_123, 0, _121);
PULSE.c:26:3: missed: statement clobbers memory: memset (_116, 0, _114);
PULSE.c:26:3: missed: statement clobbers memory: memset (_109, 0, _107);
PULSE.c:26:3: missed: statement clobbers memory: memset (_87, 0, _85);
PULSE.c:75:6: missed: statement clobbers memory: _21 (current_183, args);
PULSE.c:80:4: missed: statement clobbers memory: printf ("Epoch: %d Item: %d Loss: %.10f\r", i_181, j_182, _22);
PULSE.c:47:6: missed: statement clobbers memory: __builtin_stack_restore (saved_stack.7_35);
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4DI
PULSE.c:47:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:89:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:89:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:94:8: missed: couldn't vectorize loop
PULSE.c:94:8: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:91:6: note: vectorized 0 loops in function.
PULSE.c:96:3: missed: statement clobbers memory: _1 (current_10);
PULSE.c:99:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:99:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Loss.c:15:19: optimized: loop vectorized using 32 byte vectors
Loss.c:15:19: optimized:  loop versioned for vectorization because of possible aliasing
Loss.c:15:19: optimized: loop vectorized using 16 byte vectors
Loss.c:12:23: note: vectorized 1 loops in function.
Loss.c:12:23: note: ***** Analysis failed with vector mode V8SF
Loss.c:12:23: note: ***** The result for vector mode V32QI would be the same
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V16QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V16QI
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V8QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V8QI
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V4QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V4QI
Loss.c:7:19: missed: couldn't vectorize loop
Loss.c:8:38: missed: not vectorized: unsupported use in stmt.
Loss.c:4:23: note: vectorized 0 loops in function.
Loss.c:9:13: note: ***** Analysis failed with vector mode V8SF
Loss.c:9:13: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Loss.c:23:2: note: ***** Analysis failed with vector mode VOID
Include/PulseAlloc.h:13:11: missed: statement clobbers memory: _18 = aligned_alloc (64, _8);
Include/PulseAlloc.h:10:28: missed: statement clobbers memory: _20 = aligned_alloc (64, _2);
Include/PulseAlloc.h:18:2: missed: statement clobbers memory: exit (1);
Include/PulseAlloc.h:18:2: note: ***** Analysis failed with vector mode VOID
Include/PulseAlloc.h:32:11: missed: statement clobbers memory: _21 = aligned_alloc (64, _10);
Include/PulseAlloc.h:28:28: missed: statement clobbers memory: _23 = aligned_alloc (64, _3);
Include/PulseAlloc.h:37:2: missed: statement clobbers memory: exit (1);
Include/PulseAlloc.h:37:2: note: ***** Analysis failed with vector mode VOID
Include/PulseAlloc.h:13:11: missed: statement clobbers memory: _75 = aligned_alloc (64, _74);
Include/PulseAlloc.h:13:11: missed: statement clobbers memory: _3 = aligned_alloc (64, _76);
Include/PulseAlloc.h:13:11: missed: statement clobbers memory: _14 = aligned_alloc (64, _91);
Include/PulseAlloc.h:13:11: missed: statement clobbers memory: _49 = aligned_alloc (64, prephitmp_83);
Include/PulseAlloc.h:10:28: missed: statement clobbers memory: _66 = aligned_alloc (64, _65);
Include/PulseAlloc.h:10:28: missed: statement clobbers memory: _53 = aligned_alloc (64, _52);
Include/PulseAlloc.h:10:28: missed: statement clobbers memory: _40 = aligned_alloc (64, _52);
Layer.c:14:19: missed: statement clobbers memory: _6 = PULSE_GetActivationFunctionPtr (activation_function_16(D));
Include/PulseAlloc.h:18:2: missed: statement clobbers memory: exit (1);
Layer.c:19:9: note: ***** Analysis succeeded with vector mode V8SI
Layer.c:19:9: note: SLPing BB part
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x730f398 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_15(D);
Layer.c:19:9: note: 	stmt 0 MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_15(D);
Layer.c:19:9: note: 	stmt 1 MEM <unsigned int> [(struct PULSE_Layer *)&<retval> + 4B] = optimization_11(D);
Layer.c:19:9: note: 	children 0x730f418
Layer.c:19:9: note: node (external) 0x730f418 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ type_15(D), optimization_11(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x730f498 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: <retval>.n_inputs = n_inputs_9(D);
Layer.c:19:9: note: 	stmt 0 <retval>.n_inputs = n_inputs_9(D);
Layer.c:19:9: note: 	stmt 1 <retval>.n_outputs = n_outputs_10(D);
Layer.c:19:9: note: 	children 0x730f518
Layer.c:19:9: note: node (external) 0x730f518 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_9(D), n_outputs_10(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x730f618 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.inputs = _94;
Layer.c:19:9: note: 	stmt 0 <retval>.inputs = _94;
Layer.c:19:9: note: 	stmt 1 <retval>.outputs = _93;
Layer.c:19:9: note: 	children 0x730f698
Layer.c:19:9: note: node 0x730f698 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: _94 = PHI <_66(3), _75(9)>
Layer.c:19:9: note: 	stmt 0 _94 = PHI <_66(3), _75(9)>
Layer.c:19:9: note: 	stmt 1 _93 = PHI <_53(3), _96(9)>
Layer.c:19:9: note: 	children 0x730f718 0x730fb18
Layer.c:19:9: note: node (external) 0x730f718 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	stmt 0 _66 = aligned_alloc (64, _65);
Layer.c:19:9: note: 	stmt 1 _53 = aligned_alloc (64, _52);
Layer.c:19:9: note: 	children 0x730f798 0x730f818
Layer.c:19:9: note: node (constant) 0x730f798 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 64, 64 }
Layer.c:19:9: note: node 0x730f818 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: _65 = (long unsigned int) _64;
Layer.c:19:9: note: 	stmt 0 _65 = (long unsigned int) _64;
Layer.c:19:9: note: 	stmt 1 _52 = (long unsigned int) _51;
Layer.c:19:9: note: 	children 0x730f898
Layer.c:19:9: note: node 0x730f898 (max_nunits=2, refcnt=1) vector(2) int
Layer.c:19:9: note: op template: _64 = n_inputs.2_1 * 4;
Layer.c:19:9: note: 	stmt 0 _64 = n_inputs.2_1 * 4;
Layer.c:19:9: note: 	stmt 1 _51 = n_outputs.3_87 * 4;
Layer.c:19:9: note: 	children 0x730f918 0x730fa18
Layer.c:19:9: note: node 0x730f918 (max_nunits=2, refcnt=1) vector(2) int
Layer.c:19:9: note: op template: n_inputs.2_1 = (int) n_inputs_9(D);
Layer.c:19:9: note: 	stmt 0 n_inputs.2_1 = (int) n_inputs_9(D);
Layer.c:19:9: note: 	stmt 1 n_outputs.3_87 = (int) n_outputs_10(D);
Layer.c:19:9: note: 	children 0x730f998
Layer.c:19:9: note: node (external) 0x730f998 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_9(D), n_outputs_10(D) }
Layer.c:19:9: note: node (constant) 0x730fa18 (max_nunits=1, refcnt=1) vector(2) int
Layer.c:19:9: note: 	{ 4, 4 }
Layer.c:19:9: note: node (external) 0x730fb18 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ _75, _96 }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 52
  Scalar cost: 40
Layer.c:19:9: missed: not vectorized: vectorization is not profitable.
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x730fc18 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: op template: <retval>.feed = feed_18(D);
Layer.c:19:9: note: 	stmt 0 <retval>.feed = feed_18(D);
Layer.c:19:9: note: 	stmt 1 <retval>.back = back_19(D);
Layer.c:19:9: note: 	stmt 2 <retval>.fix = fix_20(D);
Layer.c:19:9: note: 	stmt 3 <retval>.destroy = destroy_21(D);
Layer.c:19:9: note: 	children 0x730fc98
Layer.c:19:9: note: node (external) 0x730fc98 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: 	{ feed_18(D), back_19(D), fix_20(D), destroy_21(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 64
  Scalar cost: 64
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x730fd98 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 0 <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 1 <retval>.child = 0B;
Layer.c:19:9: note: 	children 0x730fe18
Layer.c:19:9: note: node (constant) 0x730fe18 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ 0B, 0B }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Basic block will be vectorized using SLP
Layer.c:19:9: optimized: basic block part vectorized using 8 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x730f398 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_15(D);
Layer.c:19:9: note: 	stmt 0 MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_15(D);
Layer.c:19:9: note: 	stmt 1 MEM <unsigned int> [(struct PULSE_Layer *)&<retval> + 4B] = optimization_11(D);
Layer.c:19:9: note: 	children 0x730f418
Layer.c:19:9: note: node (external) 0x730f418 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ type_15(D), optimization_11(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_15(D);
Layer.c:19:9: note: vect_is_simple_use: operand optimization_11(D), type of def: external
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>]
Layer.c:19:9: note: created &MEM <unsigned int> [(struct PULSE_Layer *)&<retval>]
Layer.c:19:9: note: add new stmt: MEM <vector(2) unsigned int> [(struct PULSE_Layer *)&<retval>] = _59;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 8 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x730f498 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: <retval>.n_inputs = n_inputs_9(D);
Layer.c:19:9: note: 	stmt 0 <retval>.n_inputs = n_inputs_9(D);
Layer.c:19:9: note: 	stmt 1 <retval>.n_outputs = n_outputs_10(D);
Layer.c:19:9: note: 	children 0x730f518
Layer.c:19:9: note: node (external) 0x730f518 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_9(D), n_outputs_10(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.n_inputs = n_inputs_9(D);
Layer.c:19:9: note: vect_is_simple_use: operand n_outputs_10(D), type of def: external
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: <retval>.n_inputs
Layer.c:19:9: note: created &<retval>.n_inputs
Layer.c:19:9: note: add new stmt: MEM <vector(2) unsigned int> [(unsigned int *)&<retval> + 96B] = _42;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 32 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x730fc18 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: op template: <retval>.feed = feed_18(D);
Layer.c:19:9: note: 	stmt 0 <retval>.feed = feed_18(D);
Layer.c:19:9: note: 	stmt 1 <retval>.back = back_19(D);
Layer.c:19:9: note: 	stmt 2 <retval>.fix = fix_20(D);
Layer.c:19:9: note: 	stmt 3 <retval>.destroy = destroy_21(D);
Layer.c:19:9: note: 	children 0x730fc98
Layer.c:19:9: note: node (external) 0x730fc98 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: 	{ feed_18(D), back_19(D), fix_20(D), destroy_21(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.feed = feed_18(D);
Layer.c:19:9: note: vect_is_simple_use: operand back_19(D), type of def: external
Layer.c:19:9: note: vect_is_simple_use: operand fix_20(D), type of def: external
Layer.c:19:9: note: vect_is_simple_use: operand destroy_21(D), type of def: external
Layer.c:19:9: note: conflicting alias set types.
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(4) long unsigned int  vectorizing a pointer ref: <retval>.feed
Layer.c:19:9: note: created &<retval>.feed
Layer.c:19:9: note: add new stmt: MEM <vector(4) long unsigned int> [(void *)&<retval> + 32B] = _102;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 16 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x730fd98 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 0 <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 1 <retval>.child = 0B;
Layer.c:19:9: note: 	children 0x730fe18
Layer.c:19:9: note: node (constant) 0x730fe18 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ 0B, 0B }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.parent = 0B;
Layer.c:19:9: note: vect_is_simple_use: operand 0B, type of def: constant
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.parent
Layer.c:19:9: note: created &<retval>.parent
Layer.c:19:9: note: add new stmt: MEM <vector(2) long unsigned int> [(struct PULSE_Layer * *)&<retval> + 72B] = { 0, 0 };
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: note: ***** The result for vector mode V32QI would be the same
Layer.c:24:2: missed: statement clobbers memory: free (_1);
Layer.c:25:2: missed: statement clobbers memory: free (_2);
Layer.c:26:2: missed: statement clobbers memory: free (_3);
Layer.c:27:1: note: ***** Analysis failed with vector mode V4DI
Layer.c:27:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:7:27: missed: couldn't vectorize loop
Dense.c:7:27: missed: not vectorized: unsupported outerloop form.
Dense.c:10:20: missed: couldn't vectorize loop
Dense.c:11:21: missed: not vectorized: complicated access pattern.
Dense.c:4:13: note: vectorized 0 loops in function.
Dense.c:14:2: missed: statement clobbers memory: _30 (pretmp_91, _50, 0);
Dense.c:7:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:7:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:7:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:7:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:7:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:7:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:7:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:7:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:22:27: missed: couldn't vectorize loop
Dense.c:22:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:26:20: optimized: loop vectorized using 32 byte vectors
Dense.c:26:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:26:20: optimized: loop vectorized using 16 byte vectors
Dense.c:26:20: missed: couldn't vectorize loop
Dense.c:28:20: missed: not vectorized: no vectype for stmt: _21 = *_20;
 scalar_type: float
Dense.c:18:13: note: vectorized 1 loops in function.
Dense.c:21:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:22:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:22:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:22:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:22:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:22:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:22:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:22:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:22:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:39:28: missed: couldn't vectorize loop
Dense.c:39:28: missed: not vectorized: unsupported outerloop form.
Dense.c:43:21: optimized: loop vectorized using 32 byte vectors
Dense.c:43:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:43:21: optimized: loop vectorized using 16 byte vectors
Dense.c:35:13: note: vectorized 1 loops in function.
Dense.c:35:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:35:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:35:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:35:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:35:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:35:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:35:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:39:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:143:19: missed: couldn't vectorize loop
Dense.c:143:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:134:19: missed: couldn't vectorize loop
Dense.c:134:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:127:13: note: vectorized 0 loops in function.
Dense.c:151:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:151:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:96:28: missed: couldn't vectorize loop
Dense.c:96:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:99:21: missed: couldn't vectorize loop
Dense.c:99:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:113:28: missed: couldn't vectorize loop
Dense.c:113:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:116:21: missed: couldn't vectorize loop
Dense.c:116:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:82:19: missed: couldn't vectorize loop
Dense.c:82:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:76:13: note: vectorized 0 loops in function.
Dense.c:79:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:101:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:101:17: note: SLPing BB part
Dense.c:118:17: note: Costing subgraph: 
Dense.c:118:17: note: node 0x7ac1458 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:118:17: note: op template: _49 = (sizetype) j_137;
Dense.c:118:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:118:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:118:17: note: 	children 0x7ac1558
Dense.c:118:17: note: node (external) 0x7ac1558 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:118:17: note: 	{ j_137, wi_136 }
Dense.c:118:17: note: Cost model analysis: 
Dense.c:118:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:118:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:118:17: missed: not vectorized: vectorization is not profitable.
Dense.c:101:17: note: Costing subgraph: 
Dense.c:101:17: note: node 0x7ac1658 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:101:17: note: op template: _24 = (sizetype) j_134;
Dense.c:101:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:101:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:101:17: note: 	children 0x7ac1758
Dense.c:101:17: note: node (external) 0x7ac1758 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:101:17: note: 	{ j_134, wi_133 }
Dense.c:101:17: note: Cost model analysis: 
Dense.c:101:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:101:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:101:17: missed: not vectorized: vectorization is not profitable.
Dense.c:101:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:101:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:101:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:101:17: note: SLPing BB part
Dense.c:118:17: note: Costing subgraph: 
Dense.c:118:17: note: node 0x7ac1658 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:118:17: note: op template: _49 = (sizetype) j_137;
Dense.c:118:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:118:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:118:17: note: 	children 0x7ac1458
Dense.c:118:17: note: node (external) 0x7ac1458 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:118:17: note: 	{ j_137, wi_136 }
Dense.c:118:17: note: Cost model analysis: 
Dense.c:118:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:118:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:118:17: missed: not vectorized: vectorization is not profitable.
Dense.c:101:17: note: Costing subgraph: 
Dense.c:101:17: note: node 0x7ac17d8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:101:17: note: op template: _24 = (sizetype) j_134;
Dense.c:101:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:101:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:101:17: note: 	children 0x7ac16d8
Dense.c:101:17: note: node (external) 0x7ac16d8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:101:17: note: 	{ j_134, wi_133 }
Dense.c:101:17: note: Cost model analysis: 
Dense.c:101:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:101:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:101:17: missed: not vectorized: vectorization is not profitable.
Dense.c:101:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:96:55: note: ***** Analysis failed with vector mode V8QI
Dense.c:96:55: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:96:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:56:27: missed: couldn't vectorize loop
Dense.c:56:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:59:20: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:905:10: missed: not vectorized: no vectype for stmt: _41 = MEM[(__m256_u * {ref-all})_6];
 scalar_type: __m256_u
Dense.c:59:20: note: ***** Analysis failed with vector mode VOID
Dense.c:52:13: note: vectorized 0 loops in function.
Dense.c:52:13: missed: splitting region at dont-vectorize loop 3 entry at bb18
Dense.c:61:14: note: ***** Analysis failed with vector mode V4DI
Dense.c:61:14: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:61:14: missed: splitting region at dominance boundary bb8
Dense.c:61:14: note: ***** Analysis failed with vector mode VOID
Dense.c:61:14: missed: splitting region at loop 1 exit at bb16
Dense.c:56:27: note: ***** Analysis failed with vector mode V8SF
Dense.c:56:27: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Dense.c:56:27: missed: splitting region at dominance boundary bb10
Dense.c:56:27: note: ***** Analysis failed with vector mode VOID
Dense.c:72:2: missed: statement clobbers memory: _27 (pretmp_153, _61, 0);
Dense.c:73:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:73:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Include/PulseAlloc.h:41:37: missed: statement clobbers memory: free (_1);
Include/PulseAlloc.h:41:37: missed: statement clobbers memory: free (_2);
Include/PulseAlloc.h:41:37: missed: statement clobbers memory: free (_3);
Include/PulseAlloc.h:41:37: missed: statement clobbers memory: free (_4);
Include/PulseAlloc.h:41:37: missed: statement clobbers memory: free (dense_7);
Dense.c:163:2: missed: statement clobbers memory: PULSE_DestroyLayer (this_6(D));
Dense.c:164:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:164:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Include/PulseAlloc.h:13:11: missed: statement clobbers memory: _18 = aligned_alloc (64, _8);
Include/PulseAlloc.h:10:28: missed: statement clobbers memory: _20 = aligned_alloc (64, _2);
Include/PulseAlloc.h:18:2: missed: statement clobbers memory: exit (1);
Include/PulseAlloc.h:18:2: note: ***** Analysis failed with vector mode VOID
Include/PulseAlloc.h:32:11: missed: statement clobbers memory: _21 = aligned_alloc (64, _10);
Include/PulseAlloc.h:28:28: missed: statement clobbers memory: _23 = aligned_alloc (64, _3);
Include/PulseAlloc.h:37:2: missed: statement clobbers memory: exit (1);
Include/PulseAlloc.h:37:2: note: ***** Analysis failed with vector mode VOID
Dense.c:178:19: missed: couldn't vectorize loop
Dense.c:178:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:168:13: note: vectorized 0 loops in function.
Dense.c:170:47: missed: statement clobbers memory: dense_30 = malloc (40);
Include/PulseAlloc.h:32:11: missed: statement clobbers memory: _187 = aligned_alloc (64, _185);
Include/PulseAlloc.h:32:11: missed: statement clobbers memory: _177 = aligned_alloc (64, _175);
Include/PulseAlloc.h:32:11: missed: statement clobbers memory: _108 = aligned_alloc (64, prephitmp_182);
Include/PulseAlloc.h:13:11: missed: statement clobbers memory: _140 = aligned_alloc (64, _148);
Include/PulseAlloc.h:13:11: missed: statement clobbers memory: _109 = aligned_alloc (64, _148);
Include/PulseAlloc.h:13:11: missed: statement clobbers memory: _167 = aligned_alloc (64, _165);
Include/PulseAlloc.h:13:11: missed: statement clobbers memory: _157 = aligned_alloc (64, _165);
Include/PulseAlloc.h:13:11: missed: statement clobbers memory: _67 = aligned_alloc (64, prephitmp_171);
Include/PulseAlloc.h:28:28: missed: statement clobbers memory: _113 = aligned_alloc (64, _112);
Include/PulseAlloc.h:28:28: missed: statement clobbers memory: _98 = aligned_alloc (64, _112);
Include/PulseAlloc.h:10:28: missed: statement clobbers memory: _84 = aligned_alloc (64, _83);
Include/PulseAlloc.h:10:28: missed: statement clobbers memory: _71 = aligned_alloc (64, _83);
Include/PulseAlloc.h:10:28: missed: statement clobbers memory: _58 = aligned_alloc (64, _83);
Dense.c:179:39: missed: statement clobbers memory: _6 = rand ();
Dense.c:179:73: missed: statement clobbers memory: _45 = sqrt (_13);
Dense.c:185:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (_161, _162, 1, activation_function_46(D), _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:188:4: missed: statement clobbers memory: layer = PULSE_CreateLayer (_161, _162, 1, activation_function_46(D), _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:198:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Include/PulseAlloc.h:37:2: missed: statement clobbers memory: exit (1);
Include/PulseAlloc.h:37:2: note: ***** Analysis failed with vector mode V4DI
Include/PulseAlloc.h:37:2: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Activations.c:17:19: optimized: loop vectorized using 32 byte vectors
Activations.c:17:19: optimized: loop vectorized using 16 byte vectors
Activations.c:17:19: optimized: loop vectorized using 32 byte vectors
Activations.c:17:19: optimized: loop vectorized using 16 byte vectors
Activations.c:14:13: note: vectorized 2 loops in function.
Activations.c:14:13: note: ***** Analysis failed with vector mode V8SF
Activations.c:14:13: note: ***** The result for vector mode V32QI would be the same
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V16QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V16QI
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V8QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V8QI
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V4QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V4QI
Activations.c:28:19: missed: couldn't vectorize loop
Activations.c:28:19: missed: not vectorized: unsupported control flow in loop.
Activations.c:28:19: optimized: loop vectorized using 32 byte vectors
Activations.c:28:19: optimized: loop vectorized using 16 byte vectors
Activations.c:25:13: note: vectorized 1 loops in function.
Activations.c:25:13: note: ***** Analysis failed with vector mode V8SF
Activations.c:25:13: note: ***** The result for vector mode V32QI would be the same
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V16QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V16QI
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V8QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V8QI
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V4QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V4QI
Activations.c:38:1: note: ***** Analysis failed with vector mode VOID
Activations.c:5:19: missed: couldn't vectorize loop
Activations.c:9:21: missed: statement clobbers memory: _36 = expf (_18);
Activations.c:5:19: missed: couldn't vectorize loop
Activations.c:9:21: missed: statement clobbers memory: _12 = expf (_11);
Activations.c:3:13: note: vectorized 0 loops in function.
Activations.c:9:21: missed: statement clobbers memory: _12 = expf (_11);
Activations.c:9:21: missed: statement clobbers memory: _36 = expf (_18);
Activations.c:11:1: note: ***** Analysis failed with vector mode V8SF
Activations.c:11:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Activations.c:44:2: note: ***** Analysis failed with vector mode VOID
Include/PulseAlloc.h:13:11: missed: statement clobbers memory: _18 = aligned_alloc (64, _8);
Include/PulseAlloc.h:10:28: missed: statement clobbers memory: _20 = aligned_alloc (64, _2);
Include/PulseAlloc.h:18:2: missed: statement clobbers memory: exit (1);
Include/PulseAlloc.h:18:2: note: ***** Analysis failed with vector mode VOID
Include/PulseAlloc.h:32:11: missed: statement clobbers memory: _21 = aligned_alloc (64, _10);
Include/PulseAlloc.h:28:28: missed: statement clobbers memory: _23 = aligned_alloc (64, _3);
Include/PulseAlloc.h:37:2: missed: statement clobbers memory: exit (1);
Include/PulseAlloc.h:37:2: note: ***** Analysis failed with vector mode VOID
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:4:18: note: vectorized 0 loops in function.
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_4, inputs_15, _3);
PULSE.c:8:2: missed: statement clobbers memory: _5 (layer_17);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_12, pretmp_26, _9);
PULSE.c:13:28: note: ***** Analysis failed with vector mode V8SI
PULSE.c:13:28: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:22:2: missed: statement clobbers memory: _1 (layer_10(D));
PULSE.c:22:2: missed: statement clobbers memory: _14 (_2);
PULSE.c:22:2: missed: statement clobbers memory: _21 (_15);
PULSE.c:22:2: missed: statement clobbers memory: _28 (_22);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_29);
PULSE.c:26:3: missed: statement clobbers memory: memset (_34, 0, _32);
PULSE.c:26:3: missed: statement clobbers memory: memset (_27, 0, _25);
PULSE.c:26:3: missed: statement clobbers memory: memset (_20, 0, _18);
PULSE.c:26:3: missed: statement clobbers memory: memset (_7, 0, _5);
PULSE.c:28:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:28:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:32:6: note: vectorized 1 loops in function.
PULSE.c:34:8: missed: statement clobbers memory: _1 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_2);
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _9 = rand ();
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8SI
PULSE.c:32:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:61:16: missed: couldn't vectorize loop
PULSE.c:61:16: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:64:17: missed: couldn't vectorize loop
PULSE.c:64:17: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:73:19: missed: couldn't vectorize loop
PULSE.c:73:19: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _64 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:53:22: missed: couldn't vectorize loop
PULSE.c:53:22: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:47:6: note: vectorized 1 loops in function.
PULSE.c:48:1: missed: statement clobbers memory: saved_stack.9_35 = __builtin_stack_save ();
PULSE.c:49:46: missed: statement clobbers memory: _1 = PULSE_GetLossFunctionPtr (loss_function_36(D));
PULSE.c:60:10: missed: statement clobbers memory: random.6_42 = __builtin_alloca_with_align (_4, 32);
PULSE.c:34:8: missed: statement clobbers memory: _56 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_57);
PULSE.c:39:29: missed: statement clobbers memory: _64 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _67 = rand ();
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_93, inputs_88, _92);
PULSE.c:8:2: missed: statement clobbers memory: _94 (layer_89);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_100, _99, _98);
PULSE.c:67:11: missed: statement clobbers memory: loss_51 = PULSE_GetLoss_38 (_17, _16, _12, _11);
PULSE.c:22:2: missed: statement clobbers memory: _81 (output_30);
PULSE.c:22:2: missed: statement clobbers memory: _103 (_82);
PULSE.c:22:2: missed: statement clobbers memory: _110 (_104);
PULSE.c:22:2: missed: statement clobbers memory: _117 (_111);
PULSE.c:22:2: missed: statement clobbers memory: _124 (_118);
PULSE.c:22:2: missed: statement clobbers memory: _131 (_125);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_132);
PULSE.c:26:3: missed: statement clobbers memory: memset (_137, 0, _135);
PULSE.c:26:3: missed: statement clobbers memory: memset (_130, 0, _128);
PULSE.c:26:3: missed: statement clobbers memory: memset (_123, 0, _121);
PULSE.c:26:3: missed: statement clobbers memory: memset (_116, 0, _114);
PULSE.c:26:3: missed: statement clobbers memory: memset (_109, 0, _107);
PULSE.c:26:3: missed: statement clobbers memory: memset (_87, 0, _85);
PULSE.c:75:6: missed: statement clobbers memory: _21 (current_183, args);
PULSE.c:80:4: missed: statement clobbers memory: printf ("Epoch: %d Item: %d Loss: %.10f\r", i_181, j_182, _22);
PULSE.c:47:6: missed: statement clobbers memory: __builtin_stack_restore (saved_stack.9_35);
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4DI
PULSE.c:47:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:89:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:89:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:94:8: missed: couldn't vectorize loop
PULSE.c:94:8: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:91:6: note: vectorized 0 loops in function.
PULSE.c:96:3: missed: statement clobbers memory: _1 (current_10);
PULSE.c:99:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:99:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Loss.c:15:19: optimized: loop vectorized using 32 byte vectors
Loss.c:15:19: optimized:  loop versioned for vectorization because of possible aliasing
Loss.c:15:19: optimized: loop vectorized using 16 byte vectors
Loss.c:12:23: note: vectorized 1 loops in function.
Loss.c:12:23: note: ***** Analysis failed with vector mode V8SF
Loss.c:12:23: note: ***** The result for vector mode V32QI would be the same
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V16QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V16QI
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V8QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V8QI
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V4QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V4QI
Loss.c:7:19: missed: couldn't vectorize loop
Loss.c:8:38: missed: not vectorized: unsupported use in stmt.
Loss.c:4:23: note: vectorized 0 loops in function.
Loss.c:9:13: note: ***** Analysis failed with vector mode V8SF
Loss.c:9:13: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Loss.c:23:2: note: ***** Analysis failed with vector mode VOID
Layer.c:7:34: missed: statement clobbers memory: _2 = PULSE_Alloc (64, 4, n_inputs.0_1, optimization_11(D));
Layer.c:8:35: missed: statement clobbers memory: _4 = PULSE_Alloc (64, 4, n_outputs.1_3, optimization_11(D));
Layer.c:9:34: missed: statement clobbers memory: _5 = PULSE_Alloc (64, 4, n_outputs.1_3, optimization_11(D));
Layer.c:14:19: missed: statement clobbers memory: _6 = PULSE_GetActivationFunctionPtr (activation_function_16(D));
Layer.c:19:9: note: ***** Analysis succeeded with vector mode V8SI
Layer.c:19:9: note: SLPing BB part
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x8bf7878 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_15(D);
Layer.c:19:9: note: 	stmt 0 MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_15(D);
Layer.c:19:9: note: 	stmt 1 MEM <unsigned int> [(struct PULSE_Layer *)&<retval> + 4B] = optimization_11(D);
Layer.c:19:9: note: 	children 0x8bf78f8
Layer.c:19:9: note: node (external) 0x8bf78f8 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ type_15(D), optimization_11(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x8bf7978 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: <retval>.n_inputs = n_inputs_9(D);
Layer.c:19:9: note: 	stmt 0 <retval>.n_inputs = n_inputs_9(D);
Layer.c:19:9: note: 	stmt 1 <retval>.n_outputs = n_outputs_10(D);
Layer.c:19:9: note: 	children 0x8bf79f8
Layer.c:19:9: note: node (external) 0x8bf79f8 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_9(D), n_outputs_10(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x8bf7af8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.inputs = _2;
Layer.c:19:9: note: 	stmt 0 <retval>.inputs = _2;
Layer.c:19:9: note: 	stmt 1 <retval>.outputs = _4;
Layer.c:19:9: note: 	children 0x8bf7b78
Layer.c:19:9: note: node (external) 0x8bf7b78 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	stmt 0 _2 = PULSE_Alloc (64, 4, n_inputs.0_1, optimization_11(D));
Layer.c:19:9: note: 	stmt 1 _4 = PULSE_Alloc (64, 4, n_outputs.1_3, optimization_11(D));
Layer.c:19:9: note: 	children 0x8bf7bf8 0x8bf7c78 0x8bf7cf8 0x8bf7df8
Layer.c:19:9: note: node (constant) 0x8bf7bf8 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 64, 64 }
Layer.c:19:9: note: node (constant) 0x8bf7c78 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 4, 4 }
Layer.c:19:9: note: node 0x8bf7cf8 (max_nunits=2, refcnt=1) vector(2) int
Layer.c:19:9: note: op template: n_inputs.0_1 = (int) n_inputs_9(D);
Layer.c:19:9: note: 	stmt 0 n_inputs.0_1 = (int) n_inputs_9(D);
Layer.c:19:9: note: 	stmt 1 n_outputs.1_3 = (int) n_outputs_10(D);
Layer.c:19:9: note: 	children 0x8bf7d78
Layer.c:19:9: note: node (external) 0x8bf7d78 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_9(D), n_outputs_10(D) }
Layer.c:19:9: note: node (external) 0x8bf7df8 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ optimization_11(D), optimization_11(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x8bf7ef8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: op template: <retval>.feed = feed_18(D);
Layer.c:19:9: note: 	stmt 0 <retval>.feed = feed_18(D);
Layer.c:19:9: note: 	stmt 1 <retval>.back = back_19(D);
Layer.c:19:9: note: 	stmt 2 <retval>.fix = fix_20(D);
Layer.c:19:9: note: 	stmt 3 <retval>.destroy = destroy_21(D);
Layer.c:19:9: note: 	children 0x8bf7f78
Layer.c:19:9: note: node (external) 0x8bf7f78 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: 	{ feed_18(D), back_19(D), fix_20(D), destroy_21(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 64
  Scalar cost: 64
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x8bf8078 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 0 <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 1 <retval>.child = 0B;
Layer.c:19:9: note: 	children 0x8bf80f8
Layer.c:19:9: note: node (constant) 0x8bf80f8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ 0B, 0B }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Basic block will be vectorized using SLP
Layer.c:19:9: optimized: basic block part vectorized using 8 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x8bf7878 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_15(D);
Layer.c:19:9: note: 	stmt 0 MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_15(D);
Layer.c:19:9: note: 	stmt 1 MEM <unsigned int> [(struct PULSE_Layer *)&<retval> + 4B] = optimization_11(D);
Layer.c:19:9: note: 	children 0x8bf78f8
Layer.c:19:9: note: node (external) 0x8bf78f8 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ type_15(D), optimization_11(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_15(D);
Layer.c:19:9: note: vect_is_simple_use: operand optimization_11(D), type of def: external
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>]
Layer.c:19:9: note: created &MEM <unsigned int> [(struct PULSE_Layer *)&<retval>]
Layer.c:19:9: note: add new stmt: MEM <vector(2) unsigned int> [(struct PULSE_Layer *)&<retval>] = _38;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 8 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x8bf7978 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: <retval>.n_inputs = n_inputs_9(D);
Layer.c:19:9: note: 	stmt 0 <retval>.n_inputs = n_inputs_9(D);
Layer.c:19:9: note: 	stmt 1 <retval>.n_outputs = n_outputs_10(D);
Layer.c:19:9: note: 	children 0x8bf79f8
Layer.c:19:9: note: node (external) 0x8bf79f8 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_9(D), n_outputs_10(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.n_inputs = n_inputs_9(D);
Layer.c:19:9: note: vect_is_simple_use: operand n_outputs_10(D), type of def: external
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: <retval>.n_inputs
Layer.c:19:9: note: created &<retval>.n_inputs
Layer.c:19:9: note: add new stmt: MEM <vector(2) unsigned int> [(unsigned int *)&<retval> + 96B] = _40;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 16 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x8bf7af8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.inputs = _2;
Layer.c:19:9: note: 	stmt 0 <retval>.inputs = _2;
Layer.c:19:9: note: 	stmt 1 <retval>.outputs = _4;
Layer.c:19:9: note: 	children 0x8bf7b78
Layer.c:19:9: note: node (external) 0x8bf7b78 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	stmt 0 _2 = PULSE_Alloc (64, 4, n_inputs.0_1, optimization_11(D));
Layer.c:19:9: note: 	stmt 1 _4 = PULSE_Alloc (64, 4, n_outputs.1_3, optimization_11(D));
Layer.c:19:9: note: 	children 0x8bf7bf8 0x8bf7c78 0x8bf7cf8 0x8bf7df8
Layer.c:19:9: note: node (constant) 0x8bf7bf8 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 64, 64 }
Layer.c:19:9: note: node (constant) 0x8bf7c78 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 4, 4 }
Layer.c:19:9: note: node 0x8bf7cf8 (max_nunits=2, refcnt=1) vector(2) int
Layer.c:19:9: note: op template: n_inputs.0_1 = (int) n_inputs_9(D);
Layer.c:19:9: note: 	stmt 0 n_inputs.0_1 = (int) n_inputs_9(D);
Layer.c:19:9: note: 	stmt 1 n_outputs.1_3 = (int) n_outputs_10(D);
Layer.c:19:9: note: 	children 0x8bf7d78
Layer.c:19:9: note: node (external) 0x8bf7d78 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_9(D), n_outputs_10(D) }
Layer.c:19:9: note: node (external) 0x8bf7df8 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ optimization_11(D), optimization_11(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.inputs = _2;
Layer.c:19:9: note: vect_is_simple_use: operand PULSE_Alloc (64, 4, n_outputs.1_3, optimization_11(D)), type of def: internal
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.inputs
Layer.c:19:9: note: created &<retval>.inputs
Layer.c:19:9: note: add new stmt: MEM <vector(2) long unsigned int> [(float * *)&<retval> + 8B] = _44;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 32 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x8bf7ef8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: op template: <retval>.feed = feed_18(D);
Layer.c:19:9: note: 	stmt 0 <retval>.feed = feed_18(D);
Layer.c:19:9: note: 	stmt 1 <retval>.back = back_19(D);
Layer.c:19:9: note: 	stmt 2 <retval>.fix = fix_20(D);
Layer.c:19:9: note: 	stmt 3 <retval>.destroy = destroy_21(D);
Layer.c:19:9: note: 	children 0x8bf7f78
Layer.c:19:9: note: node (external) 0x8bf7f78 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: 	{ feed_18(D), back_19(D), fix_20(D), destroy_21(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.feed = feed_18(D);
Layer.c:19:9: note: vect_is_simple_use: operand back_19(D), type of def: external
Layer.c:19:9: note: vect_is_simple_use: operand fix_20(D), type of def: external
Layer.c:19:9: note: vect_is_simple_use: operand destroy_21(D), type of def: external
Layer.c:19:9: note: conflicting alias set types.
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(4) long unsigned int  vectorizing a pointer ref: <retval>.feed
Layer.c:19:9: note: created &<retval>.feed
Layer.c:19:9: note: add new stmt: MEM <vector(4) long unsigned int> [(void *)&<retval> + 32B] = _50;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 16 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x8bf8078 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 0 <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 1 <retval>.child = 0B;
Layer.c:19:9: note: 	children 0x8bf80f8
Layer.c:19:9: note: node (constant) 0x8bf80f8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ 0B, 0B }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.parent = 0B;
Layer.c:19:9: note: vect_is_simple_use: operand 0B, type of def: constant
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.parent
Layer.c:19:9: note: created &<retval>.parent
Layer.c:19:9: note: add new stmt: MEM <vector(2) long unsigned int> [(struct PULSE_Layer * *)&<retval> + 72B] = { 0, 0 };
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: note: ***** The result for vector mode V32QI would be the same
Layer.c:24:2: missed: statement clobbers memory: free (_1);
Layer.c:25:2: missed: statement clobbers memory: free (_2);
Layer.c:26:2: missed: statement clobbers memory: free (_3);
Layer.c:27:1: note: ***** Analysis failed with vector mode V4DI
Layer.c:27:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:7:27: missed: couldn't vectorize loop
Dense.c:7:27: missed: not vectorized: unsupported outerloop form.
Dense.c:10:20: missed: couldn't vectorize loop
Dense.c:11:21: missed: not vectorized: complicated access pattern.
Dense.c:4:13: note: vectorized 0 loops in function.
Dense.c:14:2: missed: statement clobbers memory: _30 (pretmp_91, _50, 0);
Dense.c:7:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:7:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:7:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:7:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:7:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:7:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:7:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:7:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:22:27: missed: couldn't vectorize loop
Dense.c:22:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:26:20: optimized: loop vectorized using 32 byte vectors
Dense.c:26:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:26:20: optimized: loop vectorized using 16 byte vectors
Dense.c:26:20: missed: couldn't vectorize loop
Dense.c:28:20: missed: not vectorized: no vectype for stmt: _21 = *_20;
 scalar_type: float
Dense.c:18:13: note: vectorized 1 loops in function.
Dense.c:21:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:22:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:22:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:22:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:22:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:22:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:22:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:22:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:22:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:39:28: missed: couldn't vectorize loop
Dense.c:39:28: missed: not vectorized: unsupported outerloop form.
Dense.c:43:21: optimized: loop vectorized using 32 byte vectors
Dense.c:43:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:43:21: optimized: loop vectorized using 16 byte vectors
Dense.c:35:13: note: vectorized 1 loops in function.
Dense.c:35:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:35:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:35:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:35:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:35:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:35:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:35:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:39:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:143:19: missed: couldn't vectorize loop
Dense.c:143:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:134:19: missed: couldn't vectorize loop
Dense.c:134:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:127:13: note: vectorized 0 loops in function.
Dense.c:151:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:151:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:96:28: missed: couldn't vectorize loop
Dense.c:96:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:99:21: missed: couldn't vectorize loop
Dense.c:99:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:113:28: missed: couldn't vectorize loop
Dense.c:113:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:116:21: missed: couldn't vectorize loop
Dense.c:116:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:82:19: missed: couldn't vectorize loop
Dense.c:82:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:76:13: note: vectorized 0 loops in function.
Dense.c:79:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:101:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:101:17: note: SLPing BB part
Dense.c:118:17: note: Costing subgraph: 
Dense.c:118:17: note: node 0x87e3e88 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:118:17: note: op template: _49 = (sizetype) j_137;
Dense.c:118:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:118:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:118:17: note: 	children 0x87e3f88
Dense.c:118:17: note: node (external) 0x87e3f88 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:118:17: note: 	{ j_137, wi_136 }
Dense.c:118:17: note: Cost model analysis: 
Dense.c:118:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:118:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:118:17: missed: not vectorized: vectorization is not profitable.
Dense.c:101:17: note: Costing subgraph: 
Dense.c:101:17: note: node 0x87e4088 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:101:17: note: op template: _24 = (sizetype) j_134;
Dense.c:101:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:101:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:101:17: note: 	children 0x87e4188
Dense.c:101:17: note: node (external) 0x87e4188 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:101:17: note: 	{ j_134, wi_133 }
Dense.c:101:17: note: Cost model analysis: 
Dense.c:101:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:101:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:101:17: missed: not vectorized: vectorization is not profitable.
Dense.c:101:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:101:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:101:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:101:17: note: SLPing BB part
Dense.c:118:17: note: Costing subgraph: 
Dense.c:118:17: note: node 0x87e4088 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:118:17: note: op template: _49 = (sizetype) j_137;
Dense.c:118:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:118:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:118:17: note: 	children 0x87e3e88
Dense.c:118:17: note: node (external) 0x87e3e88 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:118:17: note: 	{ j_137, wi_136 }
Dense.c:118:17: note: Cost model analysis: 
Dense.c:118:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:118:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:118:17: missed: not vectorized: vectorization is not profitable.
Dense.c:101:17: note: Costing subgraph: 
Dense.c:101:17: note: node 0x87e4208 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:101:17: note: op template: _24 = (sizetype) j_134;
Dense.c:101:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:101:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:101:17: note: 	children 0x87e4108
Dense.c:101:17: note: node (external) 0x87e4108 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:101:17: note: 	{ j_134, wi_133 }
Dense.c:101:17: note: Cost model analysis: 
Dense.c:101:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:101:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:101:17: missed: not vectorized: vectorization is not profitable.
Dense.c:101:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:96:55: note: ***** Analysis failed with vector mode V8QI
Dense.c:96:55: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:96:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:56:27: missed: couldn't vectorize loop
Dense.c:56:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:59:20: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:905:10: missed: not vectorized: no vectype for stmt: _41 = MEM[(__m256_u * {ref-all})_6];
 scalar_type: __m256_u
Dense.c:59:20: note: ***** Analysis failed with vector mode VOID
Dense.c:52:13: note: vectorized 0 loops in function.
Dense.c:52:13: missed: splitting region at dont-vectorize loop 3 entry at bb18
Dense.c:61:14: note: ***** Analysis failed with vector mode V4DI
Dense.c:61:14: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:61:14: missed: splitting region at dominance boundary bb8
Dense.c:61:14: note: ***** Analysis failed with vector mode VOID
Dense.c:61:14: missed: splitting region at loop 1 exit at bb16
Dense.c:56:27: note: ***** Analysis failed with vector mode V8SF
Dense.c:56:27: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Dense.c:56:27: missed: splitting region at dominance boundary bb10
Dense.c:56:27: note: ***** Analysis failed with vector mode VOID
Dense.c:72:2: missed: statement clobbers memory: _27 (pretmp_153, _61, 0);
Dense.c:73:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:73:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:158:2: missed: statement clobbers memory: PULSE_Free (_1);
Dense.c:159:2: missed: statement clobbers memory: PULSE_Free (_2);
Dense.c:160:2: missed: statement clobbers memory: PULSE_Free (_3);
Dense.c:161:2: missed: statement clobbers memory: PULSE_Free (_4);
Dense.c:162:2: missed: statement clobbers memory: PULSE_Free (dense_7);
Dense.c:163:2: missed: statement clobbers memory: PULSE_DestroyLayer (this_6(D));
Dense.c:164:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:164:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:178:19: missed: couldn't vectorize loop
Dense.c:178:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:168:13: note: vectorized 0 loops in function.
Dense.c:170:47: missed: statement clobbers memory: dense_30 = malloc (40);
Dense.c:172:36: missed: statement clobbers memory: _1 = PULSE_Alloc2D (64, 4, n_inputs_31(D), n_outputs_32(D), optimization_33(D));
Dense.c:173:38: missed: statement clobbers memory: _2 = PULSE_Alloc2D (64, 4, n_inputs_31(D), n_outputs_32(D), optimization_33(D));
Dense.c:174:36: missed: statement clobbers memory: _3 = PULSE_Alloc (64, 4, n_outputs_32(D), optimization_33(D));
Dense.c:175:35: missed: statement clobbers memory: _4 = PULSE_Alloc (64, 4, n_outputs_32(D), optimization_33(D));
Dense.c:176:36: missed: statement clobbers memory: _5 = PULSE_Alloc (64, 4, n_outputs_32(D), optimization_33(D));
Dense.c:179:39: missed: statement clobbers memory: _6 = rand ();
Dense.c:179:73: missed: statement clobbers memory: _58 = sqrt (_13);
Dense.c:191:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:192:4: missed: statement clobbers memory: exit (1);
Dense.c:188:4: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.3_24, n_outputs.2_23, 1, activation_function_46(D), _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:185:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.1_22, n_outputs.0_21, 1, activation_function_46(D), _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:198:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Dense.c:198:9: note: ***** Analysis failed with vector mode V4DI
Dense.c:198:9: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Activations.c:17:19: optimized: loop vectorized using 32 byte vectors
Activations.c:17:19: optimized: loop vectorized using 16 byte vectors
Activations.c:17:19: optimized: loop vectorized using 32 byte vectors
Activations.c:17:19: optimized: loop vectorized using 16 byte vectors
Activations.c:14:13: note: vectorized 2 loops in function.
Activations.c:14:13: note: ***** Analysis failed with vector mode V8SF
Activations.c:14:13: note: ***** The result for vector mode V32QI would be the same
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V16QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V16QI
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V8QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V8QI
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V4QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V4QI
Activations.c:28:19: missed: couldn't vectorize loop
Activations.c:28:19: missed: not vectorized: unsupported control flow in loop.
Activations.c:28:19: optimized: loop vectorized using 32 byte vectors
Activations.c:28:19: optimized: loop vectorized using 16 byte vectors
Activations.c:25:13: note: vectorized 1 loops in function.
Activations.c:25:13: note: ***** Analysis failed with vector mode V8SF
Activations.c:25:13: note: ***** The result for vector mode V32QI would be the same
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V16QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V16QI
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V8QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V8QI
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V4QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V4QI
Activations.c:38:1: note: ***** Analysis failed with vector mode VOID
Activations.c:5:19: missed: couldn't vectorize loop
Activations.c:9:21: missed: statement clobbers memory: _36 = expf (_18);
Activations.c:5:19: missed: couldn't vectorize loop
Activations.c:9:21: missed: statement clobbers memory: _12 = expf (_11);
Activations.c:3:13: note: vectorized 0 loops in function.
Activations.c:9:21: missed: statement clobbers memory: _12 = expf (_11);
Activations.c:9:21: missed: statement clobbers memory: _36 = expf (_18);
Activations.c:11:1: note: ***** Analysis failed with vector mode V8SF
Activations.c:11:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Activations.c:44:2: note: ***** Analysis failed with vector mode VOID
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:4:18: note: vectorized 0 loops in function.
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_4, inputs_15, _3);
PULSE.c:8:2: missed: statement clobbers memory: _5 (layer_17);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_12, pretmp_26, _9);
PULSE.c:13:28: note: ***** Analysis failed with vector mode V8SI
PULSE.c:13:28: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:22:2: missed: statement clobbers memory: _1 (layer_10(D));
PULSE.c:22:2: missed: statement clobbers memory: _14 (_2);
PULSE.c:22:2: missed: statement clobbers memory: _21 (_15);
PULSE.c:22:2: missed: statement clobbers memory: _28 (_22);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_29);
PULSE.c:26:3: missed: statement clobbers memory: memset (_34, 0, _32);
PULSE.c:26:3: missed: statement clobbers memory: memset (_27, 0, _25);
PULSE.c:26:3: missed: statement clobbers memory: memset (_20, 0, _18);
PULSE.c:26:3: missed: statement clobbers memory: memset (_7, 0, _5);
PULSE.c:28:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:28:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:32:6: note: vectorized 1 loops in function.
PULSE.c:34:8: missed: statement clobbers memory: _1 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_2);
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _9 = rand ();
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8SI
PULSE.c:32:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:61:16: missed: couldn't vectorize loop
PULSE.c:61:16: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:64:17: missed: couldn't vectorize loop
PULSE.c:64:17: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:73:19: missed: couldn't vectorize loop
PULSE.c:73:19: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _64 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:53:22: missed: couldn't vectorize loop
PULSE.c:53:22: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:47:6: note: vectorized 1 loops in function.
PULSE.c:48:1: missed: statement clobbers memory: saved_stack.7_35 = __builtin_stack_save ();
PULSE.c:49:46: missed: statement clobbers memory: _1 = PULSE_GetLossFunctionPtr (loss_function_36(D));
PULSE.c:60:10: missed: statement clobbers memory: random.4_42 = __builtin_alloca_with_align (_4, 32);
PULSE.c:34:8: missed: statement clobbers memory: _56 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_57);
PULSE.c:39:29: missed: statement clobbers memory: _64 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _67 = rand ();
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_93, inputs_88, _92);
PULSE.c:8:2: missed: statement clobbers memory: _94 (layer_89);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_100, _99, _98);
PULSE.c:67:11: missed: statement clobbers memory: loss_51 = PULSE_GetLoss_38 (_17, _16, _12, _11);
PULSE.c:22:2: missed: statement clobbers memory: _81 (output_30);
PULSE.c:22:2: missed: statement clobbers memory: _103 (_82);
PULSE.c:22:2: missed: statement clobbers memory: _110 (_104);
PULSE.c:22:2: missed: statement clobbers memory: _117 (_111);
PULSE.c:22:2: missed: statement clobbers memory: _124 (_118);
PULSE.c:22:2: missed: statement clobbers memory: _131 (_125);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_132);
PULSE.c:26:3: missed: statement clobbers memory: memset (_137, 0, _135);
PULSE.c:26:3: missed: statement clobbers memory: memset (_130, 0, _128);
PULSE.c:26:3: missed: statement clobbers memory: memset (_123, 0, _121);
PULSE.c:26:3: missed: statement clobbers memory: memset (_116, 0, _114);
PULSE.c:26:3: missed: statement clobbers memory: memset (_109, 0, _107);
PULSE.c:26:3: missed: statement clobbers memory: memset (_87, 0, _85);
PULSE.c:75:6: missed: statement clobbers memory: _21 (current_183, args);
PULSE.c:80:4: missed: statement clobbers memory: printf ("Epoch: %d Item: %d Loss: %.10f\r", i_181, j_182, _22);
PULSE.c:47:6: missed: statement clobbers memory: __builtin_stack_restore (saved_stack.7_35);
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4DI
PULSE.c:47:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:89:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:89:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:94:8: missed: couldn't vectorize loop
PULSE.c:94:8: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:91:6: note: vectorized 0 loops in function.
PULSE.c:96:3: missed: statement clobbers memory: _1 (current_10);
PULSE.c:99:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:99:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Loss.c:15:19: optimized: loop vectorized using 32 byte vectors
Loss.c:15:19: optimized:  loop versioned for vectorization because of possible aliasing
Loss.c:15:19: optimized: loop vectorized using 16 byte vectors
Loss.c:12:23: note: vectorized 1 loops in function.
Loss.c:12:23: note: ***** Analysis failed with vector mode V8SF
Loss.c:12:23: note: ***** The result for vector mode V32QI would be the same
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V16QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V16QI
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V8QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V8QI
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V4QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V4QI
Loss.c:7:19: missed: couldn't vectorize loop
Loss.c:8:38: missed: not vectorized: unsupported use in stmt.
Loss.c:4:23: note: vectorized 0 loops in function.
Loss.c:9:13: note: ***** Analysis failed with vector mode V8SF
Loss.c:9:13: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Loss.c:23:2: note: ***** Analysis failed with vector mode VOID
Layer.c:7:34: missed: statement clobbers memory: _2 = PULSE_Alloc (64, 4, n_inputs.0_1, optimization_11(D));
Layer.c:8:35: missed: statement clobbers memory: _4 = PULSE_Alloc (64, 4, n_outputs.1_3, optimization_11(D));
Layer.c:9:34: missed: statement clobbers memory: _5 = PULSE_Alloc (64, 4, n_outputs.1_3, optimization_11(D));
Layer.c:14:19: missed: statement clobbers memory: _6 = PULSE_GetActivationFunctionPtr (activation_function_16(D));
Layer.c:19:9: note: ***** Analysis succeeded with vector mode V8SI
Layer.c:19:9: note: SLPing BB part
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x84da878 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_15(D);
Layer.c:19:9: note: 	stmt 0 MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_15(D);
Layer.c:19:9: note: 	stmt 1 MEM <unsigned int> [(struct PULSE_Layer *)&<retval> + 4B] = optimization_11(D);
Layer.c:19:9: note: 	children 0x84da8f8
Layer.c:19:9: note: node (external) 0x84da8f8 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ type_15(D), optimization_11(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x84da978 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: <retval>.n_inputs = n_inputs_9(D);
Layer.c:19:9: note: 	stmt 0 <retval>.n_inputs = n_inputs_9(D);
Layer.c:19:9: note: 	stmt 1 <retval>.n_outputs = n_outputs_10(D);
Layer.c:19:9: note: 	children 0x84da9f8
Layer.c:19:9: note: node (external) 0x84da9f8 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_9(D), n_outputs_10(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x84daaf8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.inputs = _2;
Layer.c:19:9: note: 	stmt 0 <retval>.inputs = _2;
Layer.c:19:9: note: 	stmt 1 <retval>.outputs = _4;
Layer.c:19:9: note: 	children 0x84dab78
Layer.c:19:9: note: node (external) 0x84dab78 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	stmt 0 _2 = PULSE_Alloc (64, 4, n_inputs.0_1, optimization_11(D));
Layer.c:19:9: note: 	stmt 1 _4 = PULSE_Alloc (64, 4, n_outputs.1_3, optimization_11(D));
Layer.c:19:9: note: 	children 0x84dabf8 0x84dac78 0x84dacf8 0x84dadf8
Layer.c:19:9: note: node (constant) 0x84dabf8 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 64, 64 }
Layer.c:19:9: note: node (constant) 0x84dac78 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 4, 4 }
Layer.c:19:9: note: node 0x84dacf8 (max_nunits=2, refcnt=1) vector(2) int
Layer.c:19:9: note: op template: n_inputs.0_1 = (int) n_inputs_9(D);
Layer.c:19:9: note: 	stmt 0 n_inputs.0_1 = (int) n_inputs_9(D);
Layer.c:19:9: note: 	stmt 1 n_outputs.1_3 = (int) n_outputs_10(D);
Layer.c:19:9: note: 	children 0x84dad78
Layer.c:19:9: note: node (external) 0x84dad78 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_9(D), n_outputs_10(D) }
Layer.c:19:9: note: node (external) 0x84dadf8 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ optimization_11(D), optimization_11(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x84daef8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: op template: <retval>.feed = feed_18(D);
Layer.c:19:9: note: 	stmt 0 <retval>.feed = feed_18(D);
Layer.c:19:9: note: 	stmt 1 <retval>.back = back_19(D);
Layer.c:19:9: note: 	stmt 2 <retval>.fix = fix_20(D);
Layer.c:19:9: note: 	stmt 3 <retval>.destroy = destroy_21(D);
Layer.c:19:9: note: 	children 0x84daf78
Layer.c:19:9: note: node (external) 0x84daf78 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: 	{ feed_18(D), back_19(D), fix_20(D), destroy_21(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 64
  Scalar cost: 64
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x84db078 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 0 <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 1 <retval>.child = 0B;
Layer.c:19:9: note: 	children 0x84db0f8
Layer.c:19:9: note: node (constant) 0x84db0f8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ 0B, 0B }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Basic block will be vectorized using SLP
Layer.c:19:9: optimized: basic block part vectorized using 8 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x84da878 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_15(D);
Layer.c:19:9: note: 	stmt 0 MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_15(D);
Layer.c:19:9: note: 	stmt 1 MEM <unsigned int> [(struct PULSE_Layer *)&<retval> + 4B] = optimization_11(D);
Layer.c:19:9: note: 	children 0x84da8f8
Layer.c:19:9: note: node (external) 0x84da8f8 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ type_15(D), optimization_11(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_15(D);
Layer.c:19:9: note: vect_is_simple_use: operand optimization_11(D), type of def: external
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>]
Layer.c:19:9: note: created &MEM <unsigned int> [(struct PULSE_Layer *)&<retval>]
Layer.c:19:9: note: add new stmt: MEM <vector(2) unsigned int> [(struct PULSE_Layer *)&<retval>] = _38;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 8 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x84da978 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: <retval>.n_inputs = n_inputs_9(D);
Layer.c:19:9: note: 	stmt 0 <retval>.n_inputs = n_inputs_9(D);
Layer.c:19:9: note: 	stmt 1 <retval>.n_outputs = n_outputs_10(D);
Layer.c:19:9: note: 	children 0x84da9f8
Layer.c:19:9: note: node (external) 0x84da9f8 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_9(D), n_outputs_10(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.n_inputs = n_inputs_9(D);
Layer.c:19:9: note: vect_is_simple_use: operand n_outputs_10(D), type of def: external
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: <retval>.n_inputs
Layer.c:19:9: note: created &<retval>.n_inputs
Layer.c:19:9: note: add new stmt: MEM <vector(2) unsigned int> [(unsigned int *)&<retval> + 96B] = _40;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 16 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x84daaf8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.inputs = _2;
Layer.c:19:9: note: 	stmt 0 <retval>.inputs = _2;
Layer.c:19:9: note: 	stmt 1 <retval>.outputs = _4;
Layer.c:19:9: note: 	children 0x84dab78
Layer.c:19:9: note: node (external) 0x84dab78 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	stmt 0 _2 = PULSE_Alloc (64, 4, n_inputs.0_1, optimization_11(D));
Layer.c:19:9: note: 	stmt 1 _4 = PULSE_Alloc (64, 4, n_outputs.1_3, optimization_11(D));
Layer.c:19:9: note: 	children 0x84dabf8 0x84dac78 0x84dacf8 0x84dadf8
Layer.c:19:9: note: node (constant) 0x84dabf8 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 64, 64 }
Layer.c:19:9: note: node (constant) 0x84dac78 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 4, 4 }
Layer.c:19:9: note: node 0x84dacf8 (max_nunits=2, refcnt=1) vector(2) int
Layer.c:19:9: note: op template: n_inputs.0_1 = (int) n_inputs_9(D);
Layer.c:19:9: note: 	stmt 0 n_inputs.0_1 = (int) n_inputs_9(D);
Layer.c:19:9: note: 	stmt 1 n_outputs.1_3 = (int) n_outputs_10(D);
Layer.c:19:9: note: 	children 0x84dad78
Layer.c:19:9: note: node (external) 0x84dad78 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_9(D), n_outputs_10(D) }
Layer.c:19:9: note: node (external) 0x84dadf8 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ optimization_11(D), optimization_11(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.inputs = _2;
Layer.c:19:9: note: vect_is_simple_use: operand PULSE_Alloc (64, 4, n_outputs.1_3, optimization_11(D)), type of def: internal
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.inputs
Layer.c:19:9: note: created &<retval>.inputs
Layer.c:19:9: note: add new stmt: MEM <vector(2) long unsigned int> [(float * *)&<retval> + 8B] = _44;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 32 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x84daef8 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: op template: <retval>.feed = feed_18(D);
Layer.c:19:9: note: 	stmt 0 <retval>.feed = feed_18(D);
Layer.c:19:9: note: 	stmt 1 <retval>.back = back_19(D);
Layer.c:19:9: note: 	stmt 2 <retval>.fix = fix_20(D);
Layer.c:19:9: note: 	stmt 3 <retval>.destroy = destroy_21(D);
Layer.c:19:9: note: 	children 0x84daf78
Layer.c:19:9: note: node (external) 0x84daf78 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: 	{ feed_18(D), back_19(D), fix_20(D), destroy_21(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.feed = feed_18(D);
Layer.c:19:9: note: vect_is_simple_use: operand back_19(D), type of def: external
Layer.c:19:9: note: vect_is_simple_use: operand fix_20(D), type of def: external
Layer.c:19:9: note: vect_is_simple_use: operand destroy_21(D), type of def: external
Layer.c:19:9: note: conflicting alias set types.
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(4) long unsigned int  vectorizing a pointer ref: <retval>.feed
Layer.c:19:9: note: created &<retval>.feed
Layer.c:19:9: note: add new stmt: MEM <vector(4) long unsigned int> [(void *)&<retval> + 32B] = _50;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 16 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x84db078 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 0 <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 1 <retval>.child = 0B;
Layer.c:19:9: note: 	children 0x84db0f8
Layer.c:19:9: note: node (constant) 0x84db0f8 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ 0B, 0B }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.parent = 0B;
Layer.c:19:9: note: vect_is_simple_use: operand 0B, type of def: constant
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.parent
Layer.c:19:9: note: created &<retval>.parent
Layer.c:19:9: note: add new stmt: MEM <vector(2) long unsigned int> [(struct PULSE_Layer * *)&<retval> + 72B] = { 0, 0 };
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: note: ***** The result for vector mode V32QI would be the same
Layer.c:24:2: missed: statement clobbers memory: free (_1);
Layer.c:25:2: missed: statement clobbers memory: free (_2);
Layer.c:26:2: missed: statement clobbers memory: free (_3);
Layer.c:27:1: note: ***** Analysis failed with vector mode V4DI
Layer.c:27:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:7:27: missed: couldn't vectorize loop
Dense.c:7:27: missed: not vectorized: unsupported outerloop form.
Dense.c:10:20: missed: couldn't vectorize loop
Dense.c:11:21: missed: not vectorized: complicated access pattern.
Dense.c:4:13: note: vectorized 0 loops in function.
Dense.c:14:2: missed: statement clobbers memory: _30 (pretmp_91, _50, 0);
Dense.c:7:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:7:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:7:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:7:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:7:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:7:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:7:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:7:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:22:27: missed: couldn't vectorize loop
Dense.c:22:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:26:20: optimized: loop vectorized using 32 byte vectors
Dense.c:26:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:26:20: optimized: loop vectorized using 16 byte vectors
Dense.c:26:20: missed: couldn't vectorize loop
Dense.c:28:20: missed: not vectorized: no vectype for stmt: _21 = *_20;
 scalar_type: float
Dense.c:18:13: note: vectorized 1 loops in function.
Dense.c:21:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:22:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:22:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:22:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:22:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:22:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:22:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:22:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:22:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:39:28: missed: couldn't vectorize loop
Dense.c:39:28: missed: not vectorized: unsupported outerloop form.
Dense.c:43:21: optimized: loop vectorized using 32 byte vectors
Dense.c:43:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:43:21: optimized: loop vectorized using 16 byte vectors
Dense.c:35:13: note: vectorized 1 loops in function.
Dense.c:35:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:35:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:35:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:35:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:35:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:35:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:35:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:39:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:143:19: missed: couldn't vectorize loop
Dense.c:143:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:134:19: missed: couldn't vectorize loop
Dense.c:134:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:127:13: note: vectorized 0 loops in function.
Dense.c:151:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:151:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:96:28: missed: couldn't vectorize loop
Dense.c:96:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:99:21: missed: couldn't vectorize loop
Dense.c:99:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:113:28: missed: couldn't vectorize loop
Dense.c:113:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:116:21: missed: couldn't vectorize loop
Dense.c:116:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:82:19: missed: couldn't vectorize loop
Dense.c:82:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:76:13: note: vectorized 0 loops in function.
Dense.c:79:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:101:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:101:17: note: SLPing BB part
Dense.c:118:17: note: Costing subgraph: 
Dense.c:118:17: note: node 0x7c9b198 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:118:17: note: op template: _49 = (sizetype) j_137;
Dense.c:118:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:118:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:118:17: note: 	children 0x7c9b298
Dense.c:118:17: note: node (external) 0x7c9b298 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:118:17: note: 	{ j_137, wi_136 }
Dense.c:118:17: note: Cost model analysis: 
Dense.c:118:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:118:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:118:17: missed: not vectorized: vectorization is not profitable.
Dense.c:101:17: note: Costing subgraph: 
Dense.c:101:17: note: node 0x7c9b398 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:101:17: note: op template: _24 = (sizetype) j_134;
Dense.c:101:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:101:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:101:17: note: 	children 0x7c9b498
Dense.c:101:17: note: node (external) 0x7c9b498 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:101:17: note: 	{ j_134, wi_133 }
Dense.c:101:17: note: Cost model analysis: 
Dense.c:101:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:101:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:101:17: missed: not vectorized: vectorization is not profitable.
Dense.c:101:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:101:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:101:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:101:17: note: SLPing BB part
Dense.c:118:17: note: Costing subgraph: 
Dense.c:118:17: note: node 0x7c9b398 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:118:17: note: op template: _49 = (sizetype) j_137;
Dense.c:118:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:118:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:118:17: note: 	children 0x7c9b198
Dense.c:118:17: note: node (external) 0x7c9b198 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:118:17: note: 	{ j_137, wi_136 }
Dense.c:118:17: note: Cost model analysis: 
Dense.c:118:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:118:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:118:17: missed: not vectorized: vectorization is not profitable.
Dense.c:101:17: note: Costing subgraph: 
Dense.c:101:17: note: node 0x7c9b518 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:101:17: note: op template: _24 = (sizetype) j_134;
Dense.c:101:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:101:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:101:17: note: 	children 0x7c9b418
Dense.c:101:17: note: node (external) 0x7c9b418 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:101:17: note: 	{ j_134, wi_133 }
Dense.c:101:17: note: Cost model analysis: 
Dense.c:101:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:101:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:101:17: missed: not vectorized: vectorization is not profitable.
Dense.c:101:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:96:55: note: ***** Analysis failed with vector mode V8QI
Dense.c:96:55: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:96:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:56:27: missed: couldn't vectorize loop
Dense.c:56:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:59:20: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:905:10: missed: not vectorized: no vectype for stmt: _41 = MEM[(__m256_u * {ref-all})_6];
 scalar_type: __m256_u
Dense.c:59:20: note: ***** Analysis failed with vector mode VOID
Dense.c:52:13: note: vectorized 0 loops in function.
Dense.c:52:13: missed: splitting region at dont-vectorize loop 3 entry at bb18
Dense.c:61:14: note: ***** Analysis failed with vector mode V4DI
Dense.c:61:14: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:61:14: missed: splitting region at dominance boundary bb8
Dense.c:61:14: note: ***** Analysis failed with vector mode VOID
Dense.c:61:14: missed: splitting region at loop 1 exit at bb16
Dense.c:56:27: note: ***** Analysis failed with vector mode V8SF
Dense.c:56:27: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Dense.c:56:27: missed: splitting region at dominance boundary bb10
Dense.c:56:27: note: ***** Analysis failed with vector mode VOID
Dense.c:72:2: missed: statement clobbers memory: _27 (pretmp_153, _61, 0);
Dense.c:73:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:73:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:158:2: missed: statement clobbers memory: PULSE_Free (_1);
Dense.c:159:2: missed: statement clobbers memory: PULSE_Free (_2);
Dense.c:160:2: missed: statement clobbers memory: PULSE_Free (_3);
Dense.c:161:2: missed: statement clobbers memory: PULSE_Free (_4);
Dense.c:162:2: missed: statement clobbers memory: PULSE_Free (dense_7);
Dense.c:163:2: missed: statement clobbers memory: PULSE_DestroyLayer (this_6(D));
Dense.c:164:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:164:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:178:19: missed: couldn't vectorize loop
Dense.c:178:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:168:13: note: vectorized 0 loops in function.
Dense.c:170:47: missed: statement clobbers memory: dense_30 = malloc (40);
Dense.c:172:36: missed: statement clobbers memory: _1 = PULSE_Alloc2D (64, 4, n_inputs_31(D), n_outputs_32(D), optimization_33(D));
Dense.c:173:38: missed: statement clobbers memory: _2 = PULSE_Alloc2D (64, 4, n_inputs_31(D), n_outputs_32(D), optimization_33(D));
Dense.c:174:36: missed: statement clobbers memory: _3 = PULSE_Alloc (64, 4, n_outputs_32(D), optimization_33(D));
Dense.c:175:35: missed: statement clobbers memory: _4 = PULSE_Alloc (64, 4, n_outputs_32(D), optimization_33(D));
Dense.c:176:36: missed: statement clobbers memory: _5 = PULSE_Alloc (64, 4, n_outputs_32(D), optimization_33(D));
Dense.c:179:39: missed: statement clobbers memory: _6 = rand ();
Dense.c:179:73: missed: statement clobbers memory: _58 = sqrt (_13);
Dense.c:191:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:192:4: missed: statement clobbers memory: exit (1);
Dense.c:188:4: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.3_24, n_outputs.2_23, 1, activation_function_46(D), _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:185:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.1_22, n_outputs.0_21, 1, activation_function_46(D), _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:198:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Dense.c:198:9: note: ***** Analysis failed with vector mode V4DI
Dense.c:198:9: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Activations.c:17:19: optimized: loop vectorized using 32 byte vectors
Activations.c:17:19: optimized: loop vectorized using 16 byte vectors
Activations.c:17:19: optimized: loop vectorized using 32 byte vectors
Activations.c:17:19: optimized: loop vectorized using 16 byte vectors
Activations.c:14:13: note: vectorized 2 loops in function.
Activations.c:14:13: note: ***** Analysis failed with vector mode V8SF
Activations.c:14:13: note: ***** The result for vector mode V32QI would be the same
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V16QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V16QI
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V8QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V8QI
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V4QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V4QI
Activations.c:28:19: missed: couldn't vectorize loop
Activations.c:28:19: missed: not vectorized: unsupported control flow in loop.
Activations.c:28:19: optimized: loop vectorized using 32 byte vectors
Activations.c:28:19: optimized: loop vectorized using 16 byte vectors
Activations.c:25:13: note: vectorized 1 loops in function.
Activations.c:25:13: note: ***** Analysis failed with vector mode V8SF
Activations.c:25:13: note: ***** The result for vector mode V32QI would be the same
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V16QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V16QI
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V8QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V8QI
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V4QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V4QI
Activations.c:38:1: note: ***** Analysis failed with vector mode VOID
Activations.c:5:19: missed: couldn't vectorize loop
Activations.c:9:21: missed: statement clobbers memory: _36 = expf (_18);
Activations.c:5:19: missed: couldn't vectorize loop
Activations.c:9:21: missed: statement clobbers memory: _12 = expf (_11);
Activations.c:3:13: note: vectorized 0 loops in function.
Activations.c:9:21: missed: statement clobbers memory: _12 = expf (_11);
Activations.c:9:21: missed: statement clobbers memory: _36 = expf (_18);
Activations.c:11:1: note: ***** Analysis failed with vector mode V8SF
Activations.c:11:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Activations.c:44:2: note: ***** Analysis failed with vector mode VOID
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:4:18: note: vectorized 0 loops in function.
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_4, inputs_15, _3);
PULSE.c:8:2: missed: statement clobbers memory: _5 (layer_17);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_12, pretmp_26, _9);
PULSE.c:13:28: note: ***** Analysis failed with vector mode V8SI
PULSE.c:13:28: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:22:2: missed: statement clobbers memory: _1 (layer_10(D));
PULSE.c:22:2: missed: statement clobbers memory: _14 (_2);
PULSE.c:22:2: missed: statement clobbers memory: _21 (_15);
PULSE.c:22:2: missed: statement clobbers memory: _28 (_22);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_29);
PULSE.c:26:3: missed: statement clobbers memory: memset (_34, 0, _32);
PULSE.c:26:3: missed: statement clobbers memory: memset (_27, 0, _25);
PULSE.c:26:3: missed: statement clobbers memory: memset (_20, 0, _18);
PULSE.c:26:3: missed: statement clobbers memory: memset (_7, 0, _5);
PULSE.c:28:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:28:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:32:6: note: vectorized 1 loops in function.
PULSE.c:34:8: missed: statement clobbers memory: _1 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_2);
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _9 = rand ();
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8SI
PULSE.c:32:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:61:16: missed: couldn't vectorize loop
PULSE.c:61:16: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:64:17: missed: couldn't vectorize loop
PULSE.c:64:17: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:73:19: missed: couldn't vectorize loop
PULSE.c:73:19: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _64 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:53:22: missed: couldn't vectorize loop
PULSE.c:53:22: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:47:6: note: vectorized 1 loops in function.
PULSE.c:48:1: missed: statement clobbers memory: saved_stack.7_35 = __builtin_stack_save ();
PULSE.c:49:46: missed: statement clobbers memory: _1 = PULSE_GetLossFunctionPtr (loss_function_36(D));
PULSE.c:60:10: missed: statement clobbers memory: random.4_42 = __builtin_alloca_with_align (_4, 32);
PULSE.c:34:8: missed: statement clobbers memory: _56 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_57);
PULSE.c:39:29: missed: statement clobbers memory: _64 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _67 = rand ();
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_93, inputs_88, _92);
PULSE.c:8:2: missed: statement clobbers memory: _94 (layer_89);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_100, _99, _98);
PULSE.c:67:11: missed: statement clobbers memory: loss_51 = PULSE_GetLoss_38 (_17, _16, _12, _11);
PULSE.c:22:2: missed: statement clobbers memory: _81 (output_30);
PULSE.c:22:2: missed: statement clobbers memory: _103 (_82);
PULSE.c:22:2: missed: statement clobbers memory: _110 (_104);
PULSE.c:22:2: missed: statement clobbers memory: _117 (_111);
PULSE.c:22:2: missed: statement clobbers memory: _124 (_118);
PULSE.c:22:2: missed: statement clobbers memory: _131 (_125);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_132);
PULSE.c:26:3: missed: statement clobbers memory: memset (_137, 0, _135);
PULSE.c:26:3: missed: statement clobbers memory: memset (_130, 0, _128);
PULSE.c:26:3: missed: statement clobbers memory: memset (_123, 0, _121);
PULSE.c:26:3: missed: statement clobbers memory: memset (_116, 0, _114);
PULSE.c:26:3: missed: statement clobbers memory: memset (_109, 0, _107);
PULSE.c:26:3: missed: statement clobbers memory: memset (_87, 0, _85);
PULSE.c:75:6: missed: statement clobbers memory: _21 (current_183, args);
PULSE.c:80:4: missed: statement clobbers memory: printf ("Epoch: %d Item: %d Loss: %.10f\r", i_181, j_182, _22);
PULSE.c:47:6: missed: statement clobbers memory: __builtin_stack_restore (saved_stack.7_35);
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4DI
PULSE.c:47:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:89:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:89:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:94:8: missed: couldn't vectorize loop
PULSE.c:94:8: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:91:6: note: vectorized 0 loops in function.
PULSE.c:96:3: missed: statement clobbers memory: _1 (current_10);
PULSE.c:99:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:99:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Loss.c:15:19: optimized: loop vectorized using 32 byte vectors
Loss.c:15:19: optimized:  loop versioned for vectorization because of possible aliasing
Loss.c:15:19: optimized: loop vectorized using 16 byte vectors
Loss.c:12:23: note: vectorized 1 loops in function.
Loss.c:12:23: note: ***** Analysis failed with vector mode V8SF
Loss.c:12:23: note: ***** The result for vector mode V32QI would be the same
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V16QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V16QI
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V8QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V8QI
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V4QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V4QI
Loss.c:7:19: missed: couldn't vectorize loop
Loss.c:8:38: missed: not vectorized: unsupported use in stmt.
Loss.c:4:23: note: vectorized 0 loops in function.
Loss.c:9:13: note: ***** Analysis failed with vector mode V8SF
Loss.c:9:13: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Loss.c:23:2: note: ***** Analysis failed with vector mode VOID
Layer.c:7:34: missed: statement clobbers memory: _2 = PULSE_Alloc (64, 4, n_inputs.0_1, optimization_11(D));
Layer.c:8:35: missed: statement clobbers memory: _4 = PULSE_Alloc (64, 4, n_outputs.1_3, optimization_11(D));
Layer.c:9:34: missed: statement clobbers memory: _5 = PULSE_Alloc (64, 4, n_outputs.1_3, optimization_11(D));
Layer.c:14:19: missed: statement clobbers memory: _6 = PULSE_GetActivationFunctionPtr (activation_function_16(D));
Layer.c:19:9: note: ***** Analysis succeeded with vector mode V8SI
Layer.c:19:9: note: SLPing BB part
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x7f169f8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_15(D);
Layer.c:19:9: note: 	stmt 0 MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_15(D);
Layer.c:19:9: note: 	stmt 1 MEM <unsigned int> [(struct PULSE_Layer *)&<retval> + 4B] = optimization_11(D);
Layer.c:19:9: note: 	children 0x7f16a78
Layer.c:19:9: note: node (external) 0x7f16a78 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ type_15(D), optimization_11(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x7f16af8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: <retval>.n_inputs = n_inputs_9(D);
Layer.c:19:9: note: 	stmt 0 <retval>.n_inputs = n_inputs_9(D);
Layer.c:19:9: note: 	stmt 1 <retval>.n_outputs = n_outputs_10(D);
Layer.c:19:9: note: 	children 0x7f16b78
Layer.c:19:9: note: node (external) 0x7f16b78 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_9(D), n_outputs_10(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x7f16c78 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.inputs = _2;
Layer.c:19:9: note: 	stmt 0 <retval>.inputs = _2;
Layer.c:19:9: note: 	stmt 1 <retval>.outputs = _4;
Layer.c:19:9: note: 	children 0x7f16cf8
Layer.c:19:9: note: node (external) 0x7f16cf8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	stmt 0 _2 = PULSE_Alloc (64, 4, n_inputs.0_1, optimization_11(D));
Layer.c:19:9: note: 	stmt 1 _4 = PULSE_Alloc (64, 4, n_outputs.1_3, optimization_11(D));
Layer.c:19:9: note: 	children 0x7f16d78 0x7f16df8 0x7f16e78 0x7f16f78
Layer.c:19:9: note: node (constant) 0x7f16d78 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 64, 64 }
Layer.c:19:9: note: node (constant) 0x7f16df8 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 4, 4 }
Layer.c:19:9: note: node 0x7f16e78 (max_nunits=2, refcnt=1) vector(2) int
Layer.c:19:9: note: op template: n_inputs.0_1 = (int) n_inputs_9(D);
Layer.c:19:9: note: 	stmt 0 n_inputs.0_1 = (int) n_inputs_9(D);
Layer.c:19:9: note: 	stmt 1 n_outputs.1_3 = (int) n_outputs_10(D);
Layer.c:19:9: note: 	children 0x7f16ef8
Layer.c:19:9: note: node (external) 0x7f16ef8 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_9(D), n_outputs_10(D) }
Layer.c:19:9: note: node (external) 0x7f16f78 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ optimization_11(D), optimization_11(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x7f17078 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: op template: <retval>.feed = feed_18(D);
Layer.c:19:9: note: 	stmt 0 <retval>.feed = feed_18(D);
Layer.c:19:9: note: 	stmt 1 <retval>.back = back_19(D);
Layer.c:19:9: note: 	stmt 2 <retval>.fix = fix_20(D);
Layer.c:19:9: note: 	stmt 3 <retval>.destroy = destroy_21(D);
Layer.c:19:9: note: 	children 0x7f170f8
Layer.c:19:9: note: node (external) 0x7f170f8 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: 	{ feed_18(D), back_19(D), fix_20(D), destroy_21(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 64
  Scalar cost: 64
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x7f171f8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 0 <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 1 <retval>.child = 0B;
Layer.c:19:9: note: 	children 0x7f17278
Layer.c:19:9: note: node (constant) 0x7f17278 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ 0B, 0B }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Basic block will be vectorized using SLP
Layer.c:19:9: optimized: basic block part vectorized using 8 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x7f169f8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_15(D);
Layer.c:19:9: note: 	stmt 0 MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_15(D);
Layer.c:19:9: note: 	stmt 1 MEM <unsigned int> [(struct PULSE_Layer *)&<retval> + 4B] = optimization_11(D);
Layer.c:19:9: note: 	children 0x7f16a78
Layer.c:19:9: note: node (external) 0x7f16a78 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ type_15(D), optimization_11(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_15(D);
Layer.c:19:9: note: vect_is_simple_use: operand optimization_11(D), type of def: external
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>]
Layer.c:19:9: note: created &MEM <unsigned int> [(struct PULSE_Layer *)&<retval>]
Layer.c:19:9: note: add new stmt: MEM <vector(2) unsigned int> [(struct PULSE_Layer *)&<retval>] = _38;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 8 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x7f16af8 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: <retval>.n_inputs = n_inputs_9(D);
Layer.c:19:9: note: 	stmt 0 <retval>.n_inputs = n_inputs_9(D);
Layer.c:19:9: note: 	stmt 1 <retval>.n_outputs = n_outputs_10(D);
Layer.c:19:9: note: 	children 0x7f16b78
Layer.c:19:9: note: node (external) 0x7f16b78 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_9(D), n_outputs_10(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.n_inputs = n_inputs_9(D);
Layer.c:19:9: note: vect_is_simple_use: operand n_outputs_10(D), type of def: external
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: <retval>.n_inputs
Layer.c:19:9: note: created &<retval>.n_inputs
Layer.c:19:9: note: add new stmt: MEM <vector(2) unsigned int> [(unsigned int *)&<retval> + 96B] = _40;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 16 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x7f16c78 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.inputs = _2;
Layer.c:19:9: note: 	stmt 0 <retval>.inputs = _2;
Layer.c:19:9: note: 	stmt 1 <retval>.outputs = _4;
Layer.c:19:9: note: 	children 0x7f16cf8
Layer.c:19:9: note: node (external) 0x7f16cf8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	stmt 0 _2 = PULSE_Alloc (64, 4, n_inputs.0_1, optimization_11(D));
Layer.c:19:9: note: 	stmt 1 _4 = PULSE_Alloc (64, 4, n_outputs.1_3, optimization_11(D));
Layer.c:19:9: note: 	children 0x7f16d78 0x7f16df8 0x7f16e78 0x7f16f78
Layer.c:19:9: note: node (constant) 0x7f16d78 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 64, 64 }
Layer.c:19:9: note: node (constant) 0x7f16df8 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 4, 4 }
Layer.c:19:9: note: node 0x7f16e78 (max_nunits=2, refcnt=1) vector(2) int
Layer.c:19:9: note: op template: n_inputs.0_1 = (int) n_inputs_9(D);
Layer.c:19:9: note: 	stmt 0 n_inputs.0_1 = (int) n_inputs_9(D);
Layer.c:19:9: note: 	stmt 1 n_outputs.1_3 = (int) n_outputs_10(D);
Layer.c:19:9: note: 	children 0x7f16ef8
Layer.c:19:9: note: node (external) 0x7f16ef8 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_9(D), n_outputs_10(D) }
Layer.c:19:9: note: node (external) 0x7f16f78 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ optimization_11(D), optimization_11(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.inputs = _2;
Layer.c:19:9: note: vect_is_simple_use: operand PULSE_Alloc (64, 4, n_outputs.1_3, optimization_11(D)), type of def: internal
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.inputs
Layer.c:19:9: note: created &<retval>.inputs
Layer.c:19:9: note: add new stmt: MEM <vector(2) long unsigned int> [(float * *)&<retval> + 8B] = _44;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 32 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x7f17078 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: op template: <retval>.feed = feed_18(D);
Layer.c:19:9: note: 	stmt 0 <retval>.feed = feed_18(D);
Layer.c:19:9: note: 	stmt 1 <retval>.back = back_19(D);
Layer.c:19:9: note: 	stmt 2 <retval>.fix = fix_20(D);
Layer.c:19:9: note: 	stmt 3 <retval>.destroy = destroy_21(D);
Layer.c:19:9: note: 	children 0x7f170f8
Layer.c:19:9: note: node (external) 0x7f170f8 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: 	{ feed_18(D), back_19(D), fix_20(D), destroy_21(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.feed = feed_18(D);
Layer.c:19:9: note: vect_is_simple_use: operand back_19(D), type of def: external
Layer.c:19:9: note: vect_is_simple_use: operand fix_20(D), type of def: external
Layer.c:19:9: note: vect_is_simple_use: operand destroy_21(D), type of def: external
Layer.c:19:9: note: conflicting alias set types.
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(4) long unsigned int  vectorizing a pointer ref: <retval>.feed
Layer.c:19:9: note: created &<retval>.feed
Layer.c:19:9: note: add new stmt: MEM <vector(4) long unsigned int> [(void *)&<retval> + 32B] = _50;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 16 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x7f171f8 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 0 <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 1 <retval>.child = 0B;
Layer.c:19:9: note: 	children 0x7f17278
Layer.c:19:9: note: node (constant) 0x7f17278 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ 0B, 0B }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.parent = 0B;
Layer.c:19:9: note: vect_is_simple_use: operand 0B, type of def: constant
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.parent
Layer.c:19:9: note: created &<retval>.parent
Layer.c:19:9: note: add new stmt: MEM <vector(2) long unsigned int> [(struct PULSE_Layer * *)&<retval> + 72B] = { 0, 0 };
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: note: ***** The result for vector mode V32QI would be the same
Layer.c:24:2: missed: statement clobbers memory: free (_1);
Layer.c:25:2: missed: statement clobbers memory: free (_2);
Layer.c:26:2: missed: statement clobbers memory: free (_3);
Layer.c:27:1: note: ***** Analysis failed with vector mode V4DI
Layer.c:27:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:7:27: missed: couldn't vectorize loop
Dense.c:7:27: missed: not vectorized: unsupported outerloop form.
Dense.c:10:20: missed: couldn't vectorize loop
Dense.c:11:21: missed: not vectorized: complicated access pattern.
Dense.c:4:13: note: vectorized 0 loops in function.
Dense.c:14:2: missed: statement clobbers memory: _30 (pretmp_91, _50, 0);
Dense.c:7:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:7:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:7:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:7:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:7:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:7:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:7:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:7:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:22:27: missed: couldn't vectorize loop
Dense.c:22:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:26:20: optimized: loop vectorized using 32 byte vectors
Dense.c:26:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:26:20: optimized: loop vectorized using 16 byte vectors
Dense.c:26:20: missed: couldn't vectorize loop
Dense.c:28:20: missed: not vectorized: no vectype for stmt: _21 = *_20;
 scalar_type: float
Dense.c:18:13: note: vectorized 1 loops in function.
Dense.c:21:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:22:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:22:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:22:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:22:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:22:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:22:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:22:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:22:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:39:28: missed: couldn't vectorize loop
Dense.c:39:28: missed: not vectorized: unsupported outerloop form.
Dense.c:43:21: optimized: loop vectorized using 32 byte vectors
Dense.c:43:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:43:21: optimized: loop vectorized using 16 byte vectors
Dense.c:35:13: note: vectorized 1 loops in function.
Dense.c:35:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:35:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:35:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:35:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:35:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:35:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:35:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:39:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:143:19: missed: couldn't vectorize loop
Dense.c:143:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:134:19: missed: couldn't vectorize loop
Dense.c:134:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:127:13: note: vectorized 0 loops in function.
Dense.c:151:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:151:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:96:28: missed: couldn't vectorize loop
Dense.c:96:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:99:21: missed: couldn't vectorize loop
Dense.c:99:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:113:28: missed: couldn't vectorize loop
Dense.c:113:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:116:21: missed: couldn't vectorize loop
Dense.c:116:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:82:19: missed: couldn't vectorize loop
Dense.c:82:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:76:13: note: vectorized 0 loops in function.
Dense.c:79:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:101:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:101:17: note: SLPing BB part
Dense.c:118:17: note: Costing subgraph: 
Dense.c:118:17: note: node 0x6e2f1d8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:118:17: note: op template: _49 = (sizetype) j_137;
Dense.c:118:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:118:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:118:17: note: 	children 0x6e2f2d8
Dense.c:118:17: note: node (external) 0x6e2f2d8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:118:17: note: 	{ j_137, wi_136 }
Dense.c:118:17: note: Cost model analysis: 
Dense.c:118:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:118:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:118:17: missed: not vectorized: vectorization is not profitable.
Dense.c:101:17: note: Costing subgraph: 
Dense.c:101:17: note: node 0x6e2f3d8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:101:17: note: op template: _24 = (sizetype) j_134;
Dense.c:101:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:101:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:101:17: note: 	children 0x6e2f4d8
Dense.c:101:17: note: node (external) 0x6e2f4d8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:101:17: note: 	{ j_134, wi_133 }
Dense.c:101:17: note: Cost model analysis: 
Dense.c:101:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:101:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:101:17: missed: not vectorized: vectorization is not profitable.
Dense.c:101:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:101:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:101:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:101:17: note: SLPing BB part
Dense.c:118:17: note: Costing subgraph: 
Dense.c:118:17: note: node 0x6e2f3d8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:118:17: note: op template: _49 = (sizetype) j_137;
Dense.c:118:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:118:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:118:17: note: 	children 0x6e2f1d8
Dense.c:118:17: note: node (external) 0x6e2f1d8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:118:17: note: 	{ j_137, wi_136 }
Dense.c:118:17: note: Cost model analysis: 
Dense.c:118:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:118:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:118:17: missed: not vectorized: vectorization is not profitable.
Dense.c:101:17: note: Costing subgraph: 
Dense.c:101:17: note: node 0x6e2f558 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:101:17: note: op template: _24 = (sizetype) j_134;
Dense.c:101:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:101:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:101:17: note: 	children 0x6e2f458
Dense.c:101:17: note: node (external) 0x6e2f458 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:101:17: note: 	{ j_134, wi_133 }
Dense.c:101:17: note: Cost model analysis: 
Dense.c:101:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:101:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:101:17: missed: not vectorized: vectorization is not profitable.
Dense.c:101:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:96:55: note: ***** Analysis failed with vector mode V8QI
Dense.c:96:55: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:96:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:56:27: missed: couldn't vectorize loop
Dense.c:56:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:59:20: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:905:10: missed: not vectorized: no vectype for stmt: _41 = MEM[(__m256_u * {ref-all})_6];
 scalar_type: __m256_u
Dense.c:59:20: note: ***** Analysis failed with vector mode VOID
Dense.c:52:13: note: vectorized 0 loops in function.
Dense.c:52:13: missed: splitting region at dont-vectorize loop 3 entry at bb18
Dense.c:61:14: note: ***** Analysis failed with vector mode V4DI
Dense.c:61:14: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:61:14: missed: splitting region at dominance boundary bb8
Dense.c:61:14: note: ***** Analysis failed with vector mode VOID
Dense.c:61:14: missed: splitting region at loop 1 exit at bb16
Dense.c:56:27: note: ***** Analysis failed with vector mode V8SF
Dense.c:56:27: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Dense.c:56:27: missed: splitting region at dominance boundary bb10
Dense.c:56:27: note: ***** Analysis failed with vector mode VOID
Dense.c:72:2: missed: statement clobbers memory: _27 (pretmp_153, _61, 0);
Dense.c:73:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:73:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:158:2: missed: statement clobbers memory: PULSE_Free (_1);
Dense.c:159:2: missed: statement clobbers memory: PULSE_Free (_2);
Dense.c:160:2: missed: statement clobbers memory: PULSE_Free (_3);
Dense.c:161:2: missed: statement clobbers memory: PULSE_Free (_4);
Dense.c:162:2: missed: statement clobbers memory: PULSE_Free (dense_7);
Dense.c:163:2: missed: statement clobbers memory: PULSE_DestroyLayer (this_6(D));
Dense.c:164:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:164:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:178:19: missed: couldn't vectorize loop
Dense.c:178:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:168:13: note: vectorized 0 loops in function.
Dense.c:170:47: missed: statement clobbers memory: dense_30 = malloc (40);
Dense.c:172:36: missed: statement clobbers memory: _1 = PULSE_Alloc2D (64, 4, n_inputs_31(D), n_outputs_32(D), optimization_33(D));
Dense.c:173:38: missed: statement clobbers memory: _2 = PULSE_Alloc2D (64, 4, n_inputs_31(D), n_outputs_32(D), optimization_33(D));
Dense.c:174:36: missed: statement clobbers memory: _3 = PULSE_Alloc (64, 4, n_outputs_32(D), optimization_33(D));
Dense.c:175:35: missed: statement clobbers memory: _4 = PULSE_Alloc (64, 4, n_outputs_32(D), optimization_33(D));
Dense.c:176:36: missed: statement clobbers memory: _5 = PULSE_Alloc (64, 4, n_outputs_32(D), optimization_33(D));
Dense.c:179:39: missed: statement clobbers memory: _6 = rand ();
Dense.c:179:73: missed: statement clobbers memory: _58 = sqrt (_13);
Dense.c:191:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:192:4: missed: statement clobbers memory: exit (1);
Dense.c:188:4: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.3_24, n_outputs.2_23, 1, activation_function_46(D), _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:185:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.1_22, n_outputs.0_21, 1, activation_function_46(D), _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:198:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Dense.c:198:9: note: ***** Analysis failed with vector mode V4DI
Dense.c:198:9: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Activations.c:17:19: optimized: loop vectorized using 32 byte vectors
Activations.c:17:19: optimized: loop vectorized using 16 byte vectors
Activations.c:17:19: optimized: loop vectorized using 32 byte vectors
Activations.c:17:19: optimized: loop vectorized using 16 byte vectors
Activations.c:14:13: note: vectorized 2 loops in function.
Activations.c:14:13: note: ***** Analysis failed with vector mode V8SF
Activations.c:14:13: note: ***** The result for vector mode V32QI would be the same
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V16QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V16QI
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V8QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V8QI
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V4QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V4QI
Activations.c:28:19: missed: couldn't vectorize loop
Activations.c:28:19: missed: not vectorized: unsupported control flow in loop.
Activations.c:28:19: optimized: loop vectorized using 32 byte vectors
Activations.c:28:19: optimized: loop vectorized using 16 byte vectors
Activations.c:25:13: note: vectorized 1 loops in function.
Activations.c:25:13: note: ***** Analysis failed with vector mode V8SF
Activations.c:25:13: note: ***** The result for vector mode V32QI would be the same
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V16QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V16QI
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V8QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V8QI
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V4QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V4QI
Activations.c:38:1: note: ***** Analysis failed with vector mode VOID
Activations.c:5:19: missed: couldn't vectorize loop
Activations.c:9:21: missed: statement clobbers memory: _36 = expf (_18);
Activations.c:5:19: missed: couldn't vectorize loop
Activations.c:9:21: missed: statement clobbers memory: _12 = expf (_11);
Activations.c:3:13: note: vectorized 0 loops in function.
Activations.c:9:21: missed: statement clobbers memory: _12 = expf (_11);
Activations.c:9:21: missed: statement clobbers memory: _36 = expf (_18);
Activations.c:11:1: note: ***** Analysis failed with vector mode V8SF
Activations.c:11:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Activations.c:44:2: note: ***** Analysis failed with vector mode VOID
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:4:18: note: vectorized 0 loops in function.
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_4, inputs_15, _3);
PULSE.c:8:2: missed: statement clobbers memory: _5 (layer_17);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_12, pretmp_26, _9);
PULSE.c:13:28: note: ***** Analysis failed with vector mode V8SI
PULSE.c:13:28: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:22:2: missed: statement clobbers memory: _1 (layer_10(D));
PULSE.c:22:2: missed: statement clobbers memory: _14 (_2);
PULSE.c:22:2: missed: statement clobbers memory: _21 (_15);
PULSE.c:22:2: missed: statement clobbers memory: _28 (_22);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_29);
PULSE.c:26:3: missed: statement clobbers memory: memset (_34, 0, _32);
PULSE.c:26:3: missed: statement clobbers memory: memset (_27, 0, _25);
PULSE.c:26:3: missed: statement clobbers memory: memset (_20, 0, _18);
PULSE.c:26:3: missed: statement clobbers memory: memset (_7, 0, _5);
PULSE.c:28:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:28:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:32:6: note: vectorized 1 loops in function.
PULSE.c:34:8: missed: statement clobbers memory: _1 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_2);
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _9 = rand ();
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8SI
PULSE.c:32:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:61:16: missed: couldn't vectorize loop
PULSE.c:61:16: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:64:17: missed: couldn't vectorize loop
PULSE.c:64:17: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:73:19: missed: couldn't vectorize loop
PULSE.c:73:19: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _64 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:53:22: missed: couldn't vectorize loop
PULSE.c:53:22: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:47:6: note: vectorized 1 loops in function.
PULSE.c:48:1: missed: statement clobbers memory: saved_stack.7_35 = __builtin_stack_save ();
PULSE.c:49:46: missed: statement clobbers memory: _1 = PULSE_GetLossFunctionPtr (loss_function_36(D));
PULSE.c:60:10: missed: statement clobbers memory: random.4_42 = __builtin_alloca_with_align (_4, 32);
PULSE.c:34:8: missed: statement clobbers memory: _56 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_57);
PULSE.c:39:29: missed: statement clobbers memory: _64 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _67 = rand ();
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_93, inputs_88, _92);
PULSE.c:8:2: missed: statement clobbers memory: _94 (layer_89);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_100, _99, _98);
PULSE.c:67:11: missed: statement clobbers memory: loss_51 = PULSE_GetLoss_38 (_17, _16, _12, _11);
PULSE.c:22:2: missed: statement clobbers memory: _81 (output_30);
PULSE.c:22:2: missed: statement clobbers memory: _103 (_82);
PULSE.c:22:2: missed: statement clobbers memory: _110 (_104);
PULSE.c:22:2: missed: statement clobbers memory: _117 (_111);
PULSE.c:22:2: missed: statement clobbers memory: _124 (_118);
PULSE.c:22:2: missed: statement clobbers memory: _131 (_125);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_132);
PULSE.c:26:3: missed: statement clobbers memory: memset (_137, 0, _135);
PULSE.c:26:3: missed: statement clobbers memory: memset (_130, 0, _128);
PULSE.c:26:3: missed: statement clobbers memory: memset (_123, 0, _121);
PULSE.c:26:3: missed: statement clobbers memory: memset (_116, 0, _114);
PULSE.c:26:3: missed: statement clobbers memory: memset (_109, 0, _107);
PULSE.c:26:3: missed: statement clobbers memory: memset (_87, 0, _85);
PULSE.c:75:6: missed: statement clobbers memory: _21 (current_183, args);
PULSE.c:80:4: missed: statement clobbers memory: printf ("Epoch: %d Item: %d Loss: %.10f\r", i_181, j_182, _22);
PULSE.c:47:6: missed: statement clobbers memory: __builtin_stack_restore (saved_stack.7_35);
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4DI
PULSE.c:47:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:89:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:89:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:94:8: missed: couldn't vectorize loop
PULSE.c:94:8: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:91:6: note: vectorized 0 loops in function.
PULSE.c:96:3: missed: statement clobbers memory: _1 (current_10);
PULSE.c:99:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:99:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Loss.c:15:19: optimized: loop vectorized using 32 byte vectors
Loss.c:15:19: optimized:  loop versioned for vectorization because of possible aliasing
Loss.c:15:19: optimized: loop vectorized using 16 byte vectors
Loss.c:12:23: note: vectorized 1 loops in function.
Loss.c:12:23: note: ***** Analysis failed with vector mode V8SF
Loss.c:12:23: note: ***** The result for vector mode V32QI would be the same
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V16QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V16QI
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V8QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V8QI
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V4QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V4QI
Loss.c:7:19: missed: couldn't vectorize loop
Loss.c:8:38: missed: not vectorized: unsupported use in stmt.
Loss.c:4:23: note: vectorized 0 loops in function.
Loss.c:9:13: note: ***** Analysis failed with vector mode V8SF
Loss.c:9:13: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Loss.c:23:2: note: ***** Analysis failed with vector mode VOID
PulseAlloc.c:11:11: missed: statement clobbers memory: _18 = aligned_alloc (64, _8);
PulseAlloc.c:8:28: missed: statement clobbers memory: _20 = aligned_alloc (64, _2);
PulseAlloc.c:16:2: missed: statement clobbers memory: exit (1);
PulseAlloc.c:16:2: note: ***** Analysis failed with vector mode VOID
PulseAlloc.c:30:11: missed: statement clobbers memory: _21 = aligned_alloc (64, _10);
PulseAlloc.c:26:28: missed: statement clobbers memory: _23 = aligned_alloc (64, _3);
PulseAlloc.c:35:2: missed: statement clobbers memory: exit (1);
PulseAlloc.c:35:2: note: ***** Analysis failed with vector mode VOID
PulseAlloc.c:11:11: missed: statement clobbers memory: _18 = aligned_alloc (64, _8);
PulseAlloc.c:8:28: missed: statement clobbers memory: _20 = aligned_alloc (64, _2);
PulseAlloc.c:16:2: missed: statement clobbers memory: exit (1);
PulseAlloc.c:16:2: note: ***** Analysis failed with vector mode VOID
PulseAlloc.c:30:11: missed: statement clobbers memory: _21 = aligned_alloc (64, _10);
PulseAlloc.c:26:28: missed: statement clobbers memory: _23 = aligned_alloc (64, _3);
PulseAlloc.c:35:2: missed: statement clobbers memory: exit (1);
PulseAlloc.c:35:2: note: ***** Analysis failed with vector mode VOID
PulseAlloc.c:39:30: missed: statement clobbers memory: free (ptr_2(D));
PulseAlloc.c:39:40: note: ***** Analysis failed with vector mode VOID
Layer.c:7:34: missed: statement clobbers memory: _2 = PULSE_Alloc (64, 4, n_inputs.0_1, optimization_11(D));
Layer.c:8:35: missed: statement clobbers memory: _4 = PULSE_Alloc (64, 4, n_outputs.1_3, optimization_11(D));
Layer.c:9:34: missed: statement clobbers memory: _5 = PULSE_Alloc (64, 4, n_outputs.1_3, optimization_11(D));
Layer.c:14:19: missed: statement clobbers memory: _6 = PULSE_GetActivationFunctionPtr (activation_function_16(D));
Layer.c:19:9: note: ***** Analysis succeeded with vector mode V8SI
Layer.c:19:9: note: SLPing BB part
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x7e11d98 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_15(D);
Layer.c:19:9: note: 	stmt 0 MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_15(D);
Layer.c:19:9: note: 	stmt 1 MEM <unsigned int> [(struct PULSE_Layer *)&<retval> + 4B] = optimization_11(D);
Layer.c:19:9: note: 	children 0x7e11e18
Layer.c:19:9: note: node (external) 0x7e11e18 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ type_15(D), optimization_11(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x7e11e98 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: <retval>.n_inputs = n_inputs_9(D);
Layer.c:19:9: note: 	stmt 0 <retval>.n_inputs = n_inputs_9(D);
Layer.c:19:9: note: 	stmt 1 <retval>.n_outputs = n_outputs_10(D);
Layer.c:19:9: note: 	children 0x7e11f18
Layer.c:19:9: note: node (external) 0x7e11f18 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_9(D), n_outputs_10(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x7e12018 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.inputs = _2;
Layer.c:19:9: note: 	stmt 0 <retval>.inputs = _2;
Layer.c:19:9: note: 	stmt 1 <retval>.outputs = _4;
Layer.c:19:9: note: 	children 0x7e12098
Layer.c:19:9: note: node (external) 0x7e12098 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	stmt 0 _2 = PULSE_Alloc (64, 4, n_inputs.0_1, optimization_11(D));
Layer.c:19:9: note: 	stmt 1 _4 = PULSE_Alloc (64, 4, n_outputs.1_3, optimization_11(D));
Layer.c:19:9: note: 	children 0x7e12118 0x7e12198 0x7e12218 0x7e12318
Layer.c:19:9: note: node (constant) 0x7e12118 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 64, 64 }
Layer.c:19:9: note: node (constant) 0x7e12198 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 4, 4 }
Layer.c:19:9: note: node 0x7e12218 (max_nunits=2, refcnt=1) vector(2) int
Layer.c:19:9: note: op template: n_inputs.0_1 = (int) n_inputs_9(D);
Layer.c:19:9: note: 	stmt 0 n_inputs.0_1 = (int) n_inputs_9(D);
Layer.c:19:9: note: 	stmt 1 n_outputs.1_3 = (int) n_outputs_10(D);
Layer.c:19:9: note: 	children 0x7e12298
Layer.c:19:9: note: node (external) 0x7e12298 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_9(D), n_outputs_10(D) }
Layer.c:19:9: note: node (external) 0x7e12318 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ optimization_11(D), optimization_11(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x7e12418 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: op template: <retval>.feed = feed_18(D);
Layer.c:19:9: note: 	stmt 0 <retval>.feed = feed_18(D);
Layer.c:19:9: note: 	stmt 1 <retval>.back = back_19(D);
Layer.c:19:9: note: 	stmt 2 <retval>.fix = fix_20(D);
Layer.c:19:9: note: 	stmt 3 <retval>.destroy = destroy_21(D);
Layer.c:19:9: note: 	children 0x7e12498
Layer.c:19:9: note: node (external) 0x7e12498 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: 	{ feed_18(D), back_19(D), fix_20(D), destroy_21(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 64
  Scalar cost: 64
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x7e12598 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 0 <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 1 <retval>.child = 0B;
Layer.c:19:9: note: 	children 0x7e12618
Layer.c:19:9: note: node (constant) 0x7e12618 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ 0B, 0B }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Basic block will be vectorized using SLP
Layer.c:19:9: optimized: basic block part vectorized using 8 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x7e11d98 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_15(D);
Layer.c:19:9: note: 	stmt 0 MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_15(D);
Layer.c:19:9: note: 	stmt 1 MEM <unsigned int> [(struct PULSE_Layer *)&<retval> + 4B] = optimization_11(D);
Layer.c:19:9: note: 	children 0x7e11e18
Layer.c:19:9: note: node (external) 0x7e11e18 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ type_15(D), optimization_11(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_15(D);
Layer.c:19:9: note: vect_is_simple_use: operand optimization_11(D), type of def: external
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>]
Layer.c:19:9: note: created &MEM <unsigned int> [(struct PULSE_Layer *)&<retval>]
Layer.c:19:9: note: add new stmt: MEM <vector(2) unsigned int> [(struct PULSE_Layer *)&<retval>] = _38;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 8 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x7e11e98 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: <retval>.n_inputs = n_inputs_9(D);
Layer.c:19:9: note: 	stmt 0 <retval>.n_inputs = n_inputs_9(D);
Layer.c:19:9: note: 	stmt 1 <retval>.n_outputs = n_outputs_10(D);
Layer.c:19:9: note: 	children 0x7e11f18
Layer.c:19:9: note: node (external) 0x7e11f18 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_9(D), n_outputs_10(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.n_inputs = n_inputs_9(D);
Layer.c:19:9: note: vect_is_simple_use: operand n_outputs_10(D), type of def: external
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: <retval>.n_inputs
Layer.c:19:9: note: created &<retval>.n_inputs
Layer.c:19:9: note: add new stmt: MEM <vector(2) unsigned int> [(unsigned int *)&<retval> + 96B] = _40;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 16 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x7e12018 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.inputs = _2;
Layer.c:19:9: note: 	stmt 0 <retval>.inputs = _2;
Layer.c:19:9: note: 	stmt 1 <retval>.outputs = _4;
Layer.c:19:9: note: 	children 0x7e12098
Layer.c:19:9: note: node (external) 0x7e12098 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	stmt 0 _2 = PULSE_Alloc (64, 4, n_inputs.0_1, optimization_11(D));
Layer.c:19:9: note: 	stmt 1 _4 = PULSE_Alloc (64, 4, n_outputs.1_3, optimization_11(D));
Layer.c:19:9: note: 	children 0x7e12118 0x7e12198 0x7e12218 0x7e12318
Layer.c:19:9: note: node (constant) 0x7e12118 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 64, 64 }
Layer.c:19:9: note: node (constant) 0x7e12198 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 4, 4 }
Layer.c:19:9: note: node 0x7e12218 (max_nunits=2, refcnt=1) vector(2) int
Layer.c:19:9: note: op template: n_inputs.0_1 = (int) n_inputs_9(D);
Layer.c:19:9: note: 	stmt 0 n_inputs.0_1 = (int) n_inputs_9(D);
Layer.c:19:9: note: 	stmt 1 n_outputs.1_3 = (int) n_outputs_10(D);
Layer.c:19:9: note: 	children 0x7e12298
Layer.c:19:9: note: node (external) 0x7e12298 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_9(D), n_outputs_10(D) }
Layer.c:19:9: note: node (external) 0x7e12318 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ optimization_11(D), optimization_11(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.inputs = _2;
Layer.c:19:9: note: vect_is_simple_use: operand PULSE_Alloc (64, 4, n_outputs.1_3, optimization_11(D)), type of def: internal
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.inputs
Layer.c:19:9: note: created &<retval>.inputs
Layer.c:19:9: note: add new stmt: MEM <vector(2) long unsigned int> [(float * *)&<retval> + 8B] = _44;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 32 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x7e12418 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: op template: <retval>.feed = feed_18(D);
Layer.c:19:9: note: 	stmt 0 <retval>.feed = feed_18(D);
Layer.c:19:9: note: 	stmt 1 <retval>.back = back_19(D);
Layer.c:19:9: note: 	stmt 2 <retval>.fix = fix_20(D);
Layer.c:19:9: note: 	stmt 3 <retval>.destroy = destroy_21(D);
Layer.c:19:9: note: 	children 0x7e12498
Layer.c:19:9: note: node (external) 0x7e12498 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: 	{ feed_18(D), back_19(D), fix_20(D), destroy_21(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.feed = feed_18(D);
Layer.c:19:9: note: vect_is_simple_use: operand back_19(D), type of def: external
Layer.c:19:9: note: vect_is_simple_use: operand fix_20(D), type of def: external
Layer.c:19:9: note: vect_is_simple_use: operand destroy_21(D), type of def: external
Layer.c:19:9: note: conflicting alias set types.
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(4) long unsigned int  vectorizing a pointer ref: <retval>.feed
Layer.c:19:9: note: created &<retval>.feed
Layer.c:19:9: note: add new stmt: MEM <vector(4) long unsigned int> [(void *)&<retval> + 32B] = _50;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 16 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x7e12598 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 0 <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 1 <retval>.child = 0B;
Layer.c:19:9: note: 	children 0x7e12618
Layer.c:19:9: note: node (constant) 0x7e12618 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ 0B, 0B }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.parent = 0B;
Layer.c:19:9: note: vect_is_simple_use: operand 0B, type of def: constant
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.parent
Layer.c:19:9: note: created &<retval>.parent
Layer.c:19:9: note: add new stmt: MEM <vector(2) long unsigned int> [(struct PULSE_Layer * *)&<retval> + 72B] = { 0, 0 };
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: note: ***** The result for vector mode V32QI would be the same
Layer.c:24:2: missed: statement clobbers memory: free (_1);
Layer.c:25:2: missed: statement clobbers memory: free (_2);
Layer.c:26:2: missed: statement clobbers memory: free (_3);
Layer.c:27:1: note: ***** Analysis failed with vector mode V4DI
Layer.c:27:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:7:27: missed: couldn't vectorize loop
Dense.c:7:27: missed: not vectorized: unsupported outerloop form.
Dense.c:10:20: missed: couldn't vectorize loop
Dense.c:11:21: missed: not vectorized: complicated access pattern.
Dense.c:4:13: note: vectorized 0 loops in function.
Dense.c:14:2: missed: statement clobbers memory: _30 (pretmp_91, _50, 0);
Dense.c:7:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:7:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:7:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:7:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:7:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:7:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:7:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:7:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:22:27: missed: couldn't vectorize loop
Dense.c:22:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:26:20: optimized: loop vectorized using 32 byte vectors
Dense.c:26:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:26:20: optimized: loop vectorized using 16 byte vectors
Dense.c:26:20: missed: couldn't vectorize loop
Dense.c:28:20: missed: not vectorized: no vectype for stmt: _21 = *_20;
 scalar_type: float
Dense.c:18:13: note: vectorized 1 loops in function.
Dense.c:21:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:22:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:22:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:22:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:22:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:22:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:22:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:22:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:22:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:39:28: missed: couldn't vectorize loop
Dense.c:39:28: missed: not vectorized: unsupported outerloop form.
Dense.c:43:21: optimized: loop vectorized using 32 byte vectors
Dense.c:43:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:43:21: optimized: loop vectorized using 16 byte vectors
Dense.c:35:13: note: vectorized 1 loops in function.
Dense.c:35:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:35:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:35:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:35:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:35:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:35:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:35:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:39:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:143:19: missed: couldn't vectorize loop
Dense.c:143:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:134:19: missed: couldn't vectorize loop
Dense.c:134:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:127:13: note: vectorized 0 loops in function.
Dense.c:151:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:151:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:96:28: missed: couldn't vectorize loop
Dense.c:96:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:99:21: missed: couldn't vectorize loop
Dense.c:99:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:113:28: missed: couldn't vectorize loop
Dense.c:113:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:116:21: missed: couldn't vectorize loop
Dense.c:116:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:82:19: missed: couldn't vectorize loop
Dense.c:82:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:76:13: note: vectorized 0 loops in function.
Dense.c:79:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:101:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:101:17: note: SLPing BB part
Dense.c:118:17: note: Costing subgraph: 
Dense.c:118:17: note: node 0x6fa81c8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:118:17: note: op template: _49 = (sizetype) j_137;
Dense.c:118:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:118:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:118:17: note: 	children 0x6fa82c8
Dense.c:118:17: note: node (external) 0x6fa82c8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:118:17: note: 	{ j_137, wi_136 }
Dense.c:118:17: note: Cost model analysis: 
Dense.c:118:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:118:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:118:17: missed: not vectorized: vectorization is not profitable.
Dense.c:101:17: note: Costing subgraph: 
Dense.c:101:17: note: node 0x6fa83c8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:101:17: note: op template: _24 = (sizetype) j_134;
Dense.c:101:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:101:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:101:17: note: 	children 0x6fa84c8
Dense.c:101:17: note: node (external) 0x6fa84c8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:101:17: note: 	{ j_134, wi_133 }
Dense.c:101:17: note: Cost model analysis: 
Dense.c:101:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:101:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:101:17: missed: not vectorized: vectorization is not profitable.
Dense.c:101:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:101:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:101:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:101:17: note: SLPing BB part
Dense.c:118:17: note: Costing subgraph: 
Dense.c:118:17: note: node 0x6fa83c8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:118:17: note: op template: _49 = (sizetype) j_137;
Dense.c:118:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:118:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:118:17: note: 	children 0x6fa81c8
Dense.c:118:17: note: node (external) 0x6fa81c8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:118:17: note: 	{ j_137, wi_136 }
Dense.c:118:17: note: Cost model analysis: 
Dense.c:118:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:118:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:118:17: missed: not vectorized: vectorization is not profitable.
Dense.c:101:17: note: Costing subgraph: 
Dense.c:101:17: note: node 0x6fa8548 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:101:17: note: op template: _24 = (sizetype) j_134;
Dense.c:101:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:101:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:101:17: note: 	children 0x6fa8448
Dense.c:101:17: note: node (external) 0x6fa8448 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:101:17: note: 	{ j_134, wi_133 }
Dense.c:101:17: note: Cost model analysis: 
Dense.c:101:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:101:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:101:17: missed: not vectorized: vectorization is not profitable.
Dense.c:101:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:96:55: note: ***** Analysis failed with vector mode V8QI
Dense.c:96:55: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:96:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:56:27: missed: couldn't vectorize loop
Dense.c:56:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:59:20: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:905:10: missed: not vectorized: no vectype for stmt: _41 = MEM[(__m256_u * {ref-all})_6];
 scalar_type: __m256_u
Dense.c:59:20: note: ***** Analysis failed with vector mode VOID
Dense.c:52:13: note: vectorized 0 loops in function.
Dense.c:52:13: missed: splitting region at dont-vectorize loop 3 entry at bb18
Dense.c:61:14: note: ***** Analysis failed with vector mode V4DI
Dense.c:61:14: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:61:14: missed: splitting region at dominance boundary bb8
Dense.c:61:14: note: ***** Analysis failed with vector mode VOID
Dense.c:61:14: missed: splitting region at loop 1 exit at bb16
Dense.c:56:27: note: ***** Analysis failed with vector mode V8SF
Dense.c:56:27: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Dense.c:56:27: missed: splitting region at dominance boundary bb10
Dense.c:56:27: note: ***** Analysis failed with vector mode VOID
Dense.c:72:2: missed: statement clobbers memory: _27 (pretmp_153, _61, 0);
Dense.c:73:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:73:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:158:2: missed: statement clobbers memory: PULSE_Free (_1);
Dense.c:159:2: missed: statement clobbers memory: PULSE_Free (_2);
Dense.c:160:2: missed: statement clobbers memory: PULSE_Free (_3);
Dense.c:161:2: missed: statement clobbers memory: PULSE_Free (_4);
Dense.c:162:2: missed: statement clobbers memory: PULSE_Free (dense_7);
Dense.c:163:2: missed: statement clobbers memory: PULSE_DestroyLayer (this_6(D));
Dense.c:164:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:164:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:178:19: missed: couldn't vectorize loop
Dense.c:178:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:168:13: note: vectorized 0 loops in function.
Dense.c:170:47: missed: statement clobbers memory: dense_30 = malloc (40);
Dense.c:172:36: missed: statement clobbers memory: _1 = PULSE_Alloc2D (64, 4, n_inputs_31(D), n_outputs_32(D), optimization_33(D));
Dense.c:173:38: missed: statement clobbers memory: _2 = PULSE_Alloc2D (64, 4, n_inputs_31(D), n_outputs_32(D), optimization_33(D));
Dense.c:174:36: missed: statement clobbers memory: _3 = PULSE_Alloc (64, 4, n_outputs_32(D), optimization_33(D));
Dense.c:175:35: missed: statement clobbers memory: _4 = PULSE_Alloc (64, 4, n_outputs_32(D), optimization_33(D));
Dense.c:176:36: missed: statement clobbers memory: _5 = PULSE_Alloc (64, 4, n_outputs_32(D), optimization_33(D));
Dense.c:179:39: missed: statement clobbers memory: _6 = rand ();
Dense.c:179:73: missed: statement clobbers memory: _58 = sqrt (_13);
Dense.c:191:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:192:4: missed: statement clobbers memory: exit (1);
Dense.c:188:4: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.3_24, n_outputs.2_23, 1, activation_function_46(D), _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:185:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.1_22, n_outputs.0_21, 1, activation_function_46(D), _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:198:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Dense.c:198:9: note: ***** Analysis failed with vector mode V4DI
Dense.c:198:9: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Activations.c:17:19: optimized: loop vectorized using 32 byte vectors
Activations.c:17:19: optimized: loop vectorized using 16 byte vectors
Activations.c:17:19: optimized: loop vectorized using 32 byte vectors
Activations.c:17:19: optimized: loop vectorized using 16 byte vectors
Activations.c:14:13: note: vectorized 2 loops in function.
Activations.c:14:13: note: ***** Analysis failed with vector mode V8SF
Activations.c:14:13: note: ***** The result for vector mode V32QI would be the same
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V16QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V16QI
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V8QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V8QI
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V4QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V4QI
Activations.c:28:19: missed: couldn't vectorize loop
Activations.c:28:19: missed: not vectorized: unsupported control flow in loop.
Activations.c:28:19: optimized: loop vectorized using 32 byte vectors
Activations.c:28:19: optimized: loop vectorized using 16 byte vectors
Activations.c:25:13: note: vectorized 1 loops in function.
Activations.c:25:13: note: ***** Analysis failed with vector mode V8SF
Activations.c:25:13: note: ***** The result for vector mode V32QI would be the same
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V16QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V16QI
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V8QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V8QI
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V4QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V4QI
Activations.c:38:1: note: ***** Analysis failed with vector mode VOID
Activations.c:5:19: missed: couldn't vectorize loop
Activations.c:9:21: missed: statement clobbers memory: _36 = expf (_18);
Activations.c:5:19: missed: couldn't vectorize loop
Activations.c:9:21: missed: statement clobbers memory: _12 = expf (_11);
Activations.c:3:13: note: vectorized 0 loops in function.
Activations.c:9:21: missed: statement clobbers memory: _12 = expf (_11);
Activations.c:9:21: missed: statement clobbers memory: _36 = expf (_18);
Activations.c:11:1: note: ***** Analysis failed with vector mode V8SF
Activations.c:11:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Activations.c:44:2: note: ***** Analysis failed with vector mode VOID
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:4:18: note: vectorized 0 loops in function.
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_4, inputs_15, _3);
PULSE.c:8:2: missed: statement clobbers memory: _5 (layer_17);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_12, pretmp_26, _9);
PULSE.c:13:28: note: ***** Analysis failed with vector mode V8SI
PULSE.c:13:28: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:22:2: missed: statement clobbers memory: _1 (layer_10(D));
PULSE.c:22:2: missed: statement clobbers memory: _14 (_2);
PULSE.c:22:2: missed: statement clobbers memory: _21 (_15);
PULSE.c:22:2: missed: statement clobbers memory: _28 (_22);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_29);
PULSE.c:26:3: missed: statement clobbers memory: memset (_34, 0, _32);
PULSE.c:26:3: missed: statement clobbers memory: memset (_27, 0, _25);
PULSE.c:26:3: missed: statement clobbers memory: memset (_20, 0, _18);
PULSE.c:26:3: missed: statement clobbers memory: memset (_7, 0, _5);
PULSE.c:28:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:28:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:32:6: note: vectorized 1 loops in function.
PULSE.c:34:8: missed: statement clobbers memory: _1 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_2);
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _9 = rand ();
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8SI
PULSE.c:32:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:61:16: missed: couldn't vectorize loop
PULSE.c:61:16: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:64:17: missed: couldn't vectorize loop
PULSE.c:64:17: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:73:19: missed: couldn't vectorize loop
PULSE.c:73:19: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _64 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:53:22: missed: couldn't vectorize loop
PULSE.c:53:22: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:47:6: note: vectorized 1 loops in function.
PULSE.c:48:1: missed: statement clobbers memory: saved_stack.7_35 = __builtin_stack_save ();
PULSE.c:49:46: missed: statement clobbers memory: _1 = PULSE_GetLossFunctionPtr (loss_function_36(D));
PULSE.c:60:10: missed: statement clobbers memory: random.4_42 = __builtin_alloca_with_align (_4, 32);
PULSE.c:34:8: missed: statement clobbers memory: _56 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_57);
PULSE.c:39:29: missed: statement clobbers memory: _64 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _67 = rand ();
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_93, inputs_88, _92);
PULSE.c:8:2: missed: statement clobbers memory: _94 (layer_89);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_100, _99, _98);
PULSE.c:67:11: missed: statement clobbers memory: loss_51 = PULSE_GetLoss_38 (_17, _16, _12, _11);
PULSE.c:22:2: missed: statement clobbers memory: _81 (output_30);
PULSE.c:22:2: missed: statement clobbers memory: _103 (_82);
PULSE.c:22:2: missed: statement clobbers memory: _110 (_104);
PULSE.c:22:2: missed: statement clobbers memory: _117 (_111);
PULSE.c:22:2: missed: statement clobbers memory: _124 (_118);
PULSE.c:22:2: missed: statement clobbers memory: _131 (_125);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_132);
PULSE.c:26:3: missed: statement clobbers memory: memset (_137, 0, _135);
PULSE.c:26:3: missed: statement clobbers memory: memset (_130, 0, _128);
PULSE.c:26:3: missed: statement clobbers memory: memset (_123, 0, _121);
PULSE.c:26:3: missed: statement clobbers memory: memset (_116, 0, _114);
PULSE.c:26:3: missed: statement clobbers memory: memset (_109, 0, _107);
PULSE.c:26:3: missed: statement clobbers memory: memset (_87, 0, _85);
PULSE.c:75:6: missed: statement clobbers memory: _21 (current_183, args);
PULSE.c:80:4: missed: statement clobbers memory: printf ("Epoch: %d Item: %d Loss: %.10f\r", i_181, j_182, _22);
PULSE.c:47:6: missed: statement clobbers memory: __builtin_stack_restore (saved_stack.7_35);
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4DI
PULSE.c:47:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:89:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:89:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:94:8: missed: couldn't vectorize loop
PULSE.c:94:8: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:91:6: note: vectorized 0 loops in function.
PULSE.c:96:3: missed: statement clobbers memory: _1 (current_10);
PULSE.c:99:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:99:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Loss.c:15:19: optimized: loop vectorized using 32 byte vectors
Loss.c:15:19: optimized:  loop versioned for vectorization because of possible aliasing
Loss.c:15:19: optimized: loop vectorized using 16 byte vectors
Loss.c:12:23: note: vectorized 1 loops in function.
Loss.c:12:23: note: ***** Analysis failed with vector mode V8SF
Loss.c:12:23: note: ***** The result for vector mode V32QI would be the same
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V16QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V16QI
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V8QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V8QI
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V4QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V4QI
Loss.c:7:19: missed: couldn't vectorize loop
Loss.c:8:38: missed: not vectorized: unsupported use in stmt.
Loss.c:4:23: note: vectorized 0 loops in function.
Loss.c:9:13: note: ***** Analysis failed with vector mode V8SF
Loss.c:9:13: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Loss.c:23:2: note: ***** Analysis failed with vector mode VOID
PulseAlloc.c:11:11: missed: statement clobbers memory: _18 = aligned_alloc (64, _8);
PulseAlloc.c:8:28: missed: statement clobbers memory: _20 = aligned_alloc (64, _2);
PulseAlloc.c:16:2: missed: statement clobbers memory: exit (1);
PulseAlloc.c:16:2: note: ***** Analysis failed with vector mode VOID
PulseAlloc.c:30:11: missed: statement clobbers memory: _21 = aligned_alloc (64, _10);
PulseAlloc.c:26:28: missed: statement clobbers memory: _23 = aligned_alloc (64, _3);
PulseAlloc.c:35:2: missed: statement clobbers memory: exit (1);
PulseAlloc.c:35:2: note: ***** Analysis failed with vector mode VOID
PulseAlloc.c:39:30: missed: statement clobbers memory: free (ptr_2(D));
PulseAlloc.c:39:40: note: ***** Analysis failed with vector mode VOID
Layer.c:7:34: missed: statement clobbers memory: _2 = PULSE_Alloc (64, 4, n_inputs.0_1, optimization_11(D));
Layer.c:8:35: missed: statement clobbers memory: _4 = PULSE_Alloc (64, 4, n_outputs.1_3, optimization_11(D));
Layer.c:9:34: missed: statement clobbers memory: _5 = PULSE_Alloc (64, 4, n_outputs.1_3, optimization_11(D));
Layer.c:14:19: missed: statement clobbers memory: _6 = PULSE_GetActivationFunctionPtr (activation_function_16(D));
Layer.c:19:9: note: ***** Analysis succeeded with vector mode V8SI
Layer.c:19:9: note: SLPing BB part
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x8b0ba18 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_15(D);
Layer.c:19:9: note: 	stmt 0 MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_15(D);
Layer.c:19:9: note: 	stmt 1 MEM <unsigned int> [(struct PULSE_Layer *)&<retval> + 4B] = optimization_11(D);
Layer.c:19:9: note: 	children 0x8b0ba98
Layer.c:19:9: note: node (external) 0x8b0ba98 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ type_15(D), optimization_11(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x8b0bb18 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: <retval>.n_inputs = n_inputs_9(D);
Layer.c:19:9: note: 	stmt 0 <retval>.n_inputs = n_inputs_9(D);
Layer.c:19:9: note: 	stmt 1 <retval>.n_outputs = n_outputs_10(D);
Layer.c:19:9: note: 	children 0x8b0bb98
Layer.c:19:9: note: node (external) 0x8b0bb98 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_9(D), n_outputs_10(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x8b0bc98 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.inputs = _2;
Layer.c:19:9: note: 	stmt 0 <retval>.inputs = _2;
Layer.c:19:9: note: 	stmt 1 <retval>.outputs = _4;
Layer.c:19:9: note: 	children 0x8b0bd18
Layer.c:19:9: note: node (external) 0x8b0bd18 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	stmt 0 _2 = PULSE_Alloc (64, 4, n_inputs.0_1, optimization_11(D));
Layer.c:19:9: note: 	stmt 1 _4 = PULSE_Alloc (64, 4, n_outputs.1_3, optimization_11(D));
Layer.c:19:9: note: 	children 0x8b0bd98 0x8b0be18 0x8b0be98 0x8b0bf98
Layer.c:19:9: note: node (constant) 0x8b0bd98 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 64, 64 }
Layer.c:19:9: note: node (constant) 0x8b0be18 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 4, 4 }
Layer.c:19:9: note: node 0x8b0be98 (max_nunits=2, refcnt=1) vector(2) int
Layer.c:19:9: note: op template: n_inputs.0_1 = (int) n_inputs_9(D);
Layer.c:19:9: note: 	stmt 0 n_inputs.0_1 = (int) n_inputs_9(D);
Layer.c:19:9: note: 	stmt 1 n_outputs.1_3 = (int) n_outputs_10(D);
Layer.c:19:9: note: 	children 0x8b0bf18
Layer.c:19:9: note: node (external) 0x8b0bf18 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_9(D), n_outputs_10(D) }
Layer.c:19:9: note: node (external) 0x8b0bf98 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ optimization_11(D), optimization_11(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x8b0c098 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: op template: <retval>.feed = feed_18(D);
Layer.c:19:9: note: 	stmt 0 <retval>.feed = feed_18(D);
Layer.c:19:9: note: 	stmt 1 <retval>.back = back_19(D);
Layer.c:19:9: note: 	stmt 2 <retval>.fix = fix_20(D);
Layer.c:19:9: note: 	stmt 3 <retval>.destroy = destroy_21(D);
Layer.c:19:9: note: 	children 0x8b0c118
Layer.c:19:9: note: node (external) 0x8b0c118 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: 	{ feed_18(D), back_19(D), fix_20(D), destroy_21(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 64
  Scalar cost: 64
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x8b0c218 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 0 <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 1 <retval>.child = 0B;
Layer.c:19:9: note: 	children 0x8b0c298
Layer.c:19:9: note: node (constant) 0x8b0c298 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ 0B, 0B }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Basic block will be vectorized using SLP
Layer.c:19:9: optimized: basic block part vectorized using 8 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x8b0ba18 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_15(D);
Layer.c:19:9: note: 	stmt 0 MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_15(D);
Layer.c:19:9: note: 	stmt 1 MEM <unsigned int> [(struct PULSE_Layer *)&<retval> + 4B] = optimization_11(D);
Layer.c:19:9: note: 	children 0x8b0ba98
Layer.c:19:9: note: node (external) 0x8b0ba98 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ type_15(D), optimization_11(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_15(D);
Layer.c:19:9: note: vect_is_simple_use: operand optimization_11(D), type of def: external
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>]
Layer.c:19:9: note: created &MEM <unsigned int> [(struct PULSE_Layer *)&<retval>]
Layer.c:19:9: note: add new stmt: MEM <vector(2) unsigned int> [(struct PULSE_Layer *)&<retval>] = _38;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 8 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x8b0bb18 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: <retval>.n_inputs = n_inputs_9(D);
Layer.c:19:9: note: 	stmt 0 <retval>.n_inputs = n_inputs_9(D);
Layer.c:19:9: note: 	stmt 1 <retval>.n_outputs = n_outputs_10(D);
Layer.c:19:9: note: 	children 0x8b0bb98
Layer.c:19:9: note: node (external) 0x8b0bb98 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_9(D), n_outputs_10(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.n_inputs = n_inputs_9(D);
Layer.c:19:9: note: vect_is_simple_use: operand n_outputs_10(D), type of def: external
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: <retval>.n_inputs
Layer.c:19:9: note: created &<retval>.n_inputs
Layer.c:19:9: note: add new stmt: MEM <vector(2) unsigned int> [(unsigned int *)&<retval> + 96B] = _40;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 16 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x8b0bc98 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.inputs = _2;
Layer.c:19:9: note: 	stmt 0 <retval>.inputs = _2;
Layer.c:19:9: note: 	stmt 1 <retval>.outputs = _4;
Layer.c:19:9: note: 	children 0x8b0bd18
Layer.c:19:9: note: node (external) 0x8b0bd18 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	stmt 0 _2 = PULSE_Alloc (64, 4, n_inputs.0_1, optimization_11(D));
Layer.c:19:9: note: 	stmt 1 _4 = PULSE_Alloc (64, 4, n_outputs.1_3, optimization_11(D));
Layer.c:19:9: note: 	children 0x8b0bd98 0x8b0be18 0x8b0be98 0x8b0bf98
Layer.c:19:9: note: node (constant) 0x8b0bd98 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 64, 64 }
Layer.c:19:9: note: node (constant) 0x8b0be18 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 4, 4 }
Layer.c:19:9: note: node 0x8b0be98 (max_nunits=2, refcnt=1) vector(2) int
Layer.c:19:9: note: op template: n_inputs.0_1 = (int) n_inputs_9(D);
Layer.c:19:9: note: 	stmt 0 n_inputs.0_1 = (int) n_inputs_9(D);
Layer.c:19:9: note: 	stmt 1 n_outputs.1_3 = (int) n_outputs_10(D);
Layer.c:19:9: note: 	children 0x8b0bf18
Layer.c:19:9: note: node (external) 0x8b0bf18 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_9(D), n_outputs_10(D) }
Layer.c:19:9: note: node (external) 0x8b0bf98 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ optimization_11(D), optimization_11(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.inputs = _2;
Layer.c:19:9: note: vect_is_simple_use: operand PULSE_Alloc (64, 4, n_outputs.1_3, optimization_11(D)), type of def: internal
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.inputs
Layer.c:19:9: note: created &<retval>.inputs
Layer.c:19:9: note: add new stmt: MEM <vector(2) long unsigned int> [(float * *)&<retval> + 8B] = _44;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 32 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x8b0c098 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: op template: <retval>.feed = feed_18(D);
Layer.c:19:9: note: 	stmt 0 <retval>.feed = feed_18(D);
Layer.c:19:9: note: 	stmt 1 <retval>.back = back_19(D);
Layer.c:19:9: note: 	stmt 2 <retval>.fix = fix_20(D);
Layer.c:19:9: note: 	stmt 3 <retval>.destroy = destroy_21(D);
Layer.c:19:9: note: 	children 0x8b0c118
Layer.c:19:9: note: node (external) 0x8b0c118 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: 	{ feed_18(D), back_19(D), fix_20(D), destroy_21(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.feed = feed_18(D);
Layer.c:19:9: note: vect_is_simple_use: operand back_19(D), type of def: external
Layer.c:19:9: note: vect_is_simple_use: operand fix_20(D), type of def: external
Layer.c:19:9: note: vect_is_simple_use: operand destroy_21(D), type of def: external
Layer.c:19:9: note: conflicting alias set types.
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(4) long unsigned int  vectorizing a pointer ref: <retval>.feed
Layer.c:19:9: note: created &<retval>.feed
Layer.c:19:9: note: add new stmt: MEM <vector(4) long unsigned int> [(void *)&<retval> + 32B] = _50;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 16 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x8b0c218 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 0 <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 1 <retval>.child = 0B;
Layer.c:19:9: note: 	children 0x8b0c298
Layer.c:19:9: note: node (constant) 0x8b0c298 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ 0B, 0B }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.parent = 0B;
Layer.c:19:9: note: vect_is_simple_use: operand 0B, type of def: constant
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.parent
Layer.c:19:9: note: created &<retval>.parent
Layer.c:19:9: note: add new stmt: MEM <vector(2) long unsigned int> [(struct PULSE_Layer * *)&<retval> + 72B] = { 0, 0 };
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: note: ***** The result for vector mode V32QI would be the same
Layer.c:24:2: missed: statement clobbers memory: free (_1);
Layer.c:25:2: missed: statement clobbers memory: free (_2);
Layer.c:26:2: missed: statement clobbers memory: free (_3);
Layer.c:27:1: note: ***** Analysis failed with vector mode V4DI
Layer.c:27:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:7:27: missed: couldn't vectorize loop
Dense.c:7:27: missed: not vectorized: unsupported outerloop form.
Dense.c:10:20: missed: couldn't vectorize loop
Dense.c:11:21: missed: not vectorized: complicated access pattern.
Dense.c:4:13: note: vectorized 0 loops in function.
Dense.c:14:2: missed: statement clobbers memory: _30 (pretmp_91, _50, 0);
Dense.c:7:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:7:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:7:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:7:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:7:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:7:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:7:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:7:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:22:27: missed: couldn't vectorize loop
Dense.c:22:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:26:20: optimized: loop vectorized using 32 byte vectors
Dense.c:26:20: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:26:20: optimized: loop vectorized using 16 byte vectors
Dense.c:26:20: missed: couldn't vectorize loop
Dense.c:28:20: missed: not vectorized: no vectype for stmt: _21 = *_20;
 scalar_type: float
Dense.c:18:13: note: vectorized 1 loops in function.
Dense.c:21:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:22:54: note: ***** Analysis failed with vector mode V4DI
Dense.c:22:54: note: ***** The result for vector mode V32QI would be the same
Dense.c:22:54: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:22:54: note: ***** Analysis failed with vector mode V16QI
Dense.c:22:54: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:22:54: note: ***** Analysis failed with vector mode V8QI
Dense.c:22:54: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:22:54: note: ***** Analysis failed with vector mode V4QI
Dense.c:39:28: missed: couldn't vectorize loop
Dense.c:39:28: missed: not vectorized: unsupported outerloop form.
Dense.c:43:21: optimized: loop vectorized using 32 byte vectors
Dense.c:43:21: optimized:  loop versioned for vectorization because of possible aliasing
Dense.c:43:21: optimized: loop vectorized using 16 byte vectors
Dense.c:35:13: note: vectorized 1 loops in function.
Dense.c:35:13: note: ***** Analysis failed with vector mode V4DI
Dense.c:35:13: note: ***** The result for vector mode V32QI would be the same
Dense.c:35:13: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:35:13: note: ***** Analysis failed with vector mode V16QI
Dense.c:35:13: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:35:13: note: ***** Analysis failed with vector mode V8QI
Dense.c:35:13: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:39:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:143:19: missed: couldn't vectorize loop
Dense.c:143:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:134:19: missed: couldn't vectorize loop
Dense.c:134:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:127:13: note: vectorized 0 loops in function.
Dense.c:151:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:151:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:96:28: missed: couldn't vectorize loop
Dense.c:96:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:99:21: missed: couldn't vectorize loop
Dense.c:99:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:113:28: missed: couldn't vectorize loop
Dense.c:113:28: missed: not vectorized: could not determine main exit from loop with multiple exits.
Dense.c:116:21: missed: couldn't vectorize loop
Dense.c:116:21: missed: not vectorized: number of iterations cannot be computed.
Dense.c:82:19: missed: couldn't vectorize loop
Dense.c:82:19: missed: not vectorized: number of iterations cannot be computed.
Dense.c:76:13: note: vectorized 0 loops in function.
Dense.c:79:2: missed: statement clobbers memory: _1 (_3, _2, 1);
Dense.c:101:17: note: ***** Analysis succeeded with vector mode V4DI
Dense.c:101:17: note: SLPing BB part
Dense.c:118:17: note: Costing subgraph: 
Dense.c:118:17: note: node 0x75fe138 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:118:17: note: op template: _49 = (sizetype) j_137;
Dense.c:118:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:118:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:118:17: note: 	children 0x75fe238
Dense.c:118:17: note: node (external) 0x75fe238 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:118:17: note: 	{ j_137, wi_136 }
Dense.c:118:17: note: Cost model analysis: 
Dense.c:118:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:118:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:118:17: missed: not vectorized: vectorization is not profitable.
Dense.c:101:17: note: Costing subgraph: 
Dense.c:101:17: note: node 0x75fe338 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:101:17: note: op template: _24 = (sizetype) j_134;
Dense.c:101:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:101:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:101:17: note: 	children 0x75fe438
Dense.c:101:17: note: node (external) 0x75fe438 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:101:17: note: 	{ j_134, wi_133 }
Dense.c:101:17: note: Cost model analysis: 
Dense.c:101:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:101:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:101:17: missed: not vectorized: vectorization is not profitable.
Dense.c:101:17: note: ***** The result for vector mode V32QI would be the same
Dense.c:101:17: note: ***** Re-trying analysis with vector mode V16QI
Dense.c:101:17: note: ***** Analysis succeeded with vector mode V16QI
Dense.c:101:17: note: SLPing BB part
Dense.c:118:17: note: Costing subgraph: 
Dense.c:118:17: note: node 0x75fe338 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:118:17: note: op template: _49 = (sizetype) j_137;
Dense.c:118:17: note: 	stmt 0 _49 = (sizetype) j_137;
Dense.c:118:17: note: 	stmt 1 _209 = (sizetype) wi_136;
Dense.c:118:17: note: 	children 0x75fe138
Dense.c:118:17: note: node (external) 0x75fe138 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:118:17: note: 	{ j_137, wi_136 }
Dense.c:118:17: note: Cost model analysis: 
Dense.c:118:17: note: Scalar 2 and vector 3 loop part do not match up, skipping scalar part
Dense.c:118:17: note: Cost model analysis for part in loop 3:
  Vector cost: 36
  Scalar cost: 8
Dense.c:118:17: missed: not vectorized: vectorization is not profitable.
Dense.c:101:17: note: Costing subgraph: 
Dense.c:101:17: note: node 0x75fe4b8 (max_nunits=2, refcnt=1) vector(2) sizetype
Dense.c:101:17: note: op template: _24 = (sizetype) j_134;
Dense.c:101:17: note: 	stmt 0 _24 = (sizetype) j_134;
Dense.c:101:17: note: 	stmt 1 _229 = (sizetype) wi_133;
Dense.c:101:17: note: 	children 0x75fe3b8
Dense.c:101:17: note: node (external) 0x75fe3b8 (max_nunits=1, refcnt=1) vector(2) int
Dense.c:101:17: note: 	{ j_134, wi_133 }
Dense.c:101:17: note: Cost model analysis: 
Dense.c:101:17: note: Scalar 4 and vector 5 loop part do not match up, skipping scalar part
Dense.c:101:17: note: Cost model analysis for part in loop 5:
  Vector cost: 36
  Scalar cost: 8
Dense.c:101:17: missed: not vectorized: vectorization is not profitable.
Dense.c:101:17: note: ***** Re-trying analysis with vector mode V8QI
Dense.c:96:55: note: ***** Analysis failed with vector mode V8QI
Dense.c:96:55: note: ***** Re-trying analysis with vector mode V4QI
Dense.c:96:55: note: ***** Analysis failed with vector mode V4QI
Dense.c:56:27: missed: couldn't vectorize loop
Dense.c:56:27: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
Dense.c:59:20: missed: couldn't vectorize loop
/usr/lib/gcc/x86_64-pc-linux-gnu/14.1.1/include/avxintrin.h:905:10: missed: not vectorized: no vectype for stmt: _41 = MEM[(__m256_u * {ref-all})_6];
 scalar_type: __m256_u
Dense.c:59:20: note: ***** Analysis failed with vector mode VOID
Dense.c:52:13: note: vectorized 0 loops in function.
Dense.c:52:13: missed: splitting region at dont-vectorize loop 3 entry at bb18
Dense.c:61:14: note: ***** Analysis failed with vector mode V4DI
Dense.c:61:14: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:61:14: missed: splitting region at dominance boundary bb8
Dense.c:61:14: note: ***** Analysis failed with vector mode VOID
Dense.c:61:14: missed: splitting region at loop 1 exit at bb16
Dense.c:56:27: note: ***** Analysis failed with vector mode V8SF
Dense.c:56:27: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Dense.c:56:27: missed: splitting region at dominance boundary bb10
Dense.c:56:27: note: ***** Analysis failed with vector mode VOID
Dense.c:72:2: missed: statement clobbers memory: _27 (pretmp_153, _61, 0);
Dense.c:73:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:73:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:158:2: missed: statement clobbers memory: PULSE_Free (_1);
Dense.c:159:2: missed: statement clobbers memory: PULSE_Free (_2);
Dense.c:160:2: missed: statement clobbers memory: PULSE_Free (_3);
Dense.c:161:2: missed: statement clobbers memory: PULSE_Free (_4);
Dense.c:162:2: missed: statement clobbers memory: PULSE_Free (dense_7);
Dense.c:163:2: missed: statement clobbers memory: PULSE_DestroyLayer (this_6(D));
Dense.c:164:1: note: ***** Analysis failed with vector mode V4DI
Dense.c:164:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Dense.c:178:19: missed: couldn't vectorize loop
Dense.c:178:19: missed: not vectorized: unsupported control flow in loop.
Dense.c:168:13: note: vectorized 0 loops in function.
Dense.c:170:47: missed: statement clobbers memory: dense_30 = malloc (40);
Dense.c:172:36: missed: statement clobbers memory: _1 = PULSE_Alloc2D (64, 4, n_inputs_31(D), n_outputs_32(D), optimization_33(D));
Dense.c:173:38: missed: statement clobbers memory: _2 = PULSE_Alloc2D (64, 4, n_inputs_31(D), n_outputs_32(D), optimization_33(D));
Dense.c:174:36: missed: statement clobbers memory: _3 = PULSE_Alloc (64, 4, n_outputs_32(D), optimization_33(D));
Dense.c:175:35: missed: statement clobbers memory: _4 = PULSE_Alloc (64, 4, n_outputs_32(D), optimization_33(D));
Dense.c:176:36: missed: statement clobbers memory: _5 = PULSE_Alloc (64, 4, n_outputs_32(D), optimization_33(D));
Dense.c:179:39: missed: statement clobbers memory: _6 = rand ();
Dense.c:179:73: missed: statement clobbers memory: _58 = sqrt (_13);
Dense.c:191:4: missed: statement clobbers memory: printf ("ERROR: PULSE Layer GPU are not supported on this device");
Dense.c:192:4: missed: statement clobbers memory: exit (1);
Dense.c:188:4: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.3_24, n_outputs.2_23, 1, activation_function_46(D), _SIMD_FeedDense, _SIMD_BackDense, _SIMD_FixDense, _DestroyDense, 1); [return slot optimization]
Dense.c:185:12: missed: statement clobbers memory: layer = PULSE_CreateLayer (n_inputs.1_22, n_outputs.0_21, 1, activation_function_46(D), _FeedDense, _BackDense, _FixDense, _DestroyDense, 0); [return slot optimization]
Dense.c:198:9: missed: not vectorized: more than one data ref in stmt: <retval> = layer;
Dense.c:198:9: note: ***** Analysis failed with vector mode V4DI
Dense.c:198:9: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Activations.c:17:19: optimized: loop vectorized using 32 byte vectors
Activations.c:17:19: optimized: loop vectorized using 16 byte vectors
Activations.c:17:19: optimized: loop vectorized using 32 byte vectors
Activations.c:17:19: optimized: loop vectorized using 16 byte vectors
Activations.c:14:13: note: vectorized 2 loops in function.
Activations.c:14:13: note: ***** Analysis failed with vector mode V8SF
Activations.c:14:13: note: ***** The result for vector mode V32QI would be the same
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V16QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V16QI
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V8QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V8QI
Activations.c:14:13: note: ***** Re-trying analysis with vector mode V4QI
Activations.c:14:13: note: ***** Analysis failed with vector mode V4QI
Activations.c:28:19: missed: couldn't vectorize loop
Activations.c:28:19: missed: not vectorized: unsupported control flow in loop.
Activations.c:28:19: optimized: loop vectorized using 32 byte vectors
Activations.c:28:19: optimized: loop vectorized using 16 byte vectors
Activations.c:25:13: note: vectorized 1 loops in function.
Activations.c:25:13: note: ***** Analysis failed with vector mode V8SF
Activations.c:25:13: note: ***** The result for vector mode V32QI would be the same
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V16QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V16QI
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V8QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V8QI
Activations.c:25:13: note: ***** Re-trying analysis with vector mode V4QI
Activations.c:25:13: note: ***** Analysis failed with vector mode V4QI
Activations.c:38:1: note: ***** Analysis failed with vector mode VOID
Activations.c:5:19: missed: couldn't vectorize loop
Activations.c:9:21: missed: statement clobbers memory: _36 = expf (_18);
Activations.c:5:19: missed: couldn't vectorize loop
Activations.c:9:21: missed: statement clobbers memory: _12 = expf (_11);
Activations.c:3:13: note: vectorized 0 loops in function.
Activations.c:9:21: missed: statement clobbers memory: _12 = expf (_11);
Activations.c:9:21: missed: statement clobbers memory: _36 = expf (_18);
Activations.c:11:1: note: ***** Analysis failed with vector mode V8SF
Activations.c:11:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Activations.c:44:2: note: ***** Analysis failed with vector mode VOID
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:4:18: note: vectorized 0 loops in function.
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_4, inputs_15, _3);
PULSE.c:8:2: missed: statement clobbers memory: _5 (layer_17);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_12, pretmp_26, _9);
PULSE.c:13:28: note: ***** Analysis failed with vector mode V8SI
PULSE.c:13:28: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SI
PULSE.c:22:2: missed: statement clobbers memory: _1 (layer_10(D));
PULSE.c:22:2: missed: statement clobbers memory: _14 (_2);
PULSE.c:22:2: missed: statement clobbers memory: _21 (_15);
PULSE.c:22:2: missed: statement clobbers memory: _28 (_22);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_29);
PULSE.c:26:3: missed: statement clobbers memory: memset (_34, 0, _32);
PULSE.c:26:3: missed: statement clobbers memory: memset (_27, 0, _25);
PULSE.c:26:3: missed: statement clobbers memory: memset (_20, 0, _18);
PULSE.c:26:3: missed: statement clobbers memory: memset (_7, 0, _5);
PULSE.c:28:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:28:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:32:6: note: vectorized 1 loops in function.
PULSE.c:34:8: missed: statement clobbers memory: _1 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_2);
PULSE.c:39:29: missed: statement clobbers memory: _7 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _9 = rand ();
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8SI
PULSE.c:32:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:32:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:32:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:61:16: missed: couldn't vectorize loop
PULSE.c:61:16: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:64:17: missed: couldn't vectorize loop
PULSE.c:64:17: missed: not vectorized: loop nest containing two or more consecutive inner loops cannot be vectorized
PULSE.c:73:19: missed: couldn't vectorize loop
PULSE.c:73:19: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:10:4: missed: couldn't vectorize loop
PULSE.c:10:4: missed: not vectorized: unsupported control flow in loop.
PULSE.c:37:20: missed: couldn't vectorize loop
PULSE.c:39:29: missed: statement clobbers memory: _64 = rand ();
PULSE.c:35:20: optimized: loop vectorized using 32 byte vectors
PULSE.c:35:20: optimized: loop vectorized using 16 byte vectors
PULSE.c:53:22: missed: couldn't vectorize loop
PULSE.c:53:22: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:47:6: note: vectorized 1 loops in function.
PULSE.c:48:1: missed: statement clobbers memory: saved_stack.7_35 = __builtin_stack_save ();
PULSE.c:49:46: missed: statement clobbers memory: _1 = PULSE_GetLossFunctionPtr (loss_function_36(D));
PULSE.c:60:10: missed: statement clobbers memory: random.4_42 = __builtin_alloca_with_align (_4, 32);
PULSE.c:34:8: missed: statement clobbers memory: _56 = time (0B);
PULSE.c:34:2: missed: statement clobbers memory: srand (_57);
PULSE.c:39:29: missed: statement clobbers memory: _64 = rand ();
PULSE.c:40:30: missed: statement clobbers memory: _67 = rand ();
PULSE.c:7:3: missed: statement clobbers memory: memcpy (_93, inputs_88, _92);
PULSE.c:8:2: missed: statement clobbers memory: _94 (layer_89);
PULSE.c:12:3: missed: statement clobbers memory: memcpy (_100, _99, _98);
PULSE.c:67:11: missed: statement clobbers memory: loss_51 = PULSE_GetLoss_38 (_17, _16, _12, _11);
PULSE.c:22:2: missed: statement clobbers memory: _81 (output_30);
PULSE.c:22:2: missed: statement clobbers memory: _103 (_82);
PULSE.c:22:2: missed: statement clobbers memory: _110 (_104);
PULSE.c:22:2: missed: statement clobbers memory: _117 (_111);
PULSE.c:22:2: missed: statement clobbers memory: _124 (_118);
PULSE.c:22:2: missed: statement clobbers memory: _131 (_125);
PULSE.c:25:3: missed: statement clobbers memory: PULSE_Back (_132);
PULSE.c:26:3: missed: statement clobbers memory: memset (_137, 0, _135);
PULSE.c:26:3: missed: statement clobbers memory: memset (_130, 0, _128);
PULSE.c:26:3: missed: statement clobbers memory: memset (_123, 0, _121);
PULSE.c:26:3: missed: statement clobbers memory: memset (_116, 0, _114);
PULSE.c:26:3: missed: statement clobbers memory: memset (_109, 0, _107);
PULSE.c:26:3: missed: statement clobbers memory: memset (_87, 0, _85);
PULSE.c:75:6: missed: statement clobbers memory: _21 (current_183, args);
PULSE.c:80:4: missed: statement clobbers memory: printf ("Epoch: %d Item: %d Loss: %.10f\r", i_181, j_182, _22);
PULSE.c:47:6: missed: statement clobbers memory: __builtin_stack_restore (saved_stack.7_35);
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4DI
PULSE.c:47:6: note: ***** The result for vector mode V32QI would be the same
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V16QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V16QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V8QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V8QI
PULSE.c:47:6: note: ***** Re-trying analysis with vector mode V4QI
PULSE.c:47:6: note: ***** Analysis failed with vector mode V4QI
PULSE.c:89:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:89:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
PULSE.c:94:8: missed: couldn't vectorize loop
PULSE.c:94:8: missed: not vectorized: number of iterations cannot be computed.
PULSE.c:91:6: note: vectorized 0 loops in function.
PULSE.c:96:3: missed: statement clobbers memory: _1 (current_10);
PULSE.c:99:1: note: ***** Analysis failed with vector mode V4DI
PULSE.c:99:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
Loss.c:15:19: optimized: loop vectorized using 32 byte vectors
Loss.c:15:19: optimized:  loop versioned for vectorization because of possible aliasing
Loss.c:15:19: optimized: loop vectorized using 16 byte vectors
Loss.c:12:23: note: vectorized 1 loops in function.
Loss.c:12:23: note: ***** Analysis failed with vector mode V8SF
Loss.c:12:23: note: ***** The result for vector mode V32QI would be the same
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V16QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V16QI
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V8QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V8QI
Loss.c:12:23: note: ***** Re-trying analysis with vector mode V4QI
Loss.c:12:23: note: ***** Analysis failed with vector mode V4QI
Loss.c:7:19: missed: couldn't vectorize loop
Loss.c:8:38: missed: not vectorized: unsupported use in stmt.
Loss.c:4:23: note: vectorized 0 loops in function.
Loss.c:9:13: note: ***** Analysis failed with vector mode V8SF
Loss.c:9:13: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V8SF
Loss.c:23:2: note: ***** Analysis failed with vector mode VOID
PulseAlloc.c:11:11: missed: statement clobbers memory: _18 = aligned_alloc (64, _8);
PulseAlloc.c:8:11: missed: statement clobbers memory: _20 = aligned_alloc (64, _2);
PulseAlloc.c:16:2: missed: statement clobbers memory: exit (1);
PulseAlloc.c:16:2: note: ***** Analysis failed with vector mode VOID
PulseAlloc.c:30:11: missed: statement clobbers memory: _21 = aligned_alloc (64, _10);
PulseAlloc.c:26:11: missed: statement clobbers memory: _23 = aligned_alloc (64, _3);
PulseAlloc.c:35:2: missed: statement clobbers memory: exit (1);
PulseAlloc.c:35:2: note: ***** Analysis failed with vector mode VOID
PulseAlloc.c:39:30: missed: statement clobbers memory: free (ptr_2(D));
PulseAlloc.c:39:40: note: ***** Analysis failed with vector mode VOID
Layer.c:7:34: missed: statement clobbers memory: _2 = PULSE_Alloc (64, 4, n_inputs.0_1, optimization_11(D));
Layer.c:8:35: missed: statement clobbers memory: _4 = PULSE_Alloc (64, 4, n_outputs.1_3, optimization_11(D));
Layer.c:9:34: missed: statement clobbers memory: _5 = PULSE_Alloc (64, 4, n_outputs.1_3, optimization_11(D));
Layer.c:14:19: missed: statement clobbers memory: _6 = PULSE_GetActivationFunctionPtr (activation_function_16(D));
Layer.c:19:9: note: ***** Analysis succeeded with vector mode V8SI
Layer.c:19:9: note: SLPing BB part
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x74af518 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_15(D);
Layer.c:19:9: note: 	stmt 0 MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_15(D);
Layer.c:19:9: note: 	stmt 1 MEM <unsigned int> [(struct PULSE_Layer *)&<retval> + 4B] = optimization_11(D);
Layer.c:19:9: note: 	children 0x74af598
Layer.c:19:9: note: node (external) 0x74af598 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ type_15(D), optimization_11(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x74af618 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: <retval>.n_inputs = n_inputs_9(D);
Layer.c:19:9: note: 	stmt 0 <retval>.n_inputs = n_inputs_9(D);
Layer.c:19:9: note: 	stmt 1 <retval>.n_outputs = n_outputs_10(D);
Layer.c:19:9: note: 	children 0x74af698
Layer.c:19:9: note: node (external) 0x74af698 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_9(D), n_outputs_10(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x74af798 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.inputs = _2;
Layer.c:19:9: note: 	stmt 0 <retval>.inputs = _2;
Layer.c:19:9: note: 	stmt 1 <retval>.outputs = _4;
Layer.c:19:9: note: 	children 0x74af818
Layer.c:19:9: note: node (external) 0x74af818 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	stmt 0 _2 = PULSE_Alloc (64, 4, n_inputs.0_1, optimization_11(D));
Layer.c:19:9: note: 	stmt 1 _4 = PULSE_Alloc (64, 4, n_outputs.1_3, optimization_11(D));
Layer.c:19:9: note: 	children 0x74af898 0x74af918 0x74af998 0x74afa98
Layer.c:19:9: note: node (constant) 0x74af898 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 64, 64 }
Layer.c:19:9: note: node (constant) 0x74af918 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 4, 4 }
Layer.c:19:9: note: node 0x74af998 (max_nunits=2, refcnt=1) vector(2) int
Layer.c:19:9: note: op template: n_inputs.0_1 = (int) n_inputs_9(D);
Layer.c:19:9: note: 	stmt 0 n_inputs.0_1 = (int) n_inputs_9(D);
Layer.c:19:9: note: 	stmt 1 n_outputs.1_3 = (int) n_outputs_10(D);
Layer.c:19:9: note: 	children 0x74afa18
Layer.c:19:9: note: node (external) 0x74afa18 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_9(D), n_outputs_10(D) }
Layer.c:19:9: note: node (external) 0x74afa98 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ optimization_11(D), optimization_11(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x74afb98 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: op template: <retval>.feed = feed_18(D);
Layer.c:19:9: note: 	stmt 0 <retval>.feed = feed_18(D);
Layer.c:19:9: note: 	stmt 1 <retval>.back = back_19(D);
Layer.c:19:9: note: 	stmt 2 <retval>.fix = fix_20(D);
Layer.c:19:9: note: 	stmt 3 <retval>.destroy = destroy_21(D);
Layer.c:19:9: note: 	children 0x74afc18
Layer.c:19:9: note: node (external) 0x74afc18 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: 	{ feed_18(D), back_19(D), fix_20(D), destroy_21(D) }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 64
  Scalar cost: 64
Layer.c:19:9: note: Costing subgraph: 
Layer.c:19:9: note: node 0x74afd18 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 0 <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 1 <retval>.child = 0B;
Layer.c:19:9: note: 	children 0x74afd98
Layer.c:19:9: note: node (constant) 0x74afd98 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ 0B, 0B }
Layer.c:19:9: note: Cost model analysis: 
Layer.c:19:9: note: Cost model analysis for part in loop 0:
  Vector cost: 32
  Scalar cost: 32
Layer.c:19:9: note: Basic block will be vectorized using SLP
Layer.c:19:9: optimized: basic block part vectorized using 8 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x74af518 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_15(D);
Layer.c:19:9: note: 	stmt 0 MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_15(D);
Layer.c:19:9: note: 	stmt 1 MEM <unsigned int> [(struct PULSE_Layer *)&<retval> + 4B] = optimization_11(D);
Layer.c:19:9: note: 	children 0x74af598
Layer.c:19:9: note: node (external) 0x74af598 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ type_15(D), optimization_11(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>] = type_15(D);
Layer.c:19:9: note: vect_is_simple_use: operand optimization_11(D), type of def: external
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: MEM <unsigned int> [(struct PULSE_Layer *)&<retval>]
Layer.c:19:9: note: created &MEM <unsigned int> [(struct PULSE_Layer *)&<retval>]
Layer.c:19:9: note: add new stmt: MEM <vector(2) unsigned int> [(struct PULSE_Layer *)&<retval>] = _38;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 8 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x74af618 (max_nunits=2, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: op template: <retval>.n_inputs = n_inputs_9(D);
Layer.c:19:9: note: 	stmt 0 <retval>.n_inputs = n_inputs_9(D);
Layer.c:19:9: note: 	stmt 1 <retval>.n_outputs = n_outputs_10(D);
Layer.c:19:9: note: 	children 0x74af698
Layer.c:19:9: note: node (external) 0x74af698 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_9(D), n_outputs_10(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.n_inputs = n_inputs_9(D);
Layer.c:19:9: note: vect_is_simple_use: operand n_outputs_10(D), type of def: external
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) unsigned int  vectorizing a pointer ref: <retval>.n_inputs
Layer.c:19:9: note: created &<retval>.n_inputs
Layer.c:19:9: note: add new stmt: MEM <vector(2) unsigned int> [(unsigned int *)&<retval> + 96B] = _40;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 16 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x74af798 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.inputs = _2;
Layer.c:19:9: note: 	stmt 0 <retval>.inputs = _2;
Layer.c:19:9: note: 	stmt 1 <retval>.outputs = _4;
Layer.c:19:9: note: 	children 0x74af818
Layer.c:19:9: note: node (external) 0x74af818 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	stmt 0 _2 = PULSE_Alloc (64, 4, n_inputs.0_1, optimization_11(D));
Layer.c:19:9: note: 	stmt 1 _4 = PULSE_Alloc (64, 4, n_outputs.1_3, optimization_11(D));
Layer.c:19:9: note: 	children 0x74af898 0x74af918 0x74af998 0x74afa98
Layer.c:19:9: note: node (constant) 0x74af898 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 64, 64 }
Layer.c:19:9: note: node (constant) 0x74af918 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ 4, 4 }
Layer.c:19:9: note: node 0x74af998 (max_nunits=2, refcnt=1) vector(2) int
Layer.c:19:9: note: op template: n_inputs.0_1 = (int) n_inputs_9(D);
Layer.c:19:9: note: 	stmt 0 n_inputs.0_1 = (int) n_inputs_9(D);
Layer.c:19:9: note: 	stmt 1 n_outputs.1_3 = (int) n_outputs_10(D);
Layer.c:19:9: note: 	children 0x74afa18
Layer.c:19:9: note: node (external) 0x74afa18 (max_nunits=1, refcnt=1) vector(2) unsigned int
Layer.c:19:9: note: 	{ n_inputs_9(D), n_outputs_10(D) }
Layer.c:19:9: note: node (external) 0x74afa98 (max_nunits=1, refcnt=1)
Layer.c:19:9: note: 	{ optimization_11(D), optimization_11(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.inputs = _2;
Layer.c:19:9: note: vect_is_simple_use: operand PULSE_Alloc (64, 4, n_outputs.1_3, optimization_11(D)), type of def: internal
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.inputs
Layer.c:19:9: note: created &<retval>.inputs
Layer.c:19:9: note: add new stmt: MEM <vector(2) long unsigned int> [(float * *)&<retval> + 8B] = _44;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 32 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x74afb98 (max_nunits=4, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: op template: <retval>.feed = feed_18(D);
Layer.c:19:9: note: 	stmt 0 <retval>.feed = feed_18(D);
Layer.c:19:9: note: 	stmt 1 <retval>.back = back_19(D);
Layer.c:19:9: note: 	stmt 2 <retval>.fix = fix_20(D);
Layer.c:19:9: note: 	stmt 3 <retval>.destroy = destroy_21(D);
Layer.c:19:9: note: 	children 0x74afc18
Layer.c:19:9: note: node (external) 0x74afc18 (max_nunits=1, refcnt=1) vector(4) long unsigned int
Layer.c:19:9: note: 	{ feed_18(D), back_19(D), fix_20(D), destroy_21(D) }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.feed = feed_18(D);
Layer.c:19:9: note: vect_is_simple_use: operand back_19(D), type of def: external
Layer.c:19:9: note: vect_is_simple_use: operand fix_20(D), type of def: external
Layer.c:19:9: note: vect_is_simple_use: operand destroy_21(D), type of def: external
Layer.c:19:9: note: conflicting alias set types.
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(4) long unsigned int  vectorizing a pointer ref: <retval>.feed
Layer.c:19:9: note: created &<retval>.feed
Layer.c:19:9: note: add new stmt: MEM <vector(4) long unsigned int> [(void *)&<retval> + 32B] = _50;
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: optimized: basic block part vectorized using 16 byte vectors
Layer.c:19:9: note: Vectorizing SLP tree:
Layer.c:19:9: note: node 0x74afd18 (max_nunits=2, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: op template: <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 0 <retval>.parent = 0B;
Layer.c:19:9: note: 	stmt 1 <retval>.child = 0B;
Layer.c:19:9: note: 	children 0x74afd98
Layer.c:19:9: note: node (constant) 0x74afd98 (max_nunits=1, refcnt=1) vector(2) long unsigned int
Layer.c:19:9: note: 	{ 0B, 0B }
Layer.c:19:9: note: ------>vectorizing SLP node starting from: <retval>.parent = 0B;
Layer.c:19:9: note: vect_is_simple_use: operand 0B, type of def: constant
Layer.c:19:9: note: transform store. ncopies = 1
Layer.c:19:9: note: create vector_type-pointer variable to type: vector(2) long unsigned int  vectorizing a pointer ref: <retval>.parent
Layer.c:19:9: note: created &<retval>.parent
Layer.c:19:9: note: add new stmt: MEM <vector(2) long unsigned int> [(struct PULSE_Layer * *)&<retval> + 72B] = { 0, 0 };
Layer.c:19:9: note: vectorizing stmts using SLP.
Layer.c:19:9: note: ***** The result for vector mode V32QI would be the same
Layer.c:24:2: missed: statement clobbers memory: PULSE_Free (_1);
Layer.c:25:2: missed: statement clobbers memory: PULSE_Free (_2);
Layer.c:26:2: missed: statement clobbers memory: PULSE_Free (_3);
Layer.c:27:1: note: ***** Analysis failed with vector mode V4DI
Layer.c:27:1: note: ***** Skipping vector mode V32QI, which would repeat the analysis for V4DI
